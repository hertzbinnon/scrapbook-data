<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=UTF-8" http-equiv="Content-Type">

<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">

<title>Browser APIs and Protocols: WebRTC - High Performance Browser Networking
(O'Reilly)</title>
<meta name="description" content="What every web developer must know about mobile networks, protocols, and APIs provided by browser to deliver the best user experience.">



<link rel="preconnect" href="https://fonts.gstatic.com/" crossorigin="anonymous">


<link rel="manifest" href="https://hpbn.co/7a58c37113db4464699ec4f4646b5566.json">
<link rel="icon" sizes="192x192" href="icon-192.png">
<meta name="theme-color" content="#000">
<meta itemprop="name" content="Browser APIs and Protocols: WebRTC - High Performance Browser Networking (O'Reilly)">
<meta itemprop="description" content="What every web developer must know about mobile networks, protocols, and APIs provided by browser to deliver the best user experience.">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:title" content="Browser APIs and Protocols: WebRTC - High Performance Browser Networking (O'Reilly)">
<meta name="twitter:description" content="What every web developer must know about mobile networks, protocols, and APIs provided by browser to deliver the best user experience.">
<meta name="twitter:creator" content="@igrigorik">
<meta name="twitter:image:src" content="https://hpbn.co/assets/twitter.jpg">
<meta property="og:title" content="Browser APIs and Protocols: WebRTC - High Performance Browser Networking (O'Reilly)">
<meta property="og:description" content="What every web developer must know about mobile networks, protocols, and APIs provided by browser to deliver the best user experience.">
<meta property="og:site_name" content="High Performance Browser Networking">
<meta property="fb:admins" content="688996186">



<link media="all" href="index.css" type="text/css" rel="stylesheet">
</head>
<body data-type="book">
  <header>
    <div id="book-title" class="">
      <div class="center">
        <input class="check" id="check" type="checkbox"> <label for="check" class="icon"><svg viewBox="0 0 18 18">
        <title>Menu</title>

        <path fill="white" d="M3 18h18v-2H3v2zm0-5h18v-2H3v2zm0-7v2h18V6H3z">
        </path></svg></label> <a href="https://hpbn.co/">High Performance Browser
        Networking</a> <span>&nbsp;|&nbsp; O'Reilly</span>

        <div class="drawer menu">
          <div class="title">
            WebRTC
          </div>

          <hr>

          <ul class="content-container" id="nav"><li class="h2"><a href="#" class="">Introduction</a></li><li class="h2"><a href="#standard-under-construction">Standard under
        construction</a></li><li class="h2"><a href="#standards-and-development-of-webrtc" class="active">Standards and
      Development of WebRTC</a></li><li class="h2"><a href="#audio-and-video-engines" class="active">Audio and Video Engines</a></li><li class="h3"><a href="#acquiring-audio-and-video-with-getusermedia" class="active">Acquiring Audio and Video with getUserMedia</a></li><li class="h2"><a href="#real-time-network-transports" class="active">Real-Time Network
      Transports</a></li><li class="h3"><a href="#brief-introduction-to-rtcpeerconnection-api" class="active">Brief Introduction to RTCPeerConnection API</a></li><li class="h2"><a href="#establishing-a-peer-to-peer-connection" class="">Establishing a Peer-to-Peer Connection</a></li><li class="h3"><a href="#signaling-and-session-negotiation" class="active">Signaling and
        Session Negotiation</a></li><li class="h3"><a href="#session-description-protocol-sdp" class="active">Session
        Description Protocol (SDP)</a></li><li class="h3"><a href="#interactive-connectivity-establishment-ice" class="active">Interactive Connectivity Establishment (ICE)</a></li><li class="h3"><a href="#incremental-provisioning-trickle-ice" class="active">Incremental
        Provisioning (Trickle ICE)</a></li><li class="h3"><a href="#tracking-ice-gathering-and-connectivity-status" class="active">Tracking ICE Gathering and Connectivity Status</a></li><li class="h3"><a href="#putting-it-all-together" class="">Putting It All Together</a></li><li class="h3"><a href="#">Initiating a WebRTC connection</a></li><li class="h3"><a href="#">Responding to a WebRTC connection</a></li><li class="h2"><a href="#delivering-media-and-application-data" class="">Delivering
      Media and Application Data</a></li><li class="h3"><a href="#secure-communication-with-dtls" class="active">Secure
        Communication with DTLS</a></li><li class="h3"><a href="#delivering-media-with-srtp-and-srtcp" class="active">Delivering
        Media with SRTP and SRTCP</a></li><li class="h3"><a href="#delivering-application-data-with-sctp" class="active">Delivering
        application data with SCTP</a></li><li class="h2"><a href="#datachannel" class="active">DataChannel</a></li><li class="h3"><a href="#setup-and-negotiation" class="active">Setup and Negotiation</a></li><li class="h3"><a href="#configuring-message-order-and-reliability" class="active">Configuring Message Order and Reliability</a></li><li class="h3"><a href="#partially-reliable-delivery-and-message-size" class="active">Partially Reliable Delivery and Message Size</a></li><li class="h2"><a href="#webrtc-use-cases-and-performance" class="active">WebRTC Use Cases
      and Performance</a></li><li class="h3"><a href="#audio-video-and-data-streaming" class="active">Audio, Video, and
        Data Streaming</a></li><li class="h3"><a href="#multiparty-architectures" class="active">Multiparty Architectures</a></li><li class="h3"><a href="#infrastructure-and-capacity-planning" class="active">Infrastructure and Capacity Planning</a></li><li class="h3"><a href="#data-efficiency-and-compression" class="active">Data Efficiency
        and Compression</a></li><li class="h2"><a href="#performance-checklist" class="active">Performance Checklist</a></li>
          </ul>

          <hr>

          <ul class="content-container" id="nav-other">
            <li>
              <a href="https://hpbn.co/#toc">Table of Contents</a>

            </li><li>
              <a href="https://hpbn.co/#author">About the Author</a>

            </li><li>
              <a id="feedback" target="_top" href="https://github.com/igrigorik/hpbn.co/issues/new?title=%5BWebRTC%5D:%20...">
              Submit Feedback</a>
          </li></ul>
        </div>
        <label for="check" class="closemenu">&nbsp;</label>
      </div>
    </div>

    <h1>WebRTC</h1>

    <p id="chapter">Browser APIs and Protocols, Chapter 18
  </p></header>

  <article data-type="chapter" id="WEBRTC">
    <section id="introduction">
      <h2>Introduction</h2>

      <p>Web Real-Time Communication (WebRTC) is a collection of standards,
      protocols, and JavaScript APIs, the combination of which enables
      peer-to-peer audio, video, and data sharing between browsers (peers).
      Instead of relying on third-party plug-ins or proprietary software,
      WebRTC turns real-time communication into a standard feature that any web
      application can leverage via a simple JavaScript API.

      </p><p>Delivering rich, high-quality, RTC applications such as audio and
      video teleconferencing and peer-to-peer data exchange requires a lot of
      new functionality in the browser: audio and video processing
      capabilities, new application APIs, and support for half a dozen new
      network protocols. Thankfully, the browser abstracts most of this
      complexity behind three primary APIs:

      </p><ul>
        <li>
          <p><code>MediaStream</code>: acquisition of audio and video streams

        </p></li><li>
          <p><code>RTCPeerConnection</code>: communication of audio and video
          data

        </p></li><li>
          <p><code>RTCDataChannel</code>: communication of arbitrary
          application data
      </p></li></ul>

      <p>All it takes is a dozen lines of JavaScript code, and any web
      application can enable a rich teleconferencing experience with
      peer-to-peer data transfers. That’s the promise and the power of WebRTC!
      However, the listed APIs are also just the tip of the iceberg: signaling,
      peer discovery, connection negotiation, security, and entire layers of
      new protocols are just a few components required to bring it all
      together.

      </p><p>Not surprisingly, the architecture and the protocols powering WebRTC
      also determine its performance characteristics: connection setup latency,
      protocol overhead, and delivery semantics, to name a few. In fact, unlike
      all other browser communication, WebRTC transports its data over UDP.
      However, UDP is also just a starting point. It takes a lot more than raw
      UDP to make real-time communication in the browser a reality. Let’s take
      a closer look.

      </p><div>
        <h2 id="standard-under-construction"><a href="#standard-under-construction" class="anchor">§</a>Standard under
        construction</h2>

        <p>WebRTC is already enabled for 1B+ users: the latest Chrome and
        Firefox browsers provide WebRTC support to all of their users! Having
        said that, WebRTC is also under active construction, both at the
        browser API level and at the transport and protocol levels. As a
        result, the specific APIs and protocols discussed in the following
        chapters may still change in the future.
      </p></div>
    </section>

    <section>
      <h2 id="standards-and-development-of-webrtc"><a href="#standards-and-development-of-webrtc" class="anchor">§</a>Standards and
      Development of WebRTC</h2>

      <p>Enabling real-time communication in the browser is an ambitious
      undertaking, and arguably, one of the most significant additions to the
      web platform since its very beginning. WebRTC breaks away from the
      familiar client-to-server communication model, which results in a full
      re-engineering of the networking layer in the browser, and also brings a
      whole new media stack, which is required to enable efficient, real-time
      processing of audio and video.

      </p><p>As a result, the WebRTC architecture consists of over a dozen
      different standards, covering both the application and browser APIs, as
      well as many different protocols and data formats required to make it
      work:

      </p><ul>
        <li>
          <p>Web Real-Time Communications (WEBRTC) W3C Working Group is
          responsible for defining the browser APIs.

        </p></li><li>
          <p>Real-Time Communication in Web-browsers (RTCWEB) is the IETF
          Working Group responsible for defining the protocols, data formats,
          security, and all other necessary aspects to enable peer-to-peer
          communication in the browser.
      </p></li></ul>

      <p>WebRTC is not a blank-slate standard. While its primary purpose is to
      enable real-time communication between browsers, it is also designed such
      that it can be integrated with existing communication systems: voice over
      IP (VOIP), various SIP clients, and even the public switched telephone
      network (PSTN), just to name a few. The WebRTC standards do not define
      any specific interoperability requirements, or APIs, but they do try to
      reuse the same concepts and protocols where possible.

      </p><p>In other words, WebRTC is not only about bringing real-time
      communication to the browser, but also about bringing all the
      capabilities of the Web to the telecommunications world—a $4.7 trillion
      industry in 2012! Not surprisingly, this is a significant development and
      one that many existing telecom vendors, businesses, and startups are
      following closely. WebRTC is much more than just another browser API.
    </p></section>

    <section>
      <h2 id="audio-and-video-engines"><a href="#audio-and-video-engines" class="anchor">§</a>Audio and Video Engines</h2>

      <p>Enabling a rich teleconferencing experience in the browser requires
      that the browser be able to access the system hardware to capture both
      audio and video—no third-party plug-ins or custom drivers, just a simple
      and a consistent API. However, raw audio and video streams are also not
      sufficient on their own: each stream must be processed to enhance
      quality, synchronized, and the output bitrate must adjust to the
      continuously fluctuating bandwidth and latency between the clients.

      </p><p>On the receiving end, the process is reversed, and the client must
      decode the streams in real-time and be able to adjust to network jitter
      and latency delays. In short, capturing and processing audio and video is
      a complex problem. However, the good news is that WebRTC brings fully
      featured audio and video engines to the browser (<a data-type="xref" href="#webrtc-audio-video">Figure&nbsp;18-1</a>), which take care of all
      the signal processing, and more, on our behalf.

      </p><figure id="webrtc-audio-video">
        <img src="b8cf759a74914c66cec01d50b18de6e0.svg" alt="Figure 18-1. WebRTC audio and video engines">

        <figcaption>
          <span class="label">Figure 18-1.</span> WebRTC audio and video
          engines
        </figcaption>
      </figure>

      <div data-type="note" id="id-j0CgH6TG">
        <p>The full implementation and technical details of the audio and video
        engines is easily a topic for a dedicated book, and is outside the
        scope of our discussion. To learn more, head to <em><a class="orm:hideurl" href="http://www.webrtc.org/">http://www.webrtc.org</a></em>.
      </p></div>

      <p>The acquired audio stream is processed for noise reduction and echo
      cancellation, then automatically encoded with one of the optimized
      narrowband or wideband audio codecs. Finally, a special error-concealment
      algorithm is used to hide the negative effects of network jitter and
      packet loss—that’s just the highlights! The video engine performs similar
      processing by optimizing image quality, picking the optimal compression
      and codec settings, applying jitter and packet-loss concealment, and
      more.

      </p><p>All of the processing is done directly by the browser, and even more
      importantly, the browser dynamically adjusts its processing pipeline to
      account for the continuously changing parameters of the audio and video
      streams and networking conditions. Once all of this work is done, the web
      application receives the optimized media stream, which it can then output
      to the local screen and speakers, forward to its peers, or post-process
      using one of the HTML5 media APIs!

      </p><section>
        <h3 id="acquiring-audio-and-video-with-getusermedia"><a href="#acquiring-audio-and-video-with-getusermedia" class="anchor">§</a>Acquiring Audio and Video with getUserMedia</h3>

        <p>The Media Capture and Streams W3C specification defines a set of new
        JavaScript APIs that enable the application to request audio and video
        streams from the platform, as well as a set of APIs to manipulate and
        process the acquired media streams. The <code>MediaStream</code> object
        (<a data-type="xref" href="#mediastream">Figure&nbsp;18-2</a>) is the
        primary interface that enables all of this functionality.

        </p><figure id="mediastream">
          <img src="1a86ca9ae4a3c0e208ddf2f7fdc38b95.svg" alt="Figure 18-2. MediaStream carries one or more synchronized tracks">

          <figcaption>
            <span class="label">Figure 18-2.</span> MediaStream carries one or
            more synchronized tracks
          </figcaption>
        </figure>

        <ul>
          <li>
            <p>The MediaStream object consists of one or more individual tracks
            (MediaStreamTrack).

          </p></li><li>
            <p>Tracks within a MediaStream object are synchronized with one
            another.

          </p></li><li>
            <p>The input source can be a physical device, such as a microphone,
            webcam or a local or remote file from the user’s hard drive or a
            remote network peer.

          </p></li><li>
            <p>The output of a MediaStream can be sent to one or more
            destinations: a local video or audio element, JavaScript code for
            post-processing, or a remote peer.
        </p></li></ul>

        <p>A MediaStream object represents a real-time media stream and allows
        the application code to acquire data, manipulate individual tracks, and
        specify outputs. All the audio and video processing, such as noise
        cancellation, equalization, image enhancement, and more are
        automatically handled by the audio and video engines.

        </p><p>However, the features of the acquired media stream are constrained
        by the capabilities of the input source: a microphone can emit only an
        audio stream, and some webcams can produce higher-resolution video
        streams than others. As a result, when requesting media streams in the
        browser, the <code>getUserMedia()</code> API allows us to specify a
        list of mandatory and optional constraints to match the needs of the
        application:

        </p><div data-type="example" id="-67CgIjtjT4">
          <pre data-type="programlisting">&lt;video autoplay&gt;&lt;/video&gt; <a class="counter" id="msoutput-co" href="#msoutput"></a>

&lt;script&gt;
  var constraints = {
    audio: true, <a class="counter" id="msaudio-co" href="#msaudio"></a>
    video: { <a class="counter" id="msvideo-co" href="#msvideo"></a>
      mandatory: {  <a class="counter" id="msvideom-co" href="#msvideom"></a>
        width: { min: 320 },
        height: { min: 180 }
      },
      optional: [  <a class="counter" id="msvideoo-co" href="#msvideoo"></a>
        { width: { max: 1280 }},
        { frameRate: 30 },
        { facingMode: "user" }
      ]
    }
  }

  navigator.getUserMedia(constraints, gotStream, logError);  <a class="counter" id="gum-co" href="#gum"></a>

  function gotStream(stream) { <a class="counter" id="gumcb-co" href="#gumcb"></a>
    var video = document.querySelector('video');
    video.src = window.URL.createObjectURL(stream);
  }

  function logError(error) { ... }
&lt;/script&gt;
</pre>

          <ol class="notation">
            <li>
              <a class="co" id="msoutput" href="#msoutput-co"></a>

              <p>HTML video output element

            </p></li><li>
              <a class="co" id="msaudio" href="#msaudio-co"></a>

              <p>Request a mandatory audio track

            </p></li><li>
              <a class="co" id="msvideo" href="#msvideo-co"></a>

              <p>Request a mandatory video track

            </p></li><li>
              <a class="co" id="msvideom" href="#msvideom-co"></a>

              <p>List of mandatory constraints for video track

            </p></li><li>
              <a class="co" id="msvideoo" href="#msvideoo-co"></a>

              <p>Array of optional constraints for video track

            </p></li><li>
              <a class="co" id="gum" href="#gum-co"></a>

              <p>Request audio and video streams from the browser

            </p></li><li>
              <a class="co" id="gumcb" href="#gumcb-co"></a>

              <p>Callback function to process acquired MediaStream
          </p></li></ol>
        </div>

        <p>This example illustrates one of the more elaborate scenarios: we are
        requesting audio and video tracks, and we are specifying both the
        minimum resolution and type of camera that must be used, as well as a
        list of optional constraints for 720p HD video! The
        <code>getUserMedia()</code> API is responsible for requesting access to
        the microphone and camera from the user, and acquiring the streams that
        match the specified constraints—that’s the whirlwind tour.

        </p><p>The provided APIs also enable the application to manipulate
        individual tracks, clone them, modify constraints, and more. Further,
        once the stream is acquired, we can feed it into a variety of other
        browser APIs:

        </p><ul>
          <li>
            <p>Web Audio API enables processing of audio in the browser.

          </p></li><li>
            <p>Canvas API enables capture and post-processing of individual
            video frames.

          </p></li><li>
            <p>CSS3 and WebGL APIs can apply a variety of 2D/3D effects on the
            output stream.
        </p></li></ul>

        <p>To make a long story short, <code>getUserMedia()</code> is a simple
        API to acquire audio and video streams from the underlying platform.
        The media is automatically optimized, encoded, and decoded by the
        WebRTC audio and video engines and is then routed to one or more
        outputs. With that, we are halfway to building a real-time
        teleconferencing application—we just need to route the data to a peer!

        </p><div data-type="note" id="id-4lC4UDtnTk">
          <p>For a full list of capabilities of the Media Capture and Streams
          APIs, head to the <a href="http://www.w3.org/TR/mediacapture-streams">official W3C
          standard</a>.
        </p></div>

        <aside>
          <h4 id="audio-opus-and-video-vp8-bitrates"><a href="#audio-opus-and-video-vp8-bitrates" class="anchor">§</a>Audio (OPUS)
          and Video (VP8) Bitrates</h4>

          <p>When requesting audio and video from the browser, pay careful
          attention to the size and quality of the streams. While the hardware
          may be capable of capturing HD quality streams, the CPU and bandwidth
          must be able to keep up! Current WebRTC implementations use Opus and
          VP8 codecs:

          </p><ul>
            <li>
              <p>The Opus codec is used for audio and supports constant and
              variable bitrate encoding and requires 6–510 Kbit/s of bandwidth.
              The good news is that the codec can switch seamlessly and adapt
              to variable bandwidth.

            </p></li><li>
              <p>The VP8 codec used for video encoding also requires 100–2,000+
              Kbit/s of bandwidth, and the bitrate depends on the quality of
              the streams:

              </p><ul>
                <li>
                  <p>720p at 30 FPS: 1.0~2.0 Mbps

                </p></li><li>
                  <p>360p at 30 FPS: 0.5~1.0 Mbps

                </p></li><li>
                  <p>180p at 30 FPS: 0.1~0.5 Mbps
              </p></li></ul>
          </li></ul>

          <p>As a result, a single-party HD call can require up to 2.5+ Mbps of
          network bandwidth. Add a few more peers, and the quality must drop to
          account for the extra bandwidth and CPU, GPU, and memory processing
          requirements.
        </p></aside>
      </section>
    </section>

    <section>
      <h2 id="real-time-network-transports"><a href="#real-time-network-transports" class="anchor">§</a>Real-Time Network
      Transports</h2>

      <p>Real-time communication is time-sensitive; that should come as no
      surprise. As a result, audio and video streaming applications are
      designed to tolerate intermittent packet loss: the audio and video codecs
      can fill in small data gaps, often with minimal impact on the output
      quality. Similarly, applications must implement their own logic to
      recover from lost or delayed packets carrying other types of application
      data. Timeliness and low latency can be more important than reliability.

      </p><div data-type="note" id="id-A3C6FmCe">
        <p>Audio and video streaming in particular have to adapt to the unique
        properties of our brains. Turns out we are very good at filling in the
        gaps but highly sensitive to latency delays. Add some variable delays
        into an audio stream, and "it just won’t feel right," but drop a few
        samples in between, and most of us won’t even notice!
      </p></div>

      <p>The requirement for timeliness over reliability is the primary reason
      why the UDP protocol is a preferred transport for delivery of real-time
      data. TCP delivers a reliable, ordered stream of data: if an intermediate
      packet is lost, then TCP buffers all the packets after it, waits for a
      retransmission, and then delivers the stream in order to the application.
      By comparison, UDP offers the following "non-services":

      </p><dl>
        <dt>No guarantee of message delivery

        </dt><dd>
          <p>No acknowledgments, retransmissions, or timeouts.

        </p></dd><dt>No guarantee of order of delivery

        </dt><dd>
          <p>No packet sequence numbers, no reordering, no head-of-line
          blocking.

        </p></dd><dt>No connection state tracking

        </dt><dd>
          <p>No connection establishment or teardown state machines.

        </p></dd><dt>No congestion control

        </dt><dd>
          <p>No built-in client or network feedback mechanisms.
      </p></dd></dl>

      <div data-type="note" id="id-pPCmuRCL">
        <p>Before we go any further, you may want to revisit <a data-type="xref" href="https://hpbn.co/building-blocks-of-udp/">Building Blocks of UDP</a> and
        in particular the section <a data-type="xref" href="https://hpbn.co/building-blocks-of-udp/#null-protocol-services">Null Protocol
        Services</a>, for a refresher on the inner workings (or lack thereof)
        of UDP.
      </p></div>

      <p>UDP offers no promises on reliability or order of the data, and
      delivers each packet to the application the moment it arrives. In effect,
      it is a thin wrapper around the best-effort delivery model offered by the
      IP layer of our network stacks.

      </p><p>WebRTC uses UDP at the transport layer: latency and timeliness are
      critical. With that, we can just fire off our audio, video, and
      application UDP packets, and we are good to go, right? Well, not quite.
      We also need mechanisms to traverse the many layers of NATs and
      firewalls, negotiate the parameters for each stream, provide encryption
      of user data, implement congestion and flow control, and more!

      </p><p>UDP is the foundation for real-time communication in the browser, but
      to meet all the requirements of WebRTC, the browser also needs a large
      supporting cast (<a data-type="xref" href="#webrtc-stack">Figure&nbsp;18-3</a>) of protocols and services above it.

      </p><figure id="webrtc-stack">
        <img src="f91164cbbb944d8986c90a1e93afcd82.svg" alt="Figure 18-3. WebRTC protocol stack">

        <figcaption>
          <span class="label">Figure 18-3.</span> WebRTC protocol stack
        </figcaption>
      </figure>

      <ul>
        <li>
          <p>ICE: Interactive Connectivity Establishment (RFC 5245)

          </p><ul>
            <li>
              <p>STUN: Session Traversal Utilities for NAT (RFC 5389)

            </p></li><li>
              <p>TURN: Traversal Using Relays around NAT (RFC 5766)
          </p></li></ul>

        </li><li>
          <p>SDP: Session Description Protocol (RFC 4566)

        </p></li><li>
          <p>DTLS: Datagram Transport Layer Security (RFC 6347)

        </p></li><li>
          <p>SCTP: Stream Control Transport Protocol (RFC 4960)

        </p></li><li>
          <p>SRTP: Secure Real-Time Transport Protocol (RFC 3711)
      </p></li></ul>

      <p>ICE, STUN, and TURN are necessary to establish and maintain a
      peer-to-peer connection over UDP. DTLS is used to secure all data
      transfers between peers; encryption is a mandatory feature of WebRTC.
      Finally, SCTP and SRTP are the application protocols used to multiplex
      the different streams, provide congestion and flow control, and provide
      partially reliable delivery and other additional services on top of UDP.

      </p><p>Yes, that is a complicated stack, and not surprisingly, before we can
      talk about the end-to-end performance, we need to understand how each
      works under the hood. It will be a whirlwind tour, but that’s our focus
      for the remainder of the chapter. Let’s dive in.

      </p><div data-type="note" id="id-LWCziNCK">
        <p>We didn’t forget about SDP! As we will see, SDP is a data format
        used to negotiate the parameters of the peer-to-peer connection.
        However, the SDP "offer" and "answer" are communicated out of band,
        which is why SDP is missing from the protocol diagram.
      </p></div>

      <section>
        <h3 id="brief-introduction-to-rtcpeerconnection-api"><a href="#brief-introduction-to-rtcpeerconnection-api" class="anchor">§</a>Brief Introduction to RTCPeerConnection API</h3>

        <p>Despite the many protocols involved in setting up and maintaining a
        peer-to-peer connection, the application API exposed by the browser is
        relatively simple. The <code>RTCPeerConnection</code> interface
        (<a data-type="xref" href="#rtcpeerconnection">Figure&nbsp;18-4</a>) is
        responsible for managing the full life cycle of each peer-to-peer
        connection.

        </p><figure id="rtcpeerconnection">
          <img src="f38aae954de1cde63e2dffddc23a13f3.svg" alt="Figure 18-4. RTCPeerConnection API">

          <figcaption>
            <span class="label">Figure 18-4.</span> RTCPeerConnection API
          </figcaption>
        </figure>

        <ul>
          <li>
            <p>RTCPeerConnection manages the full ICE workflow for NAT
            traversal.

          </p></li><li>
            <p>RTCPeerConnection sends automatic (STUN) keepalives between
            peers.

          </p></li><li>
            <p>RTCPeerConnection keeps track of local streams.

          </p></li><li>
            <p>RTCPeerConnection keeps track of remote streams.

          </p></li><li>
            <p>RTCPeerConnection triggers automatic stream renegotiation as
            required.

          </p></li><li>
            <p>RTCPeerConnection provides necessary APIs to generate the
            connection offer, accept the answer, allows us to query the
            connection for its current state, and more.
        </p></li></ul>

        <p>In short, RTCPeerConnection encapsulates all the connection setup,
        management, and state within a single interface. However, before we
        dive into the details of each configuration option of the
        RTCPeerConnection API, we need to understand signaling and negotiation,
        the offer-answer workflow, and ICE traversal. Let’s take it step by
        step.

        </p><aside>
          <h4 id="datachannel"><a href="#datachannel" class="anchor">§</a>DataChannel</h4>

          <p>DataChannel API enables exchange of arbitrary application data
          between peers—think WebSocket, but peer-to-peer, and with
          customizable delivery properties of the underlying transport. Each
          DataChannel can be configured to provide the following:

          </p><ul>
            <li>
              <p>Reliable or partially reliable delivery of sent messages

            </p></li><li>
              <p>In-order or out-of-order delivery of sent messages
          </p></li></ul>

          <p>Unreliable, out-of-order delivery is equivalent to raw UDP
          semantics. The message may make it, or it may not, and order is not
          important. However, we can also configure the channel to be
          "partially reliable" by specifying the maximum number of
          retransmissions or setting a time limit for retransmissions: the
          WebRTC stack will handle the acknowledgments and timeouts!

          </p><p>Each configuration of the channel has its own performance
          characteristics and limitations, a topic we will cover in depth
          later. Let’s keep going.
        </p></aside>
      </section>
    </section>

    <section>
      <h2 id="establishing-a-peer-to-peer-connection"><a href="#establishing-a-peer-to-peer-connection" class="anchor">§</a>Establishing a Peer-to-Peer Connection</h2>

      <p>Initiating a peer-to-peer connection requires (much) more work than
      opening an XHR, EventSource, or a new WebSocket session: the latter three
      rely on a well-defined HTTP handshake mechanism to negotiate the
      parameters of the connection, and all three implicitly assume that the
      destination server is reachable by the client—i.e., the server has a
      publicly routable IP address or the client and server are located on the
      same internal network.

      </p><p>By contrast, it is likely that the two WebRTC peers are within their
      own, distinct private networks and behind one or more layers of NATs. As
      a result, neither peer is directly reachable by the other. To initiate a
      session, we must first gather the possible IP and port candidates for
      each peer, traverse the NATs, and then run the connectivity checks to
      find the ones that work, and even then, there are no guarantees that we
      will succeed.

      </p><div data-type="note" id="id-aZC1h7cd">
        <p>Refer to <a data-type="xref" href="https://hpbn.co/building-blocks-of-udp/#udp-and-network-address-translators">UDP and
        Network Address Translators</a> and <a data-type="xref" href="https://hpbn.co/building-blocks-of-udp/#nat-traversal">NAT Traversal</a> for an
        in-depth discussion of the challenges posed by NATs for UDP and
        peer-to-peer communication in particular.
      </p></div>

      <p>However, while NAT traversal is an issue we must deal with, we may
      have gotten ahead of ourselves already. When we open an HTTP connection
      to a server, there is an implicit assumption that the server is listening
      for our handshake; it may wish to decline it, but it is nonetheless
      always listening for new connections. Unfortunately, the same can’t be
      said about a remote peer: the peer may be offline or unreachable, busy,
      or simply not interested in initiating a connection with the other party.

      </p><p>As a result, in order to establish a successful peer-to-peer
      connection, we must first solve several additional problems:

      </p><ol>
        <li>
          <p>We must notify the other peer of the intent to open a peer-to-peer
          connection, such that it knows to start listening for incoming
          packets.

        </p></li><li>
          <p>We must identify potential routing paths for the peer-to-peer
          connection on both sides of the connection and relay this information
          between peers.

        </p></li><li>
          <p>We must exchange the necessary information about the parameters of
          the different media and data streams—protocols, encodings used, and
          so on.
      </p></li></ol>

      <p>The good news is that WebRTC solves one of the problems on our behalf:
      the built-in ICE protocol performs the necessary routing and connectivity
      checks. However, the delivery of notifications (signaling) and initial
      session negotiation is left to the application.

      </p><section>
        <h3 id="signaling-and-session-negotiation"><a href="#signaling-and-session-negotiation" class="anchor">§</a>Signaling and
        Session Negotiation</h3>

        <p>Before any connectivity checks or session negotiation can occur, we
        must find out if the other peer is reachable and if it is willing to
        establish the connection. We must extend an offer, and the peer must
        return an answer (<a data-type="xref" href="#signalchannel">Figure&nbsp;18-5</a>). However, now we have a dilemma:
        if the other peer is not listening for incoming packets, how do we
        notify it of our intent? At a minimum, we need a shared signaling
        channel.

        </p><figure id="signalchannel">
          <img src="06b379fb58cbcab5530946c7059bfdef.svg" alt="Figure 18-5. Shared signaling channel">

          <figcaption>
            <span class="label">Figure 18-5.</span> Shared signaling channel
          </figcaption>
        </figure>

        <p>WebRTC defers the choice of signaling transport and protocol to the
        application; the standard intentionally does not provide any
        recommendations or implementation for the signaling stack. Why? This
        allows interoperability with a variety of other signaling protocols
        powering existing communications infrastructure, such as the following:

        </p><dl>
          <dt>Session Initiation Protocol (SIP)

          </dt><dd>
            <p>Application-level signaling protocol, widely used for voice over
            IP (VoIP) and videoconferencing over IP networks.

          </p></dd><dt>Jingle

          </dt><dd>
            <p>Signaling extension for the XMPP protocol, used for session
            control of voice over IP and videoconferencing over IP networks.

          </p></dd><dt>ISDN User Part (ISUP)

          </dt><dd>
            <p>Signaling protocol used for setup of telephone calls in many
            public switched telephone networks around the globe.
        </p></dd></dl>

        <div data-type="note" id="id-b4C6uXTzcj">
          <p>A "signaling channel" can be as simple as a shout across the
          room—that is, if your intended peer is within shouting distance! The
          choice of the signaling medium and the protocol is left to the
          application.
        </p></div>

        <p>A WebRTC application can choose to use any of the existing signaling
        protocols and gateways (<a data-type="xref" href="#rtcgateways">Figure&nbsp;18-6</a>) to negotiate a call or a video
        conference with an existing communication system—e.g., initiate a
        "telephone" call with a PSTN client! Alternatively, it can choose to
        implement its own signaling service with a custom protocol.

        </p><figure id="rtcgateways">
          <img src="edff4f485cfbaa3b77d359c081016bf5.svg" alt="Figure 18-6. SIP, Jingle, ISUP, and custom signaling gateways">

          <figcaption>
            <span class="label">Figure 18-6.</span> SIP, Jingle, ISUP, and
            custom signaling gateways
          </figcaption>
        </figure>

        <p>The signaling server can act as a gateway to an existing
        communications network, in which case it is the responsibility of the
        network to notify the target peer of a connection offer and then route
        the answer back to the WebRTC client initiating the exchange.
        Alternatively, the application can also use its own custom signaling
        channel, which may consist of one or more servers and a custom protocol
        to communicate the messages: if both peers are connected to the same
        signaling service, then the service can shuttle messages between them.

        </p><div data-type="note" id="id-exCVCbTdcO">
          <p>Skype is a great example of a peer-to-peer system with custom
          signaling: the audio and video communication are peer-to-peer, but
          Skype users have to connect to Skype’s signaling servers, which use
          their own proprietary protocol, to help initiate the peer-to-peer
          connection.
        </p></div>

        <aside>
          <h4 id="selecting-a-signaling-service"><a href="#selecting-a-signaling-service" class="anchor">§</a>Selecting a
          Signaling Service</h4>

          <p>WebRTC enables peer-to-peer communication, but every WebRTC
          application will also need a signaling server to negotiate and
          establish the connection. What are our options?

          </p><p>There is a growing list of existing communication gateways that
          can interoperate with WebRTC. For example, Asterisk is a popular,
          free, and open source framework that is used by both individual
          businesses and large carriers around the world for their
          telecommunication needs. As an option, Asterisk has a WebSocket
          module, which will allow SIP to be used as a signaling protocol: the
          browser establishes a WebSocket connection to the Asterisk gateway,
          and the two exchange SIP messages to negotiate the session!

          </p><p>Alternatively, the application can easily develop and deploy a
          custom signaling gateway if interoperability with other networks is
          not required. For example, a website may choose to offer peer-to-peer
          audio, video, and data exchange to its users: the site is already
          tracking which users are logged in, and it can keep signaling
          connections open to all of its online users. Then, when two peers
          want to initiate a peer-to-peer session, the site’s servers can relay
          the signaling messages between clients.

          </p><p>There is no single correct choice for a signaling gateway: the
          choice depends on the requirements of the application. However,
          before you set out to invent your own, survey the available
          commercial and open source options first! And, of course, pay close
          attention to the underlying signaling transport, as it may have
          significant impact on both the latency of the signaling channel and
          the client and server overhead; see <a data-type="xref" href="https://hpbn.co/primer-on-browser-networking/#application-apis-and-protocols">Application
          APIs and Protocols</a>.
        </p></aside>
      </section>

      <section>
        <h3 id="session-description-protocol-sdp"><a href="#session-description-protocol-sdp" class="anchor">§</a>Session
        Description Protocol (SDP)</h3>

        <p>Assuming the application implements a shared signaling channel, we
        can now perform the first steps required to initiate a WebRTC
        connection:

        </p><div data-type="example" id="-67CQFdCqc4">
          <pre data-type="programlisting">var signalingChannel = new SignalingChannel(); <a class="counter" id="sdpscinit-co" href="#sdpscinit"></a>
var pc = new RTCPeerConnection({}); <a class="counter" id="pconn-co" href="#pconn"></a>

navigator.getUserMedia({ "audio": true }, gotStream, logError);  <a class="counter" id="sdpgum-co" href="#sdpgum"></a>

function gotStream(stream) {
  pc.addStream(stream); <a class="counter" id="sdpaddstream-co" href="#sdpaddstream"></a>

  pc.createOffer(function(offer) { <a class="counter" id="sdpoffer-co" href="#sdpoffer"></a>
    pc.setLocalDescription(offer); <a class="counter" id="sdpsld-co" href="#sdpsld"></a>
    signalingChannel.send(offer.sdp); <a class="counter" id="sdpscsend-co" href="#sdpscsend"></a>
  });
}

function logError() { ... }
</pre>

          <ol class="notation">
            <li>
              <a class="co" id="sdpscinit" href="#sdpscinit-co"></a>

              <p>Initialize the shared signaling channel

            </p></li><li>
              <a class="co" id="pconn" href="#pconn-co"></a>

              <p>Initialize the RTCPeerConnection object

            </p></li><li>
              <a class="co" id="sdpgum" href="#sdpgum-co"></a>

              <p>Request audio stream from the browser

            </p></li><li>
              <a class="co" id="sdpaddstream" href="#sdpaddstream-co"></a>

              <p>Register local audio stream with RTCPeerConnection object

            </p></li><li>
              <a class="co" id="sdpoffer" href="#sdpoffer-co"></a>

              <p>Create SDP (offer) description of the peer connection

            </p></li><li>
              <a class="co" id="sdpsld" href="#sdpsld-co"></a>

              <p>Apply generated SDP as local description of peer connection

            </p></li><li>
              <a class="co" id="sdpscsend" href="#sdpscsend-co"></a>

              <p>Send generated SDP offer to remote peer via signaling channel
          </p></li></ol>
        </div>

        <div data-type="note" id="id-LWC7hNC3c3">
          <p>We will be using unprefixed APIs in our examples, as they are
          defined by the W3C standard. Until the browser implementations are
          finalized, you may need to adjust the code for your favorite browser.
        </p></div>

        <p>WebRTC uses <em>Session Description Protocol</em> (SDP) to describe
        the parameters of the peer-to-peer connection. SDP does not deliver any
        media itself; instead it is used to describe the "session profile,"
        which represents a list of properties of the connection: types of media
        to be exchanged (audio, video, and application data), network
        transports, used codecs and their settings, bandwidth information, and
        other metadata.

        </p><p id="SDPAUDIO">In the preceding example, once a local audio stream is
        registered with the RTCPeerConnection object, we call
        <code>createOffer()</code> to generate the SDP description of the
        intended session. What does the generated SDP contain? Let’s take a
        look:

        </p><div data-type="example" id="-Z9CVIvC2cd">
          <pre data-type="programlisting">(... snip ...)
m=audio 1 RTP/SAVPF 111 ... <a class="counter" id="saudio-co" href="#saudio"></a>
a=extmap:1 urn:ietf:params:rtp-hdrext:ssrc-audio-level
a=candidate:1862263974 1 udp 2113937151 192.168.1.73 60834 typ host ... <a class="counter" id="scandidate-co" href="#scandidate"></a>
a=mid:audio
a=rtpmap:111 opus/48000/2 <a class="counter" id="opus-co" href="#opus"></a>
a=fmtp:111 minptime=10
(... snip ...)
</pre>

          <ol class="notation">
            <li>
              <a class="co" id="saudio" href="#saudio-co"></a>

              <p>Secure audio profile with feedback

            </p></li><li>
              <a class="co" id="scandidate" href="#scandidate-co"></a>

              <p>Candidate IP, port, and protocol for the media stream

            </p></li><li>
              <a class="co" id="opus" href="#opus-co"></a>

              <p>Opus codec and basic configuration
          </p></li></ol>
        </div>

        <p>SDP is a simple text-based protocol (RFC 4568) for describing the
        properties of the intended session; in the previous case, it provides a
        description of the acquired audio stream. The good news is, WebRTC
        applications do not have to deal with SDP directly. The JavaScript
        Session Establishment Protocol (JSEP) abstracts all the inner workings
        of SDP behind a few simple method calls on the RTCPeerConnection
        object.

        </p><p>Once the offer is generated, it can be sent to the remote peer via
        the signaling channel. Once again, how the SDP is encoded is up to the
        application: the SDP string can be transferred directly as shown
        earlier (as a simple text blob), or it can be encoded in any other
        format—e.g., the Jingle protocol provides a mapping from SDP to XMPP
        (XML) stanzas.

        </p><p>To establish a peer-to-peer connection, both peers must follow a
        symmetric workflow (<a data-type="xref" href="#localremotesdp">Figure&nbsp;18-7</a>) to exchange SDP descriptions of
        their respective audio, video, and other data streams.

        </p><figure id="localremotesdp">
          <img src="69aa329ffbfae6fd0446de77623c93fb.svg" alt="Figure 18-7. Offer/answer SDP exchange between peers">

          <figcaption>
            <span class="label">Figure 18-7.</span> Offer/answer SDP exchange
            between peers
          </figcaption>
        </figure>

        <ol>
          <li>
            <p>The initiator (Amy) registers one or more streams with her local
            RTCPeerConnection object, creates an offer, and sets it as her
            "local description" of the session.

          </p></li><li>
            <p>Amy then sends the generated session offer to the other peer
            (Bob).

          </p></li><li>
            <p>Once the offer is received by Bob, he sets Amy’s description as
            the "remote description" of the session, registers his own streams
            with his own RTCPeerConnection object, generates the "answer" SDP
            description, and sets it as the "local description" of the
            session—phew!

          </p></li><li>
            <p>Bob then sends the generated session answer back to Amy.

          </p></li><li>
            <p>Once Bob’s SDP answer is received by Amy, she sets his answer as
            the "remote description" of her original session.
        </p></li></ol>

        <p>With that, once the SDP session descriptions have been exchanged via
        the signaling channel, both parties have now negotiated the type of
        streams to be exchanged, and their settings. We are almost ready to
        begin our peer-to-peer communication! Now, there is just one more
        detail to take care of: connectivity checks and NAT traversal.
      </p></section>

      <section>
        <h3 id="interactive-connectivity-establishment-ice"><a href="#interactive-connectivity-establishment-ice" class="anchor">§</a>Interactive Connectivity Establishment (ICE)</h3>

        <p>In order to establish a peer-to-peer connection, by definition, the
        peers must be able to route packets to each other. A trivial statement
        on the surface, but hard to achieve in practice due to the numerous
        layers of firewalls and NAT devices between most peers; see
        <a data-type="xref" href="https://hpbn.co/building-blocks-of-udp/#udp-and-network-address-translators">UDP and
        Network Address Translators</a>.

        </p><p>First, let’s consider the trivial case, where both peers are located
        on the same internal network, and there are no firewalls or NATs
        between them. To establish the connection, each peer can simply query
        its operating system for its IP address (or multiple, if there are
        multiple network interfaces), append the provided IP and port tuples to
        the generated SDP strings, and forward it to the other peer. Once the
        SDP exchange is complete, both peers can initiate a direct peer-to-peer
        connection.

        </p><div data-type="note" id="id-b4Cbh4czcj">
          <p>The earlier SDP example (<a data-type="xref" href="#sdpaudio">undefined '18-114'</a>) illustrates the preceding
          scenario: the <code>a=candidate</code> line lists a private
          (192.168.x.x) IP address for the peer initiating the session; see
          <a data-type="xref" href="https://hpbn.co/building-blocks-of-udp/#reserved-private-network-ranges">Reserved
          Private Network Ranges</a>.
        </p></div>

        <p>So far, so good. However, what would happen if one or both of the
        peers were on distinct private networks? We could repeat the preceding
        workflow, discover and embed the private IP addresses of each peer, but
        the peer-to-peer connections would obviously fail! What we need is a
        public routing path between the peers. Thankfully, the WebRTC framework
        manages most of this complexity on our behalf:

        </p><ul>
          <li>
            <p>Each RTCPeerConnection connection object contains an "ICE
            agent."

          </p></li><li>
            <p>ICE agent is responsible for gathering local IP, port tuples
            (candidates).

          </p></li><li>
            <p>ICE agent is responsible for performing connectivity checks
            between peers.

          </p></li><li>
            <p>ICE agent is responsible for sending connection keepalives.
        </p></li></ul>

        <p>Once a session description (local or remote) is set, local ICE agent
        automatically begins the process of discovering all the possible
        candidate IP, port tuples for the local peer:

        </p><ol>
          <li>
            <p>ICE agent queries the operating system for local IP addresses.

          </p></li><li>
            <p>If configured, ICE agent queries an external STUN server to
            retrieve the public IP and port tuple of the peer.

          </p></li><li>
            <p>If configured, ICE agent appends the TURN server as a last
            resort candidate. If the peer-to-peer connection fails, the data
            will be relayed through the specified intermediary.
        </p></li></ol>

        <div data-type="note" id="id-OyC8TkcacZ">
          <p>If you have ever had to answer the "What is my public IP address?"
          question, then you’ve effectively performed a manual "STUN lookup."
          The STUN protocol allows the browser to learn if it’s behind a NAT
          and to discover its public IP and port; see <a data-type="xref" href="https://hpbn.co/building-blocks-of-udp/#stun-turn-and-ice">STUN, TURN, and ICE</a>.
        </p></div>

        <p>Whenever a new candidate (an IP, port tuple) is discovered, the
        agent automatically registers it with the RTCPeerConnection object and
        notifies the application via a callback function
        (<code>onicecandidate</code>). Once the ICE gathering is complete, the
        same callback is fired to notify the application. Let’s extend our
        earlier example to work with ICE:

        </p><div data-type="example" id="-3MCQcpcVc6">
          <pre data-type="programlisting">var ice = {"iceServers": [
  {"url": "stun:stun.l.google.com:19302"}, <a class="counter" id="gstun-co" href="#gstun"></a>
  {"url": "turn:turnserver.com", "username": "user", "credential": "pass"} <a class="counter" id="turn-co" href="#turn"></a>
]};

var signalingChannel = new SignalingChannel();
var pc = new RTCPeerConnection(ice);

navigator.getUserMedia({ "audio": true }, gotStream, logError);

function gotStream(stream) {
  pc.addStream(stream);

  pc.createOffer(function(offer) {
    pc.setLocalDescription(offer); <a class="counter" id="triggerice-co" href="#triggerice"></a>
  });
}

pc.onicecandidate = function(evt) {
  if (evt.target.iceGatheringState == "complete") { <a class="counter" id="icecomplete-co" href="#icecomplete"></a>
      local.createOffer(function(offer) {
        console.log("Offer with ICE candidates: " + offer.sdp);
        signalingChannel.send(offer.sdp); <a class="counter" id="iceoffer-co" href="#iceoffer"></a>
      });
  }
}

...

// Offer with ICE candidates:
// a=candidate:1862263974 1 udp 2113937151 192.168.1.73 60834 typ host ... <a class="counter" id="icelocal-co" href="#icelocal"></a>
// a=candidate:2565840242 1 udp 1845501695 50.76.44.100 60834 typ srflx ... <a class="counter" id="icepublic-co" href="#icepublic"></a>
</pre>

          <ol class="notation">
            <li>
              <a class="co" id="gstun" href="#gstun-co"></a>

              <p>STUN server, configured to use Google's public test server

            </p></li><li>
              <a class="co" id="turn" href="#turn-co"></a>

              <p>TURN server for relaying data if peer-to-peer connection fails

            </p></li><li>
              <a class="co" id="triggerice" href="#triggerice-co"></a>

              <p>Apply local session description: initiates ICE gathering
              process

            </p></li><li>
              <a class="co" id="icecomplete" href="#icecomplete-co"></a>

              <p>Subscribe to ICE events and listen for ICE gathering
              completion

            </p></li><li>
              <a class="co" id="iceoffer" href="#iceoffer-co"></a>

              <p>Regenerate the SDP offer (now with discovered ICE candidates)

            </p></li><li>
              <a class="co" id="icelocal" href="#icelocal-co"></a>

              <p>Private ICE candidate (192.168.1.73:60834) for the peer

            </p></li><li>
              <a class="co" id="icepublic" href="#icepublic-co"></a>

              <p>Public ICE candidate (50.76.44.100:69834) returned by the STUN
              server
          </p></li></ol>
        </div>

        <div data-type="note" id="id-dOC0UpcOcb">
          <p>The previous example uses Google’s public demo STUN server.
          Unfortunately, STUN alone may not be sufficient (see <a data-type="xref" href="https://hpbn.co/building-blocks-of-udp/#stun-and-turn-in-practice">STUN
          and TURN in Practice</a>), and you may also need to provide a TURN
          server to guarantee connectivity for peers that cannot establish a
          direct peer-to-peer connection (~8% of users).
        </p></div>

        <p>As the example illustrates, the ICE agent handles most of the
        complexity on our behalf: the ICE gathering process is triggered
        automatically, STUN lookups are performed in the background, and the
        discovered candidates are registered with the RTCPeerConnection object.
        Once the process is complete, we can generate the SDP offer and use the
        signaling channel to deliver it to the other peer.

        </p><p>Then, once the ICE candidates are received by the other peer, we are
        ready to begin the second phase of establishing a peer-to-peer
        connection: once the remote session description is set on the
        RTCPeerConnection object, which now contains a list of candidate IP and
        port tuples for the other peer, the ICE agent begins connectivity
        checks (<a data-type="xref" href="#stunbind">Figure&nbsp;18-8</a>) to
        see if it can reach the other party.

        </p><figure id="stunbind">
          <img src="a2813f1c382a12a4b0b0b229ca22ee9f.png" alt="Figure 18-8. WireShark capture of a peer-to-peer STUN binding request and response">

          <figcaption>
            <span class="label">Figure 18-8.</span> WireShark capture of a
            peer-to-peer STUN binding request and response
          </figcaption>
        </figure>

        <p>The ICE agent sends a message (a STUN binding request), which the
        other peer must acknowledge with a successful STUN response. If this
        completes, then we finally have a routing path for a peer-to-peer
        connection! Conversely, if all candidates fail, then either the
        RTCPeerConnection is marked as failed, or the connection falls back to
        a TURN relay server to establish the connection.

        </p><div data-type="note" id="id-GGC8F6c7c7">
          <p>The ICE agent automatically ranks and prioritizes the order in
          which the candidate connection checks are performed: local IP
          addresses are checked first, then public, and TURN is used as a last
          resort. Once a connection is established, the ICE agent continues to
          issue periodic STUN requests to the other peer. This serves as a
          connection keepalive.
        </p></div>

        <p>Phew! As we said at the beginning of this section, initiating a
        peer-to-peer connection requires (much) more work than opening an XHR,
        EventSource, or a new WebSocket session. The good news is, most of this
        work is done on our behalf by the browser. However, for performance
        reasons, it is important to keep in mind that the process may incur
        multiple roundtrips between the STUN servers and between the individual
        peers before we can begin transmitting data—that is, assuming ICE
        negotiation is successful.
      </p></section>

      <section>
        <h3 id="incremental-provisioning-trickle-ice"><a href="#incremental-provisioning-trickle-ice" class="anchor">§</a>Incremental
        Provisioning (Trickle ICE)</h3>

        <p>The ICE gathering process is anything but instantaneous: retrieving
        local IP addresses is fast, but querying the STUN server requires a
        roundtrip to the external server, followed by another round of STUN
        connectivity checks between the individual peers. Trickle ICE is an
        extension to the ICE protocol that allows incremental gathering and
        connectivity checks between the peers. The core idea is very simple:

        </p><ul>
          <li>
            <p>Both peers exchange SDP offers without ICE candidates.

          </p></li><li>
            <p>ICE candidates are sent via the signaling channel as they are
            discovered.

          </p></li><li>
            <p>ICE connectivity checks are run as soon as the new candidate
            description is available.
        </p></li></ul>

        <p>In short, instead of waiting for the ICE gathering process to
        complete, we rely on the signaling channel to deliver incremental
        updates to the other peer, which helps accelerate the process. The
        WebRTC implementation is also fairly simple:

        </p><div data-type="example" id="-Z9C7HbU2cd">
          <pre data-type="programlisting">var ice = {"iceServers": [
  {"url": "stun:stun.l.google.com:19302"},
  {"url": "turn:turnserver.com", "username": "user", "credential": "pass"}
]};

var pc = new RTCPeerConnection(ice);
navigator.getUserMedia({ "audio": true }, gotStream, logError);

function gotStream(stream) {
  pc.addStream(stream);

  pc.createOffer(function(offer) {
    pc.setLocalDescription(offer);
    signalingChannel.send(offer.sdp); <a class="counter" id="trickleoffer-co" href="#trickleoffer"></a>
  });
}

pc.onicecandidate = function(evt) {
  if (evt.candidate) {
    signalingChannel.send(evt.candidate); <a class="counter" id="tricklecandidate-co" href="#tricklecandidate"></a>
  }
}

signalingChannel.onmessage = function(msg) {
  if (msg.candidate) {
    pc.addIceCandidate(msg.candidate); <a class="counter" id="addicecandidate-co" href="#addicecandidate"></a>
  }
}
</pre>

          <ol class="notation">
            <li>
              <a class="co" id="trickleoffer" href="#trickleoffer-co"></a>

              <p>Send SDP offer without ICE candidates

            </p></li><li>
              <a class="co" id="tricklecandidate" href="#tricklecandidate-co"></a>

              <p>Send individual ICE candidate as it is discovered by local ICE
              agent

            </p></li><li>
              <a class="co" id="addicecandidate" href="#addicecandidate-co"></a>

              <p>Register remote ICE candidate and begin connectivity checks
          </p></li></ol>
        </div>

        <p>Trickle ICE generates more traffic over the signaling channel, but
        it can yield a significant improvement in the time required to initiate
        the peer-to-peer connection. For this reason, it is also the
        recommended strategy for all WebRTC applications: send the offer as
        soon as possible, and then <em>trickle</em> ICE candidates as they are
        discovered.
      </p></section>

      <section>
        <h3 id="tracking-ice-gathering-and-connectivity-status"><a href="#tracking-ice-gathering-and-connectivity-status" class="anchor">§</a>Tracking ICE Gathering and Connectivity Status</h3>

        <p>The built-in ICE framework manages candidate discovery, connectivity
        checks, keepalives, and more. If all works well, then all of this work
        is completely transparent to the application: the only thing we have to
        do is specify the STUN and TURN servers when initializing the
        RTCPeerConnection object. However, not all connections will succeed,
        and it is important to be able to isolate and resolve the problem. To
        do so, we can query the status of the ICE agent and subscribe to its
        notifications:

        </p><div data-type="example" id="-RkC9F7f7cZ">
          <pre data-type="programlisting">var ice = {"iceServers": [
  {"url": "stun:stun.l.google.com:19302"},
  {"url": "turn:turnserver.com", "username": "user", "credential": "pass"}
]};

var pc = new RTCPeerConnection(ice);

logStatus("ICE gathering state: "  + pc.iceGatheringState); <a class="counter" id="icegstate-co" href="#icegstate"></a>
pc.onicecandidate = function(evt) { <a class="counter" id="icegstates-co" href="#icegstates"></a>
   logStatus("ICE gathering state change: " + evt.target.iceGatheringState);
}

logStatus("ICE connection state: " + pc.iceConnectionState); <a class="counter" id="icecstate-co" href="#icestate"></a>
pc.oniceconnectionstatechange = function(evt) { <a class="counter" id="icecstates-co" href="#icestates"></a>
  logStatus("ICE connection state change: " + evt.target.iceConnectionState);
}
</pre>

          <ol class="notation">
            <li>
              <a class="co" id="icegstate" href="#icegstate-co"></a>

              <p>Log current ICE gathering state

            </p></li><li>
              <a class="co" id="icegstates" href="#icegstates-co"></a>

              <p>Subscribe to ICE gathering events

            </p></li><li>
              <a class="co" id="icestate" href="#icecstate-co"></a>

              <p>Log current ICE connection state

            </p></li><li>
              <a class="co" id="icestates" href="#icecstates-co"></a>

              <p>Subscribe to ICE connection state events
          </p></li></ol>
        </div>

        <p>The <code>iceGatheringState</code> attribute, as its name implies,
        reports the status of the candidate gathering process for the local
        peer. As a result, it can be in three different states:

        </p><dl>
          <dt class="horizontal"><code>new</code>

          </dt><dd>
            <p>The object was just created and no networking has occurred yet.

          </p></dd><dt class="horizontal"><code>gathering</code>

          </dt><dd>
            <p>The ICE agent is in the process of gathering local candidates.

          </p></dd><dt class="horizontal"><code>complete</code>

          </dt><dd>
            <p>The ICE agent has completed the gathering process.
        </p></dd></dl>

        <p>On the other hand, the <code>iceConnectionState</code> attribute
        reports the status of the peer-to-peer connection (<a data-type="xref" href="#iceconnectionstate">Figure&nbsp;18-9</a>), which can be in one
        of seven possible states:

        </p><dl>
          <dt><code>new</code>

          </dt><dd>
            <p>The ICE agent is gathering candidates and/or waiting for remote
            candidates to be supplied.

          </p></dd><dt><code>checking</code>

          </dt><dd>
            <p>The ICE agent has received remote candidates on at least one
            component and is checking candidate pairs but has not yet found a
            connection. In addition to checking, it may also still be
            gathering.

          </p></dd><dt><code>connected</code>

          </dt><dd>
            <p>The ICE agent has found a usable connection for all components
            but is still checking other candidate pairs to see if there is a
            better connection. It may also still be gathering.

          </p></dd><dt><code>completed</code>

          </dt><dd>
            <p>The ICE agent has finished gathering and checking and found a
            connection for all components.

          </p></dd><dt><code>failed</code>

          </dt><dd>
            <p>The ICE agent is finished checking all candidate pairs and
            failed to find a connection for at least one component. Connections
            may have been found for some components.

          </p></dd><dt><code>disconnected</code>

          </dt><dd>
            <p>Liveness checks have failed for one or more components. This is
            more aggressive than failed and may trigger intermittently (and
            resolve itself without action) on a flaky network.

          </p></dd><dt><code>closed</code>

          </dt><dd>
            <p>The ICE agent has shut down and is no longer responding to STUN
            requests.
        </p></dd></dl>

        <figure id="iceconnectionstate">
          <img src="4b4766fd02af08ca2894b4cce8b44d85.svg" alt="Figure 18-9. ICE agent connectivity states and transitions">

          <figcaption>
            <span class="label">Figure 18-9.</span> ICE agent connectivity
            states and transitions
          </figcaption>
        </figure>

        <p>A WebRTC session may require multiple streams for delivering audio,
        video, and application data. As a result, a successful connection is
        one that is able to establish connectivity for all the requested
        streams. Further, due to the unreliable nature of peer-to-peer
        connectivity, there are no guarantees that once the connection is
        established that it will stay that way: the connection may periodically
        flip between connected and disconnected states while the ICE agent
        attempts to find the best possible path to re-establish connectivity.

        </p><div data-type="note" id="id-dOCYCEfOcb">
          <p>The first and primary goal for the ICE agent is to identify a
          viable routing path between the peers. However, it doesn’t stop
          there. Even once connected, the ICE agent may periodically try other
          candidates to see if it can deliver better performance via an
          alternate route.
        </p></div>

        <aside>
          <h4 id="inspecting-webrtc-connection-status-with-google-chrome">
          <a href="#inspecting-webrtc-connection-status-with-google-chrome" class="anchor">§</a>Inspecting WebRTC Connection Status with Google
          Chrome</h4>

          <p>Google Chrome provides a simple and very useful tool to
          investigate the entire workflow and state of any WebRTC connection:
          open a new tab and load <code>chrome://webrtc-internals</code>.
          There, you can inspect (<a data-type="xref" href="#webrtcinternals">Figure&nbsp;18-10</a>) all of the open
          peer-to-peer connections, inspect the exchanged SDP descriptions, and
          more.

          </p><figure id="webrtcinternals">
            <img src="e32a63d9d4c6b1ffcaf49c42078f47cd.png" alt="Figure 18-10. chrome://webrtc-internals">

            <figcaption>
              <span class="label">Figure 18-10.</span>
              chrome://webrtc-internals
            </figcaption>
          </figure>

          <p>Chrome will also report a number of statistics for each stream,
          such as available bandwidth, latency, bitrate of the encoded video
          and audio streams, and more. Even if you are not developing a WebRTC
          application, start a WebRTC session with a friend or between multiple
          browser windows, and head to <code>chrome://webrtc-internals</code>;
          it is an indispensable tool for familiarizing yourself with the
          internals of WebRTC.
        </p></aside>
      </section>

      <section>
        <h3 id="putting-it-all-together"><a href="#putting-it-all-together" class="anchor">§</a>Putting It All Together</h3>

        <p>We have covered a lot of ground: we’ve discussed signaling, the
        offer-answer workflow, session parameter negotiation with SDP, and took
        a deep dive into the inner workings of the ICE protocol required to
        establish a peer-to-peer connection. Finally, we now have all the
        necessary pieces to initiate a peer-to-peer connection over WebRTC.

        </p><section data-type="sect3" id="initiating-a-webrtc-connection-2DULFXivcL">
          <h3>Initiating a WebRTC connection</h3>

          <p>We have been filling in all the necessary pieces bit by bit
          throughout the preceding pages, but now let’s take a look at a
          complete example for the peer responsible for initiating the WebRTC
          connection:

          </p><div data-type="example" id="-exCOFkF4ioc6">
            <pre data-type="programlisting">&lt;video id="local_video" autoplay&gt;&lt;/video&gt; <a class="counter" id="ilvout-co" href="#ilvout"></a>
&lt;video id="remote_video" autoplay&gt;&lt;/video&gt; <a class="counter" id="irvout-co" href="#irvout"></a>

&lt;script&gt;
  var ice = {"iceServers": [
    {"url": "stun:stunserver.com:12345"},
    {"url": "turn:turnserver.com", "username": "user", "credential": "pass"}
  ]};

  var signalingChannel = new SignalingChannel(); <a class="counter" id="isig-co" href="#isig"></a>
  var pc = new RTCPeerConnection(ice); <a class="counter" id="ipc-co" href="#ipc"></a>

  navigator.getUserMedia({ "audio": true, "video": true }, gotStream, logError); <a class="counter" id="igum-co" href="#igum"></a>

  function gotStream(evt) {
    pc.addStream(evt.stream); <a class="counter" id="iaddstream-co" href="#iaddstream"></a>

    var local_video = document.getElementById('local_video');
    local_video.src = window.URL.createObjectURL(evt.stream); <a class="counter" id="ivd-co" href="#ivd"></a>

    pc.createOffer(function(offer) { <a class="counter" id="ioffer-co" href="#ioffer"></a>
      pc.setLocalDescription(offer);
      signalingChannel.send(offer.sdp);
    });
  }

  pc.onicecandidate = function(evt) { <a class="counter" id="itrickle-co" href="#itrickle"></a>
    if (evt.candidate) {
      signalingChannel.send(evt.candidate);
    }
  }

  signalingChannel.onmessage = function(msg) { <a class="counter" id="irtrickle-co" href="#irtrickle"></a>
    if (msg.candidate) {
      pc.addIceCandidate(msg.candidate);
    }
  }

  pc.onaddstream = function (evt) { <a class="counter" id="irvd-co" href="#irvd"></a>
    var remote_video = document.getElementById('remote_video');
    remote_video.src = window.URL.createObjectURL(evt.stream);
  }

  function logError() { ... }
&lt;/script&gt;
</pre>

            <ol class="notation">
              <li>
                <a class="co" id="ilvout" href="#ilvout-co"></a>

                <p>Video element for output of local stream

              </p></li><li>
                <a class="co" id="irvout" href="#irvout-co"></a>

                <p>Video element for output of remote stream

              </p></li><li>
                <a class="co" id="isig" href="#isig-co"></a>

                <p>Initialize shared signaling channel

              </p></li><li>
                <a class="co" id="ipc" href="#ipc-co"></a>

                <p>Initialize peer connection object

              </p></li><li>
                <a class="co" id="igum" href="#igum-co"></a>

                <p>Acquire local audio and video streams

              </p></li><li>
                <a class="co" id="iaddstream" href="#iaddstream-co"></a>

                <p>Register local MediaStream with peer connection

              </p></li><li>
                <a class="co" id="ivd" href="#ivd-co"></a>

                <p>Output local video stream to video element (self view)

              </p></li><li>
                <a class="co" id="ioffer" href="#ioffer-co"></a>

                <p>Generate SDP offer describing peer connection and send to
                peer

              </p></li><li>
                <a class="co" id="itrickle" href="#itrickle-co"></a>

                <p>Trickle ICE candidates to the peer via the signaling channel

              </p></li><li>
                <a class="co" id="irtrickle" href="#irtrickle-co"></a>

                <p>Register remote ICE candidate to begin connectivity checks

              </p></li><li>
                <a class="co" id="irvd" href="#irvd-co"></a>

                <p>Output remote video stream to video element (remote view)
            </p></li></ol>
          </div>

          <p>The entire process can be a bit daunting on the first pass, but
          now that we understand how all the pieces work, it is fairly
          straightforward: initialize the peer connection and the signaling
          channel, acquire and register media streams, send the offer, trickle
          ICE candidates, and finally output the acquired media streams. A more
          complete implementation can also register additional callbacks to
          track ICE gathering and connection states and provide more feedback
          to the user.

          </p><div data-type="note" id="id-xACGHXFLiNcd">
            <p>Once the connection is established, the application can still
            add and remove streams from the RTCPeerConnection object. Each time
            this happens, an automatic SDP renegotiation is invoked, and the
            same initialization procedure is repeated.
          </p></div>
        </section>

        <section data-type="sect3" id="responding-to-a-webrtc-connection-nmU0h7imc9">
          <h3>Responding to a WebRTC connection</h3>

          <p>The process to answer the request for a new WebRTC connection is
          very similar, with the only major difference being that most of the
          logic is executed when the signaling channel delivers the SDP offer.
          Let’s take a hands-on look:

          </p><div data-type="example" id="-OyCAFOh8iQc1">
            <pre data-type="programlisting">&lt;video id="local_video" autoplay&gt;&lt;/video&gt;
&lt;video id="remote_video" autoplay&gt;&lt;/video&gt;

&lt;script&gt;
  var signalingChannel = new SignalingChannel();

  var pc = null;
  var ice = {"iceServers": [
    {"url": "stun:stunserver.com:12345"},
    {"url": "turn:turnserver.com", "username": "user", "credential": "pass"}
  ]};

  signalingChannel.onmessage = function(msg) {
    if (msg.offer) { <a class="counter" id="roffer-co" href="#roffer"></a>
      pc = new RTCPeerConnection(ice);
      pc.setRemoteDescription(msg.offer);

      pc.onicecandidate = function(evt) {
        if (evt.candidate) {
          signalingChannel.send(evt.candidate);
        }
      }

      pc.onaddstream = function (evt) {
        var remote_video = document.getElementById('remote_video');
        remote_video.src = window.URL.createObjectURL(evt.stream);
      }

      navigator.getUserMedia({ "audio": true, "video": true },
        gotStream, logError);

    } else if (msg.candidate) { <a class="counter" id="rice-co" href="#rice"></a>
      pc.addIceCandidate(msg.candidate);
    }
  }

  function gotStream(evt) {
    pc.addStream(evt.stream);

    var local_video = document.getElementById('local_video');
    local_video.src = window.URL.createObjectURL(evt.stream);

    pc.createAnswer(function(answer) { <a class="counter" id="ranswer-co" href="#ranswer"></a>
      pc.setLocalDescription(answer);
      signalingChannel.send(answer.sdp);
    });
  }

  function logError() { ... }
&lt;/script&gt;
</pre>

            <ol class="notation">
              <li>
                <a class="co" id="roffer" href="#roffer-co"></a>

                <p>Listen and process remote offers delivered via signaling
                channel

              </p></li><li>
                <a class="co" id="rice" href="#rice-co"></a>

                <p>Register remote ICE candidate to begin connectivity checks

              </p></li><li>
                <a class="co" id="ranswer" href="#ranswer-co"></a>

                <p>Generate SDP answer describing peer connection and send to
                peer
            </p></li></ol>
          </div>

          <p>Not surprisingly, the code looks very similar. The only major
          difference, aside from initiating the peer connection workflow based
          on an offer message delivered via the shared signaling channel, is
          that the preceding code is generating an SDP answer (via
          <code>createAnswer</code>) instead of an offer object. Otherwise, the
          process is symmetric: initialize the peer connection, acquire and
          register media streams, send the answer, trickle ICE candidates, and
          finally output the acquired media streams.

          </p><p>With that, we can copy the code, add an implementation for the
          signaling channel, and we have a real-time, peer-to-peer video and
          audio session videoconferencing application running in the
          browser—not bad for fewer than 100 lines of JavaScript code!

          </p><aside>
            <h4 id="initiating-a-webrtc-session-with-simplewebrtc"><a href="#initiating-a-webrtc-session-with-simplewebrtc" class="anchor">§</a>Initiating a WebRTC Session with SimpleWebRTC</h4>

            <p>In practice, the previous code can be made much simpler. Our
            example manually wires up all the necessary pieces, but there is no
            reason why most of this work cannot be wrapped by another library.
            As a practical example, the <em>simpleWebRTC</em> library does just
            that:

            </p><pre data-type="programlisting" data-code-language="html" data-highlighted="true"><code class="nt">&lt;script </code><code class="na">src=</code><code class="s">"http://simplewebrtc.com/latest.js"</code><code class="nt">&gt;&lt;/script&gt;</code>

<code class="nt">&lt;div</code> <code class="na">id=</code><code class="s">"local_video"</code><code class="nt">&gt;&lt;/div&gt;</code>
<code class="nt">&lt;div</code> <code class="na">id=</code><code class="s">"remote_video"</code><code class="nt">&gt;&lt;/div&gt;</code>

<code class="nt">&lt;script&gt;</code>
  <code class="kd">var</code> <code class="nx">webrtc</code> <code class="o">=</code> <code class="k">new</code> <code class="nx">SimpleWebRTC</code><code class="p">({</code>
    <code class="nx">localVideoEl</code><code class="o">:</code> <code class="s2">"local_video"</code><code class="p">,</code>
    <code class="nx">remoteVideosEl</code><code class="o">:</code> <code class="s2">"remote_video"</code><code class="p">,</code>
    <code class="nx">autoRequestMedia</code><code class="o">:</code> <code class="kc">true</code>
  <code class="p">});</code>

  <code class="nx">webrtc</code><code class="p">.</code><code class="nx">on</code><code class="p">(</code><code class="s2">"readyToCall"</code><code class="p">,</code> <code class="kd">function</code> <code class="p">()</code> <code class="p">{</code>
      <code class="nx">webrtc</code><code class="p">.</code><code class="nx">joinRoom</code><code class="p">(</code><code class="s2">"your awesome room name"</code><code class="p">);</code>
  <code class="p">});</code>
<code class="nt">&lt;/script&gt;</code></pre>

            <p>The JavaScript delivers the same videoconferencing experience as
            our earlier example. However, there is no magic; SimpleWebRTC
            simply makes a number of decisions on our behalf. Under the hood it
            initializes the RTCPeerConnection with a public STUN server for NAT
            traversal, requests audio and video streams with getUserMedia, and
            initiates a WebSocket connection to its own signaling servers. The
            only decision left to the application is to define the "room name,"
            which the peers must agree on to initiate the peer-to-peer
            connection.

            </p><p>Check out the documentation for <a href="http://www.simplewebrtc.com/">simpleWebRTC</a>. As a bonus, the
            project also provides an open source signaling server, which you
            can run yourself or use as a reference for implementing your own
            version.
          </p></aside>
        </section>
      </section>
    </section>

    <section>
      <h2 id="delivering-media-and-application-data"><a href="#delivering-media-and-application-data" class="anchor">§</a>Delivering
      Media and Application Data</h2>

      <p>Establishing a peer-to-peer connection takes quite a bit of work.
      However, even once the clients complete the answer-offer workflow and
      each client performs its NAT traversals and STUN connectivity checks, we
      are still only halfway up our WebRTC protocol stack (<a data-type="xref" href="#webrtc-stack">Figure&nbsp;18-3</a>). At this point, both peers
      have raw UDP connections open to each other, which provides a no-frills
      datagram transport, but as we know that is not sufficient on its own; see
      <a data-type="xref" href="https://hpbn.co/building-blocks-of-udp/#optimizing-for-udp" style="">Optimizing for UDP</a>.

      </p><p>Without flow control, congestion control, error checking, and some
      mechanism for bandwidth and latency estimation, we can easily overwhelm
      the network, which would lead to degraded performance for both peers and
      those around them. Further, UDP transfers data in the clear, whereas
      WebRTC requires that we encrypt all communication! To address this,
      WebRTC layers several additional protocols on top of UDP to fill in the
      gaps:

      </p><ul>
        <li>
          <p>Datagram Transport Layer Security (DTLS) is used to negotiate the
          secret keys for encrypting media data and for secure transport of
          application data.

        </p></li><li>
          <p>Secure Real-Time Transport (SRTP) is used to transport audio and
          video streams.

        </p></li><li>
          <p>Stream Control Transport Protocol (SCTP) is used to transport
          application data.
      </p></li></ul>

      <section>
        <h3 id="secure-communication-with-dtls"><a href="#secure-communication-with-dtls" class="anchor">§</a>Secure
        Communication with DTLS</h3>

        <p>WebRTC specification requires that all transferred data—audio,
        video, and custom application payloads—must be encrypted while in
        transit. The Transport Layer Security (<a data-type="xref" href="https://hpbn.co/transport-layer-security-tls/">Transport Layer Security (TLS)</a>)
        protocol would, of course, be a perfect fit, except that it cannot be
        used over UDP, as it relies on reliable and in-order delivery offered
        by TCP. Instead, WebRTC uses DTLS, which provides equivalent security
        guarantees.

        </p><p>DTLS is deliberately designed to be as similar to TLS as possible.
        In fact, DTLS <em>is</em> TLS, but with a minimal number of
        modifications to make it compatible with datagram transport offered by
        UDP. Specifically, DTLS addresses the following problems:

        </p><ol>
          <li>
            <p>TLS requires reliable, in-order, and fragmentation friendly
            delivery of handshake records to negotiate the tunnel.

          </p></li><li>
            <p>TLS integrity checks may fail if records are fragmented across
            multiple packets.

          </p></li><li>
            <p>TLS integrity checks may fail if records are processed out of
            order.
        </p></li></ol>

        <div data-type="note" id="id-7KCLHNHmUb">
          <p>Refer to <a data-type="xref" href="https://hpbn.co/transport-layer-security-tls/#tls-handshake">TLS Handshake</a> and
          <a data-type="xref" href="https://hpbn.co/transport-layer-security-tls/#tls-record-protocol">TLS Record
          Protocol</a> for a full discussion on the handshake sequence and
          layout of the record protocol.
        </p></div>

        <p>There are no simple workarounds for fixing the TLS handshake
        sequence: each record serves a purpose, each must be sent in the exact
        order required by the handshake algorithm, and some records may easily
        span multiple packets. As a result, DTLS implements a "mini-TCP"
        (<a data-type="xref" href="#dtls-record">Figure&nbsp;18-11</a>) just
        for the handshake sequence.

        </p><figure id="dtls-record">
          <img src="e5cc4abb511e6c74a64dd96d75fa9d07.png" alt="Figure 18-11. DTLS handshake records carry sequence and fragment offsets">

          <figcaption>
            <span class="label">Figure 18-11.</span> DTLS handshake records
            carry sequence and fragment offsets
          </figcaption>
        </figure>

        <p>DTLS extends the base TLS record protocol by adding an explicit
        fragment offset and sequence number for each handshake record. This
        addresses the in-order delivery requirement and allows large records to
        be fragmented across packets and reassembled by the other peer. DTLS
        handshake records are transmitted in the exact order specified by the
        TLS protocol; any other order is an error. Finally, DTLS must also deal
        with packet loss: both sides use simple timers to retransmit handshake
        records if the reply is not received within an expected interval.

        </p><p>The combination of the record sequence number, offset, and
        retransmission timer allows DTLS to perform the handshake
        (<a data-type="xref" href="#dtls-handshake">Figure&nbsp;18-12</a>) over
        UDP. To complete this sequence, both network peers generate self-signed
        certificates and then follow the regular TLS handshake protocol.

        </p><figure id="dtls-handshake">
          <img src="33926d81cc07b922f40ddab7ab00c538.svg" alt="Figure 18-12. Peer-to-peer handshake over DTLS">

          <figcaption>
            <span class="label">Figure 18-12.</span> Peer-to-peer handshake
            over DTLS
          </figcaption>
        </figure>

        <div data-type="note" id="id-Z9Coc5HoUd">
          <p>The DTLS handshake requires two roundtrips to complete—an
          important aspect to keep in mind, as it adds extra latency to setup
          of the peer-to-peer connection.
        </p></div>

        <p>The WebRTC client automatically generates self-signed certificates
        for each peer. As a result, there is no certificate chain to verify.
        DTLS provides encryption and integrity, but defers authentication to
        the application; see <a data-type="xref" href="https://hpbn.co/transport-layer-security-tls/#encryption-authentication-and-integrity">
        Encryption, Authentication, and Integrity</a>. Finally, with the
        handshake requirements satisfied, DTLS adds two important rules to
        account for possible fragmentation and out-of-order processing of
        regular records:

        </p><ul>
          <li>
            <p>DTLS records must fit into a single network packet.

          </p></li><li>
            <p>A block cipher must be used for encrypting record data.
        </p></li></ul>

        <p>A regular TLS record can be up to 16 KB in size. TCP handles the
        fragmentation and reassembly, but UDP provides no such services. As a
        result, to preserve the out-of-order and best-effort semantics of the
        UDP protocol, each DTLS record carrying application data must fit into
        a single UDP packet. Similarly, stream ciphers are disallowed because
        they implicitly rely on in-order delivery of record data.

        </p><aside>
          <h4 id="identity-and-authentication"><a href="#identity-and-authentication" class="anchor">§</a>Identity and
          Authentication</h4>

          <p>The DTLS handshake performed between two WebRTC clients relies on
          self-signed certificates. As a result, the certificates themselves
          cannot be used to authenticate the peer, as there is no explicit
          chain of trust (see <a data-type="xref" href="https://hpbn.co/transport-layer-security-tls/#chain-of-trust-and-certificate-authorities">
          Chain of Trust and Certificate Authorities</a>) to verify. If
          required, the WebRTC application must perform its own authentication
          and identity verification of the participating peers:

          </p><ul>
            <li>
              <p>A web application can use its existing identity verification
              system (e.g., require login to authenticate the user) prior to
              setting up the WebRTC session.

            </p></li><li>
              <p>Alternatively, each participating peer can specify its
              "identity provider" when generating the SDP offer/answer. Then,
              when the SDP message is received, the opposing peer can contact
              the specified identity provider to verify the received
              certificate.
          </p></li></ul>

          <p>The latter "identity provider" mechanism is still under active
          discussion and development in the W3C WebRTC working group. Consult
          the specification and the mailing list for the latest implementation
          status.
        </p></aside>
      </section>

      <section>
        <h3 id="delivering-media-with-srtp-and-srtcp"><a href="#delivering-media-with-srtp-and-srtcp" class="anchor">§</a>Delivering
        Media with SRTP and SRTCP</h3>

        <p>WebRTC provides media acquisition and delivery as a fully managed
        service: from camera to the network, and from network to the screen.
        The WebRTC application specifies the media constraints to acquire the
        streams and then registers them with the RTCPeerConnection object
        (<a data-type="xref" href="#webrtc-media-flow">Figure&nbsp;18-13</a>).
        From there, the rest is handled by the WebRTC media and network engines
        provided by the browser: encoding optimization, dealing with packet
        loss, network jitter, error recovery, flow, control, and more.

        </p><figure id="webrtc-media-flow">
          <img src="b7877f7c09eee79e8dfd7847e0a5930f.svg" alt="Figure 18-13. Audio and video delivery via SRTP over UDP">

          <figcaption>
            <span class="label">Figure 18-13.</span> Audio and video delivery
            via SRTP over UDP
          </figcaption>
        </figure>

        <p>The implication of this architecture is that beyond specifying the
        initial constraints of the acquired media streams (e.g., 720p vs. 360p
        video), the application does not have any direct control over how the
        video is optimized or delivered to the other peer. This design choice
        is intentional: delivering a high-quality, real-time audio and video
        stream over an unreliable transport with fluctuating bandwidth and
        packet latency is a nontrivial problem. The browser solves it for us:

        </p><ul>
          <li>
            <p>Regardless of the quality and size of provided media streams,
            the network stack implements its own flow and congestion control
            algorithms: every connection starts by streaming audio and video at
            a low bitrate (&lt;500 Kbps) and then begins to adjust the quality
            of the streams to match the available bandwidth.

          </p></li><li>
            <p>The media and network engines dynamically adjust the quality of
            the streams throughout the lifespan of the connection to adapt to
            the continuously changing network weather: bandwidth fluctuations,
            packet loss, and network jitter. In other words, WebRTC implements
            its own variant of adaptive streaming (see <a data-type="xref" href="https://hpbn.co/wifi/#adaptive-bitrate-streaming">Adaptive Bitrate
            Streaming</a>).
        </p></li></ul>

        <p>The WebRTC network engine cannot guarantee that an HD video stream
        provided by the application will be delivered at its highest quality:
        there may be insufficient bandwidth between the peers or high packet
        loss. Instead, the engine will attempt to adapt the provided stream to
        match the current conditions of the network.

        </p><div data-type="note" id="id-LWC4I1uOU3">
          <p>An audio or video stream may be delivered at a lower quality than
          that of the original stream acquired by the application. However, the
          inverse is not true: WebRTC will not upgrade the quality of the
          stream. If the application provides a 360p video constraint, then
          that serves as a cap on the amount of bandwidth that will be used.
        </p></div>

        <p>How does WebRTC optimize and adapt the quality of each media stream?
        Turns out WebRTC is not the first application to run up against the
        challenge of implementing real-time audio and video delivery over IP
        networks. As a result, WebRTC is reusing existing transport protocols
        used by VoIP phones, communication gateways, and numerous commercial
        and open source communication services:

        </p><dl>
          <dt>Secure Real-time Transport Protocol (SRTP)

          </dt><dd>
            <p>Secure profile of the standardized format for delivery of
            real-time data, such as audio and video over IP networks.

          </p></dd><dt>Secure Real-time Control Transport Protocol (SRTCP)

          </dt><dd>
            <p>Secure profile of the control protocol for delivery of sender
            and receiver statistics and control information for an SRTP flow.
        </p></dd></dl>

        <div data-type="note" id="id-Z9CyCZuoUd">
          <p>Real-Time Transport Protocol (RTP) is defined by RFC 3550.
          However, WebRTC requires that all communication must be encrypted
          while in transit. As a result, WebRTC uses the "secure profile" (RFC
          3711) of RTP—hence the S in SRTP and SRTCP.
        </p></div>

        <p>SRTP defines a standard packet format (<a data-type="xref" href="#srtp-packet">Figure&nbsp;18-14</a>) for delivering audio and video
        over IP networks. By itself, SRTP does not provide any mechanism or
        guarantees on timeliness, reliability, or error recovery of the
        transferred data. Instead, it simply wraps the digitized audio samples
        and video frames with additional metadata to assist the receiver in
        processing each stream.

        </p><figure id="srtp-packet">
          <img src="e80b19c3f2eb66734051854f9df395bf.svg" alt="Figure 18-14. SRTP header (12 bytes + payload and optional fields)">

          <figcaption>
            <span class="label">Figure 18-14.</span> SRTP header (12 bytes +
            payload and optional fields)
          </figcaption>
        </figure>

        <ul>
          <li>
            <p>Each SRTP packet carries an auto-incrementing sequence number,
            which enables the receiver to detect and account for out-of-order
            delivery of media data.

          </p></li><li>
            <p>Each SRTP packet carries a timestamp, which represents the
            sampling time of the first byte of the media payload. This
            timestamp is used for synchronization of different media
            streams—e.g., audio and video tracks.

          </p></li><li>
            <p>Each SRTP packet carries an SSRC identifier, which is a unique
            stream ID used to associate each packet with an individual media
            stream.

          </p></li><li>
            <p>Each SRTP packet may contain other optional metadata.

          </p></li><li>
            <p>Each SRTP packet carries an encrypted media payload and an
            authentication tag, which verifies the integrity of the delivered
            packet.
        </p></li></ul>

        <p>The SRTP packet provides all the essential information required by
        the media engine for real-time playback of the stream. However, the
        responsibility to control how the individual SRTP packets are delivered
        falls to the SRTCP protocol, which implements a separate, out-of-band
        feedback channel for each media stream.

        </p><p>SRTCP tracks the number of sent and lost bytes and packets, last
        received sequence number, inter-arrival jitter for each SRTP packet,
        and other SRTP statistics. Then, periodically, both peers exchange this
        data and use it to adjust the sending rate, encoding quality, and other
        parameters of each stream.

        </p><p>In short, SRTP and SRTCP run directly over UDP and work together to
        adapt and optimize the real-time delivery of the audio and video
        streams provided by the application. The WebRTC application is never
        exposed to the internals of SRTP or SRTCP protocols: if you are
        building a custom WebRTC client, then you will have to deal with these
        protocols directly, but otherwise, the browser implements all the
        necessary infrastructure on your behalf.

        </p><div data-type="note" id="id-59CaFVunUQ">
          <p>Curious to see SRTCP statistics for your WebRTC session? Check the
          latency, bitrate, and bandwidth reports in Chrome; see <a data-type="xref" href="#inspecting-webrtc-connection-status-with-google-chrome">Inspecting
          WebRTC Connection Status with Google Chrome</a>.
        </p></div>

        <aside>
          <h4 id="adapting-srtp-and-srtcp-for-webrtc"><a href="#adapting-srtp-and-srtcp-for-webrtc" class="anchor">§</a>Adapting
          SRTP and SRTCP for WebRTC</h4>

          <p>Our whirlwind tour of SRTP and SRTCP covers the highlights of each
          protocol, but for implementers, there are many additional details
          that must be taken into account to make these protocols compatible
          with WebRTC requirements:

          </p><ul>
            <li>
              <p>Both SRTP and SRTCP encrypt application payload data (a WebRTC
              requirement), but neither protocol provides a mechanism to
              negotiate the secret keys! This is why the DTLS handshake must
              run first: the DTLS handshake establishes a shared secret between
              the peers, which is then reused as keying material within SRTP
              and SRTCP.

            </p></li><li>
              <p>Both SRTP and SRTCP require separate ports for each individual
              stream, which of course is a problem for clients behind NATs and
              firewalls. To address this, WebRTC uses an additional
              multiplexing extension to enable the delivery of multiple streams
              (and their control channels) on the same destination port.

            </p></li><li>
              <p>The IETF working group is also developing new
              congestion-control algorithms, which leverage the SRTCP feedback
              to optimize the delivery of audio and video streams generated by
              WebRTC applications.
          </p></li></ul>

          <p>In short, there is a lot more to it than simply firing off UDP
          packets with digitized audio and video data! Thankfully, the WebRTC
          media and network engines handle all of this complexity on our
          behalf. Adapting and improving SRTP and SRTCP performance is an area
          of ongoing research both at the standards level and for the
          implementers.
        </p></aside>
      </section>

      <section>
        <h3 id="delivering-application-data-with-sctp"><a href="#delivering-application-data-with-sctp" class="anchor">§</a>Delivering
        application data with SCTP</h3>

        <p>In addition to transferring audio and video data, WebRTC allows
        peer-to-peer transfers of arbitrary application data via the
        DataChannel API. The SRTP protocol we covered in the previous section
        is specifically designed for media transfers and unfortunately is not a
        suitable transport for application data. As a result, DataChannel
        relies on the Stream Control Transmission Protocol (SCTP), which runs
        on top (<a data-type="xref" href="#webrtc-stack">Figure&nbsp;18-3</a>)
        of the established DTLS tunnel between the peers.

        </p><p>However, before we dive into the SCTP protocol itself, let’s first
        examine the WebRTC requirements for the RTCDataChannel interface and
        its transport protocol:

        </p><ul>
          <li>
            <p>Transport must support multiplexing of multiple independent
            channels.

            </p><ul>
              <li>
                <p>Each channel must support in-order or out-of-order delivery.

              </p></li><li>
                <p>Each channel must support reliable or unreliable delivery.

              </p></li><li>
                <p>Each channel may have a priority level defined by the
                application.
            </p></li></ul>

          </li><li>
            <p>Transport must provide a message-oriented API.

            </p><ul>
              <li>
                <p>Each application message may be fragmented and reassembled
                by the transport.
            </p></li></ul>

          </li><li>
            <p>Transport must implement flow and congestion control mechanisms.

          </p></li><li>
            <p>Transport must provide confidentiality and integrity of
            transferred data.
        </p></li></ul>

        <p>The good news is that the use of DTLS already satisfies the last
        criteria: all application data is encrypted within the payload of the
        record, and confidentiality and integrity are guaranteed. However, the
        remaining requirements are a nontrivial set to satisfy! UDP provides
        unreliable, out-of-order datagram delivery, but we also need TCP-like
        reliable delivery, channel multiplexing, priority support, message
        fragmentation, and more. That’s where SCTP comes in.

        </p><figure id="comparing-tcp-udp-sctp-table">
          <table>
            <thead>
              <tr>
                <th>

                </th><th>TCP

                </th><th>UDP

                </th><th>SCTP

            </th></tr></thead><tbody>
              <tr>
                <td>Reliability

                </td><td>reliable

                </td><td>unreliable

                </td><td>configurable

              </td></tr><tr>
                <td>Delivery

                </td><td>ordered

                </td><td>unordered

                </td><td>configurable

              </td></tr><tr>
                <td>Transmission

                </td><td>byte-oriented

                </td><td>message-oriented

                </td><td>message-oriented

              </td></tr><tr>
                <td>Flow control

                </td><td>yes

                </td><td>no

                </td><td>yes

              </td></tr><tr>
                <td>Congestion control

                </td><td>yes

                </td><td>no

                </td><td>yes
          </td></tr></tbody></table>

          <figcaption>
            <span class="label">Table 18-1.</span> Comparing TCP vs. UDP vs.
            SCTP
          </figcaption>
        </figure>

        <div data-type="note" id="id-b4CpIOIKUj">
          <p>SCTP is a transport protocol, similar to TCP and UDP, which can
          run directly on top of the IP protocol. However, in the case of
          WebRTC, SCTP is tunneled over a secure DTLS tunnel, which itself runs
          on top of UDP.
        </p></div>

        <p>SCTP provides the best features of TCP and UDP: message-oriented
        API, configurable reliability and delivery semantics, and built-in flow
        and congestion-control mechanisms. A full analysis of the protocol is
        outside the scope of our discussion, but, briefly, let’s introduce some
        SCTP concepts and terminology:

        </p><dl>
          <dt>Association

          </dt><dd>
            <p>A synonym for a connection.

          </p></dd><dt>Stream

          </dt><dd>
            <p>A unidirectional channel within which application messages are
            delivered in sequence, unless the channel is configured to use the
            unordered delivery service.

          </p></dd><dt>Message

          </dt><dd>
            <p>Application data submitted to the protocol.

          </p></dd><dt>Chunk

          </dt><dd>
            <p>The smallest unit of communication within an SCTP packet.
        </p></dd></dl>

        <p>A single SCTP association between two endpoints may carry multiple
        independent streams, each of which communicates by transferring
        application messages. In turn, each message may be split into one or
        more chunks, which are delivered within SCTP packets (<a data-type="xref" href="#sctp-packet">Figure&nbsp;18-15</a>) and then get
        reassembled at the other end.

        </p><p>Does this description sound familiar? It definitely should! The
        terms are different, but the core concepts are identical to those of
        the HTTP/2 framing layer; see <a data-type="xref" href="https://hpbn.co/http2/#streams-messages-and-frames">Streams, Messages, and
        Frames</a>. The difference here is that SCTP implements this
        functionality at a "lower layer," which enables efficient transfer and
        multiplexing of arbitrary application data.

        </p><figure id="sctp-packet">
          <img src="e86b7a4f06d7dad1ce67ee4646c3941b.svg" alt="Figure 18-15. SCTP header and data chunk">

          <figcaption>
            <span class="label">Figure 18-15.</span> SCTP header and data chunk
          </figcaption>
        </figure>

        <p>An SCTP packet consists of a common header and one or more control
        or data chunks. The header carries 12 bytes of data, which identify the
        source and destination ports, a randomly generated verification tag for
        the current SCTP association, and the checksum for the entire packet.
        Following the header, the packet carries one or more control or data
        chunks; the previous diagram is showing an SCTP packet with a single
        data chunk:

        </p><ul>
          <li>
            <p>All data chunks have a 0×0 data type.

          </p></li><li>
            <p>The unordered (U) bit indicates whether this is an unordered
            DATA chunk.

          </p></li><li>
            <p>B and E bits are used to indicate the beginning and end of a
            message split across multiple chunks: B=1, E=0 indicates the first
            fragment of a message; B=0, E=0 indicates a middle piece; B=0, E=1
            indicates the last fragment; B=1, E=1 indicates an unfragmented
            message.

          </p></li><li>
            <p>Length indicates the size of the DATA chunk, which includes the
            header—i.e., 16 bytes for chunk header, plus size of payload data.

          </p></li><li>
            <p><em>Transmission sequence number (TSN)</em> is a 32-bit number
            used internally by SCTP to acknowledge receipt of the packet and
            detect duplicate deliveries.

          </p></li><li>
            <p><em>Stream identifier</em> indicates the stream to which the
            chunk belongs.

          </p></li><li>
            <p><em>Stream sequence number</em> is an auto-incremented message
            number for the associated stream; fragmented messages carry the
            same sequence number.

          </p></li><li>
            <p><em>Payload protocol identifier (PPID)</em> is a custom field
            filled in by the application to communicate additional metadata
            about the transferred chunk.
        </p></li></ul>

        <div data-type="note" id="id-dOC4SAIyUb">
          <p>DataChannel uses the PPID field in the SCTP header to communicate
          the type of transferred data: 0×51 for UTF-8 and 0×52 for binary
          application payloads.
        </p></div>

        <p>That’s a lot of detail to absorb in one go. Let’s review it once
        again, this time in the context of the earlier WebRTC and DataChannel
        API requirements:

        </p><ul>
          <li>
            <p>The SCTP header contains a few redundant fields: we are
            tunneling SCTP over UDP, which already specifies the source and
            destination ports (<a data-type="xref" href="https://hpbn.co/building-blocks-of-udp/#udp-header">Figure&nbsp;3-2</a>).

          </p></li><li>
            <p>SCTP handles message fragmentation with the help of the
            <code>B</code>, <code>E</code> and <code>TSN</code> fields in the
            header: each chunk indicates its position (first, middle, or last),
            and the TSN value is used to order the middle chunks.

          </p></li><li>
            <p>SCTP supports stream multiplexing: each stream has a unique
            stream identifier, which is used to associate each data chunk with
            one of the active streams.
        </p></li></ul>

        <ul>
          <li>
            <p>SCTP assigns an individual sequence number to each application
            message, which allows it to provide in-order delivery semantics.
            Optionally, if the unordered bit is set, then SCTP continues to use
            the sequence number to handle message fragmentation, but can
            deliver individual messages out of order.
        </p></li></ul>

        <div data-type="note" id="id-86CZH8I5UN">
          <p>In total, SCTP adds 28 bytes of overhead to each data chunk: 12
          bytes for the common header and 16 bytes for the data chunk header
          followed by the application payload.
        </p></div>

        <p>How does an SCTP negotiate the starting parameters for the
        association? Each SCTP connection requires a handshake sequence similar
        to TCP! Similarly, SCTP also implements TCP-friendly flow and
        congestion control mechanisms: both protocols use the same initial
        congestion window size and implement similar logic to grow and reduce
        the congestion window once the connection enters the
        congestion-avoidance phase.

        </p><div data-type="note" id="id-1pCGIjIoUa">
          <p>For a review on TCP handshake latencies, slow-start, and flow
          control, refer to <a data-type="xref" href="https://hpbn.co/building-blocks-of-tcp/">Building Blocks of TCP</a>. The SCTP
          handshake and congestion and flow-control algorithms used for WebRTC
          are different but serve the same purpose and have similar costs and
          performance implications.
        </p></div>

        <p>We are getting close to satisfying all the WebRTC requirements, but
        unfortunately, even with all of that functionality, we are still short
        of a few required features:

        </p><ol>
          <li>
            <p>The base SCTP standard (RFC 4960) provides a mechanism for
            unordered delivery of messages but no facilities for configuring
            the reliability of each message. To address this, WebRTC clients
            must also use the "Partial Reliability Extension" (RFC 3758), which
            extends the SCTP protocol and allows the sender to implement custom
            delivery guarantees, a critical feature for DataChannel.

          </p></li><li>
            <p>SCTP does not provide any facilities for prioritizing individual
            streams; there are no fields within the protocol to carry the
            priority. As a result, this functionality has to be implemented
            higher in the stack.
        </p></li></ol>

        <p>In short, SCTP provides similar services as TCP, but because it is
        tunneled over UDP and is implemented by the WebRTC client, it offers a
        much more powerful API: in-order and out-of-order delivery, partial
        reliability, message-oriented API, and more. At the same time, SCTP is
        also subject to handshake latencies, slow-start, and flow and
        congestion control—all critical components to consider when thinking
        about performance of the DataChannel API.

        </p><aside>
          <h4 id="challenges-with-naked-sctp"><a href="#challenges-with-naked-sctp" class="anchor">§</a>Challenges with
          "Naked SCTP"</h4>

          <p>The use of a message-oriented API is what allows SCTP to avoid the
          head-of-line blocking problem of stream-oriented protocols like TCP;
          see <a data-type="xref" href="https://hpbn.co/building-blocks-of-tcp/#head-of-line-blocking">Head-of-Line
          Blocking</a>. Similarly, this same mechanism is what enables SCTP to
          allow configurable delivery models: in-order vs. out-of-order and
          reliable vs. partially reliable delivery.

          </p><p>With that in mind, why not just switch all communication to SCTP
          and run it directly on top of the IP protocol? Doing so would
          eliminate the need for UDP and also resolve the outstanding issues
          for delivery of HTTP/2 over TCP; see <a data-type="xref" href="https://hpbn.co/http2/#packet-loss-high-rtt-links-and-http2-performance">Packet
          Loss, High-RTT Links, and HTTP/2 Performance</a>. In fact, SCTP would
          automatically resolve most of the issues addressed by HTTP/2; we
          could dramatically simplify the HTTP protocol as well!

          </p><p>Alas, existing routers and NAT devices simply don’t handle SCTP
          correctly, which makes it near impossible to use SCTP as a "naked
          transport protocol" on the public Internet. As a result, WebRTC
          tunnels SCTP over UDP and DTLS. The protocol is implemented in "user
          space" by the WebRTC client.

          </p><p>In a controlled environment, such as an internal network, SCTP can
          deliver great results; e.g., many mobile carriers use SCTP to
          transport data from the radio tower and through their core networks
          until the packets have to exit to the public Internet. For more
          discussions on the topic, refer to <a href="http://tools.ietf.org/html/draft-ietf-behave-sctpnat"><em class="hyperlink">http://tools.ietf.org/html/draft-ietf-behave-sctpnat</em></a>.
        </p></aside>
      </section>
    </section>

    <section>
      <h2 id="datachannel"><a href="#datachannel" class="anchor">§</a>DataChannel</h2>

      <p>DataChannel enables bidirectional exchange of arbitrary application
      data between peers—think WebSocket, but peer-to-peer, and with
      customizable delivery properties of the underlying transport. Once the
      RTCPeerConnection is established, connected peers can open one or more
      channels to exchange text or binary data:

      </p><div data-type="example" id="-pPCgFzfL">
        <pre data-type="programlisting">function handleChannel(chan) { <a class="counter" id="handledc-co" href="#handledc"></a>
  chan.onerror = function(error) { ... }
  chan.onclose = function() { ... }

  chan.onopen = function(evt) {
    chan.send("DataChannel connection established. Hello peer!")
  }

  chan.onmessage = function(msg) {
    if(msg.data instanceof Blob) {
      processBlob(msg.data);
    } else {
      processText(msg.data);
    }
  }
}

var signalingChannel = new SignalingChannel();
var pc = new RTCPeerConnection(iceConfig);

var dc = pc.createDataChannel("namedChannel", {reliable: false}); <a class="counter" id="ndc-co" href="#ndc"></a>

... <a class="counter" id="ndcoa-co" href="#ndcoa"></a>

handleChannel(dc); <a class="counter" id="handlelocal-co" href="#handlelocal"></a>
pc.ondatachannel = handleChannel; <a class="counter" id="handleremote-co" href="#handleremote"></a>
</pre>

        <ol class="notation">
          <li>
            <a class="co" id="handledc" href="#handledc-co"></a>

            <p>Register WebSocket-like callbacks on DataChannel object

          </p></li><li>
            <a class="co" id="ndc" href="#ndc-co"></a>

            <p>Initialize new DataChannel with best-effort delivery semantics

          </p></li><li>
            <a class="co" id="ndcoa" href="#ndcoa-co"></a>

            <p>Regular RTCPeerConnection offer/answer code

          </p></li><li>
            <a class="co" id="handlelocal" href="#handlelocal-co"></a>

            <p>Register callbacks on locally initialized DataChannel

          </p></li><li>
            <a class="co" id="handleremote" href="#handleremote-co"></a>

            <p>Register callbacks on DataChannel initiated by remote peer
        </p></li></ol>
      </div>

      <p>The DataChannel API intentionally mirrors that of WebSocket: each
      established channel fires the same <code>onerror</code>,
      <code>onclose</code>, <code>onopen</code>, and <code>onmessage</code>
      callbacks, as well as exposes the same <code>binaryType</code>,
      <code>bufferedAmount</code>, and <code>protocol</code> fields on the
      channel.

      </p><p>However, because DataChannel is peer-to-peer and runs over a more
      flexible transport protocol, it also offers a number of additional
      features not available to WebSocket. The preceding code example
      highlights some of the most important differences:

      </p><ul>
        <li>
          <p>Unlike the WebSocket constructor, which expects the URL of the
          WebSocket server, DataChannel is a factory method on the
          RTCPeerConnection object.

        </p></li><li>
          <p>Unlike WebSocket, either peer can initiate a new DataChannel
          session: the <code>ondatachannel</code> callback is fired when a new
          DataChannel session is established.

        </p></li><li>
          <p>Unlike WebSocket, which runs on top of reliable and in-order TCP
          transport, each DataChannel can be configured with custom delivery
          and reliability semantics.
      </p></li></ul>

      <aside>
        <h4 id="datachannel-vs-websocket-apis"><a href="#datachannel-vs-websocket-apis" class="anchor">§</a>DataChannel vs.
        WebSocket APIs</h4>

        <p>DataChannel API is a superset of the WebSocket API. As a result, all
        of our previous discussions about the WebSocket callbacks, flags,
        optimizations for processing of text and binary data, and subprotocol
        negotiation are directly applicable to the DataChannel API; refer to
        <a data-type="xref" href="https://hpbn.co/websocket/#websocket-api">WebSocket API</a>.

        </p><figure id="websocket-vs-datachannel-table">
          <table>
            <thead>
              <tr>
                <th>

                </th><th>WebSocket

                </th><th>DataChannel

            </th></tr></thead><tbody>
              <tr>
                <td>Encryption

                </td><td>configurable

                </td><td>always

              </td></tr><tr>
                <td>Reliability

                </td><td>reliable

                </td><td>configurable

              </td></tr><tr>
                <td>Delivery

                </td><td>ordered

                </td><td>configurable

              </td></tr><tr>
                <td>Multiplexed

                </td><td>no (extension)

                </td><td>yes

              </td></tr><tr>
                <td>Transmission

                </td><td>message-oriented

                </td><td>message-oriented

              </td></tr><tr>
                <td>Binary transfers

                </td><td>yes

                </td><td>yes

              </td></tr><tr>
                <td>UTF-8 transfers

                </td><td>yes

                </td><td>yes

              </td></tr><tr>
                <td>Compression

                </td><td>no (extension)

                </td><td>no
          </td></tr></tbody></table>

          <figcaption>
            <span class="label">Table 18-2.</span> WebSocket vs. DataChannel
          </figcaption>
        </figure>

        <p>The biggest difference between WebSocket and DataChannel is, of
        course, the underlying transport. WebSocket runs on top of TCP, which
        provides reliable and in-order delivery of each message, whereas
        DataChannel is layered on top of three protocols:

        </p><ul>
          <li>
            <p>UDP provides peer-to-peer connectivity.

          </p></li><li>
            <p>DTLS provides encryption of transferred data.

          </p></li><li>
            <p>SCTP provides multiplexing, flow and congestion control, and
            other features.
        </p></li></ul>

        <p>DataChannel can be configured to deliver the same reliability and
        in-order message guarantees as WebSocket. Although, more importantly,
        the real power of DataChannel is precisely due to the fact that it
        doesn’t have to follow the in-order and reliable delivery semantics!
        Each channel can specify its own delivery and reliability requirements,
        and the data can be transferred directly peer to peer.
      </p></aside>

      <section>
        <h3 id="setup-and-negotiation"><a href="#setup-and-negotiation" class="anchor">§</a>Setup and Negotiation</h3>

        <p>Regardless of the type of transferred data—audio, video, or
        application data—the two participating peers must first complete the
        full offer/answer workflow, negotiate the used protocols and ports, and
        successfully complete their connectivity checks; see <a data-type="xref" href="#establishing-a-peer-to-peer-connection">Establishing a
        Peer-to-Peer Connection</a>.

        </p><p>In fact, as we now know, media transfers run over SRTP, whereas
        DataChannel uses the SCTP protocol. As a result, when the initiating
        peer first makes the connection offer, or when the answer is generated
        by the other peer, the two must specifically advertise the parameters
        for the SCTP association within the generated SDP strings:

        </p><div data-type="example" id="-LWC7h4tRf3">
          <pre data-type="programlisting">(... snip ...)
m=application 1 DTLS/SCTP 5000 <a class="counter" id="dtlssctp-co" href="#dtlssctp"></a>
c=IN IP4 0.0.0.0 <a class="counter" id="dcice-co" href="#dcice"></a>
a=mid:data
a=fmtp:5000 protocol=webrtc-datachannel; streams=10 <a class="counter" id="sctpstreams-co" href="#sctpstreams"></a>
(... snip ...)
</pre>

          <ol class="notation">
            <li>
              <a class="co" id="dtlssctp" href="#dtlssctp-co"></a>

              <p>Advertise intent to use SCTP over DTLS

            </p></li><li>
              <a class="co" id="dcice" href="#dcice-co"></a>

              <p>0.0.0.0 candidate indicates use of trickle ICE

            </p></li><li>
              <a class="co" id="sctpstreams" href="#sctpstreams-co"></a>

              <p>DataChannel protocol over SCTP with up to 10 parallel streams
          </p></li></ol>
        </div>

        <p>As previously, the RTCPeerConnection object handles all the
        necessary generation of the SDP parameters as long as one of the peers
        registers a DataChannel prior to generating the SDP description of the
        session. In fact, the application can establish a data-only
        peer-to-peer connection by setting explicit constraints to disable
        audio and video transfers:

        </p><div data-type="example" id="-RkCmujt8fZ">
          <pre data-type="programlisting">var signalingChannel = new SignalingChannel();
var pc = new RTCPeerConnection(iceConfig);

var dc = pc.createDataChannel("namedChannel", {reliable: false}); <a class="counter" id="dcchan-co" href="#dcchan"></a>

var mediaConstraints = { <a class="counter" id="dcconst-co" href="#dcconst"></a>
  mandatory: {
      OfferToReceiveAudio: false,
      OfferToReceiveVideo: false
  }
};

pc.createOffer(function(offer) { ... }, null, mediaConstraints); <a class="counter" id="dcoffer-co" href="#dcoffer"></a>

...
</pre>

          <ol class="notation">
            <li>
              <a class="co" id="dcchan" href="#dcchan-co"></a>

              <p>Register new unreliable DataChannel with RTCPeerConnection

            </p></li><li>
              <a class="co" id="dcconst" href="#dcconst-co"></a>

              <p>Set media constraints to disable audio and video transfers

            </p></li><li>
              <a class="co" id="dcoffer" href="#dcoffer-co"></a>

              <p>Generate data-only offer
          </p></li></ol>
        </div>

        <p>With the SCTP parameters negotiated between the peers, we are almost
        ready to begin exchanging application data. Notice that the SDP snippet
        we saw earlier doesn’t mention anything about the parameters of each
        DataChannel—e.g., protocol, reliability, or in-order or out-of-order
        flags. As a result, before any application data can be sent, the WebRTC
        client initiating the connection also sends a
        <code>DATA_CHANNEL_OPEN</code> message (<a data-type="xref" href="#data-channel-open">Figure&nbsp;18-16</a>) which describes the type,
        reliability, used application protocol, and other parameters of the
        channel.

        </p><figure id="data-channel-open">
          <img src="7695893485cffda5a58d1500a1dd2d7f.svg" alt="Figure 18-16. DATA_CHANNEL_OPEN message initiates new channel">

          <figcaption>
            <span class="label">Figure 18-16.</span> DATA_CHANNEL_OPEN message
            initiates new channel
          </figcaption>
        </figure>

        <div data-type="note" id="id-exCxTLtPfO">
          <p>The <code>DATA_CHANNEL_OPEN</code> message is similar to the
          <code>HEADERS</code> frame in HTTP/2: it implicitly opens a new
          stream, and data frames can be sent immediately after it; see
          <a data-type="xref" href="https://hpbn.co/http2/#initiating-a-new-stream">Initiating
          a New Stream</a>. For more information on the DataChannel protocol,
          refer to <a href="http://tools.ietf.org/html/draft-jesup-rtcweb-data-protocol"><em class="hyperlink">
          http://tools.ietf.org/html/draft-jesup-rtcweb-data-protocol</em></a>.
        </p></div>

        <p>Once the channel parameters are communicated, both peers can begin
        exchanging application data. Under the hood, each established channel
        is delivered as an independent SCTP stream: the channels are
        multiplexed over the same SCTP association, which avoids head-of-line
        blocking between the different streams and allows for simultaneous
        delivery of multiple channels over the same SCTP association.

        </p><aside>
          <h4 id="out-of-band-channel-negotiation"><a href="#out-of-band-channel-negotiation" class="anchor">§</a>Out-of-Band
          Channel Negotiation</h4>

          <p>DataChannel also allows out-of-band negotiation of channel
          parameters. When calling the <code>createDataChannel</code> method,
          the application can set the <code>negotiated</code> parameter to
          <code>true</code>, which skips the automatic dispatch of the
          <code>DATA_CHANNEL_OPEN</code> message. However, when doing so, both
          peers also have to specify the same <code>id</code> parameter, which
          is otherwise automatically generated by the browser:

          </p><div data-type="example" id="-dOCRFpcMtxfW">
            <pre data-type="programlisting">signalingChannel.send({ <a class="counter" id="dcnewgchan-co" href="#dcnewgchan"></a>
  newchannel: true,
  label: "negotiated channel",
  options: {
    negotiated: true,
    id: 10, <a class="counter" id="dcid-co" href="#dcid"></a>
    reliable: true,
    ordered: true,
    protocol: "appProtocol-v3"
  }
});

signalingChannel.onmessage = function(msg) {
  if (msg.newchannel) { <a class="counter" id="dcnewchan-co" href="#dcnewchan"></a>
    dc = pc.createDataChannel(msg.label, msg.options);
  }
}
</pre>

            <ol class="notation">
              <li>
                <a class="co" id="dcnewgchan" href="#dcnewgchan-co"></a>

                <p>Send channel configuration via signaling channel to the
                other peer

              </p></li><li>
                <a class="co" id="dcid" href="#dcid-co"></a>

                <p>Unique, application-specified channel ID (integer)

              </p></li><li>
                <a class="co" id="dcnewchan" href="#dcnewchan-co"></a>

                <p>Initialize new DataChannel using received parameters
            </p></li></ol>
          </div>

          <p>In practice, there are no additional performance benefits to using
          out-of-band negotiation with few participating peers. Let the
          RTCPeerConnection object handle the negotiation for you. However,
          where this workflow can be useful is in cases with many participating
          peers, where the signaling server can generate the same description
          and simultaneously distribute it to all the participating parties.
        </p></aside>
      </section>

      <section>
        <h3 id="configuring-message-order-and-reliability"><a href="#configuring-message-order-and-reliability" class="anchor">§</a>Configuring Message Order and Reliability</h3>

        <p>DataChannel enables peer-to-peer transfers of arbitrary application
        data via a WebSocket-compatible API: this by itself is a unique and a
        powerful feature. However, DataChannel also offers a much more flexible
        transport, which allows us to customize the delivery semantics of each
        channel to match the requirements of the application and the type of
        data being transferred.

        </p><ul>
          <li>
            <p>DataChannel can provide in-order or out-of-order delivery of
            messages.

          </p></li><li>
            <p>DataChannel can provide reliable or partially reliable delivery
            of messages.
        </p></li></ul>

        <p>Configuring the channel to use in-order and reliable delivery is, of
        course, equivalent to TCP: the same delivery guarantees as a regular
        WebSocket connection. However, and this is where it starts to get
        really interesting, DataChannel also offers two different policies for
        configuring partial reliability of each channel:

        </p><dl>
          <dt>Partially reliable delivery with retransmit

          </dt><dd>
            <p>Messages will not be retransmitted more times than specified by
            the application.

          </p></dd><dt>Partially reliable delivery with timeout

          </dt><dd>
            <p>Messages will not be retransmitted after a specified lifetime
            (in milliseconds) by the application.
        </p></dd></dl>

        <p>Both strategies are implemented by the WebRTC client, which means
        that all the application has to do is decide on the appropriate
        delivery model and set the right parameters on the channel. There is no
        need to manage application timers or retransmission counters. Let’s
        take a closer look at our configuration options:

        </p><figure id="datachannel-reliability-table">
          <table>
            <thead>
              <tr>
                <th>

                </th><th>Ordered

                </th><th>Reliable

                </th><th>Partial reliability policy

            </th></tr></thead><tbody>
              <tr>
                <td>Ordered + reliable

                </td><td>yes

                </td><td>yes

                </td><td>n/a

              </td></tr><tr>
                <td>Unordered + reliable

                </td><td>no

                </td><td>yes

                </td><td>n/a

              </td></tr><tr>
                <td>Ordered + partially reliable (retransmit)

                </td><td>yes

                </td><td>partial

                </td><td>retransmission count

              </td></tr><tr>
                <td>Unordered + partially reliable (retransmit)

                </td><td>no

                </td><td>partial

                </td><td>retransmission count

              </td></tr><tr>
                <td>Ordered + partially reliable (timed)

                </td><td>yes

                </td><td>partial

                </td><td>timeout (ms)

              </td></tr><tr>
                <td>Unordered + partially reliable (timed)

                </td><td>no

                </td><td>partial

                </td><td>timeout (ms)
          </td></tr></tbody></table>

          <figcaption>
            <span class="label">Table 18-3.</span> DataChannel reliability and
            delivery configurations
          </figcaption>
        </figure>

        <p>Ordered and reliable delivery is self-explanatory: it’s TCP. On the
        other hand, unordered and reliable delivery is already much more
        interesting—it’s TCP, but without the head-of-line blocking problem;
        see <a data-type="xref" href="https://hpbn.co/building-blocks-of-tcp/#head-of-line-blocking">Head-of-Line
        Blocking</a>.

        </p><p>When configuring a partially reliable channel, it is important to
        keep in mind that the two retransmission strategies are mutually
        exclusive. The application can specify either a timeout or a
        retransmission count, but not both; doing so will raise an error. With
        that, let’s take a look at the JavaScript API for configuring the
        channel:

        </p><div data-type="example" id="-xACoCGT2f8">
          <pre data-type="programlisting">
conf = {}; <a class="counter" id="dcdefault-co" href="#dcdefault"></a>
conf = { ordered: false };  <a class="counter" id="dcunordered-co" href="#dcunordered"></a>
conf = { ordered: true,  maxRetransmits: customNum };  <a class="counter" id="dcoc-co" href="#dcoc"></a>
conf = { ordered: false, maxRetransmits: customNum };  <a class="counter" id="dcuc-co" href="#dcuc"></a>
conf = { ordered: true,  maxRetransmitTime: customMs };  <a class="counter" id="dcot-co" href="#dcot"></a>
conf = { ordered: false, maxRetransmitTime: customMs };  <a class="counter" id="dcut-co" href="#dcut"></a>

conf = { ordered: false, maxRetransmits: 0 };  <a class="counter" id="dcudp-co" href="#dcudp"></a>

var signalingChannel = new SignalingChannel();
var pc = new RTCPeerConnection(iceConfig);

...

var dc = pc.createDataChannel("namedChannel", conf);  <a class="counter" id="dccreate-co" href="#dccreate"></a>

if (dc.reliable) {
  ...
} else {
  ...
}
</pre>

          <ol class="notation">
            <li>
              <a class="co" id="dcdefault" href="#dcdefault-co"></a>

              <p>Default to ordered and reliable delivery (TCP)

            </p></li><li>
              <a class="co" id="dcunordered" href="#dcunordered-co"></a>

              <p>Reliable, unordered delivery

            </p></li><li>
              <a class="co" id="dcoc" href="#dcoc-co"></a>

              <p>Ordered, partially reliable with custom retransmit count

            </p></li><li>
              <a class="co" id="dcuc" href="#dcuc-co"></a>

              <p>Unordered, partially reliable with custom retransmit count

            </p></li><li>
              <a class="co" id="dcot" href="#dcot-co"></a>

              <p>Ordered, partially reliable with custom retransmit timeout

            </p></li><li>
              <a class="co" id="dcut" href="#dcut-co"></a>

              <p>Unordered, partially reliable with custom retransmit timeout

            </p></li><li>
              <a class="co" id="dcudp" href="#dcudp-co"></a>

              <p>Unordered, unreliable delivery (UDP)

            </p></li><li>
              <a class="co" id="dccreate" href="#dccreate-co"></a>

              <p>Initialize DataChannel with specified order and reliability
              configuration
          </p></li></ol>
        </div>

        <div data-type="note" id="id-3MCQcATqf6">
          <p>Once a DataChannel is initialized, the application can access the
          <code>maxRetransmits</code> and <code>maxRetransmitTime</code> as
          read-only attributes. Also, as a convenience, the DataChannel
          provides a <code>reliable</code> attribute, which returns false if
          either of the partial-reliability strategies are used.
        </p></div>

        <p>Each DataChannel can be configured with custom order and reliability
        parameters, and the peers can open multiple channels, all of which will
        be multiplexed over the same SCTP association. As a result, each
        channel is independent of the others, and the peers can use different
        channels for different types of data—e.g., reliable and in-order
        delivery for peer-to-peer chat and partially reliable and out-of-order
        delivery for transient or low-priority application updates.
      </p></section>

      <section>
        <h3 id="partially-reliable-delivery-and-message-size"><a href="#partially-reliable-delivery-and-message-size" class="anchor">§</a>Partially Reliable Delivery and Message Size</h3>

        <p>The use of a partially reliable channel requires additional design
        consideration from the application. Specifically, the application must
        pay close attention to the message size: nothing is stopping the
        application from passing in a large message, which will be fragmented
        across multiple packets, but doing so will likely yield very poor
        results. To illustrate this in action, let’s assume the following
        scenario:

        </p><ul>
          <li>
            <p>Two peers have negotiated an out-of-order, unreliable
            DataChannel.

            </p><ul>
              <li>
                <p>The channel is configured with maxRetransmits set to 0, aka
                plain UDP.
            </p></li></ul>

          </li><li>
            <p>The packet loss between the peers is ~1%.

          </p></li><li>
            <p>One of the peers is trying to send a large, 120 KB message.
        </p></li></ul>

        <p>WebRTC clients set the maximum transmission unit for an SCTP packet
        to 1,280 bytes, which is the minimum and recommended MTU for an IPv6
        packet. But we must also account for the overhead of IP, UDP, DTLS, and
        SCTP protocols: 20–40 bytes, 8 bytes, 20–40 bytes, and 28 bytes,
        respectively. Let’s round this up to ~130 bytes of overhead, which
        leaves us with ~1,150 bytes of payload data per packet and a total of
        107 packets to deliver the 120 KB application message.

        </p><p>So far so good, but the packet loss probability for each individual
        packet is 1%. As a result, if we fire off all 107 packets over the
        unreliable channel, we are now looking at a very high probability of
        losing at least one of them en route! What will happen in this case?
        Even if all but one of the packets make it, the entire message will be
        dropped.

        </p><p>To address this, an application has two strategies: it can add a
        retransmit strategy (based on count or timeout), and it can decrease
        the size of the transferred message. In fact, for best results, it
        should do both.

        </p><ul>
          <li>
            <p>When using an unreliable channel, ideally, each message should
            fit into a single packet; the message should be less than 1,150
            bytes in size.

          </p></li><li>
            <p>If a message cannot fit into a single packet, then a retransmit
            strategy should be used to improve the odds of delivering the
            message.
        </p></li></ul>

        <p>Packet-loss rates and latency between the peers are unpredictable
        and vary based on current network weather. As a result, there is no one
        single and optimal setting for the retransmit count or timeout values.
        To deliver the best results over an unreliable channel, keep the
        messages as small as possible.
      </p></section>
    </section>

    <section>
      <h2 id="webrtc-use-cases-and-performance"><a href="#webrtc-use-cases-and-performance" class="anchor">§</a>WebRTC Use Cases
      and Performance</h2>

      <p>Implementing a low-latency, peer-to-peer transport is a nontrivial
      engineering challenge: there are NAT traversals and connectivity checks,
      signaling, security, congestion control, and myriad other details to take
      care of. WebRTC handles all of the above and more, on our behalf, which
      is why it is arguably one of the most significant additions to the web
      platform since its inception. In fact, it’s not just the individual
      pieces offered by WebRTC, but the fact that all the components work
      together to deliver a simple and unified API for building peer-to-peer
      applications in the browser.

      </p><p>However, even with all the built-in services, designing efficient and
      high-performance peer-to-peer applications still requires a great amount
      of careful thought and planning: peer-to-peer does not mean high
      performance on its own. If anything, the increased variability in
      bandwidth and latency between the peers, and the high demands of media
      transfers, as well as the peculiarities of unreliable delivery, make it
      an even harder engineering challenge.

      </p><section>
        <h3 id="audio-video-and-data-streaming"><a href="#audio-video-and-data-streaming" class="anchor">§</a>Audio, Video, and
        Data Streaming</h3>

        <p>Peer-to-peer audio and video streaming are one of the central use
        cases for WebRTC: <code>getUserMedia</code> API enables the application
        to acquire the media streams, and the built-in audio and video engines
        handle the optimization, error recovery, and synchronization between
        streams. However, it is important to keep in mind that even with
        aggressive optimization and compression, audio and video delivery are
        still likely to be constrained by latency and bandwidth:

        </p><ul>
          <li>
            <p>An HD quality streams requires 1–2 Mbps of bandwidth; see
            <a data-type="xref" href="#audio-opus-and-video-vp8-bitrates">Audio
            (OPUS) and Video (VP8) Bitrates</a>.

          </p></li><li>
            <p>The global average bandwidth as of Q1 2013 is just 3.1 Mbps; see
            <a data-type="xref" href="https://hpbn.co/primer-on-latency-and-bandwidth/#global-bandwidth-table">Table&nbsp;1-2</a>.

          </p></li><li>
            <p>An HD stream requires, at a minimum, a 3.5G+ connection; see
            <a data-type="xref" href="https://hpbn.co/mobile-networks/#cellular-performance">Table&nbsp;7-2</a>.
        </p></li></ul>

        <p>The good news is that the average bandwidth capacity is continuing
        to grow around the world: users are switching to broadband, and 3.5G+
        and 4G adoption is ramping up. However, even with optimistic growth
        projections, while HD streaming is now becoming viable, it is not a
        guarantee! Similarly, latency is a perennial problem, especially for
        real-time delivery, and doubly so for mobile clients. 4G will
        definitely help, but 3G networks are not going away anytime soon
        either.

        </p><div data-type="note" id="id-KPCNH8hzia">
          <p>To complicate matters further, the connections offered by most
          ISPs and mobile carriers are not symmetric: most users have
          significantly higher downlink throughput than uplink throughput. In
          fact, 10-to-1 relationships are not uncommon—e.g., 10 Mbps down, 1
          Mbps up.
        </p></div>

        <p>The net result is that you should not be surprised to see a single,
        peer-to-peer audio and video stream saturate a significant amount of
        users’ bandwidth, especially for mobile clients. Thinking of providing
        a multiparty stream? You will likely need to do some careful planning
        for the amount of available bandwidth:

        </p><ul>
          <li>
            <p>A mobile client may be able to download an HD-quality stream (1
            Mbps+) but may need to send a lower-quality stream due to lower
            uplink throughput; different parties can stream at different
            bitrates.

          </p></li><li>
            <p>The audio and video streams may need to share bandwidth with
            other applications and data transfers—e.g., one or more DataChannel
            sessions.

          </p></li><li>
            <p>Bandwidth and latency are always changing regardless of the type
            of connectivity—wired or wireless—or the generation of the network,
            and the application must be able to adapt to these conditions.
        </p></li></ul>

        <p>The good news is that the WebRTC audio and video engines work
        together with the underlying network transport to probe the available
        bandwidth and optimize delivery of the media streams. However,
        DataChannel transfers require additional application logic: the
        application must monitor the amount of buffered data and be ready to
        adjust as needed.

        </p><div data-type="note" id="id-RkCyTohyiZ">
          <p>When acquiring the audio and video streams, make sure to set the
          video constraints to match the use case; see <a data-type="xref" href="#acquiring-audio-and-video-with-getusermedia">Acquiring Audio
          and Video with getUserMedia</a>.
        </p></div>
      </section>

      <section>
        <h3 id="multiparty-architectures"><a href="#multiparty-architectures" class="anchor">§</a>Multiparty Architectures</h3>

        <p>A single peer-to-peer connection with bidirectional HD media streams
        can easily use up a significant fraction of users’ bandwidth. As a
        result, multiparty applications should carefully consider the
        architecture (<a data-type="xref" href="#p2p-architectures">Figure&nbsp;18-17</a>) of how the individual
        streams are aggregated and distributed between the peers.

        </p><figure id="p2p-architectures">
          <img src="c1a1361326d5c0842b287223f6ab4351.svg" alt="Figure 18-17. Distribution architecture for an N-way call">

          <figcaption>
            <span class="label">Figure 18-17.</span> Distribution architecture
            for an N-way call
          </figcaption>
        </figure>

        <p>One-to-one connections are easy to manage and deploy: the peers talk
        directly to each other and no further optimization is required.
        However, extending the same strategy to an N-way call, where each peer
        is responsible for connecting to every other party (a mesh network)
        would result in <img src="ceefbf33a84776dbdff23f70ee00dfad.svg" class="equation"> connections for each peer, and a total of <img src="635c6b163d4772ef406b47ecb2f00339.svg" class="equation"> connections! If bandwidth is at a premium, as it often is
        due to the much lower uplink speeds, then this type of architecture
        will quickly saturate most users’ links with just a few participants.

        </p><p>While mesh networks are easy to set up, they are often inefficient
        for multiparty systems. To address this, an alternative strategy is to
        use a "star" topology instead, where the individual peers connect to a
        "supernode," which is then responsible for distributing the streams to
        all connected parties. This way only one peer has to pay the cost of
        handling and distributing <img src="ceefbf33a84776dbdff23f70ee00dfad.svg" class="equation"> streams, and everyone else talks directly to the supernode.

        </p><p>A supernode can be another peer, or it can be a dedicated service
        specifically optimized for processing and distributing real-time data;
        which strategy is more appropriate depends on the context and the
        application. In the simplest case, the initiator can act as a
        supernode—simple, and it might just work. A better strategy might be to
        pick the peer with the best available throughput, but that also
        requires additional "election" and signaling mechanisms.

        </p><div data-type="note" id="id-b4CpI7Hpij">
          <p>The criteria and the process for picking the supernode is left up
          to the application, which by itself can be a big engineering
          challenge. WebRTC does not provide any infrastructure to assist in
          this process.
        </p></div>

        <p>Finally, the supernode could be a dedicated and even a third-party
        service. WebRTC enables peer-to-peer communication, but this does not
        mean that there is no room for centralized infrastructure! Individual
        peers can establish peer connections with a proxy server and still get
        the benefit of both the WebRTC transport infrastructure and the
        additional services offered by the server.

        </p><aside>
          <h4 id="peer-to-peer-optimization-as-a-service"><a href="#peer-to-peer-optimization-as-a-service" class="anchor">§</a>Peer-to-Peer Optimization as a Service</h4>

          <p>Many existing videoconferencing solutions (e.g., Google’s
          Hangouts) rely on "proxy servers" to aggregate the individual media
          streams, composite them, and then distribute the optimized versions
          to all the connected parties. Delivering a single stream reduces the
          amount of bandwidth and the amount of CPU and GPU resources required
          by each peer; each client sees only one stream instead of <img src="ceefbf33a84776dbdff23f70ee00dfad.svg" class="equation">!

          </p><p>Similarly, a game server can aggregate updates from all the
          players and filter and distribute only the necessary updates; e.g.,
          it won’t send updates for players that are out of view or otherwise
          don’t affect the other player.

          </p><p>Two-party streaming is simple and efficient to deploy, whereas
          multiparty architectures require a lot more thought and planning. As
          much as WebRTC is about enabling direct peer-to-peer communication,
          it is also a catalyst for a wide variety of services, both commercial
          and open source, that will help make it more efficient and
          feature-rich.
        </p></aside>
      </section>

      <section>
        <h3 id="infrastructure-and-capacity-planning"><a href="#infrastructure-and-capacity-planning" class="anchor">§</a>Infrastructure and Capacity Planning</h3>

        <p>In addition to planning and anticipating the bandwidth requirements
        of individual peer connections, every WebRTC application will require
        some centralized infrastructure for signaling, NAT and firewall
        traversal, identity verification, and other additional services offered
        by the application.

        </p><p>WebRTC defers all signaling to the application, which means that the
        application must at a minimum provide the ability to send and receive
        messages to the other peer. The volume of signaling data sent will vary
        by the number of users, the protocol, encoding of the data, and
        frequency of updates. Similarly the latency of the signaling service
        will have a great impact on the "call setup" time and other signaling
        exchanges.

        </p><ul>
          <li>
            <p>Use a low-latency transport, such as WebSocket or SSE with XHR.

          </p></li><li>
            <p>Estimate and provision sufficient capacity to handle the
            necessary signaling rate for all users of your application.

          </p></li><li>
            <p>Optionally, once the peer connection is established, the peers
            can switch to DataChannel for signaling. This can help offload the
            amount of signaling traffic that must be handled by the central
            server and also reduce latency for signaling communication.
        </p></li></ul>

        <p>Due to the prevalence of NATs and firewalls, most WebRTC
        applications will require a STUN server to perform the necessary IP
        lookups to establish the peer-to-peer connection. The good news is that
        the STUN server is used only for connection setup, but nonetheless, it
        must speak the STUN protocol and be provisioned to handle the necessary
        query load.

        </p><ul>
          <li>
            <p>Unless the WebRTC application is specifically designed to be
            used within the same internal network, always provide a STUN server
            when initiating the RTCPeerConnection object; otherwise, most
            connections will simply fail.

          </p></li><li>
            <p>Unlike the signaling server, which can use any protocol, the
            STUN server must respond to, well, STUN requests. You will need a
            public server or will have to provision your own; <em>stund</em> is
            a popular open source implementation.
        </p></li></ul>

        <p>Even with STUN in place, 8%–10% of peer-to-peer connections will
        likely fail due to the peculiarities of their network policies. For
        example, a network administrator could block UDP outright for all the
        users on the network; see <a data-type="xref" href="https://hpbn.co/building-blocks-of-udp/#stun-and-turn-in-practice">STUN and TURN in
        Practice</a>. As a result, to deliver a reliable experience, the
        application may also need a TURN server to relay the data between the
        peers.

        </p><ul>
          <li>
            <p>Relaying peer connections is suboptimal: there is an extra
            network hop, and with each stream streaming at 1+ Mbps, it is easy
            to saturate the capacity of any service. As a result, TURN is
            always used as a last resort and requires careful capacity planning
            by the application.
        </p></li></ul>

        <p>Multiparty services may require centralized infrastructure to help
        optimize the delivery of many streams and provide additional services
        as part of the RTC experience. In some ways, multiparty gateways serve
        the same role as TURN but in this case for different reasons. Having
        said that, unlike TURN servers, which act as simple packet proxies, a
        "smart proxy" may require significantly more CPU and GPU resources to
        process each individual stream prior to forwarding the final output to
        each connected party.
      </p></section>

      <section>
        <h3 id="data-efficiency-and-compression"><a href="#data-efficiency-and-compression" class="anchor">§</a>Data Efficiency
        and Compression</h3>

        <p>WebRTC audio and video engines will dynamically adjust the bitrate
        of the media streams to match the conditions of the network link
        between the peers. The application can set and update the media
        constraints (e.g., video resolution, framerate, and so on), and the
        engines do the rest—this part is easy.

        </p><p>Unfortunately, the same can’t be said for DataChannel, which is
        designed to transport arbitrary application data. Similar to WebSocket,
        the DataChannel API will accept binary and UTF-8–encoded application
        data, but it does not apply any further processing to reduce the size
        of transferred data: it is the responsibility of the WebRTC application
        to optimize the binary payloads and compress the UTF-8 content.

        </p><p>Further, unlike WebSocket, which runs on top of a reliable and
        in-order transport, WebRTC applications must account for both the extra
        overhead incurred by the UDP, DTLS, and SCTP protocols and the
        peculiarities of data delivery over a partially reliable transport; see
        <a data-type="xref" href="#partially-reliable-delivery-and-message-size">Partially Reliable
        Delivery and Message Size</a>.

        </p><div data-type="note" id="id-b4CmHOIpij">
          <p>WebSocket offers a protocol extension that provides automatic
          compression of transferred data. Alas, there is no equivalent for
          WebRTC; all messages are transferred as they are provided by the
          application.
        </p></div>
      </section>
    </section>

    <section>
      <h2 id="performance-checklist"><a href="#performance-checklist" class="anchor">§</a>Performance Checklist</h2>

      <p>Peer-to-peer architectures pose their own unique set of performance
      challenges for the application. Direct, one-to-one communication is
      relatively straightforward, but things get much more complex when more
      than two parties are involved, at least as far as performance is
      concerned. A short list of criteria to put on the agenda:

      </p><dl>
        <dt>Signaling service

        </dt><dd>
          <ul>
            <li>
              <p>Use a low-latency transport.

            </p></li><li>
              <p>Provision sufficient capacity.

            </p></li><li>
              <p>Consider using signaling over DataChannel once connection is
              established.
          </p></li></ul>

        </dd><dt>Firewall and NAT traversal

        </dt><dd>
          <ul>
            <li>
              <p>Provide a STUN server when initiating RTCPeerConnection.

            </p></li><li>
              <p>Use trickle ICE whenever possible—more signaling, but faster
              setup.

            </p></li><li>
              <p>Provide a TURN server for relaying failed peer-to-peer
              connections.

            </p></li><li>
              <p>Anticipate and provision sufficient capacity for TURN relays.
          </p></li></ul>

        </dd><dt>Data distribution

        </dt><dd>
          <ul>
            <li>
              <p>Consider using a supernode or a dedicated intermediary for
              large multiparty communication.

            </p></li><li>
              <p>Consider optimizing the received data on the intermediary
              prior to forwarding it to the other peers.
          </p></li></ul>

        </dd><dt>Data efficiency

        </dt><dd>
          <ul>
            <li>
              <p>Specify appropriate media constraints for voice and video
              streams.

            </p></li><li>
              <p>Optimize binary payloads sent over DataChannel.

            </p></li><li>
              <p>Consider compressing UTF-8 content sent over DataChannel.

            </p></li><li>
              <p>Monitor the amount of buffered data on the DataChannel and
              adapt to changes in the conditions of the network link.
          </p></li></ul>

        </dd><dt>Delivery and reliability

        </dt><dd>
          <ul>
            <li>
              <p>Use out-of-order delivery to avoid head-of-line blocking.

            </p></li><li>
              <p>If in-order delivery is used, minimize the message size to
              reduce the impact of head-of-line blocking.

            </p></li><li>
              <p>Send small messages (&lt; 1,150 bytes) to minimize the impact
              of packet loss on fragmented application messages.

            </p></li><li>
              <p>Set appropriate retransmission count and timeouts for
              partially reliable delivery. The "right" settings depend on
              message size, type of application data, and latency between the
              peers.
          </p></li></ul>
      </dd></dl>
    </section>
  </article>

  <footer>
    <div id="toast" style="display: none;">Content updated. Book is now available offline!</div>

    <p><a href="https://hpbn.co/#toc"><em>« Back to the Table of Contents</em></a>

    </p><p class="legal">Copyright © 2013 <a href="https://www.igvita.com/" rel="me">Ilya Grigorik</a>. Published by O'Reilly Media, Inc. Licensed under
    <a href="https://creativecommons.org/licenses/by-nc-nd/4.0/">CC BY-NC-ND
    4.0</a>.
  </p></footer>

</body>
</html>
